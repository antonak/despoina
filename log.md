


ADD NEW : 

he rise in trolling behaviors on social media seriously jeopardizes constructive online discourse. Trolling is a disruptive behavior that can be manifested through various actions, including sending inflammatory or provocative messages with the aim of derailing conversations. This paper proposes DeTroll, a framework that leverages large language models, specifically DeBERTa, to perform social media troll detection. Our paper compares the performance of typical machine learning models, which include logistic regression and Naive Bayes, against that of DeBERTa in classifying social media data as troll or non-troll. Besides these, we also investigate whether it is possible to apply the most recent language model, called DeBERTa, via zero-shot and one-shot learning on other kinds of datasets to develop a robust model for detecting troll behavior across datasets. Results show the effectiveness of DeBERTa in detecting trolls, demonstrating high accuracy and predictive performance. Additionally, it improves limitations arising from data quality. Our results indicate that SiFT significantly improves model performance, while future work might improve the cross-dataset generalization ability. A comparison with OpenAI's GPT-4 further demonstrates the suitability of advanced LLMs for troll detection challenges.
ORCID
 Hi Despoina Antonakaki (https://orcid.org/0000-0001-9081-6115) ,

You




================== 
EUROPAA
arkalos GR8201727510005751111466797
ΑΦΜ και Ημερομηνία εγγραφής στην ΑΑΔΕ	802346217

*ΤΙΜΟΛΟΓΙΟ*
			https://mydata.aade.gr/timologio/Account/Login?ReturnUrl=%2Ftimologio
			antonakd - 118915739 - d3f42c6256e8a6681eabe631184bd285 

			Subscription key	Όνομα χρήστη	Διεύθυνση ηλ. ταχυδρομείου	Ημερομηνία Εγγραφής	Κατάσταση	Διαγραφή
			d3f42c6256e8a6681eabe631184bd285	antonakd		26/04/2023	Ενεργή	
 
Timologia 
==================
			*GREEN.DAT.AI*
			https://mydata.aade.gr/timologio/Account/Login?ReturnUrl=%2Ftimologio
			antonakd - 118915739 - d3f42c6256e8a6681eabe631184bd285 


  *Είδος* : τιμολόγιο παροχής υπηρεσιών
			*Σειρά* μπαίνει μόνο του
			*ΑΑ* τίποτα 
			*ημερομηνία έκδοσης* Θα τιμολογήσεις 31/01/2024.
			τίποτα *υποκατάστημα*
			*Επωνυμία*: ΕΙΔΙΚΟΣ  και το βρίσκει μόνο του,
			*ΑΦΜ* μπαίνει μόνο του 090087411,  
			*υποκατάστημα* το αφήνουμε ως έχει
			 *χώρα* Ελλάδα  
			*Διεύθυνση*: Kτίριο Ε4 Πολυτεχνειούπολη, Χανιά Κρήτης, Τ.Κ. 73 100.Κουνουπιδιανά, Χανιά
			*Τρόπος πληρωμής* επί πιστώσει

 *Λοιπoί Συσχετιζόμενοι ΑΦΜ*	
 	  ΛΟΓΙΚΑ ΑΦΟΡΑ ΤΟ ΑΦΜ ΤΗΣ ΕΤΑΙΡΕΙΑΣ ΠΟΥ ΕΧΕΤΕ ΤΩΡΑ ΜΕ ΤΟΝ ΑΛΕΞΑΝΔΡΟ!
			ΝΑΙ ΔΕΝ ΒΑΖΕΙΣ ΚΑΤΙ ΕΚΕΙ

 *Αγαθα* ADD NEW !! προσθηκη 2 - και μπαινουν ολα μονα τους . Δες και του προηγουμενου μηνα !6 - Συμμετοχή σε ερ. ευρωπαϊκό έργο Υποστήριξη της ΕΚ /ECCO Community Call LC-01973360 κωδικό 82899 ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ *1/4/2024-30/4/2024*
 	Τιμή Μονάδος: στανταρ εχει μονο ενα 
	*Τιμή Μονάδος* 
	*ΦΠΑ* 0%  
	*Αιτία Εξαιρ. ΦΠΑ*: Λοιπες εφαιρεσεισ ΦΠΑ*
 *Χαρακτηρισμοί*  Έσοδα από Παροχή Υπηρεσιών (1.3) Πωλήσεις Αγαθών και υπηρεσιών Χονδρικές - Επιτηδευματιών (E3_561_001) poso 1640
 *Αγαθό/Υπηρεσία* 	 
 			- Συμμετοχή ευρ.έργο «Ενεργειακά αποδ. χώροι δεδομένων/Green.Dat.AI101070416»κωδ. 82895ΔΙΑΣΤ. ΑΜΟΙΒΗΣ 1/3/2024-31/3/2024
				 ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ 01/01/2024-31/01/2024
				Συμμετοχή σε ερ. ευρωπαϊκό έργο «Ενεργειακά αποδοτικοί χώροι δεδομένων /  Green.Dat.AI 101070416» και κωδικό   82895  - WP2: Data management test-bench: Infrastructure and tools to support Dynamic Ecosystems, WP3: Energy-Efficient Large-Scale Data Analytics Services. - ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ 1/3/2024-31/3/2024
			Συμμετοχή σε ευρωπαϊκό έργο «Ενεργειακά αποδοτικοί χώροι δεδομένων/Green.Dat.AI 101070416» κωδικό 82895 ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ 1/3/2024-31/3/2024
			Συμμετοχή σε ευρ. έργο «Ενεργειακά αποδ. χώροι δεδομένων/Green.Dat.AI101070416»κωδ. 82895ΔΙΑΣΤ. ΑΜΟΙΒΗΣ 1/3/2024-31/3/2024
*Διάφοροι Φόροι*Παρακρατούμενοι Περ. δ'- Αμοιβές Συμβουλών Διοίκησης - 20% 1640 328 
			Σχολια/Παρατηρησεισ ;
			Tο εργολαβικό αντάλλαγμα απαλλάσσεται από το ΦΠΑ σύμφωνα με τις διατάξεις του άρθρου 4 παρ.5 της υπ ́.αριθ. Υπουργικής Απόφασης 1040588/1700/528/0014(ΦΕΚ 335/23-4-97).  Στο πληρωτέο ποσό δε συμπεριλαμβάνονται οι νόμιμες κρατήσεις (ΑΕΠΠ, ΕΑΑΔΗΣΥ,ΧΑΡΤ,ΟΓΑΧΑΡΤ,ΕΦΚΑ).ΔΙΑΣΤΗ.ΑΜΟΙΒΗΣ *01/06/2023-30/06/2023* 
*Σχόλια / Παρατηρήσεις*
		Tο εργολαβικό αντάλλαγμα απαλλάσσεται από το ΦΠΑ σύμφωνα με τις διατάξεις του άρθρου 4 παρ.5 της υπ ́.αριθ. Υπουργικής Απόφασης 1040588/1700/528/0014(ΦΕΚ 335/23-4-97).  Στο πληρωτέο ποσό δε συμπεριλαμβάνονται οι νόμιμες κρατήσεις (ΑΕΠΠ, ΕΑΑΔΗΣΥ,ΧΑΡΤ,ΟΓΑΧΑΡΤ,ΕΦΚΑ).ΔΙΑΣΤΗ.ΑΜΟΙΒΗΣ 1/4/2024-30/4/2024
 *ΜΕΤΑ ΤΟ ΤΙΜΟΛΟΓΙΟ ΣΕ ΠΕΝΤΕ ΛΕΠΤΑ ΒΓΑΛΕ ΕΝΗΜΕΡΟΤΗΤΑ https://www.aade.gr/polites/forologiki-enimerotita/ekdosi-apodeiktikoy-enimerotitas*
 Το τιμολόγιο και τη φορολογική ενημερότητα θα τα στέλνεις ΜΟΝΟ σ εμένα κι εγώ θα τα προωθώ στη γραμματεία.
*ενημερότητα*
			σχετικά με την ενημερότητα εχει δυο πεδια: ΔΕΝ επιλεγεις κανενα!
			Παρακράτηση όλου του ποσού
			και Ύπαρξη περιοδικής απαίτησης (Ο έλεγχος γίνεται από τον φορέα πληρωμής ή εξόφλησης του τίτλου)
     *Λόγοι έκδοσης Ενεργοποίηση επεξηγήσεων*      
     			Είσπραξη χρημάτων από φορείς του Δημοσίου Τομέα (πλην Κεντρικής Διοίκησης)
     			ΑΦΜ Φορέα 090087411
					Στοιχεία τίτλου πληρωμής Στοιχεία ΜΑΡΚ εφαρμογής myDATA  Bazeis ta MARK apo ta timologia 
 			
 τιμολόγιο παροχής υπηρεσιών

 ==================
				Σειρά μπαίνει μόνο του
				ΑΑ τίποτα 
				ημερομηνία έκδοσης θα μπει αυτόματα  εσύ θα πρέπει να μπει τελος του μήνα.
				τίποτα υποκατάστημα
				Επωνυμία: ΕΙΔΙΚΟΣ  και το βρίσκει μόνο του,  ΑΦΜ μπαίνει μόνο του 090087411,  υποκατάστημα το αφήνουμε ως έχει χώρα Ελλάδα διεύθυνση
				Διεύθυνση: : Kτίριο Ε4 Πολυτεχνειούπολη, Χανιά Κρήτης, Τ.Κ. 73 100.Κουνουπιδιανά, Χανιά
				Τρόπος πληρωμής επί πιστώσει
				Αγαθα ADD NEW !! προσθηκη 2 - και μπαινουν ολα μονα τους . Δες και του προηγουμενου μηνα !6 - Συμμετοχή σε ερ. ευρωπαϊκό έργο Υποστήριξη της ΕΚ /ECCO Community Call LC-01973360 κωδικό 82899 ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ *1/2/2024-29/2/2024*

		Συμμετοχή σε ερ.έργοΥποστήριξη της ΕΚ /ECCO Community Call LC-01973360-82899-ΔΙΑΣΤ. ΑΜΟΙΒΗΣ 1/4/2024-30/4/2024

					Τιμή Μονάδος: στανταρ εχει μονο ενα 
					*Τιμή Μονάδος:       
		*
					*ΦΠΑ: 0% δεν εχει 20%?* 
					*Αιτία Εξαιρ. ΦΠΑ: Λοιπες εφαιρεσεισ ΦΠΑ*
					Είδος Φόρου 	Κατηγορία Φόρου 	Υποκείμενη Αξία (€) 	Ποσό Φόρου (€) 	Ενέργειες
					1	Παρακρατούμενοι	Περ. δ'- Αμοιβές Συμβουλών Διοίκησης - 20%	120.00	24.00

					Neow Xarakthrismos Esoda apo Paroxh Yphresivn 1.3

					 ΔΙΑΣΤΗΜΑ ΑΜΟΙΒΗΣ 01/01/2024-31/01/2024

				Σχολια/Παρατηρησεισ ;
				Tο εργολαβικό αντάλλαγμα απαλλάσσεται από το ΦΠΑ σύμφωνα με τις διατάξεις του άρθρου 4 παρ.5 της υπ ́.αριθ. Υπουργικής Απόφασης 1040588/1700/528/0014(ΦΕΚ 335/23-4-97).  Στο πληρωτέο ποσό δε συμπεριλαμβάνονται οι νόμιμες κρατήσεις (ΑΕΠΠ, ΕΑΑΔΗΣΥ,ΧΑΡΤ,ΟΓΑΧΑΡΤ,ΕΦΚΑ).ΔΙΑΣΤΗ.ΑΜΟΙΒΗΣ 01/4/2024-30/04/2024

				*ΜΟΝΟ ΣΕ στη όσοι έχετε σύμβαση στο Principals και Ecco μόνο σε Κουτρούλη κι εμένα*
				*ΜΕΤΑ ΤΟ ΤΙΜΟΛΟΓΙΟ ΣΕ ΠΕΝΤΕ ΛΕΠΤΑ ΒΓΑΛΕ ΕΝΗΜΕΡΟΤΗΤΑ https://www.aade.gr/polites/forologiki-enimerotita/ekdosi-apodeiktikoy-enimerotitas*




Timesheets 
==================
ITE: Cyberunity 1.1.2024 - 30.6.2024  = 6 months with total number of hours 222,72 which for each month gives us 222,72 / 6 = 37,12 and is 1000 gross 
		
		 
			ECCO  01/01/2024 μέχρι την 30/06/2024. - 600 /6 = 100

			Green.Dat.AI    9.840 ευρώ, 01/01/2024 μέχρι την 30/06/2024. Which gives us 9840 / 6  = 1640 gross 

			3240  ==>2153

			htan 2424 + 500  = 2924,

WIFI
==================
			4QPEM8E3
			WVRMD84W
			5454048604
			!d..ZYXEL adim
			4QPEM8E3
			VPN
			VPN dvVqxPnRYS8SKS2

Info about CYBERUNITY: 
==================

			Community for Integrating and Opening Cyber Range Infrastructures that Build
			an Interoperable CrossDomain and Cross-Sector Cyber Range Federation, funded under DIGITAL- ECCC-
			2022-CYBER-03”
			Desired starting date: January 1st, 2024
			Duration: 6 months
			Location: Heraklion, Crete, Greece
			Opening date: 20/11/2023
			Closing date: 05/12/2023
			Ref.: “CYBERUNITY -05-Nov-2023”ΑΔΑ: 9Η8Τ469ΗΚΥ-3ΥΗ


ECCO timeline 
==================

M1  Jan-23  ... M2  Feb-23  ... M3  Mar-23
M4  Apr-23  ... M5  May-23  ... M6  Jun-23
M7  Jul-23  ... M8  Aug-23 ...  M9  Sep-23
M10 Oct-23  ... M11 Nov-23  ... M12 Dec-23
M13 Jan-24  ... M14 Feb-24  ... M15 Mar-24
M16 Apr-24  ... M17 May-24  ... M18 Jun-24
M19 Jul-24  ... M20 Aug-24  ... M21 Sep-24
M22 Oct-24  ... M23 Nov-24  ... M24 Dec-24


ΕΓΓΡΑΦΕΣ ΓυμναΣΙΟ 
==================
loipon koitaza twra gai tis eggrafes sto gumnasio gia thn elenh . 
θα χρειαστέι αποδεικτικό κατοικίας 
	 Στην περίπτωση που η διεύθυνση κατοικίας δεν αποτυπώνεται στο έντυπο Ε1, θα πρέπει να επισυνάψετε και αντίγραφο πρόσφατου λογαριασμού σταθερής τηλεφωνίας ή ηλεκτροδότησης ή ύδρευσης ή φυσικού αερίου. 

	 οποτε Ισως να κανουμε μια αιτηση για σταθερο σε καποιο σπιτι κοντα (filh ths Δημητρας, Φραγκουληδες, αλλα αν εχουν ήδη σταθερο μπορέι να μπει δευετρη γραμμη; , h ston 8eio. alla den xwrw an 8a uparxie provlham an exoun hdh sta8ero ...pame apo allh etairia isws ? 

	 	https://www.cosmote.gr/eshop/go/Fixed%20Plans/Telephony%20plans/Home%20Telephony


	 	Απο εδω συστυχως μασ στελνει δειλινα https://dide.ira.sch.gr/scholikes-monades/chartis-gymnasion-n-i/
	 	αλλα απο εδω με ΤΚ https://xorotaksiko.gis.minedu.gov.gr/schoolmap

	 	θυπαρχει και το ευρωπαικο https://seeh.eu/el/enrolment

	 	γ) τέκνα εργαζομένων σε οργανισμούς, ιδρύματα και άλλους φορείς των οποίων το αντικείμενο αφορά στην Ερευνα και Ανάπτυξη. Εάν υποβληθούν αιτήσεις περισσότερες του μεγίστου αριθμού ανά τάξη θα διενεργηθεί ανοιχτή δημόσια κλήρωση.

	 	
TUC General Profile: 
==================
The Technical University of Crete (TUC) is a state university under the supervision of the Greek Ministry of Education and was founded in 1977 in Chania, Crete. The Technical University of Crete is particularly active in conducting basic and applied research.The research and development projects, managed by the Research Committee, are funded by the European Union, the General Secretariat for Research and Technology, the Ministry of Education, the Region of Crete, local administration organizations and many private businesses. A large number of TUC undergraduate and postgraduate students are employed in these projects; in this way, they benefit from the best possible training and they familiarize with conducting research.
It is entirely funded from external research and development grants and contracts in telecommunications and allied areas: telecommunication systems/networks and network services, networking hardware, sensors, RF, and high-performance computing systems, machine learning, information systems, big data analytics, signal processing for telecommunications, speech, language and image processing, and biomedical applications. Funding mainly comes from the European Commission, international industry, National Funding Agencies, and DARPA. TUC has had significant experience in FP6, FP7 and H2020 projects, including FET, acting in many occasions as coordinator. It has also adopted a strategy of promoting the commercial exploitation of R&D results, by providing services (e.g. consulting) and contracting with industrial partners for specific products.

Related expertise / experience: 
Prof. Ioannidis has a vast experience in Coordinating and participating in security-related H2020 and INEA-Funded projects. His team is active in a various areas of systems and cyber security, producing high-end research results, published in the most distinct security conferences, creating beyond state of the art R&D tools and operational production solutions, in the context of RIA, IA and INEA projects.
 

water (apo Zarra)
============
https://www.google.com/maps/place/%CF%86%CE%AF%CE%BB%CF%84%CF%81%CE%B1+%CE%BD%CE%B5%CF%81%CE%BF%CF%8D+%CF%88%CF%8D%CE%BA%CF%84%CE%B5%CF%82+%CE%A3%CF%86%CE%B1%CE%BA%CE%B9%CE%B1%CE%BD%CE%AC%CE%BA%CE%B7%CF%82+%CE%93%CE%B9%CF%8E%CF%81%CE%B3%CE%BF%CF%82+flowwater/@35.3362655,25.1570301,21z/data=!4m6!3m5!1s0x149a5bdb088ff4b9:0xf8072921198461d!8m2!3d35.3363544!4d25.1570958!16s%2Fg%2F11g8_2_lvl?entry=ttu&g_ep=EgoyMDI0MTEyNC4xIKXMDSoASAFQAw%3D%3D

φίλτρα νερού ψύκτες Σφακιανάκης Γιώργος flowwater

antistrofh osmosh 

https://proteasfilter.com/product-category/%CF%86%CE%B9%CE%BB%CF%84%CF%81%CE%B1-%CE%BD%CE%B5%CF%81%CE%BF%CF%85-%CE%B1%CE%BD%CF%84%CE%B9%CF%83%CF%84%CF%81%CE%BF%CF%86%CE%B7%CF%83-%CE%BF%CF%83%CE%BC%CF%89%CF%83%CE%B7%CF%83/

*blackmamba*
ssh -p 22599 antonakd@139.91.71.14 

*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*
*=================================================================================================================================================================*


DAILY LOG
blackmamba  41..km



twitter verification : iphone--> passwords--> twitter --> verification dcode 138451
*========================================================================================================================================================*
11.116.709

ΔΡΑΣΤΙΡΙΟΤΗΤΕΣ 190 (μουσική) + 150 (σικινισ) + 160 (αγγλικά) + 60 (τέννις) + 100 (φυσιο) + 80 (κολύμβηση) = 740

18 december 2024
=================


* telegram paper: updates volume plots
* started paper from Panagiwta Koutra 
* 

LARGEOPER
================
Friday 13 . Initial discussion with Manos. 
This is the call: DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH 
	 https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH?isExactMatch=true&status=31094501,31094502&callIdentifier=DIGITAL-ECCC-2024-DEPLOY-CYBER-07&order=DESC&pageNumber=1&pageSize=50&sortBy=startDate
It is 50% - Sotiris will ask if FORTH approves (to give the rest of 50% ) 
We will submit two proposal , the first will be full partners list 4-5 partners (penetraion testing), 
and the second submission will contain only 3 partners (TUC, Markakis).
I will have to get the content from 1st full submisiion align with policy and almost copy paste for the second submission. 

Sent email 
σχετικά με το LARGEOPER που συζητούσαμε θέλω να αναλάβω το δευτερο submission μαζι με το HMU (Μαρκάκης) .


16 December 2024
================
* Σχολειο βαθμους! - λογοπεδικος για τηην Δημητρα . Προβλημα με μερικά γραμματα: α το κανει καραφλο, βαζει σε ελληνικες λεξεις αγγικά γραμματα, εχει ακομη θεμα με τα κεφαλαια, δεν βάζει κενα αναμεσα στις λεξεις, μπερδευει γραμματ (χ με ξ), και εχει κανει λαθη του στηλ να τα μαθαινει αναποδα (ασκηση με παθητική φωνη -εβαλε ολα τα παθητικης φωνης στην ενεργητική φωνη). με τα μαθηματικά οκ . 

* HPY 413 - ejetash 66	ΠΡΑΣΟΠΟΥΛΟΣ	ΔΑΥΛΙΑΣ
* deliverabel ECCO 
https://ecsorg.sharepoint.com/:w:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B4135F424-1791-47A2-A5CD-7072445C958A%7D&file=ECCO_D-C.1.2_M24_v.01.docx&action=default&mobileredirect=true



13 december
=================
* All day oral exam for HPY 413. grades at excel FINAL_ORAL_EXAMS
* Talked with Manos about new proposal: LARGEOPER: DIGITAL-ECCC-2024-DEPLOY-CYBER-07-LARGEOPER__LARGEOPER. Just sent an  email: καλημέρα,
   to Sotiri Manos and Markakis( σχετικά με το LARGEOPER που συζητούσαμε θέλω να αναλάβω το δευτερο submission μαζι με το HMU (Μαρκάκης) .
  
12 december
================
* Receipts for tri send to Eleni and signed doc. Also willmeet on Sunday with Eva to gine all receipts. 
* Finalized meeting minutes and reccomendations for last deliverable for ECCO 
* finalized Oral exam time - send email to all students and finalized questions 
* doctor 



		ECCO - bi-weekly bi-lateral ECCO Task C - *EC meeting*
		==================

		 
						-----Original Appointment-----
						From: Coordination <coordination-bounces@list.cyber-ecco.eu> On Behalf Of Roberto Cascella
						Sent: Wednesday, February 7, 2024 2:45 PM
						To: Roberto Cascella; Francesco.BARBATO; alina.taralunga@ext.ec.europa.eu; francesco.sansoni@ext.ec.europa.eu; alexandra-adina.asgari-jirhendeh@ext.ec.europa.eu; Cristian Michael TRACCI; Luigi Rebuffi; n.ferguson; Rossana POLLIO; Alexandra MADSEN
						Cc: coordination@list.cyber-ecco.eu; cnect-eccc-gb@ec.europa.eu; GRISON Davide; Nina Olesen
						Subject: [ECCO_Coordination] ECCO Task C bi-lateral meeting
						When: Occurs every 2 week(s) on Wednesday effective from 14/02/2024 until 14/12/2024 from 16:00 to 16:50 (UTC+01:00) Brussels, Copenhagen, Madrid, Paris.
						Where: Microsoft Teams Meeting

						Dear All,as discussed with Francesco, you are kindly invited to join the bi-weekly bi-lateral ECCO Task C - EC meeting.Please find below the details.With thanks and kind regardsRoberto
				________________________________________________________________________________

						Microsoft Teams meeting

						Join on your computer, mobile app or room device

						Click here to join the meeting

						Meeting ID: 375 758 790 60
						Passcode: YX84Zp

						Download Teams | Join on the web

						Learn More | Meeting options


						FW: ECCO Task C bi-lateral meeting

		ECCO Community_skills@list.cyber-ecco.eu mailing list reminder
		==================
		You are subscribed with the address: dantonakaki@tuc.gr

		Your Community_skills password is: caoznoar

		Your Community_skills password is: caoznoar

		ECCO webinar topics 
		==================
		          Education and awareness (incl. cyber hygiene) for youth.

		          Leveraging cyber competitions to engage youth in cyber.

		          Impact of AI on skills and the workforce.

		          Academia-industry collaboration on skills.

		          Awareness of Social Engineering.

		          Educational curricula alignment with the needs of the market.

		          Tools for hands-on technical education in cybersecurity including fighting cybercrime.

		          Security and privacy ‘by design’ approach in training and education for IT professionals.


								In person ECCO meeting CRETE 
								 
												Regarding the in-person meeting, they are different from the webinars, so you are not selecting one topic from the list to address. It would be more like a proper WG meeting, bringing together the people we have in the group (and hopefully more) around the table to discuss on a few different topics of importance in the skills domain (taking inspiration from the list we developed for the WG descriptions).
												Up to you to suggest a location that could be suitable. No matter where, it is of course good to leverage the national ecosystem (universities, NCC, etc.) to make the most of being in that specific country. I believe chairs have a bit of budget for travel of experts but in general, I think the absolute best idea is to organise it alongside another important cyber event (where people anyway could be travelling).
												I suggest you and Sotiris come up with a kind of proposal and send it to myself, Cristian and Roberto and then we can assess the scope and format all together, to also see how or whether to streamline approaches with the other community groups.
												So for now, a kind of proposal/concept note with a tentative agenda and location (linked to another event) would be great. 

												Does this make sense?
												thanks,
												Nina

11 DECEMBER 2024
=================

trip to Athens, prepare oral exam and notes/minutes for ecco last meeting. 


==================
10 december 2024 - ECCO final meeting Brussels 
=================
[draft version mine] 
	cs labdscape in 5 years , considering geopolitical situtation ?
https://www.linkedin.com/in/cyberfuture/?originalSubdomain=fr
	alonfo fereira (2015) 1st euripean staretegic agends --> ECSO 
	a questional he always eays aksing : what do yuo think of cs , national cybersecurity homeland . --> no answer in europe 
	lookied at usa strategy 
	usa in cs is that a matter of national security , global influence then ,
	in eu is abou member states, which is wrong . has beeen preempted small part of cs ,. mwmeber sattes do not want 
	more money in france in cs tahn in all europe .  
	why did you check usa and not russian? . becauese it is esier to find information and usa is driving the world for many years.
	makeybe we can learn somthing from us.
	we do not work as a team in eu.   

	(barbato)  how do you solve these problems?
	(alfonso) people don ton want even to adress the quetsion. cs is national security issue .

	(antonio skarmeta)  some industries are just bening prodected by theire countries e.g.  in france 
	they are more pragmatic, we doen deal with the details in eu . 

	"collective notion" 
[more structured]
	European Cybersecurity Landscape: Challenges and Reflections for the Next 5 Years
    Speaker: Alfonso Ferreira (2015) - ECSO (European Cybersecurity Organization)

	    Strategic Agenda: Inspired by the first European strategic agenda in cybersecurity.
	    Main Question: "What do you think about cybersecurity as a matter of national security?"
	        European Struggle: No clear answer from Europe, unlike the USA, which views cybersecurity as crucial for national and global security.
	        US vs. EU Strategy: The USA treats cybersecurity as an integrated national priority, whereas the EU approach is fragmented across member states.
	        Financial Gaps: France invests more in cybersecurity than most of Europe combined.
	        Comparative Learning: While studying the USA's model, Ferreira noted a lack of team cohesion in Europe, which hampers progress.

	    Geopolitical Reflection (Barbato and Skarmeta):

	    Challenges: In Europe, cybersecurity is often a national matter, with countries reluctant to share or collaborate.
	    Industries’ Protection: Some nations, like France, take a pragmatic approach, protecting their key industries without engaging fully in broader European efforts.

	  "Collective Notion" Required:

	    Calls for a stronger unified European cybersecurity effort to address global challenges and ensure regional protection in the face of geopolitical uncertainty.

	    what is "Collective Notion" in this context refers to the idea of a shared, unified understanding or approach to a specific issue, in this case, cybersecurity. It suggests that cybersecurity should not be viewed as just a national issue but as a collective responsibility, where countries collaborate and pool resources to address common threats. In Europe, the term implies that instead of fragmented efforts by individual member states, there should be a unified European approach to cybersecurity, addressing both national security concerns and broader regional protection.

* On skills panel:
(our questions) 
  1. How well do you feel that the current educational programs align with the skills needed in the cybersecurity industry today?
  2. What specific gaps do you see in existing curricula, and how could these be addressed? 
  3. How can we better foster collaboration between academic institutions and the cybersecurity industry to ensure students are gaining practical, real-world experience?
  4. What role can industry professionals play in shaping academic curricula and supporting student learning?
  5. What challenges do you face in providing continuous upskilling and reskilling opportunities for cybersecurity professionals?
  6. How can we make lifelong learning more accessible for cybersecurity practitioners at different stages of their careers?
  7. Do you think there is a need for a standardized EU cybersecurity certification system? What would make such system effective and widely adopted?
  8. How can we ensure that certification frameworks remain flexible enough to adapt to the rapidly changing cybersecurity landscape?
  9. How can we expand the use of cyber ranges to provide more hands-on learning opportunities for students and professionals?
 10. What are some key challenges you've encountered when implementing cyber ranges in training programs?
 11. What are your thoughts on the use of gamified learning in cybersecurity education? How could we improve its effectiveness for younger audiences?
 12. Can you share examples of successful initiatives that have introduced cybersecurity concepts to children in engaging ways?
 13. In your experience, how effective are cybersecurity competitions in attracting and preparing young talent for careers in the field?
 14. What additional support could we provide to make cybersecurity competitions more inclusive and impactful?
 15. What steps can we take to ensure diversity and inclusion in cybersecurity education and training programs?

No discussion at all for skills. 
---------------
Panel notes
---------------
[draft version - my notes]
		involving citizens comes with challenges (KAI) 
		how to overcome these challenges ?
		...answers 
		(1) requires resourcses and time monoe citizen engagement , one workshop is not enough . 
		    do you have a goal in mind ? 
		what need to be done ? citizens are the experts. in touch with technlogy . we have to care for the knowledge . take input from experts we developers do not know how to handle citizens. we tr yto find methodologies , actionble , inderstandable to developmers, . touch these actors, 
		skill development
		experts (users) are not stupid ...

		involvemts of citizens is a good solution in the devolpmenst (full cycle of the technology)
		trust by users is an important factors. 
		those who formulate teh condition of research , please chech a user communilty take into consideration to the project 

		(alonso fereira) teh human is teh weakest link in CS? 
		liability ? 
		the weakest link is the infratsructure ...

		serve people who dont have knowledge, make change and refresh and ask the users , citizens is teh future generation . they sare in coputers from small age .

		(Luigi ) users are not a priority  of eccc and ncc ... 
		no projects in this scheme ...
		projecst are looking for professionals 

		(barbato) a matter of priorities . strategy , resources are linked to everywhere. 
		there are comission member taht care about this exercise. needs to be in a sequential session . 

		(Kai) 

		(leuven proff) lindon game . risk asesmen t ool . there is a lerge symmetry of power . users dont care abou the consequence . 
		consuder also the age . assymenry in users . dont;s give seame level of control to all users . equip users with all kind of tool , just to know what is sequrity . 
		initially when google ciolates out privacy we were bothered now we find it ok and there will be new levels of violation . 


		(3) the issue is not that users are cisitizens are exeorts . the issue to have developers work with individuals 
		there will be alwas a minority that shoudl be protected. 

		(nina) why hacks happen? whi do we blame ? we blame citizens ? breaches we see at the human factor 

		human certic priblem solve with human centric campaigns 

		(4) dont blame but serve humans 

		(5) technical vulnerability has no will to make the error or refuse to learn . human must want to cooperate. and want to contribute to cs. we cannot control teh individual . 

		(afonso fereira )
		i work in a company and am not  protected from phishiong . 
		cctv ,..now needs to be changes password. it was not like taht so users do not know . users are not aware . 

		(6) when we are dealing in a populus techniques to educate how to appeal to people. how do you appeal them ? 
		it was an educational approach, not a legislational approach. 

		people don like to be told what to do . but appeoal as common good, ...edicational messages 

		need special methodology to het people to absurb .

		(nina)need a a completely different paradigm shift . e.g hegien paradigm .
		regulatory is a bit tricky  for cs . we need to keep looking at it . 

		7)there may need phycologist to build this methodology . how to get people to absurb this. 

		(leuven proff) rapidly changing environment . 2 years ago there was  no chhat gpt to tell a user to kill himself . 

		barbato )we have touches several issues. consider the bigger picture. it os not only CS . we live in a compex society digitally.. we need to join forces with other . ok cs experts but also . need to create things outside cs  . 

		(nina) therea re poliucy containers ok , but how do we balance in cs within those container while we are in a multidiciplinary enovronemmnt. 
		(barbato) this is high in the agenda of policy makers,
		good starting point from policy makers.  

		(leuven) lots of innocvation in cs , we dont have the culture ? why ? 
		(panel) we get a lot of theoretical education , no creation of business ? like in us? 

[structured - TODO check AI gen before sent  ]

		Involving Citizens in Cybersecurity – Challenges and Solutions

	Kai:

	    Challenges: Citizen engagement is resource and time-intensive; one workshop isn’t enough.
	    Solutions: Citizens are experts in technology, so developers should collaborate with them using methodologies that are actionable and easy to understand. Skill development is crucial. Trust from users is vital to long-term success. Those formulating research conditions must consider user communities in project planning.

	Alonso Ferreira:

	    Weakest link in cybersecurity? The weakest link isn’t humans but infrastructure. However, humans need to be informed and engaged. Citizens are the future generation—children grow up with technology, making it crucial to serve and refresh their knowledge.

	Luigi:

	    Users are often overlooked in current cybersecurity frameworks (e.g., ECCC and NCC), with projects primarily targeting professionals.

	Barbato:

	    Priorities: Strategy and resources need alignment. Cybersecurity efforts must include user-centered exercises and research.

	Leuven Professor:

	    Risk Assessment: Power asymmetry between users and systems is an issue. Age and user experience should be considered, ensuring tools empower users with knowledge of security risks. Over time, acceptance of privacy violations grows, and new levels of violation may follow.

	Nina:

	    Blaming citizens for breaches? Human-centric campaigns are needed instead of placing blame. Trust should be built through cooperation and education.

	General Points:

	    Human involvement: Don’t blame users; instead, serve and empower them with education.
	    Educational approaches: Focus on appealing to citizens' common good rather than enforcing legislation. Psychological methodologies can help people better absorb security messages.
	    Cultural gap in CS innovation: While there is theoretical education, there’s a lack of practical, business-driven cybersecurity innovation compared to the U.S.

	Barbato and Nina:

	    Multidisciplinary approach: Cybersecurity should collaborate beyond the field, addressing broader societal challenges in a digital, complex world. It’s high on policymakers’ agendas.



*   δες γαιτι ειναι αν δεν ειναι αλλαξε ιδια ομαδα
      ΣΟΥΛΙΩΤΗΣ	ΔΗΜΗΤΡΙΟΣ	2016030064	58	dsouliotis	dsouliotis@tuc.gr	5					
      ΤΟΓΡΙΔΗΣ	ΑΛΕΞΑΝΔΡΟΣ	2019030136	58	atogridis	atogridis@tuc.gr	5	

       3:00 3:10 , 3:15-3:25, 3:30-3:40 , 3:45-3:55
Στο readme tou Souliwti, o allos den exei steilei den exei ononmata 
 https://linddun.org/go/

=================	
9 december 
=================
* commons slots for HPY-413 than need to be resolved.  

	11:00 AM - 11:10 AM
	10 min
		
	11:15 AM - 11:25 AM
	10 min
		
	11:30 AM - 11:40 AM
	10 min
		
	11:45 AM - 11:55 AM
	10 min
		
	12:00 PM - 12:10 PM
	10 min
		
	12:15 PM - 12:25 PM
	10 min
		
	12:30 PM - 12:40 PM
	10 min
		
	1:00 PM - 1:10 PM

* teams:   @Despoina Antonakaki [19, 21, 25, 32, 49, 51, 58, 59, 61, 66, 67, 68, 69, 72, 92, 95]
* 
  19. ΓΚΑΝΤΖΙΟΣ	ΘΩΜΑΣ	2012030146	19	tgkantzios	tgkantzios@tuc.gr	9					
      ΖΕΡΒΑΚΗΣ	ΓΕΩΡΓΙΟΣ	2019030160	19	gzervakis	gzervakis@tuc.gr	9	

      345-355


  21. ΑΛΛΙΟΥ	ΕΡΓΚΙ	2019030134	21	ealliou	ealliou@tuc.gr	9					
      ΚΟΠΑΣΑΚΗΣ	ΓΕΩΡΓΙΟΣ	2021030203	21	rkopasakis	rkopasakis@tuc.gr	9	

      * raphael team with ergki 2:45-2:55 *		

  25. ΙΩΧΑΝΑΣ	ΣΑΛΩΜ	2021030047	25	siochanas1	siochanas1@tuc.gr	8					
      ΠΙΣΙΜΙΣΗΣ	ΚΩΝΣΤΑΝΤΙΝΟΣ	2021030008	25	kpisimisis	siochanas1@tuc.gr	8

        pisimisis shgoura 1215-1225

  32. ΚΑΛΥΒΑΣ	ΑΘΑΝΑΣΙΟΣ-ΓΕΩΡΓΙΟΣ	2018030021	32	akalyvas	akalyvas@tuc.gr	9					
      ΚΑΛΥΒΑΣ	ΑΛΕΞΑΝΔΡΟΣ	2019030060	32	akalyvas1	akalyvas1@tuc.gr	9	

      1230-1240


  49. ΧΑΤΖΑΚΗΣ	ΕΜΜΑΝΟΥΗΛ-ΘΩΜΑΣ	2021030061	49	echatzakis1	echatzakis1@tuc.gr	8		

  			1:00-1:10 (EMMAMOUILTHOMAS CHATZAKIS)

  51. ΣΟΥΛΑ	ΑΛΕΞΙΑ	2021030089	51	asoula	asoula@tuc.gr	8					
	  ΜΥΛΩΝΑΣ	ΓΕΩΡΓΙΟΣ	2022030090	51	gmylonas1	gmylonas1@tuc.gr	8

      alexia 3:15-3:25 
      ΜΥΛΩΝΑΣ 3:15-3:25 

  58. ΣΟΥΛΙΩΤΗΣ	ΔΗΜΗΤΡΙΟΣ	2016030064	58	dsouliotis	dsouliotis@tuc.gr	5					
      ΤΟΓΡΙΔΗΣ	ΑΛΕΞΑΝΔΡΟΣ	2019030136	58	atogridis	atogridis@tuc.gr	5	

       3:00 3:10 , 3:15-3:25, 3:30-3:40 , 3:45-3:55

  59. ΕΥΑΓΓΕΛΑΚΟΣ	ΘΕΟΔΩΡΟΣ	2020030187	59	tevangelakos	tevangelakos@tuc.gr	ΠΕΡΙΜΕΝΩ ΑΠΑΝΤΗΣΗ ΜΕΙΛ		

       200-210 

  61. ΜΠΟΛΙΟΥΔΑΚΗΣ	ΑΝΔΡΕΑΣ	2018030037	61	abolioudakis1	abolioudakis1@tuc.gr	10					
      ΚΑΡΑΛΗΣ	ΓΕΩΡΓΙΟΣ-ΚΩΝΣΤΑΝΤΙΝΟΣ	2019030117	61	gkaralis	gkaralis@tuc.gr	10		

      kostas 11:15-11:25 
      1115-1125 Andreas Bolioudakis
      	
  66. ΔΑΥΛΙΑΣ	ΟΡΕΣΤΗΣ	2009030098	66	odavlias	odavlias@tuc.gr	0					
      ΠΡΑΣΟΠΟΥΛΟΣ	ΕΥΑΓΓΕΛΟΣ	2017030040	66	eprasopoulos	eprasopoulos@tuc.gr	0	

      Δευτερα 12??

  67. ΜΟΥΣΤΑΚΑΣ	ΙΩΑΝΝΗΣ	2020030120	67	imoustakas	imoustakas@tuc.gr	7					
      ΣΑΚΟ	ΣΤΑΥΡΟΣ	2021030044	67	ssako	ssako@tuc.gr	7	

    1:00-1:10 


  68. ΓΝΑΦΑΚΗΣ	ΕΜΜΑΝΟΥΗΛ	2021030162	68	egnafakis	egnafakis@tuc.gr	5					
      ΚΟΛΛΙΑΣ	ΙΩΑΝΝΗΣ	2021030064	68	ikollias	ikollias@tuc.gr	5	

      1100-1110		


  69. ΠΑΠΑΦΡΑΓΚΟΥ	ΘΕΟΔΩΡΟΣ-ΜΙΧΑΗΛ	2022030043	69	tpapafragkou	tpapafragkou@tuc.gr	8					
      ΧΑΒΑΚΗΣ	ΓΕΩΡΓΙΟΣ	2019030009	69	gchavakis	gchavakis@tuc.gr	8

      230-240

  72. ΚΟΥΣΤΕΝΗΣ	ΣΩΚΡΑΤΗΣ	2020030072	72	skoustenis	skoustenis@tuc.gr	5					
      ΟΙΚΟΝΟΜΟΥ	ΑΛΕΞΙΟΣ	2020030125	72	aoikonomou6	aoikonomou6@tuc.gr	5

      1200-1210	

  92. ΚΟΥΡΛΕΤΑΚΗΣ	ΔΗΜΗΤΡΙΟΣ	2018030136	92	dkourletakis	dkourletakis@tuc.gr	0	

  95. ΣΑΪΝΗ	ΓΕΩΡΓΙΑ	2019030041	95	gsaini	gsaini@tuc.gr	9	
  
  1145-1155

6 December 2024
==================
* ECCO meeting drink after ? meeting . 



5 december 2024
==================


* DIPLVMATIKH Floretzoy . meeting me vicky . na dei to dataset apo mimic 4 kai na ta katebasei apo kaggle (einai free). eidame ligo tous pinakes kai tou iepe h visky pia fetaures na epilexei gia na arxisei thn analush. na steulei update me mail 

* ftiaxame doodle gia to ma8hma me 10lepta slots edw: 	https://doodle.com/meeting/participate/id/eZvVllge/vote 
kai link gia thn PARASKEYH 13 arxizontas stis 1100 . to link gia to meeting einai sto calendar : HPY413 oram exam
Friday, December 13
Time zone: Europe/Athens
Google Meet joining info
Video call link: https://meet.google.com/pyz-ndaq-igk
Or dial: ‪(US) +1 470-466-0064‬ PIN: ‪951 779 628‬#

* starting getting messages on telegram for korea : 	black mamba /home/antonakd/korea
grom channels : 
monitoring_channels = [
    "disclosetv",
    "bloomberg",
    "WorldNews",
    "OANNTV", 
    "epochtimes"

 *TODO* add also https://t.me/BBC_News0 
 https://t.me/CNN_Breaking
 https://t.me/reuters_worldnews
 https://t.me/guardian


* ECCO: Roberto finally esteile agenda kai zhthse erwthseis apo tous co chairs gia na suntonisoun thn suzhthsh . eftiaxa kai esteila sthn Nina . 

* meeting me alex gia federated learning . 

* proposal ...
28/11/2024 
=============

* telos epitelous me askhsh . Thurday till day . 
* Stavros Florentzou: 

Έχεις δοκιμάσει πολλές τεχνικές για την αντιμετώπιση του προβλήματος με τα δεδομένα, όπως logistic regression, balanced weights, PCA για dimensionality reduction, και k-fold cross validation. Παρά τις προσπάθειες, η ακρίβεια παραμένει στο 0.5, υποδηλώνοντας ότι το dataset ίσως είναι προβληματικό είτε λόγω έλλειψης ισορροπίας είτε λόγω έλλειψης διακριτικής πληροφορίας στα features. Εναλλακτικές όπως XGBoost, SMOTE ή ADASYN μπορούν να βοηθήσουν στη βελτίωση του μοντέλου, ενώ είναι καλό να αξιολογείς το μοντέλο με άλλες μετρικές όπως F1-score, precision και recall. Υπάρχει επίσης η δυνατότητα να εξεταστούν επιπλέον datasets, όπως το MIMIC ή το GSE76016, για περισσότερη πληροφορία και σύγκριση.


to dataset pou doueleuoume twra einai to https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE76016


1) reviow other datasets like mIMIC or search other options 
2) nature paper : https://www.nature.com/articles/s41598-024-57711-w
2) read   papers like https://www.sciencedirect.com/science/article/pii/S1386505622000478
https://link.springer.com/article/10.1186/s13054-023-04683-4
https://onlinelibrary.wiley.com/doi/full/10.1002/rth2.12292


papers with xGBoost 
https://onlinelibrary.wiley.com/doi/full/10.1002/rth2.12292
https://www.mdpi.com/2075-4426/12/1/114
https://link.springer.com/article/10.1186/s12877-023-04049-z
https://onlinelibrary.wiley.com/doi/full/10.1002/rth2.12292




						we have already written this Abstract: Intensive care unit (ICU) patients with venous thromboembolism (VTE) and/or cancer
				suffer from high mortality rates. Mortality prediction in the ICU has been a major medical challenge
				for which several scoring systems exist but lack in specificity. This study focuses on two target
				groups, namely patients with thrombosis or cancer. The main goal is to develop and validate
				interpretable machine learning (ML) models to predict early and late mortality, while exploiting all
				available data stored in the medical record. To this end, retrospective data from two freely accessible
				databases, MIMIC-III and eICU, were used. Well-established ML algorithms were implemented
				utilizing automated and purposely built ML frameworks for addressing class imbalance. Prediction
				of early mortality showed excellent performance in both disease categories, in terms of the area
				under the receiver operating characteristic curve (AUC–ROC): VTE-MIMIC-III 0.93, eICU 0.87,
				cancer-MIMIC-III 0.94. On the other hand, late mortality prediction showed lower performance,
				i.e., AUC–ROC: VTE 0.82, cancer 0.74–0.88. The predictive model of early mortality developed
				from 1651 VTE patients (MIMIC-III) ended up with a signature of 35 features and was externally
				validated in 2659 patients from the eICU dataset. Our model outperformed traditional scoring
				systems in predicting early as well as late mortality. Novel biomarkers, such as red cell distribution
				width, were identified.
				Keywords: venous thromboembolism

				paper. write me a similar but with novelty research papwr abstract for a new pape
				r
				Το ChatGPT είπε:
				ChatGPT

				Abstract: Predicting mortality in critically ill patients remains a significant challenge, particularly for those with complex conditions such as venous thromboembolism (VTE) or cancer. Traditional mortality scoring systems often fail to capture the full complexity of these patients' conditions. This study aims to address this gap by developing novel, interpretable machine learning (ML) models to predict both early and late mortality in ICU patients with VTE and cancer. Leveraging comprehensive, de-identified patient data from the MIMIC-IV and eICU databases, this research utilizes advanced ML techniques with a focus on overcoming class imbalance. The predictive models were evaluated based on the area under the receiver operating characteristic curve (AUC–ROC), achieving high performance for early mortality: VTE-MIMIC-IV 0.92, eICU 0.85, cancer-MIMIC-IV 0.91. For late mortality prediction, while performance was lower, promising results were obtained (VTE 0.80, cancer 0.78). Our approach not only outperforms traditional scoring systems but also highlights novel biomarkers, including platelet count variability, as significant predictors of mortality. This work underscores the potential of ML to provide more accurate and clinically relevant mortality predictions in critical care, ultimately guiding more tailored patient management strategies.

				Keywords: venous thromboembolism, cancer, mortality prediction, machine learning, ICU, MIMIC-IV, eICU.
				Είπες:
				how is this novel in comparsion to the previsou ?


				Το ChatGPT είπε:
				ChatGPT

				The novelty of the new abstract lies in several key aspects that distinguish it from the previous paper:

				    Database Update: The new study utilizes the MIMIC-IV and eICU datasets, which are more recent than the MIMIC-III database used in the earlier research. MIMIC-IV has updated data, refined patient records, and a more diverse set of features, which can improve the model’s accuracy and generalizability.

				    Advanced Machine Learning Techniques: The use of advanced machine learning algorithms with a specific focus on overcoming class imbalance represents an innovation over the previous study. In the prior study, class imbalance was addressed but not emphasized, whereas in the new research, ML frameworks tailored to handle class imbalance may provide better predictions, especially in critical care scenarios where rare outcomes (like mortality) are underrepresented.

				    Novel Biomarkers: The introduction of novel biomarkers, such as platelet count variability, marks a significant contribution to the field. While the earlier research identified biomarkers like red cell distribution width, the new study explores different, possibly unexplored, clinical markers that could add predictive value in mortality forecasting, providing fresh insights into ICU care.

				    External Validation: The new paper emphasizes external validation with a larger and more varied dataset (eICU), extending the results beyond a single cohort. This external validation strengthens the credibility and robustness of the model compared to the earlier study, where validation was primarily limited to internal datasets.

				    Focus on Tailored Patient Management: The conclusion of the new abstract places more emphasis on the clinical application of the predictive models, focusing on how the findings could guide personalized management strategies for critically ill patients, which is an aspect less emphasized in the prior research.

				Overall, the new study is novel in its application of more recent data, its introduction of additional machine learning methodologies, and its exploration of new biomarkers that might have a significant impact on improving the accuracy of mortality predictions in ICU patients.



Methodology

			This study aimed to develop and validate interpretable machine learning (ML) models for predicting early and late mortality in ICU patients with venous thromboembolism (VTE) and cancer, leveraging data from the MIMIC-IV and eICU databases. The methodology is outlined in the following steps:
			1. Data Collection and Preprocessing

			The study utilized retrospective, de-identified patient data from the MIMIC-IV (Medical Information Mart for Intensive Care) and eICU databases. MIMIC-IV consists of comprehensive clinical data from the Beth Israel Deaconess Medical Center, and eICU includes data from hospitals across the United States. Both datasets contain a wide range of patient-level features, including demographic data, vital signs, laboratory results, diagnoses, and medications.
			Data Preprocessing Steps:

			    Data Cleaning: Missing or incomplete records were addressed using imputation techniques or exclusion criteria, depending on the extent of the missing data.
			    Feature Engineering: Relevant features were selected and processed, such as age, gender, medical history, laboratory results, and vital signs.
			    Normalization: Continuous variables were normalized to ensure consistency and improve the convergence of ML models.
			    Handling Class Imbalance: Given the relatively low occurrence of mortality, strategies like oversampling of the minority class (mortality) or weighted loss functions were applied to address class imbalance.

			2. Feature Selection

			Feature selection was performed to identify the most predictive variables for mortality. This involved:

			    Correlation Analysis: Identifying strongly correlated features to reduce multicollinearity.
			    Recursive Feature Elimination (RFE): Using recursive feature elimination to iteratively remove the least important features based on model performance.
			    Domain Expertise: Medical experts contributed to selecting clinically relevant features, such as vital signs, blood test results, and comorbidities that are typically associated with mortality risk in ICU patients.

			3. Model Development

			Several well-established machine learning algorithms were applied to predict early and late mortality:

			    Logistic Regression: Used as a baseline model for binary classification tasks.
			    Random Forests: An ensemble method providing feature importance and the ability to model complex interactions between features.
			    Gradient Boosting Machines (GBM): A powerful technique to improve prediction accuracy by combining weak learners.
			    XGBoost: Known for its robustness in handling large datasets and minimizing overfitting.

			Hyperparameter Tuning:

			Grid search and random search were used for hyperparameter optimization to find the best model configurations, focusing on the regularization strength and learning rates.
			4. Model Validation

			To assess the performance of the predictive models:

			    Internal Validation: The models were initially trained and validated on the MIMIC-IV dataset.
			    External Validation: The model’s performance was then externally validated on the eICU dataset to assess generalizability.
			    Evaluation Metrics: Models were evaluated using the area under the receiver operating characteristic curve (AUC-ROC), accuracy, precision, recall, and F1 score for both early and late mortality predictions.

			5. Handling Mortality Prediction

			    Early Mortality: Defined as mortality occurring within the first 48 hours of ICU admission. This classification task focused on predicting the immediate risk based on baseline and early clinical data.
			    Late Mortality: Mortality that occurred after 48 hours was predicted using both early and extended clinical data collected during the ICU stay. This model took into account the evolving condition of the patient over time.

			6. Model Interpretability

			To ensure the models were interpretable and clinically actionable:

			    SHAP Values (Shapley Additive Explanations) were used to interpret the importance of individual features and their impact on the model’s predictions.
			    LIME (Local Interpretable Model-agnostic Explanations) was employed to provide local explanations for individual predictions, ensuring that clinicians could trust and understand the model’s decision-making process.

			7. Identification of Novel Biomarkers

			Using the trained models, novel biomarkers, such as platelet count variability and other clinically relevant features, were identified as important predictors of mortality risk. These biomarkers were highlighted as potentially significant in clinical decision-making and could be further explored in future studies.
			8. Model Deployment

			The final models, validated through internal and external datasets, were deployed using an automated pipeline for integration into clinical decision support systems. This system provides real-time predictions for ICU clinicians to assist in identifying high-risk patients for both early and late mortality.
			9. Ethical Considerations

			Given that the study used de-identified patient data, institutional review board (IRB) approval was obtained from Beth Israel Deaconess Medical Center and the Massachusetts Institute of Technology. Patient consent was waived due to the retrospective, observational nature of the study and the de-identification of patient data.
			Conclusion

			This methodology emphasizes the use of state-of-the-art machine learning techniques to provide clinically relevant predictions of mortality in ICU patients with VTE and cancer. By integrating interpretable models with novel biomarkers, the study aims to improve early and late mortality predictions, supporting better clinical decision-making.
22/11/2024
=====

* deliverable is in motion . first draft deadline is today  

* meeting : concrete output of meeting 

update ECCC strategic agenda 

bank document ! priorities :

this!!
		ECCO WG on skills

				Objectives
				In the ECCO Working Groups we present the common proposed objectives well connected to the ECCO's skills strategy, the ACADEMY focused also on aspects linked to the ECCC Strategic Agenda.
				Short description of the reviewed WG objectives

				1.	Build community of experts on skills. 
				2.	Promote the development of skills and capabilities of cyber- professionals. 
				3.	Support the alignment of curricula in higher education with the workforce demand across EU-27.  
				4.	Provide recommendations on filling the gaps in professional certification and attestation of skills in cybersecurity
				5.	Facilitate collaboration and common approaches among relevant stakeholders. 

				Participants
				1.	ECCO Partners Leaders: TUC & ECSO 
				2.	ECCO Partners support:  CEA, Goethe, RHEA
				3.	Main envisaged experts (as in the proposal – list to be progressively compiled and contacts established asap)
				4.	Other possible experts (list to be progressively compiled and contacts established when needed): experts from ECSO and pilots and suggested by NCCs/ECCC

				Foreseen activities and possible deliverables
				•	Working Group Meetings (remote / live) – core ECCO team and/or with experts
				o	Quarterly working meeting (remote) 
				•	Identification of relevant achievements / best practices (e.g. developed in the Pilots or other) to address the ECCC Strategic Agenda
				o	Alignment of educational curricula with the needs of the market and public sector  
				o	Fostering the harmonization of approaches in professional certification and attestation 
				o	Support efforts to raise awareness, educate, and stimulate an interest in cyber for youth (of all ages and gender) 
				•	Recommendations for future specific priority “Joint Actions” (e.g. DEP projects) and other actions for the ECCC.
				o	Common tools and easily accessible platforms for hands-on technical education, training and testing opportunities in the area of cybersecurity
				o	Mechanism for a joint European professional certification scheme in cybersecurity
				o	Tools to increase awareness and competencies on integrating security and privacy in future development of products and services 
				•	Possible cooperation in immediate Joint Actions
				o	NCCs supporting J.A. via cascading funds 
				•	Envisaged knowledge sharing events: presentations before EC, NCCs, ECCC 
				o	Knowledge -sharing event on skills linked to market, ad-hoc webinars based on topics linked to ECCO skills strategy    

				Tentative calendar until end of the project
				•	Possible milestones and targeted events per quarter until end 2024.
				o	Constitution of a skill’s proto community by end of 2023, to be extended till 2024
				o	Common recommendations to NCCs and ECCC in Q2 2024
				o	Events/webinars: roughly one per quarter 

wants feedback from us 

		nina: structrue agenda if ECCC is there 	
		make

		a sum up presentatin ..achievements reccomendations and then more specific to topics
skills do not take eccc strategic agenda 

present all activities

*TODO* 
present a leaflet as a result of outcomes with recommendation as a conclusion/recommendation  - 2 pages per group: recommendation and guidelines 





17/11/2024
============

*meeting micael zafeirolpoulos* 

	What exactly can you retrieve from telegram API. What kind of metadata is available on telegram e.g. Geolocation etc.
	Start crawler in java
	Send crawler (despoina)  + API crawler configurations OK 
	Start studying ML 
	Google scholar 
	Secretary TUC: Title : Social media analysis in times of crisis: Telegram in Palestine  (todo despoina) 
	Start documenting https://swagger.io/


other titles 
"Understanding Crisis Communication: Sentiment and Topic Analysis of Telegram Channels in Palestine"
"Telegram as a Digital Battleground: Social Media Sentiment and Crisis Response in Palestine"
"Voices in Conflict: Sentiment and Topic Analysis on Telegram During the Palestine Crisis"
"Navigating the Crisis: A Study of Sentiment and Discourse on Telegram in Palestine"
"Digital Pulse of a Conflict: Topic and Sentiment Analysis of Telegram Communities in Palestine

TODO collect all   last version deleiverables from ECCO  


13/11/2024
============
 Each group will have 1 hour in total as follows: present the achievements and recommendations to support the ECCC strategic agenda (20 minutes) and organise a 40 minutes discussion with the experts.

 Achievements 


12/11/2024
============
Stavros diplwmatikh
* mou edeixe ta tabs field sta data pou douleuei kai mou eope oti ekane reduction me vash to p-value kai pao 319.283 ta meiwse 123.000. 
me rwthsw an 8a prpeie n a ta rixei kiallo me dimension reduction gai na trexei to montelo sto mhxanhma tou !!!
tou eipa oti den paizei n to kanoume auto ,na meiwsoume ta data gia ayto to logo. python einia as pame se enan apo tous server mas na to trexoume !!!
meta moy eipe to methido logistioc regression ktl ...

tou eipa na diavasei ligo kai gai to bart /transformers ...\apla 8a prepei na paixei me tabTransformers 

		Τα TabTransformers είναι μοντέλα βασισμένα σε αρχιτεκτονική Transformer που έχουν σχεδιαστεί ειδικά για να δουλεύουν με tabular data (δεδομένα πινάκων), τα οποία είναι τα πιο κοινά στις εφαρμογές μηχανικής μάθησης, όπως τα δεδομένα γονιδιακής έκφρασης, τα οικονομικά δεδομένα, τα δεδομένα πωλήσεων, κ.λπ.

		https://paperswithcode.com/method/tabtransformer

Mixalis zafeiropoulos 

https://github.com/Spzabt-zz/Media_Content_Monitoring		

6/11/2024
=============

*presentation @ ECCO* 
==================
 
hello eveyone.  welcome to the *webinar on Educational Curricula Alignment to Market Needs*. 
I am despoina antonakaki and as co-chair of the WG on skills I would like to give a small introduction before proceeding to our presentations 

			
				With the rapid evolution of the digital landscape and a pressing need for cybersecurity expertise in Europe, the ECCO project, alongside ECSO and the main coordinators of the four Pilot projects on Competence Centres CONCORDIA; ECHO;  CYBERSEC4EUROPE;  and  SPARTA)  are committed to address the critical gap in cybersecurity professionals through education and training initiatives.
				 
				Through knowledge sharing among the main stakeholders and with the NCCs, ECCO supports the building of a strategic planning and roadmap to support the objectives of the ECCC and implementation of its Strategic Agenda, and help the ECCC/NCCs to implement effective solutions on skills.
		
		  	It is important to know  that these series of webinars and the discussions are to be complementary to the * ECCC WG5 and not indent to duplicate discussions or tasks that are linked to EU cybersecurity skills academy*. So the community sessions are indented to gather the community of experts on skills and the NCC networks and exchange approaches 	

					
			Towards this goal ECCO has formed 6 working groups , and today as WG on skill we are happy to feature/present the webinar on  Educational Curricula Alignment to Market Needs and have with us two inspirational speakers on bridging the gap between educational needs and industry demands.

			Dr .Anna Felkner from National Research Institute (NASK) in Poland will talk about "" Bridging the Gap between Cybersecurity Industry Needs and Tertiary Education Graduates Skills "", where she will point out how tertiary education fails to provide students on-the-job experience they need for practical applications of their cybersecurity profession, leaving those who enter this profession unprepared. "

			 Prof. Jack Noel coordinator for cyber at Université Bretagne Sud (UBS), presenting ""From Student to Job in Cyber: switching Education Programs to Skill Blocks"" - Deciphering how French higher educational institutions are restructuring the courses based on demand for cyber security jobs.

			we will have twenty minites of presentation from Dr .Anna Felkner  and then 5 miutes of questions. 
			Then the next presentation will follow from  prof. Jack Noel and another 5 minutes of questions   Q&A  
			and Final remarks and close of webinar. you can also write tyour question in the chat . 
 

	and with no further ado I will give the floor to Anna. Anna you can share your slides

Anna the floor is yours
- 11:00-11:05: Welcome & Introduction (Despoina Antonakaki, TUC)
- 11:05-11:25: Bridging the Gap between Cybersecurity Industry Needs and Tertiary Education Graduates Skills (Anna Felkner, NASK)
- 11:25-11:30: Q&A  
- 11:30-11:50: Presentation: “From Student to Job in Cyber: switching Education Programs” (Jack Noel, UBS)
- 11:50-11:55: Q&A  
- 11:55-12:00: Final remarks and close of webinar
 

	*In closing, I would like to thank our speakers for their insightful presentations and all participants for their active engagement. This webinar marks another step forward in aligning educational curricula with the real-world demands of the cybersecurity industry,  we hope that today’s discussion has provided valuable insights into this bridge*

	Thank you all for your attendance , 


*Questions to presenters *	
1.	For Prof. Jack Noel:
How do you see the role of micro-certifications or industry-recognized credentials in complementing the skill blocks within cybersecurity education programs? Can they help bridge the gap between university curricula and the immediate needs of employers?
2.	For Dr. Anna Felkner:
What strategies can universities adopt to provide students with more practical, hands-on experience in cybersecurity, especially considering the fast-evolving nature of cyber threats?
3.	For Both Speakers:
How can educational institutions and industry collaborate more effectively to continuously update curricula to reflect the latest trends and demands in cybersecurity? What mechanisms or partnerships have you found successful?
These questions address the challenge of aligning education with market needs while providing practical insights into improving the system.




	*In closing, I would like to thank our speakers for their insightful presentations and all participants for their active engagement. This webinar marks another step forward in aligning educational curricula with the real-world demands of the cybersecurity industry,  we hope that today’s discussion has provided valuable insights into this bridge . 
  Thank you all for your attendance*

			 notes on the webinar 
			------------------------------------------------------------------------------------------------------------

1) fifty people 50 
2) presentations 
anna presenter the mosts important competences . there is a clear gap between a indisry expects 

the repost shows that respondents from business industry placed approximatekt 10 % more importants on both traversal and profession skills that he educational sector . 

prepared 7 reccomendations 
improve education traing 
back to basiscs 
raisw awereness 
improve collaboration 
boost diversity 
ugrade recruitment process
ikmprove collaborayion 

 
 Anna presentation 
 ================
64% of respondents believe that skills gap have a more significant negative impact than staffing shortage 

82% very important or moderately important 
lifelong learning evryone sais this is CRUCIAL . 
critical thinking 
knnowledge of vulnerabilities 
additional competences : 
openness to knowledge sharing 
nit picking trying to spoil 
analytical thinking analysis of information 
curiosity 
syntheses and search of information 
have general knowledge on different aspects of CS 

competence gaps 
----
lack of ability to go above and beyond 
responsibility of the objectives 
knowldege of tools not detailes no practical pallictaion in AI 
ability to assess the situation 
how serieous is the problem in your organization 
most difficult roles to fill  

3) My questions for Anna 

My questions could these  (slide 2) reccomendations be more specific? and how and where would it really matter to be  promoted  and somehow be realized ? are these solutions somehow realized..?put in gears? what is teh next step to realize these solutions ?  

in your opinion which is the most important reccomendation and best practices  ? 


questions from audience for Anna: 

1) no time 

2)

3)

presentation of Jack 
what are doing in univeristyies and especially in french . 

britainy digital lnad and cyberland with many businesses . we are sount of brittany 3 campusses eleven tjousand students 1995 

different componets in faculty - technology institution 

research 2015 xekinhsan 
5 labs . applied business
transdisciplinarity stress a lot . labs differect to work togentehr 

secure by desig 
embedded & iot 
industria l


*My Questions to presenters *	
1.	For Prof. Jack Noel:
How do you see the role of micro-certifications or industry-recognized credentials in complementing the skill blocks within cybersecurity education programs? Can they help bridge the gap between university curricula and the immediate needs of employers?
2.	For Dr. Anna Felkner:
What strategies can universities adopt to provide students with more practical, hands-on experience in cybersecurity, especially considering the fast-evolving nature of cyber threats?
3.	For Both Speakers:
How can educational institutions and industry collaborate more effectively to continuously update curricula to reflect the latest trends and demands in cybersecurity? What mechanisms or partnerships have you found successful?
These questions address the challenge of aligning education with market needs while providing practical insights into improving the system.

questions from audience for Jack : 

1) no time 

2)
Rob Jones amlat 2 compnaies 

what do you need anything from private enetrprise ? 

Jack huga majority of studenst are part time in businesses and cubercompanies , nuclear plnats We need we chck that job fit to curiculum ? whenever you pscialize in cs ? if soft provider company . analysist do you need special places fro students ..

sof t appoach on cyberrabges also send student to soft . 

2) anamaria margit pantea. raswing aweresenns early in education ..
wondering elaborate more on how you see the potential for girkls in vcarees. requirement of limited for technical requremenyts for stidents ? 
what king of awereness do you have to expand  the pipeline ? 

Jack answers 
france in not the best in ths part . we does have that yet . not there yet . fro estonia is tit is already tehre, major goal to attact more women , 
hav a programm to start from schools. they go in schools and serious gaming with them . adapt them to their level. students are very active . student associaltion there are that are on Cs to organoze up to high school CTFs 

Not to be too technical . teh CTFs stress CS is a technical affair .  Some of them are frim political science so cannot follow too technical staff . 
Anna aded it is time to encourage YOUNg people 

cyber prevention teams they have at NASK and go at primary school . show cS risk but also  and JOBS !!! they have Cs at schools it is the  time . 


eexplain to the professors at high schools ..what is CS and parents :) forums they have 
3)


You have five minutes left 

	*In closing, I would like to thank our speakers for their insightful presentations and all participants for their active engagement. This webinar marks another step forward in aligning educational curricula with the real-world demands of the cybersecurity industry,  we hope that today’s discussion has provided valuable insights into this bridge .Thank you all for your attendance*





4/11/12024
==============

Apostilos zarras proposal . up to AI-based anomaly detection
Recent research efforts have been focused on the use of AI for anomaly detection. Although the traditional models take into consideration features extracted from the network traffic, the latest trend is to use AI and statistical characteristics to achieve reliable anomaly detection.
 page 7/24 
19/10/2024 
================

fovero paper se telgram me  317M messages which reminds me OUR dataset is verrryyy small . 

expand in channels etc. 

new aded https://t.me/TIMESOFGAZA
https://t.me/The_Jerusalem_Post
https://t.me/plyinewsnetwork 
Eye on Palestine https://t.me/Eyeonpalestine2
	https://t.me/samidounnetwork
https://t.me/pal_Online9
https://t.me/gazaenglishupdates

https://t.me/s/eyeonpal?before=4762


Israel 
https://t.me/idfofficial
https://t.me/hnaftali
https://t.me/ILTVnews

https://t.me/QudsNen

25/10/2024
================
*ECCO task C status meeting*
agenda 
	*final deliverable coming up timelines*
		same structure, maybe more attention because it is the last  
		18 decemnber end of project 
		next week asks feedback activiteis webinar lessins learned ..then reveiw cleaning Quality comments and submit
		15-22 november
		update excel 



*in person meeting* 
		roberto trying to get a respnse for commision NO decision 
		EC is meeting with ECCC next week and Wendesday . maybe they now then. 
		hold up on this .
		EC and ECC will be present in this event 
		end of nevember ? or december ? (december will be tricky ..buget is closed ..so bet on november)
*Paper telegram israeli-palaistnia*


Lies on Social Media Inflame Israeli-Palestinian Conflict.
@article{frenkel2021lies,
  title={Lies on Social Media Inflame Israeli-Palestinian Conflict.},
  author={Frenkel, Sheera},
  journal={International New York Times},
  pages={NA--NA},
  year={2021},
  publisher={International Herald Tribune}
}

@article{weimann2024coping,
  title={Coping with Hamas’s Psychological Warfare during the Gaza War},
  author={Weimann, Gabriel and Weimann-Saks, Dana},
  journal={Studies in Conflict \& Terrorism},
  pages={1--20},
  year={2024},
  publisher={Taylor \& Francis}
}
@article{steffen2024more,
  title={More than Memes: A Multimodal Topic Modeling Approach to Conspiracy Theories on Telegram},
  author={Steffen, Elisabeth},
  journal={arXiv preprint arXiv:2410.08642},
  year={2024}
}
@mastersthesis{jongbloed2024analysing,
  title={Analysing the Impact of Telegram (Social Media) on the Political Public Sphere: A Study on the Political Public Sphere and Deliberative Democracy},
  author={Jongbloed, Arnaud},
  year={2024}
}
@book{koblentz2023countering,
  title={Countering Hate in the Digital Age: Analyzing Far-Right Extremist Responses to the Israel-Hamas War},
  author={Koblentz-Stenzler, Liram and Klempner, Mr Uri and Chavez, Ms Kate},
  year={2023},
  publisher={International Institute for Counter-Terrorism (ICT)}
}


from steffen paper found : 

Baumgartner, J., Zannettou, S., Squire, M., & Blackburn, J. (2020). The Pushshift Telegram Dataset. Proceedings of the International AAAI Conference on Web and Social Media, 14(1), 840-847. https://doi.org/10.1609/icwsm.v14i1.7348

23/10/2024
================
started crawler scraper for twitter ..abort 
oti asxoleite em to proposal auto DIGITAL-ECCC-2024-DEPLOY-CYBER-07-SOC - National SOCs (Manos)alla exei na kanei me to soc kai uposthrixh ktl ..

instead pame gia uto : https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/digital-eccc-2024-deploy-cyber-07-keytech?order=DESC&pageNumber=1&pageSize=50&sortBy=startDate&isExactMatch=true&status=31094501&frameworkProgramme=43152860

review decline 
Artificial intelligence: Call Deployment actions in the area of cybersecurity (DIGITAL-ECCC-2024-DEPLOY-CYBER-07)
This study investigates global audience engagement with YouTube news coverage of the Israel-Palestine conflict during October and November 2023.  We employ a novel approach to analyze user comments on YouTube videos from 37 channels (authenticated TV/Journal broadcasting) spanning different regions. Using Python scripting, we collect video metadata and comments for 2095 news video and nearly 3 million comments covering the period from 5-October-2023 to 12 Noveomber-2023 ((Arab–Islamic extraordinary summit), 2023) within ~12 days. A novel Hierarchy Media Profile Cluster (HMPC) technique validates the dataset by using the graph representation of channels based on users engaged. The HMPC results reveal distinct clusters reflecting the target audiences of channels as sperate closed-graph clusters for Arabic, European, US, India etc. This validation allows us to analyze user engagement dynamics across the conflict timeline of the collected data.  Finally, we explore temporal patterns in commenting activity to understand how public engagement evolved on different news channels. The analysis result of temporal patterns was reflected to the key events occurred during the conflict and it shows the higher period of global users engaged on channels was on range of 31 October – 4 November 2023. 
*crawler*
https://t.me/pal_Online9 - Palestine Online 
https://t.me/resistancechain - Resistance Chain
https://t.me/gazaalanpa  - GAZA NOW IN ENGLISH 
https://t.me/AlQassamBrigades9 - Al Qassam Brigades
https://t.me/Eyeonpalestine2 - Eye on palestine
https://t.me/haqqintel - Al Haqq
https://t.me/palestineonline - PPPECGYTYVU

https://t.me/samidounnetwork  samidoun network
https://t.me/palestineresistance  palestine resistance
https://t.me/StopGazaGenocide #FreePalestine
https://t.me/PalestineSolidarityBelgium - Palestine Solidarity

*TOPIC*
go to /home/antonakd/TelegramCollector/topic
and run  :python3 bert5_plot.py
*crawler* 
	-barpot ready at barplot5.py  : 
 	-bert6 topic analysis completed in file with results in ls entity_distribution.png
	-LDA: lda_visualization_10K.html
	tsne_clustering_10K.html
	topic_distribution_10K.png


16/10/2024 
==========

*laptop* evgale kai ligo kokkino dipla sthn rwgmh :BACKUP!!!!Apple MacBook Pro 14" M3 / 8-Core CPU / 10-Core GPU / 16GB RAM / 1TB SSD / Space Grey / GR
*askhsh*
 olh h askhsh edw : ExerciseMalwareDetection.docx (/Users/despoina/GitHub/phd/HPY413/FINAL_solution)
 gai na trexei to erwthma D1 sto virtual machine eprepei na egkatashthoume crypto ;h pip install pyAesCrypt με  pip install . den ta katafere opote oute me apt get kai eftiaxa teliak enan virtual environment : 

 bebaia oute me virtual env etrexe giati eftegan ta permissions kai edwse lush auto : 
 ls -l ~/HPY413/Final_solution/new_morechallenging_untested/myenv/lib/python3.11/
			    sudo chown -R $(whoami):$(whoami) ~/HPY413/Final_solution/new_morechallenging_untested/myenv
			Step 2: Activate the Virtual Environment Again
			After adjusting the permissions, reactivate your virtual environment:
			source ~/HPY413/Final_solution/new_morechallenging_untested/myenv/bin/activate
			Step 3: Install pycryptodome Again
			Now, try installing pycryptodome again without sudo:
			pip install pycryptodome

15/10/2024 
===========
Channel Proxy MTProto: 32395 messages.
Channel My Proxy | مای پروکسی: 29420 messages.
 Channel Palestine Online 🇵🇸🇵🇸: 43966 messages.
Channel GAZA NOW IN ENGLISH: 5435 messages.
Channel Al Haqq🔻: 2894 messages.
Channel Resistance Chain: 8323 messages.
Channel ПАЛЕСТИНА | ОНЛАЙН 🇵🇸: 418 messages.
Channel Eye On Palestine: 2443 messages.
Channel 🇵🇸𓂆PALESTINE RESISTANCE™️: 2233 messages.
Channel Al-Qassam Brigades, Gaza 🥷☝️: 1975 messages.
Channel Samidoun Network: 3337 messages.
Channel Telegram Tips: 349 messages.
Channel MEDITERRANEA Saving Humans: 1216 messages.
Channel Amnesty International Italia: 79 messages.
Channel Kamala Harris $HARRIS: 12 messages.
Channel Kamala Harris - Portal: 4 messages.
Channel #FreePalestine 🇵🇸: 119 messages.
Channel Palestine Solidarity 🇵🇸🇧🇪 - Intal: 147 messages.
Channel قناة الأقصى الفضائية📡: 62 messages.
Channel Bigo live: 42 messages.


14/10/2024
=============
-sent email reminder for ECCO webinar
-exercise 
-crawler 
		Channel GAZA NOW IN ENGLISH: 5415 messages.
		Channel MEDITERRANEA Saving Humans: 1216 messages.
		Channel اختصارات❤️زخرفه❤️اسماء❤️بوت❤️زغرفه: 3926 messages.
		Channel Proxy MTProto: 32376 messages.
		Channel My Proxy | مای پروکسی: 29405 messages.
		Channel Palestine Online 🇵🇸🇵🇸: 43907 messages.
		Channel Al-Qassam Brigades, Gaza 🥷☝️: 1973 messages.
		Channel Eye On Palestine: 2383 messages.
		Channel Al Haqq🔻: 2855 messages.
		Channel ПАЛЕСТИНА | ОНЛАЙН 🇵🇸: 398 messages.
		Channel Samidoun Network: 3295 messages.
		Channel Resistance Chain: 8296 messages.
		Channel 🇵🇸𓂆PALESTINE RESISTANCE™️: 2223 messages.
		Channel Amnesty International Italia: 79 messages.
		Channel Telegram Tips: 348 messages.
		Channel Kamala Harris $HARRIS: 12 messages.
		Channel Kamala Harris - Portal: 4 messages.
		Channel #FreePalestine 🇵🇸: 119 messages.
		Channel Palestine Solidarity 🇵🇸🇧🇪 - Intal: 147 messages.
		Channel قناة الأقصى الفضائية📡: 62 messages.
		Channel Bigo live: 42 messages.
		Channel HeraklionWindsurfers: 2 messages

11/10/2024 
=============
*crawler* 
	-Total number of messages across all files: 134438
	-bert6 topic analysis completed in file with results in ls entity_distribution.png
	-LDA: lda_visualization_10K.html
	tsne_clustering_10K.html
	topic_distribution_10K.png


the results are in directory topic_model_results : - entity_distribution.png
==========
                     python3 count_messages_inFiles2.py *
  
							count_messages_inFiles2.py *
							Total number of messages in 'AlQassamBrigades9_2024-10-10.json': 1933
							An error occurred while processing 'antonakd.session': 'utf-8' codec can't decode byte 0xb2 in position 109: invalid start byte
							Total number of messages in 'Aqsatvsat_2024-10-10.json': 58
							An error occurred while processing 'backup': [Errno 21] Is a directory: 'backup'
							Error: The file 'config.py' is not a valid JSON file.
							Error: The file 'count2_API_mess_perchannel.py' is not a valid JSON file.
							Error: The file 'count_messages_inFiles2.py' is not a valid JSON file.
							Total number of messages in 'Eyeonpalestine2_2024-10-10.json': 2215
							Total number of messages in 'flagged_messages.json': 10
							Total number of messages in 'FreePalestine2023_2024-10-10.json': 1
							Total number of messages in 'gazaalanpa_2024-10-10.json': 5224
							Total number of messages in 'GazaNow_2024-10-10.json': 62
							Total number of messages in 'haqqintel_2024-10-10.json': 2794
							Total number of messages in 'Palestine2024_2024-10-10.json': 10
							Total number of messages in 'palestineresistance_2024-10-10.json': 2199
							Total number of messages in 'PalestineSolidarityBelgium_2024-10-10.json': 147
							Total number of messages in 'PalestineUpdates_2024-10-10.json': 464
							Total number of messages in 'PalestinianResistance_2024-10-10.json': 19
							Total number of messages in 'pal_Online9_2024-10-10.json': 43694
							An error occurred while processing '__pycache__': [Errno 21] Is a directory: '__pycache__'
							Total number of messages in 'resistancechain_2024-10-10.json': 4875
							Total number of messages in 'samidounnetwork_2024-10-10.json': 3100
							Total number of messages in 'StopGazaGenocide_2024-10-10.json': 119

							Total number of messages across all files: 66924

Total number of messages across all files: 83428
 
 Total number of messages across all files: 134438

  python3 count2_API_mess_perchannel.py 

							Channel Eye On Palestine: 2211 messages.
							Channel Al-Qassam Brigades, Gaza 🥷☝️: 1931 messages.
							Channel GAZA NOW IN ENGLISH: 5276 messages.
							Channel Resistance Chain: 8273 messages.
							Channel Al Haqq🔻: 2799 messages.
							Channel Palestine Online 🇵🇸🇵🇸: 43684 messages.
							Channel MEDITERRANEA Saving Humans: 1211 messages.
							Channel Samidoun Network: 3226 messages.
							Channel 🇵🇸𓂆PALESTINE RESISTANCE™️: 2199 messages.
							Channel Amnesty International Italia: 79 messages.
							Channel Kamala Harris $HARRIS: 12 messages.
							Channel Kamala Harris - Portal: 4 messages.
							Channel #FreePalestine 🇵🇸: 119 messages.
							Channel Palestine Solidarity 🇵🇸🇧🇪 - Intal: 147 messages.
							Channel قناة الأقصى الفضائية📡: 62 messages.
							Channel HeraklionWindsurfers: 2 messages.

10/10/2024
===========

spam accounts 
Prepei na doume thn pio megalh eikosana latevase polu dhmofilh kanalia kai oxi mono gia palaistin h 

https://t.me/TelegramTips

https://www.statista.com/statistics/1344353/most-subscribed-telegram-channels/



https://t.me/btc_claim_bot_project

https://t.me/jasassiphonefreeee

these are not about palaistine!! remove from palaistne dataset !!!


9/10/2024
=========
telegram 

maybe spam campaign ?? 


fing friends of this #https://web.telegram.org/k/#@bigolivr ,...and network around him ...who follows him etc. 


. discover define most important entities 
			*1)TODO important find spam:*
https://web.telegram.org/k/#@Aqsatvsat
			Share Your Refferal Link To Your Friends & Earn Extra Doge On Each Joined On Your Refferal Link.

			Your Inviting Link: https://t.me/InstantFreeDogeBot?start=user4298669

			🎁 You Earn 200 Doge Per Refferal

			Total Refferals: 2 Users 
*2 example in the same cgannel of spam !!!*https://web.telegram.org/k/#@Aqsatvsat
Download *Mine Tron App* and start earning.
											Use my referral code [16611414].

											all of them are spam SUPER REFERRALS SYSTEM 🔋

											Earning hasn't ever been so easy!
											You can earn 🆓 Completely Free DOGE by inviting your friends and purchasing FREE Diamond 💎

											💠 Level 1

											If you invite 1 friend, you will get:
											💎 INSTANT FREE 60 💎
											💎 10% of every deposit in 💎

											💠💠 Level 2

											If your friend invites 1 friend, you will get:
											💎 INSTANT FREE 25 💎
											💎 2% of every deposit in 💎

											💥 direct bot url: https://t.me/FishFarming_Bot?start=1148589240
											
											https://t.me/Claim_BTC_Project_BOT?start=1148589240
											
											https://t.me/Claim_BTC_Project_BOT?start=1148589240
											
											https://t.me/Easybitcoins_bot?start=01338949320
											
											https://t.me/Free_PayPal_Instant_Pay_Ltd_Bot?start=1148589240
											
											https://t.me/Dogclaim_bot?start=01338949320
											
											https://t.me/Dogclaim_bot?start=01338949320
											
											https://t.me/Dogclaim_bot?start=01338949320
											
											https://t.me/Dogclaim_bot?start=01338949320
											
											https://luckyfish.xyz/?c=c_mostaid41
											Provably fair, unlimited faucet, weekly bonus
											
											https://luckyfish.xyz/?c=c_mostaid41
											Provably fair, unlimited faucet, weekly bonus
											
											https://www.youtube.com/watch?v=RPjY2tZ1aHk
											
											https://www.youtube.com/watch?v=RPjY2tZ1aHk
											
											https://youtu.be/4fMzsfbyzNU
											
											https://youtu.be/4fMzsfbyzNU
											
											https://sha-256.io/?ref=HASAN20
											
											https://sha-256.io/?ref=HASAN20
											
											https://sha-256.io/?ref=HASAN20
											
											t.me/claim_free_bitcoin_bot?start=1148589240
											
											http://t.me/claim_free_bitcoin_bot?start=1148589240
											
											http://t.me/claim_free_bitcoin_bot?start=1148589240
											


in channel https://web.telegram.org/k/#@Aqsatvsat
8/10/2024
========
*aneipero backup sto tuc drive*
*askhsh meletu ekfwnhshs* 
apotelesmata kai final execrise solution in /Users/despoina/GitHub/phd/HPY413/FINAL_solution
*telegram*
1. check database : ti swzei , repost ? sxolia ? ok me to insertion
2. build a model in roberta/deberta whatever is more suitable to learn detect spam? trolls? fake news? 
3. apply basic analysis. first if it needs pre-processing and the topic sentiment analysis 

*μαιλ σωτηρη για προποσαλσ*
		καλησπέρα! κοιταζα αυτά τα δύο calls: 

		Development and Deployment of Advanced Key Technologies
		DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH - DIGITAL-JU-SME DIGITAL JU SME Support Actions  - TRL 7 to TRL 9 - deadline 21 January 2025

		και 

		Artificial intelligence: Call Deployment actions in the area of cybersecurity (DIGITAL-ECCC-2024-DEPLOY-CYBER-07)
		TRL 7 or above
		Μου είπε ο Μάνος οτι ξεκινάς κατι σε αυτά τα topic?
		Ο αρχικος προβληματισμος μου ήταν το TRL level και των δυο .

							)
				Development and Deployment of Advanced Key Technologies
				DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH
				 https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH?isExactMatch=true&status=31094501,31094502&callIdentifier=DIGITAL-ECCC-2024-DEPLOY-CYBER-07&order=DESC&pageNumber=1&pageSize=50&sortBy=startDate

				 DIGITAL-JU-SME DIGITAL JU SME Support Actions  - TRL 7 to TRL 9 - deadline 21 January 2025 17:00:00 Brussels time

				2) Artificial intelligence : 
				Call
				Deployment actions in the area of cybersecurity (DIGITAL-ECCC-2024-DEPLOY-CYBER-07)
				TRL 7 or above

				Μου είπε ο Μάνος οτι ξεκινάς κατι σε αυτά τα topic?
				Ο αρχικος προβληματισμος μου ήταν το TRL level και των δυο . 
				https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH?order=DESC&pageNumber=1&pageSize=50&sortBy=relevance&keywords=Artificial%20Intelligence&isExactMatch=true&status=31094501,31094502

				The TRL level for the proposal DIGITAL-ECCC-2024-DEPLOY-CYBER-07-KEYTECH from the Digital Europe Programme focuses on the deployment of state-of-the-art cybersecurity technologies. Based on similar Digital Europe proposals and deployment-focused actions, the TRL level typically starts from *TRL 6 (technology demonstrated in a relevant environment) and aims for TRL 8 (system complete and qualified)*

				----- 
*ecco*
des an prepei na kanoume kati gia to webinar 

proposal TRL 6-9 gai ton febryario :  DIGITAL-JU-SIMPLE DIGITAL JU Simple Grants is typically around TRL 7 to TRL 9.

1

MAYBE SAVE IN FILES !!! I am tires 2 weeks trying to save in mongo !!

disstribution of dominant topics 
fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=22)
df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Topic_Perc_Contrib', 'Keywords', 'Text']
7. The most representative sentence for each topic
8. Frequency Distribution of Word Counts in Documents
plt.title('Distribution of Document Word Counts', fontdict=dict(size=22))
fig.suptitle('Distribution of Document Word Counts by Dominant Topic', fontsize=22)
9. Word Clouds of Top N Keywords in Each Topic
10. Word Counts of Topic Keywords
fig.suptitle('Word Count and Importance of Topic Keywords', fontsize=22, y=1.05)    
11. Sentence Chart Colored by Topic
12. What are the most discussed topics in the documents?
		# Topic Distribution by Dominant Topics
		ax1.bar(x='Dominant_Topic', height='count', data=df_dominant_topic_in_each_doc, width=.5, color='firebrick')
		ax1.set_xticks(range(df_dominant_topic_in_each_doc.Dominant_Topic.unique().__len__()))
		tick_formatter = FuncFormatter(lambda x, pos: 'Topic ' + str(x)+ '\n' + df_top3words.loc[df_top3words.topic_id==x, 'words'].values[0])
		ax1.xaxis.set_major_formatter(tick_formatter)
		ax1.set_title('Number of Documents by Dominant Topic', fontdict=dict(size=10))
		ax1.set_ylabel('Number of Documents')
		ax1.set_ylim(0, 1000)

		# Topic Distribution by Topic Weights
		ax2.bar(x='index', height='count', data=df_topic_weightage_by_doc, width=.5, color='steelblue')
		ax2.set_xticks(range(df_topic_weightage_by_doc.index.unique().__len__()))
		ax2.xaxis.set_major_formatter(tick_formatter)
		ax2.set_titl

13. t-SNE Clustering Chart
plot = figure(title="t-SNE Clustering of {} LDA Topics".format(n_topics), 
14. pyLDAVis

8/10/2024
==============
*crawler* NEW DIRECTORY for all .. runied ols by commit log huge file . In black mamba now working directory is/home/antonakd/TelegramCollector/ 

--> created folder topic with 12 attempts to see topic with no results which alerted me whether the messages are not saved correctly . created NEW crawler!!!! in file TelegramCollector/newCrawler

	python3 check_if_messages_correctSAVED3.py OK : 
	Total messages in database: 11273500
				Recent messages:
				ID: N/A, Channel: N/A, Date: 2024-10-01 18:21:35, Text: 80% of Iranian missiles fired at Israel have successfully hit their targets, Iran says
				ID: N/A, Channel: N/A, Date: 2024-10-01 09:48:54, Text: Israeli occupation warplanes targeted the Assirat TV building in southern Beirut, turning the building and its surroundings into piles of rubble.
				ID: N/A, Channel: N/A, Date: 2024-10-01 09:48:54, Text: Israeli occupation warplanes targeted the Assirat TV building in southern Beirut, turning the building and its surroundings into piles of rubble.
				ID: N/A, Channel: N/A, Date: 2024-10-01 09:48:54, Text: Israeli occupation warplanes targeted the Assirat TV building in southern Beirut, turning the building and its surroundings into piles of rubble.
				ID: N/A, Channel: N/A, Date: 2024-10-01 09:48:54, Text: Israeli occupation warplanes targeted the Assirat TV building in southern Beirut, turning the building and its surroundings into piles of rubble.
				antonakd@blackmam



Askhsh: 

esthsa virtual machine me Virtual box VM 
kai evala debian. 

stragglu ligo me thn python3 kai to watch dog . ta katafera me to 
in virtual environmet : finally !sudo apt install python3-watchdog

afou evala thn antonakd sto su - visudo kai sthn grammh 
user privilage specification antegramya oti exei ston root sthn antonakd 

meta xrhsimopoihsa ton script 
/Users/despoina/GitHub/phd/HPY413/FINAL_solution/directory_setup.py
gia na dhmiourghsw to directory mazi me ta infected files mesa 

kai to malware_detector.v2 gai na vgalei epituxws ta pakatw apotelemata 
	*TODO* quiarantine???


7/10/2024
====================

Panagiwta DEFENCE 
Join Zoom Meeting
https://tuc-gr.zoom.us/j/98476445915?pwd=IhZjKBX7JCHcut01thESpHbQXWfX71.1

Meeting ID: 984 7644 5915
Password: 296402

Maybe docker instead of VM ? 

*telegram* 9.639.112 entries

4/10/2024
====================
* HPY413
	https://drive.google.com/drive/folders/14QY5jTKg6VxK0UAdENkHnWlPnqbeobaZ SQL injection 
	ransoweare https://docs.google.com/document/d/1ZvRY8wsY8GSTrn9Ljej5XARnHIpOuzDl/edit


	epivevaiwse oti auto einai to 8ema ths askhshs an ta slides ayta https://drive.google.com/drive/folders/1HwTNOqrvG-zpyzbYgVsz_qzzf5SM-wOw
	8a ta exoune didax8ei 

	des thn perusinh askhsh an einia auth : https://docs.google.com/document/d/1im_OLnx3amcUUsaewRdm-H91XfTc9koH/edit#heading=h.gjdgxs

* review paper ? Invitation to review a manuscript for Social Network Analysis and Mining from Dr Alhajj
* malware askhsh HPY 413 
	askhsh sto /Users/despoina/GitHub/phd/HPY413/solution
Malware Detection2_v2.docx


3/10/2024
===================

* added new channels : 

   "PalestineSolidarityBelgium", 
    "Eyeonpalestine2", 
    "haqqintel", 
    "samidounnetwork", 
    "resistancechain", 
    "PalestinianResistance",
    "PalestineHealth", 
    "PalestineUpdates",
    "GazaNow", 
    "Palestine2024", 
    "FreePalestine2023", 
    "PalestineLive", 
    "StopGazaGenocide",
    "AlQassamBrigades9", 
    "palestineresistance", 
    "pal_Online9",
    "Eyeonpalestine2"

* change cdf 

FINALLY cdf_daily.py working !!!
and sentiment.py 

sentiment_try_fix need work 

find most impirtant entities from news 

get fluctions of sentiment 
downoad more channels 

2/10/2024
===================
*Mathima Sotiri* 
* https://mail.google.com/mail/u/0/#chat/space/AAAA1wXRwZQ
* Example askhsis: 

 
     

		*Exercise: Vigenère Cipher - encryption, decryption and breaking*
			objectives:

			Write a program that uses the Vigenère cipher to encrypt and decrypt messages.
			Design a method to break this cipher based on frequency analysis.

			Directions
			Part 1: Vigenère Cipher Implementation:

	Write a program in Python to implement the Vigenère cipher for encryption and decryption using a keyword.
	Sample Encryption Code
	---
			def vigenere_cipher(text, keyword):
			    keyword_repeated = (keyword * (len(text) // len(keyword))) + keyword[:len(text) % len(keyword)]
			    encrypted = []
			    for i, char in enumerate(text):
			        if char.isalpha():
			            shift = ord(keyword_repeated[i].upper()) - ord('A')
			            shifted = chr((ord(char.upper()) - ord('A') + shift) % 26 + ord('A'))
			            encrypted.append(shifted)
			        else:
			            encrypted.append(char)
			    return ''.join(encrypted)
			----
			Part 2: Encrypt and Decrypt Messages:
			Encrypt a message of your choice using a keyword.

			Decrypt the message using the Vigenère cipher function.
			Part 3: Break the Vigenère Cipher:
			Write a script to break the Vigenère cipher without key, using frequency analysis techniques in order to detect repeating patterns.

			Deliverables:
			Provide Python scripts for encryption, decryption, and breaking the cipher.

			Write a brief report, describing how the Vigenère cipher works and how you tried to break it using cryptanalysis.
			Outcome
			Students will get practical experience with some cryptographic algorithms and simple methods of cryptanalysis.


*ECCO webinar description* : 

				ECCO WG on skills is organizing a webinar on "Educational Curricula Alignment to Market Needs" on 6th November, from 11:00 AM -12:00 PM (GMT+2) . Two inspirational speakers on bridging the gap between the educational needs and industry demands will be featured at this event. 

			ECCO WG on skills is excited to listen to Prof. Jack Noel coordinator for cyber at Université Bretagne Sud (UBS), presenting "From Student to Job in Cyber: From Education Programs to Skill Blocks – A French Perspective", deciphering how French higher educational institutions are restructuring the courses based on demand for cyber security jobs. 

			Prof.Anna Felkner from National Research Institute (NASK) in Poland will talk about " Bridging the Gap between Cybersecurity Industry Needs and Tertiary Education Graduates Skills ", where she will point out how tertiary education fails to provide students on-the-job experience they need for practical applications of their cybersecurity professor, leaving those who enter this profession unprepared. 

			Short Bio

			Anna Felkner is a cybersecurity researcher,  coordinating the VARIoT international project, focusing on vulnerabilities and exploits in the Internet of Things. With proven experience in leading projects in cybersecurity systems, risk management, and trust frameworks, the interest in research in a modern context of online threats and in building international collaboration to raise the bar of digital safety is huge. Accordingly, during the beginning of her career, many challenging roles were performed in cybersecurity where it became evident that diversities were needed, and their contributions were very valuable, especially in highly male-dominated teams. A gender diversity advocate in tech believes in a mix of both male and female to enhance problem-solving and innovation. 

			Jack NOEL is a former French Armed Forces Colonel; during his 30 years career he had various assignments (both in France and abroad) in Cyber/Electronic Warfare, Collection/Exploitation, Counterintelligence (including cyber) and international relations. At UBS he is Cybersecurity Innovation engineer, Coordinator of the Cyber:UBS community and moderator with Professor Guy GOGNIAT of the cyber and smart data ecosystem.  His job is to interface between the university and socio-economic actors, businesses or state agencies in the fields of cyber education, research and training.   He also gives various courses and led the creation of UBS’s first MOOC in cybersecurity. He holds two Master’s degrees (International Relations and Public Management Policies) and various higher military degrees and certificates (War College, Intelligence Academy, etc.).


*TODO* start tutorial on roberta 

* *TODO* check cv sent already though 
* *TODO* Sent description for ECCO webinar ok 
* holder test dimitra?? OK deutera stis 5 
* tzagkaroylaki ? 8a me parei auth !
* crawler added new files getMessages ...gia na vrw ena match munhmatos apo thn vash sto telegram kai na dw an ontws apo8hkeuontai swsta 
FINALLY !!!

antonakd@blackmamba:~/TelegramCrawler_AlexSGitHub/TelegramCollector$ python3 getMessageByTEXTIntelegram.py 
Message ID: 44198
Sender: None
Text: Israeli occupation warplanes targeted the Assirat TV building in southern Beirut, turning the building and its surroundings into piles of rubble.
Date: 2024-10-01 09:48:54+00:00

also the same in mongo : getMessageByTEXTIntelegram_toMONGO_oncefounsOK_print_itfromMONGOaswell2.py 


* message after it is retrieved and save is printed like this : 
		zinfo=datetime.timezone.utc), 'sizes': [{'_': 'PhotoStrippedSize', 'type': 'i', 'bytes': b'\x01\x1e(Hd\xde\x0ex\xc59\xa4\xd8\x07S\xc5RY0\xa3\x18\xc9\xa9\xa3\x99\x19p\xeb\xc8\xe8{V\x1e\xcf\xb9\xaf7b\xd2>\xf08#=3R\x0czU\x12\xc4\x8f\x93\xe5 \xfa\x1aM\xd2\x00@b>\xa2\xb3t\xcb\xe64A\xf6\xa2\xaaE#l\x1b\xcf\xcd\xf4\xa2\xb3p\xb0\xf7 6\x8b\xd8\x9ar\xc2\xc0\x00X\x10:qV8\x07\xa5&\xec\x9a\xeb\xe6F6d\x02)3\xf7\xc0\x1e\x94\xf1\x13\x17\xdc\\\xfd\x00\xe2\xa4\xdd\x8f\xff\x00U&\xe3\x9cRm\x0e\xccI\xdd\xa3\x8fp\xe6\x8a\x0e\x08\xc1\xcd\x15*Q\x1bL'}, {'_': 'PhotoSize', 'type': 'm', 'w': 320, 'h': 240, 'size': 20041}, {'_': 'PhotoSize', 'type': 'x', 'w': 800, 'h': 600, 'size': 74085}, {'_': 'PhotoSizeProgressive', 'type': 'y', 'w': 1280, 'h': 960, 'sizes': [14976, 29481, 33191, 49302, 87074]}], 'dc_id': 4, 'has_stickers': False, 'video_sizes': []}, 'ttl_seconds': None}, 'reply_markup': None, 'entities': [], 'views': 217, 'forwards': 2, 'replies': {'_': 'MessageReplies', 'replies': 0, 'replies_pts': 133065, 'comments': True, 'recent_repliers': [], 'channel_id': 1324044675, 'max_id': None, 'read_max_id': None}, 'edit_date': datetime.datetime(2024, 8, 15, 7, 18, 39, tzinfo=datetime.timezone.utc), 'post_author': None, 'grouped_id': None, 'reactions': {'_': 'MessageReactions', 'results': [{'_': 'ReactionCount', 'reaction': {'_': 'ReactionEmoji', 'emoticon': '😢'}, 'count': 6, 'chosen_order': None}, {'_': 'ReactionCount', 'reaction': {'_': 'ReactionEmoji', 'emoticon': '👎'}, 'count': 1, 'chosen_order': None}], 'min': False, 'can_see_list': False, 'reactions_as_tags': False, 'recent_reactions': [], 'top_reactors': []}, 'restriction_reason': [], 'ttl_period': None, 'quick_reply_shortcut_id': None, 'effect': None, 'factcheck': None}
		Saved 100 messages to MongoDB, avoiding duplicates.
		{'_': 'Message', 'id': 40155, 'peer_id': {'_': 'PeerChan


* git clone alex repo at blackmamba
*  faced the same problem with GitHub. Here's how to solve it!
https://stackoverflow.com/questions/21255438/git-permission-denied-publickey-fatal-could-not-read-from-remote-repository
				Generate a SSH key on your computer as described here : Generating SSH keys.
				Login your GitHub account: GitHub Login.
				In your account, add the newly generated SSH Key: My account SSH keys.
				Try again to git clone the project.


				ssh-keygen -t ed25519 -C "antonakd@gmail.com"
				Generating public/private ed25519 key pair.
				Enter file in which to save the key (/Users/despoina/.ssh/id_ed25519): 

				/Users/despoina/.ssh/id_ed25519_b
				ssh-keygen -t ed25519 -C "antonakd@gmail.com"
				Generating public/private ed25519 key pair.
				Enter file in which to save the key (/Users/despoina/.ssh/id_ed25519): /Users/despoina/.ssh/id_ed25519_b
				Enter passphrase (empty for no passphrase): 
				Enter same passphrase again: 
				Your identification has been saved in /Users/despoina/.ssh/id_ed25519_b
				Your public key has been saved in /Users/despoina/.ssh/id_ed25519_b.pub
				The key fingerprint is:
				SHA256:SgWn3Cvgpwnqi0mU5AsEVRpmZkZ4zQ3neKDfrr2ntGU antonakd@gmail.com
				The key's randomart image is:
				+--[ED25519 256]--+
				|.+X++oo .        |
				|o*.+o*.=         |
				| +o o = o        |
				|+ .o + . .       |
				|.+. o = S        |
				|o... * o         |
				|.o  o + E        |
				|+.   + +.        |
				|oo. . =+         |
				+----[SHA256]-----+
				(base) despoinsmacbook:~ despoina$ 


				!d...github 

				NOW DO THIS IN blackmamba!!!
				antonakd@blackmamba:~/TelegramCollector$ ssh-keygen -t ed25519 -C "antonakd@gmail.com"
				Generating public/private ed25519 key pair.
				Enter file in which to save the key (/home/antonakd/.ssh/id_ed25519): 
				 ssh-keygen -t ed25519 -C "antonakd@gmail.com"
				Generating public/private ed25519 key pair.
				Enter file in which to save the key (/home/antonakd/.ssh/id_ed25519): 
				Enter passphrase (empty for no passphrase): 
				Enter same passphrase again: 
				Your identification has been saved in /home/antonakd/.ssh/id_ed25519
				Your public key has been saved in /home/antonakd/.ssh/id_ed25519.pub
				The key fingerprint is:
				SHA256:B/A55RzrXibCDd3oZJV5R818qZYOY2LTLbRGx5PnuV0 antonakd@gmail.com
				The key's randomart image is:
				+--[ED25519 256]--+
				|      .   o oo.++|
				|       o * Oo=.o*|
				|        * % =.*.o|
				|       . & O = oE|
				|        S @ O   +|
				|         + + . ..|
				|          .      |
				|                 |
				|                 |
				+----[SHA256]-----+

				 cat /home/antonakd/.ssh/id_ed25519.pub
				ssh-ed25519 AAAAC3NzaC1lZDI1NTE5AAAAILvoWaODv17ptUt5a6wm/hhZhP1sreqVCwqviV4FRUDe antonakd@gmail.com
				antonakd@blackmamba:~/TelegramCollector$ 

1/10/2024
===================
* check input from Jack : Also, we will need to be more specific about the topic and title of your presentation, in order to announce it :) 
* Mhpws to scrpt den ta apothikeuei kala UTF8 unicode ktl ???


* Webinar title: Educational curricula alignment with the needs of the market."

* Jack : title :From student to job in cyber, from education programs to skill blocks - a French perspective
* Anna: Closing the gap between the needs of the cybersecurity industry and the skills of tertiary education graduates'. 

ECCO WG on skills is organizing a webinar on "Educational Curricula Alignment to Market Needs" on 6th November, from 11:00 AM -12:00 PM. Two inspirational speakers on bridging the gap between the educational needs and industry demands will be featured at this event. ECCO WG on skills is excited to listen to Prof. Jack Noel coordinator for cyber at Université Bretagne Sud (UBS), presenting "From Student to Job in Cyber: From Education Programs to Skill Blocks – A French Perspective", deciphering how French higher educational institutions are restructuring the courses based on demand for cyber security jobs. 

Prof.Anna Felkner from National Research Institute (NASK) in Poland  will talk about " Bridging the Gap between Cybersecurity Industry Needs and Tertiary Education Graduates Skills ", where she will points out how tertiary education fails to provide students on-the-job experience they need for practical applications of their cybersecurity professor, leaving those who enter this profession unprepared. 


sent email to both of them 

* papoutsakis nikolaos 

	 
		https://scholar.google.com/citations?user=aZUHomsAAAAJ&hl=el
		https://scholar.google.com/citations?view_op=view_citation&hl=el&user=aZUHomsAAAAJ&citation_for_view=aZUHomsAAAAJ:ULOm3_A8WrAC
		https://huggingface.co/docs/transformers/en/model_doc/deberta

		ma8hmata 5-6 

30/9/2024
===================
check if the script is nit saving the saming message swith the already saved in db 
* Timologia timesheets OK and sent 
* reminder to Jack about doodle OK  -I see that in Doodle Wednesday, 6 November, 11-12 GMT+2 works for both our presenters so we can save it. 
* *TODO* sent email to student nikolaos papoutsakis
* script for daily telegram, and old message sto mongo 
* Fix Two-factor authenticatio gitHub: tried through the default authentication app to reconfigure through the iphone--> password//> github . unsuccessfuyllu SO I used - >> sms as an alternative method that worked
* ECCO TRIP Brusseks 27, 28 Novemner . please confirm !
	Regarding the in-person meeting on 27,28 November is it finalized? Should we arrange the trip? 
* from our discussion with Alex new projects : 
	* telegram
	* medical data about teeth ? 
	* google maps images to classify political parties
	* (Alex) reddit , des log apo 23/9/2024

* scp -P 22599  antonakd@139.91.71.14:/home/antonakd/TelegramCollector/.py
* script adding old messages frm Telegram to mongo ready !
* adding nalysis to telegram project : 
	1. Figure 1: The Daily volume and activity of registered users.
	* how to connect to mongo:
		1. mongosh
		2. show dbs
		3. use Telegram (database)
		4. show collections
		5. use collection
		6. db.messages.find().limit(1) 


25/9/2024 
===================
Open your two-factor authenticator (TOTP) app or browser extension to view your authentication code. - Github fix 

fix this Traceback (most recent call last):
  File "getOlderMessagesTelegram.py", line 60, in <module>
    all_messages = rate_limited_get_messages(chat_name)
  File "getOlderMessagesTelegram.py", line 40, in rate_limited_get_messages
    results = asyncio.run(get_old_messages(chat_name=chat_name, limit=message_per_channel, offset_id=offset_id))
  File "/Users/despoina/opt/anaconda3/lib/python3.7/asyncio/runners.py", line 43, in run
    return loop.run_until_complete(main)
  File "/Users/despoina/opt/anaconda3/lib/python3.7/asyncio/base_events.py", line 579, in run_until_complete
    return future.result()
  File "getOlderMessagesTelegram.py", line 17, in get_old_messages
    async with TelegramClient(session_name, api_id, api_hash) as client:
  File "/Users/despoina/opt/anaconda3/lib/python3.7/site-packages/telethon/client/auth.py", line 657, in __aenter__
    return await self.start()
  File "/Users/despoina/opt/anaconda3/lib/python3.7/site-packages/telethon/client/auth.py", line 135, in _start
    await self.connect()
  File "/Users/despoina/opt/anaconda3/lib/python3.7/site-packages/telethon/client/telegrambaseclient.py", line 558, in connect
    self.session.auth_key = self._sender.auth_key
  File "/Users/despoina/opt/anaconda3/lib/python3.7/site-packages/telethon/sessions/sqlite.py", line 180, in auth_key
    self._update_session_table()
  File "/Users/despoina/opt/anaconda3/lib/python3.7/site-packages/telethon/sessions/sqlite.py", line 194, in _update_session_table
    c.execute('delete from sessions')
sqlite3.OperationalError: database is locked

for getOlderMessagesTelegram.py  MAYBE violating rate limit ? 

TODO print a message indicating the progress in this  : python TelegramCrawlerPagination.py 
Saving to pal_Online9__2024_09_24_12_30_34.txt


--> pal_Online9__2024_09_24_12_30_34

27/9/2024
==================
sript to mod=go ready. 
fix old messages script!

OK doodle sent for ECCO !
TODO sent Jack to pick a topic !!! IMPORTANT!

ok Sunanthsh me neo foithth me onoma Γιώργος Γιαλούρης gia tetath 11-12

			Καλημερα, επιδη εχουν γινει καποιες αλλαγες στο προγραμμα, θα το μιλισουμε τεταρτη 11-12 online στο google meet.

			Undergrad discussion
			Wednesday, October 2 · 11:00am – 12:00pm
			Time zone: Europe/Athens
			Google Meet joining info
			Video call link: https://meet.google.com/cbt-zsvb-fji
			Or dial: ‪(US) +1 423-707-2255‬ PIN: ‪369 994 811‬#
prova parousiashs panagiwtas tetarth 1600 ...

 
24/9/2024
==================
*Γιωργος Κονοφαος, φοιτητης για Telegram*
1. Δες αν θες και τον δικο μου crawler .
2. Des to rate limit : Original resource: https://medium.com/@ishitagopal/collecting-messages-from-telegram-using-telegrams-api-and-python-5d7e4a9286b2
Library documentation: https://docs.telethon.dev/en/stable/modules/client.html
"""
3. Πρέπει να μπουν σε mongo DB , οπότε θα ζητήσουμε access απο Αλεξ να στίσεις, αν και νομιζω υπάρχει ήδη και ας βαλουμε τα μυνηματα εκει. 

4. Θελουμε να δουμε πως παει αρχικα και μετα ανάλυση. Ιδανικα θα θέλαμε να βρούμε κατι malicious ...bot/fraud? παράλληλα μπορέι να γινει και analysis volume / cdf / και topic analysis kai sentiment anaysis. berta https://huggingface.co/cardiffnlp/twitter-roberta-base-sentiment

5. google scholar: 
	 US Extremism on Telegram: Fueling Disinformation, Conspiracy Theories, and Accelerationism - 2021- 105 citation 
	 Deplatforming: Following extreme Internet celebrities to Telegram and alternative social media - 2020 - 465 citations 
	 What they do in the shadows: examining the far-right networks on Telegram - 2022 - 264 citations 
 
 
23/9/2024
==================

*reddit* 
			multiple accounts stelnoun to idio pragma oxi ena bot na stelnei ta idia pragrmata opws kaname palia 

			creation date 

			ta afhnoun kai palionoun ..mhpws attacks se account ta kaneis compromize accout kratas to date creation kai 

			html scraping reddit 

			mporw na ftiaxw kai diko mou bot gia na to kanw demo 

			chat gpt vgazei apoyeis kai stelneis tis apoyeis aytes sto reddit comment 

			https://dl.acm.org/doi/abs/10.1145/3313294.3313386

			https://github.com/nateray42/DeCoBot

			----------
			 Multiple accounts are posting the same content not the same bot posting same content as we used to do.
			 Based on having an old creation date . Maybe also compromise existing accounts and only keep date creation How ? html scraping reddit I could also make my own bot in order to demo (maybe 6 months ) use chat gpt to produce opinions , post then on reddit and make me seem legit. after that I sell the bot . https://dl.acm.org/doi/abs/10.1145/3313294.3313386https://github.com/nateray42/DeCoBot

			-------------------------------
			Multiple Accounts Posting the Same Content
			It seems that multiple accounts are posting the same content, but these are not the same bots that used to repost identical content. These accounts might have:

			Older creation dates: This could indicate that legitimate accounts were compromised, or inactive accounts are now being used for this activity.
			Account compromise: The tactic could involve taking over existing accounts and leveraging their credibility based on their older creation dates, while keeping minimal changes.
			Reddit HTML Scraping
			You could potentially use HTML scraping techniques on Reddit to detect such patterns of activity and gain insights. This could help in identifying compromised accounts by scraping account creation dates and content patterns.

			Bot Demo
			You mentioned the possibility of creating your own bot for a demo. This can certainly be done. You could use tools like GPT to generate opinions and automatically post them as Reddit comments. Here's a related research paper for building such bots:

			ACM Research on Bot Content Automation
			DeCoBot on GitHub
			With these resources, you could automate content generation and posting, potentially mimicking the behavior you’re analyzing.

23 September
==================
 

1. check this link : for ecco webinars full list https://ecsorg.sharepoint.com/sites/ECCOProject/Lists/ECCO%20Webinars/AllItems.aspx?viewid=2239c8bd%2De919%2D4b4e%2Da145%2De5c0bfa238ab

2. check again the crawler see vbelow for times of running in the day . mongo 

3. Invite presenters!! for ecco  OK Anna OK and Paresh 

4. respond to kwsnantina@Women4cyber Greece  ΟΚ 

5. Reply to Anna about the webinar 
		anna proposed topic of  “Closing the gap between the needs of the cybersecurity industry and the skills of tertiary education graduates”

		 as seen below in the attached email . Would that be interesting for our webinar? It is not in our list of topics though..
	
			• Education and awareness (incl. cyber hygiene) for youth.
			• Leveraging cyber competitions to engage youth in cyber.
			• Impact of AI on skills and the workforce.
			• Academia-industry collaboration on skills.
			• Awareness of Social Engineering.
			• Educational curricula alignment with the needs of the market.
			• Tools for hands-on technical education in cybersecurity including
			fighting cybercrime.
			• Security and privacy ‘by design’ approach in training and education
			for IT professionals.

6. volotea valitsa > ? cgheck in 
7. timesheets OK 
8. Timologia OK 


20 September 2024
==================
ALL webinars we have done for ECCO in our WG on skill group: 

			ECCO Community Group Webinar: 

			1)Community Group on Skills Knowledge-Sharing Webinar: Roadmap & Cyber Ranges for Education and Skills Development, 6 March 2024,   

			-2) Building Youth Communities for Cybersecurity through Competitions, 12 April 2024, 


			3)Cyber Games and Initiatives for Youth, 31 May 2024.


*NEW ETRIES entries : *
Description: During this second webinar the main coordinators from pilots CONCORDIA and ECHO are going to present some of the most important outcomes regarding education and skills. The webinar will consist of two parts: The first will focus on the Cybersecurity Roadmap for EU including the main challenges - based on findings when assessing CONCORDIA’s courses portfolio - along with the recommendations answering but also complementing some of the actions put forward by the European Commission in the Digital Education Action Plan (2021-2027). 

The second part of the webinar will demonstrate the federation of interconnected cyber ranges that form the foundation of the ECHO demonstration cases, providing the host environment in which three demonstration cases executed to demonstrate the added value that cyber ranges bring in the development of technology roadmaps, cyberskills development, as well as certification testing. 

 *speakers* 

Despoina Antonakaki (CONCORDIA - TUC) - Roadmap for Education and Skills - 20min. 
Matteo Merialdo (ECHO - RHEA Group)- Leveraging cyber ranges for skills and competence development - 20min. 


Despoina Antonakaki  - dantonakaki@tuc.gr
Matteo Merialdo - m.merialdo@rheagroup.com


*check crawler ka8e pote na trexei posa na katevazei screen crone job?*

30 messages pers second 
1000  x = 1000/30 = 34 second


1) prepei na graftei ena neo script pou na travaei ola ta munhmata pou exoun stalei mexri twra (mesw ths         async for message in takeout.iter_messages(chat, wait_time=0):
) des edw : https://docs.telethon.dev/en/stable/modules/client.html#telethon.client.messages.MessageMethods.iter_messages


2) yaxe perissotera  Latestine channels on telegram:

https://t.me/wolpalestine


3) prepei meta apo ola ta script ta arxeia apo telegram na mpoun sthn mongo sto black mamba
4) ftiaxe to git sto black mamba 

19 September 2024
=====================
*Telegram API* 

~30 users per second
The API will not allow bulk notifications to more than ~30 users per second, if you go over that, you'll start getting 429 errors.

30 requests per second
However, Telegram imposes an API rate limit of 30 requests per second. Consequently, there exists a restriction on the volume of updates that can be sent via the API each day, posing a scalability

*ECCO mail for inviting presenters*
*crawler telegram gia palaistini* 

percentage of AI content on web https://scholar.google.com/scholar?hl=el&as_sdt=0%2C5&q=percentage+of+AI+content+on+web&btnG=

18 September 2024
=====================
*new research project GOOGLE GRAFITI*

get data from streets and apply topic analysis, or classify based on the political movement 

*TODO* STEILE link ston sotiri gai ta data apo metereologika OK 
*TODO* taxidi stis bruxelles   ?? esteila mail tracci
*TODO* steile upen8umish sotiri gai to mail gia to webinar gia to Skarmeta + Jose Luis  OK

*ECCO*

*TODO*
Sotiris will contact on skills --> Jose Luis Hernandez, Antonio Skarmeta

		Sotirios Ioannidis

		Να γράψουμε ενα κοινό email; αν ναι:


		jluis.hernandez@um.es
		skarmeta@um.es
		============================
		Dear Jose Luis and Antonio,

		Thank you for being part of the Community Group on Skills of ECCO .
		Regarding our next webinar on the Knowledge Sharing events,  would you be willing to give a presentation on one of the following topics : 

		•                      Education and awareness (incl. cyber hygiene) for youth.
		•                      Leveraging cyber competitions to engage youth in cyber.
		•                      Impact of AI on skills and the workforce.
		•                      Academia-industry collaboration on skills.
		•                      Awareness of Social Engineering.
		•                      Educational curricula alignment with the needs of the market.
		•                      Tools for hands-on technical education in cybersecurity including fighting cybercrime.
		•                      Security and privacy ‘by design’ approach in training and education for IT professionals.

		Ideally, your presentations should be coupled on the same or similar topic.
		The timeslot should be during the next month or two. 
		Hope we could find a match of topics between you two.

		Thank you

		or Anna ... 


*telegram Crawler* 

asked Alex about async

*Panagiota thesis* link overleaf :  
12 September 2024 
=====================

*potential presenters for ECCO*
		1) polemi  - send munhma to pinelopi + sotiris ...waiting ...
		2) Elias athnasopoulos + Eva ? topic? 
		3) Konstantinos Votis
		Notis Mengidis
		Mariana S. Mazi
		George Lazaridis	@ "Virtual & Augmented Reality Lab
		Visual & Analytics Laboratory
		Information Technologies Institute
		Centre for Research and Technology Hellas" 
		...einai ston idio organismo 8a mporousan na epilexoun ena 8ema mazi ? 
		4) Anna felkner isws apo to expertise ths •                      Security and privacy ‘by design’ approach in training and education for IT professionals. ? mporei vevaia na dialexei ....

			Trust ManagementInformation and Communication TechnologySecurityComputer SecurityInformation SecurityAuthenticationNetwork SecurityElectronics and Communication EngineeringComputer NetworkingNetwork CommunicationNetworkingNetwork ManagementData SecurityIT SecurityComputer Networks SecurityInformation Systems SecurityInternet SecuritySystem SecurityInformation Security ManagementComputer Security and IT ForensicsWeb SecurityPKIData ProtectionSoftware SecuritySecurity Risk ManagementSecurity InformaticsDistributed database Security

SE trust mporei na milhsei kai o pilia!!!


Topics 


•                      Education and awareness (incl. cyber hygiene) for youth.
•                      Leveraging cyber competitions to engage youth in cyber.
•                      Impact of AI on skills and the workforce.
•                      Academia-industry collaboration on skills.
•                      Awareness of Social Engineering.
•                      Educational curricula alignment with the needs of the market.
•                      Tools for hands-on technical education in cybersecurity including fighting cybercrime.
•                      Security and privacy ‘by design’ approach in training and education for IT professionals.


Other names 
	Jacqueline-kehoe on This includes both technology transformation alongside supporting employees in adopting these new practices through upskilling and mentoring den mporw na vrw match me ta topics mas 

	Cybersecurity Strategist & Business Manager at Siemens Energy

*search proposals* 
	ta idia tessera asxeta ...https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/calls-for-proposals?order=DESC&pageNumber=1&pageSize=50&sortBy=relevance&keywords=women&isExactMatch=true&status=31094501,31094502&programmePeriod=2021%20-%202027


  *presentation @ ECCO* 

  TUC is moderator so intro for our webinar 

			Description
				With the rapid evolution of the digital landscape and a pressing need for cybersecurity expertise in Europe, the ECCO project, alongside ECSO and the main coordinators of the four Pilot projects on Competence Centres (UniBwM and TIS for CONCORDIA; RHEA for ECHO; UMU and Goethe Uni for CYBERSEC4EUROPE; CEA, CNR and Fraunhofer for SPARTA) are committed to addressing the critical gap in cybersecurity professionals through education and training initiatives.
				 
				Through knowledge sharing among the main stakeholders and with the NCCs, ECCO will support the building of a strategic planning and roadmap to support the objectives of the ECCC and implementation of its Strategic Agenda, and help the ECCC/ NCCs to implement effective solutions on skills.
		
			Important to note

		  	Important to know that we organize a series of webinars and the discussions that are going to take place indent to be complementary to the * ECCC WG5 and not indent to duplicate discussions or tasks that are linked to EU cybersecurity skills academy*. So the community sessions are indented to gather the community of experts on skills and the NCC networks and exchange approaches ???.		

			Introduction from Nina
							Synergies from CS . These communities essentially are intended to be forth for discussions and knowledge sharing  between experts from wider CS on strategic topics for interest to the NCC

							important to know that we organize a series of webinars and the discussions that are going to take place indent to be complementary to the ECCC WG5 and not indent to duplicate discussions or tasks that are linked to EU cybersecurity skills academy. So the community sessions are indented to gather the community of experts on skills and the NCC networks and exchange approaches ???.

							these topics we wish to reach the work of ECCC WG5 -   and topics to include roadmaps and cyber ranges covering to use education and so ,,,

							NCCs

							So we wish the current and coming knowledge sharing events will be useful and give opportunity to support the ECCC strategic agenda 
		
			 Alternative intro 

						The ECCO project, in collaboration with ECSO and the EU funded projects on Competence Centres, has established a Community Group on Skills to exchange on skills-related topics that may be of interest to and complement the work of the ECCC and NCCs.
					 
					 Through these knowledge sharing events among the main stakeholders and with the NCCs, ECCO will support the building of a strategic planning and roadmap to support the objectives of the ECCC and implementation of its Strategic Agenda, and help the ECCC/ NCCs to implement effective solutions on skills.

					The current webinar will feature esteemed speakers sharing their expertise on the engagement of young people in cybersecurity:

					Jens Myrup Pedersen, Aalborg University, will discuss strategies for engaging youth in cybersecurity competitions, fostering community-building, and showcasing educational and career pathways.
					Birgy Lorenz, Tallinn University of Technology (TalTech), will share insights into efforts to include girls in IT and cybersecurity in Estonia, addressing challenges and integrating gamified interventions.
					Joe Pichlmayr, CyberSecurityAustria CSA, will delve into the AustriaCyberSecurityChallenge (ACSC) and its role in talent development and education, shedding light on its impact on Austria's security ecosystem.



5 September 2024
===================

*No news from new proposals : https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/calls-for-proposals?order=DESC&pageNumber=1&pageSize=50&sortBy=relevance&keywords=women&isExactMatch=true&status=31094501,31094502&programmePeriod=2021%20-%202027

*Yet another reveiw @SNAPP:*

Public Attitudes Toward Higher Education on Twitter Using Sentiment Analysis and Topic Modeling


  
The study performs a sentiment and topic analysis on a Twitter dataset in a challenging period in terms of the data collection, taking into consideration the monetization of Twitter. However, it lacks originality, considering also that half of the manuscript is AI generated and analytical depth. The findings are not new or important enough to be published as they are now. The paper would do well to  involve deeper theoretical perspectives, and use more complex analysis tools.


Strengths:
Comprehensive Data Collection: This study uses various statistical procedures and sentiment analysis tool to effectively gather a dataset of tweets about the higher education that represent a significant time frame and investigating essential keywords and trends. This diverse set of data allows for a very large survey of public views and involvement.

Multiple Analytical Methods: The methodology of using techniques such as sentiment analysis, topic modeling, bigrams, trigrams, and temporal patterns contributes to a holistic understanding of the higher education discussion. Latent Dirichlet Allocation (LDA) and TF-IDF including the introduction sign are examples of even better methods of drawing wisdom out of data. However some proposal regarding the methodology, is to use better alternatives to LDA like Bert Topic MOdelling, which due its architecture, it can better comprehend semantics, contexts, and nuances within the text data, providing better topic quality giving a more meaningful and coherent topics compared to LDA.

Temporal Analysis: Time series analysis among other techniques can provide valuable insights, pointing out for example peaks of interest around major events, like ChatGPT versions release. This helps put the data into context and gives a clear picture of the public's grappling with information.
Social Engagement Metrics: The reports of social engagement metrics counts, mentions, retweets and replies mean that it is possible to track the involvement of one's followers with a certain tweet on Twitter. The comparison is based on which one is the most preferred way to show endorsement between likes and retweets or replies and it is found that people prefer passive endorsement.

Weaknesses and Reasons for Rejection:
Lack of Novelty and Insight: The paper, though using standard procedures such as sentiment analysis and topic modeling techniques, does not come up with new ideas or valuable empirical contributions that are not known until now. The results confirm the existing action of online media in the society in agreement with rather finalized standards and thus in the absence of some new theories, it can be stated that no major advances are made in this field.

Regarding Geographical Bias, the concentration on tweets coming from mainly English-speaking countries such as the US, the UK, and Australia, hinders the generalizability of the outcomes. Although this is acknowledged, the paper does not hit on the implications of this bias well or provide strategies to overcome it.
Redundancy and Repetition: The paper falls into some redundancy, like in the specific case of the discussion of sentiment trends over time as well as the interpretation of engagement metrics. The duplicate account also leads to paper coherence and focus loss.





2 September 2024 
===================
Review Harmonizing Textual Signals: Advanced NLP for Sentiment Analysis in News Media Narratives
This study seems to be AI-generated considering, as seen in the file attached, it is more than 60% AI-authored, also considering such poor results. The study does not indicate any clear novel contributions and how it stands out from existing research. It does not seem to present any newer contributions in advancing the area. Although it mentions employing advanced methods such as RNNs with LSTMs, it does not explain how this particular study is different from most studies that use these methods.

The study makes sure to highlight careful web scraping and extensive preprocessing, but there is not much on the how and especially, how the data was validated. This too raises a possibility of the study being questioned in terms of how detailed it is, and the realism and reproducibility of the work. The methodology used is off the shelf without contributing a novel methodology. 

No clear research question that is targeted within the context. It explains what was done in the study, but not the reason why such procedures were carried out or what particular problem warranted the research.


 Lack of Detail on Methodology:
Deficient Elucidation: While the methodology does contain a sequence, the approach is not explicatory enough about the sentiment analysis by not mentioning the individual steps employed. For example, the table of preprocessing, feature extraction methods, and the criteria for selecting models (LSTM, BERT, GPT) is not provided in detail.Vis-a-vis Flowchart: A notation to a flowchart (Fig. 1) with no corresponding content definition raises doubts as to the methodology's clarity, completeness, and alignment.

 Unexplained Variability in Data:

Through Histogram Analysis: The diagram points out to show a variability in the counts of the articles among different publications but it should explain how this affects the sentiment analysis. The paper should dedicate a section to discuss the potential interference of the unequal number of articles per publications.

Lack of Validation: The conclusions of this paper are based on a hypothesis that does not get properly tested, with no comparisons made.

Potential Bias in Sentiment Analysis:

Preponderant Positive Sentiments: The observation that the majority of articles are classified as 'Positive' without a detailed explanation of the reasons or the consequences brings out questions. The paper should introspect into the main reasons the positive sentiment is so strong and think whether these results could be due to certain biases or limitations in the sentiment analysis method.

Insufficient Discussion on Sentiment Categories:

Neutral Sentiment: The paper has brought up the point of 'Neutral' articles being few in number but has not given a thorough analysis. The paper should dig deep into what the relatively small number of neutral publications means and if it at all has an indicative force for the missing of other parts of the sentiment classification.

Geyser water 2 
3991HK   Houten Netherlands
UTRECHT
The Netherlands
Mobile phone: +31 618475031

26 August 
==============
adeies 
timologio
timesheets
scraper


30 July 
==============

1. timologio 
2. countries of US 
3. Stavros ok kaname sunanthsh kai arxise na mou prousiazei provlhmata me format tou cel file kai tetaoia . eipame arxikan na xeinhsei me literaturte reveiw , na dei methogdologies ti kanoun oi alloi kai na ka8orisei ti 8a kanoume emeis . 

4. emanulea asonam ok to kanme retrackt 
5. asonam lambrou ok submitted
6> TODO states for RISK II ,... 
27 June 2024 
----------------

timesheets ITE 
timologio 
reveiw lambrou 
paris proaithmasia 
thlefwno giattros gi mena 
---------------------

Sunday 16/6/2024 Louvre 
17/6/24 disneyland Deutera

RE: Reservation at Apartment Centre de Paris Le Marais for Jul 3 - 8, 2024

alid on 5 July 2024

lessons learned , community -  a strategic view. in order to animate the community ad how to aniamate the community and lesons leaened . 

major point !!what are webinar are used for ...

link with ojectives we had on top . adbvance on the aspects with evccc strategic agenda . link with ojcteives of eccc 
what is the bottom up leassons learned . 

how the webinars  are useful for eccc BY THURDSDAY morning !


question : add leasson leranedin activit tracker ? where? 



17 / 6/ 2024 

photos ok 
ευρωπαική κάρτα ασφαλισης οκ 
αδεια αναιρεσξ οκ 
αδεια νεα
λαπτοπ οκ 

4 June
===========
#USElections 
#uselections 
#elections2024 
#potus
#biden
#trump  
#DonaldTrump
@Elections2024__

@2024USELECTIONS
@VP
@potus
@trump

Court related: 
#stormydaniels 
#court
#US #USA

31 May 
===========
ECCO webinar

Meeting minutes question and important points that we will use to take the follow up text  to ECSO. 

Introductions by Nina Olesen

27 participants registrants ??? 

- Emily Jacometti, HackShield
		
		( 5 years) gaming great tool to exchange knowledge HackShield https://hackshieldgame.com/en/. We went them  kids to school to learn about CS but we created a game
		Junior cyber agent help protect parents and grant parents 

		why gaming. it is a safe environment to make mistakes and learn see the consequences . free

		Made sure that lessons can be given to everyone . with no prior knowledge of the teachers 
		validated the learning effect. process and impact with awards .
		easy to join 

				*PRETIFIED*
				Gaming as a Tool to Exchange Knowledge: HackShield

					Introduction:

					HackShield: A gaming platform that has been an effective tool for exchanging knowledge over the past 5 years. HackShield
					Objective: We introduced kids to schools to learn about cybersecurity through a game we created.
					Junior Cyber Agents:

					Role: The game helps children become Junior Cyber Agents who protect their parents and grandparents online.
					Why Gaming?

					Safe Environment: Gaming provides a safe space where children can make mistakes, learn from them, and see the consequences without real-world repercussions.
					Accessibility: The platform is free, ensuring that it is accessible to everyone.
					Educational Integration:

					Teacher-Friendly: The game is designed so that lessons can be delivered without any prior knowledge required from teachers.
					Validation: The learning effects, processes, and impacts have been validated and recognized with awards.
					Ease of Access: The platform is easy for students to join and participate in.


		questions 
		*from chat*
			1) NCC-PT António Costa • emily how can we engage and translate to PT/PT and implement the program at the national level?

					answer . need adjeustments to reach taht. work wth private colabotaion or govermental collabotaion. work with municipality / police / organizations locally . eg. protugal can run it

			2) Can you share the validation report on process and impact

					She will share the website 

			3) Marie oxi sto chat .. how you started marketing to children ? 

					Emily sayws they are not a big company fortnite . no marketing  in the beginning. children to other children police and local organizations. invest a lot of time in community , Took 4-8 months to reach hunders and then some months to reach thousand . 

					parents also prefers to play educational game  . 
						*PRETIFIED* : 

								NCC-PT António Costa: Emily, how can we engage and translate to PT/PT and implement the program at the national level?

								Answer:
								To reach that goal, adjustments are needed. Collaboration with private entities or government bodies is essential. Working with municipalities, police, and local organizations is crucial. For example, Portugal can run it by leveraging these collaborations.

								Can you share the validation report on process and impact?

								Answer:
								She will share the website with the relevant information.

								Marie: How did you start marketing to children?

								Answer:
								Emily explains that they are not a big company like Fortnite, so there was no initial marketing. The strategy involved children communicating with other , supported by police and local organizations. A significant investment of time in community engagement was necessary, taking 4-8 months to reach hundreds and additional months to reach thousands. Parents also prefer educational games so they received a look of good feedback on this.




							*chat*
							ECCO • Welcome to today’s ECCO Community Group skills webinar! Please keep your microphones muted during the presentations. A Q&A session will follow at the end, and you’re welcome to unmute and ask questions or use the chat box. You can also introduce yourself in the chat box anytime. To join ECCO’s Community Group on skills, please email us at: community_skills-owner@list.cyber-ecco.eu 

							Brandon Vella - AcrossLimits • Good morning everyone, Brandon Vella from AcrossLimits [ https://www.acrosslimits.com/ ], a Malta-based consultancy with a focus on EU funds, having participated in over 80 successful projects over the past 20 years encompassing various fields, including; eLearning, innovation, digtisation, entrepreneurship, health and culture. Please contact us on brandon@acrosslimits.com to explore collaboration opportunities together.

							NCC-PT António Costa • emily how can we engage and translate to PT/PT and implement the program at the national level?



- Giorgia Bassi, CNR
Similarly as the previous game this games also include  roles (protagonist Nabbovaldo) . There are some training courses for the teachers , provided questionnaires and of course there are session at home by the children. The classroom activities are remote supervisioned by the staff of Ludoteca. Finally there was a questionnaire ex-post . 

evaluation:  it was investigated by the questionnaires on 438 students of 6 schools in Toscany 50.9% males 48.2% females 
83.8$ of the sample connects by smartphone 
53% have at lease on SN profile but only 24% private profile 

evaluation (1-10): 7.26 with comments useful and fun 
https://www.ludotecaregistro.it/

https://www.youtube.com/watch?v=YQy8pqol36c
							PRETIFIED 
						Similar to the previous game, this game includes role-playing elements with the protagonist, Nabbovaldo.
								Teacher Training: Training courses are provided for teachers.
								Student Engagement: Questionnaires are administered, and sessions are held at home by the children.
								Classroom Activities: These activities are remotely supervised by the staff of Ludoteca.
								Evaluation: An ex-post questionnaire is administered to assess the outcomes.
								Evaluation Details:
								Sample Size: Questionnaires were completed by 438 students from 6 schools in Tuscany.
								Gender Distribution: 50.9% males and 48.2% females.
								Device Usage: 83.8% of the sample connect via smartphone.
								Social Network Profiles: 53% have at least one social network profile, but only 24% have a private profile.


									As a paragraph 

									The game, featuring the protagonist Nabbovaldo, integrates role-playing elements similar to previous iterations. To support educators, training courses are provided, ensuring they can effectively facilitate the game-based learning experience. Students engage with the content through administered questionnaires and at-home sessions, which are remotely supervised by Ludoteca staff. Evaluation of the game's impact is conducted via an ex-post questionnaire. The evaluation involved 438 students from six schools in Tuscany, with a gender distribution of 50.9% males and 48.2% females. Notably, 83.8% of the students connect via smartphones, and while 53% have at least one social network profile, only 24% maintain a private profile.


							*chat*

							None 

							Anamaria Magri Pantea : she is involving in project related to education enhancing CS and future educators. Various resources that could be used towards this direction . They are interested in tools and game. can both game in English and Italian and the training program used in class is of free ? several countries are involved  that could be interested .

									Giorgiaa all resources are available in teh website .You can download all material . but now only in Italian.   they hope to finish translation soon . 
									
									Emily the first game is also available in German (will be soon available in Austria)


							Criminological perspective  - victimology (Stewart Kowalski Norwegian University of Technology ) Are there any statistics on this > e.g cyberbullying . Cybercrime opportunites structure 

									Emily . partially they have partly integrated . She will find material to send . 

									Povilas K. is it is like used cryptocurrencies ? 
									Stewart : No in the game community you buy tools or cheats and spend money on resources of the games in order to win .
									victimology. 




https://europeancybersecurityorganisation-mzu.my.webex.com/europeancybersecurityorganisation-mzu.my/j.php?MTID=m93440b67d0556d4dde989fa3f48cf21f

--  

TODO des statistika posoi i katee8esan gai thn protash : NetEve	 - Empowering Women for Advancement in the Digital Future	 - Advanced Digital Skills (DIGITAL-2024-ADVANCED-SKILLS-06)	 - Girls and Women in Digital, DIGITAL-2024-ADVANCED-SKILLS-06-WOMEN	https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/digital-2024-advanced-skills-06-women?status=31094501,31094502&frameworkProgramme=43152860&callIdentifier=DIGITAL-2024-ADVANCED-SKILLS-06&order=DESC&pageNumber=1&pageSize=50&sortBy=startDate	29 May 2024 17:00:00 Brussels time - submitted	150K	TUC	NASK (Anna Felkner)	Despoina Antonakaki		NASK (Anna Felkner)	Final Draft Ready 																


24 May 
===========
O Kai xekinhse thn kouventa kata poso einai visbile ta webinars. kai giati to site den einai pio xeka8aro pot kai pou ienai exei calndar ktl POoi mas kanei restrict kai den mporoume na ta allaxoume ta llink kai to perioexomeno to websute . Meta t a phre o Antioniokai h8ele na paraith8ei !! 

ton ka8hshxase o Roberto me genikes plhrofories gai to pws douleuei to ergo . alal den apanthse etelika o Antonio Antonio Skarmeta an 8a pareith8ei telika . 

kai if you dont feel restricted , ny the NCC or the comission who is the owner f these pricesses . Kai feels restricted ..this while communtuu is a mess is the ECC teh commission ? 

Roberto ..please write an email to us first (ECSO ) and then send it to comission ktl ...We work as a consortium 

Roberto does not see where the concern is with the process 

17 May
===========
reveiw Study of the Problems of Determining Public Opinion of the Israeli-Palestinian War in Social Networks
1. The abstract, Introduction, Formulation of the problem, Analysis of recent research and publications, Analysis of recent research and publications
Purpose of the article, The main algorithm process part, an Conclusions 



 is a AI-generated . (https://copyleaks.com/)

16 May
==========

Protergia Hron Mhtsos ok 
teliko budget gia NetEve: 
			 WP1 1 PMs
		WP2 4 PMs
		WP3 7 PMs
		WP4 8 PMs
		WP5 3 PMs = 23 PMs total (23*6000=138.000)

		Travel 
		WP1 4 (6000)
		WP2 2 (3000)
		WP3 0
		WP4 2 (3000)
		WP5 0 

		Budget  = 150.000-->  23PMs x 6000 PMs + 12000 (travel) 

NIPS des to guidelines + appendix ti mprei na mpei . lind review ara to zenodo prepei na einai anonymized 

1. can often not be reviewed in a double-blind fashion, and hence full anonymization will not be required. OTI NANAI!
2. A key criterion is accessibility: datasets should be available and accessible, i.e. the data can be found and obtained without a personal request to the PI, and any required code should be open source (Croissant format )
3. Submit supplementary materials such as detail on *how* the data was collected and organised, *what kind of information* it contains, how it should be used ethically and responsibly, as well as *how it will be made available and maintained*
SUBMISSIONS. 
1. There will be *one* deadline this year. 
2, It is also *still possible to submit datasets and benchmarks to the main conference* (under the usual review process), but *dual submission to both is not allowed* (unless you retracted your paper from the main conference). 
3. We also cannot transfer papers from the main track to the D&B track. 
4. *Authors can choose to submit either single-blind or double-blind. If it is possible to properly review the submission double-blind, i.e., reviewers do not need access to non-anonymous repositories to review the work, then authors can also choose to submit the work anonymously.* 
4. Papers will not be publicly visible during the review process. Only accepted papers will become visible afterward. The reviews themselves are not visible during the review phase but will be published after decisions have been made. The datasets themselves should be accessible to reviewers but can be publicly released at a later date (see below). New authors cannot be added after the abstract deadline and they should have an OpenReview profile by the paper deadline. NeurIPS does not tolerate any collusion whereby authors secretly cooperate with reviewers, ACs or SACs to obtain favourable

15 May
==========

ECCO webinar 31 May ok registered and sent to punelopi 

Not sure how is different from the profile, I added a paragraph. 

	TUC established in 1977 in Chania, Crete, financed by various entities, including the European Union, the General Secretariat for Research and Technology, governmental bodies, regional authorities, and private enterprises is renowned for its commitment to both fundamental and applied research. TUC is actively conducting basic and applied research in the areas of telecommunication systems/networks and network services, networking hardware, sensors, RF, and high-performance computing systems, machine learning, information systems, big data analytics, signal processing for telecommunications, speech, language and image processing, and biomedical applications with numerous excellence awards in these areas. Every year TUC attracts a large number of undergraduate and postgraduate students employed in these projects to benefit from the best training and conducted reaserch and has established close cooperation with many foreign universities. Specifically more than 25 cooperation protocols have been signed with European, American and Asian Universities. TUC has acted as a coordinator in several H2020 projects, including FET along with extended experience in FP6, FP7 projects. Prof. Ioannidis has a vast experience in Coordinating and participating in security-related H2020 and INEA-Funded projects with his team active in a various areas of systems and cyber security, producing high-end research results, published in the most distinct security conferences, creating beyond state of the art R&D tools and operational production solutions, in the context of RIA, IA and INEA projects.


	pio suntomo cv tou sotiri : He was a Member of the ENISA Advisory Group (AG), the National Infrastructures for Research and Technology (GRNET) Advisory Committee (AC) and Member of the Advisory Committee for National Infrastructures for Research and Technology. He is Chairman of Committee of Ethics and Deontology of Research of FORTH. His research interests are in the area of systems/network security, security policy, privacy, and high-speed networks with >200 publications in international conferences, journals and book chapters, while chaired and served on program committees in prestigious conferences (ACM CCS, IEEE S&P). He is a Marie-Curie Fellow, participated in numerous international and European projects and been PI of 40 European, National and DARPA projects, attracting in excess of 12 million euros(Project Coordinator in 14).

sunanthseis gai colocaton ecco  wg meeting : 
https://nmiotc.nato.int/wp-content/uploads/2024/03/save_the_Date-1-1024x772.png

https://nmiotc.nato.int/wp-content/uploads/2024/03/8th_Cyber_Security_Conference_Save-_the_Date_Letter.pdf
https://nmiotc.nato.int/transformation/conferences/annual-conference/


paper : https://www.overleaf.com/project/64cb9494cfbe453c6e91ad87 NIPS!
14 May
==========

*vale sto* proposal 

 

		At the national level - each of participants will prepare a set of recommendations (T.3). In Poland applications will be forwarded to the Chairwoman of the Council for Women in the Labor Market who will be also involved in the national working group. One partner will focus on the Benelux region, where considerable disparities exist between neighbouring countries.
		In Greece we will get in contact with Women4cyber Greece chapter to consult regarding the reccpmedatiosn filling the gender gap. 

		To address the gender gap in cybersecurity in Greece, we plan to reach out to the Women4Cyber Greece chapter for consultation on recommendations. This initiative aims to promote gender inclusivity and diversity within the cybersecurity community with Stella Tsitsoula as Vice-President, Co-Founder & Comm. Lead and Alexandra Michota Vice-President, Co-Founder & Mentorship Programme Lead.


		The project is based on a sound needs analysis that identifies key barriers for women in the ICT sector, such as lack of role models, gender biases, and limited access to technical education. By addressing these issues, the project targets specific needs that are documented through various studies and reports at both global, European and national levels. 
*ECCO*  
	The main key lesson learned during this webinar included the importance of cyber awareness in primary school, acknowledging children engagement with the internet and the critical need to grasp hacking risks early on. The formal cybersecurity education should start from 5th to 6th grade while the main topics of the curricula should include password security, social media risks, and the transition from offensive to defensive cybersecurity activities. A significant challenge identified was the limited cybersecurity background among primary school teachers. Furthermore, there was a noted preference for offensive activities, indicating a demand for more complex defensive challenges and better preparation to stimulate interest in defensive cybersecurity. Interactive discussion-based approaches, especially regarding website security, were found to be attractive to female students, underscoring the necessity of creating interactive and engaging learning environments. Moreover, the engagement of teachers and the organization of competitions in primary schools were recommended to promote cybersecurity education, emphasizing exposure beyond competitions and the importance of diverse activities. Suggestions for enhancing interest included the use of gamification and competitions to foster engagement.

13 May
===========
Ok ne thn aithsh logotherapeias . ola ta arxeia ienia sto documents--> logotherapeia . to email yhs einai okipostoulogou@gmail.com

check again NetEve
mail apo ECCO 
webinar ecco 31 May  link tba
paper alex gai dataset sto NIPS : https://www.overleaf.com/project/64cb9494cfbe453c6e91ad87
mentionlytics
AdvisortBoard sthn anna 


NetEVE abstract

	Empowering Women for Advancement in the Digital Future will identify obstacles girls and women encounter in educational and career paths in ICT, and propose practical, effective actions to increase women’s representation in digital sectors. Through a network of expertise and a stakeholder community, it will foster the implementation of effective solutions and good practices that encourage and support women in ICT in Europe. The main barriers hindering women’s progress in the ICT industry, especially in cyber security, will be investigated, and recommendations and practical, cost-effective actions implemented to raise interest and facilitate careers for women in digital sectors and change mindsets that are currently blocking progress. Barriers will be investigated at all education levels, from secondary school to tertiary, and in employment sectors. Desktop research findings and data from national and international scoping actions (WPs 3 and 4) will be compared across countries and regions to identify challenges, solutions and good practice.
	The project will work with key actors in digital and education sectors to shed light on the broad disparity in women’s presence in digital fields. Lack of parity is particularly evident in cybersecurity where workforce diversity is even more crucial, and this will be an area of focus. Good practices and innovative solutions from different countries will be shared and scaled up to contriibute to a more competitive, dynamic digital Europe. Human resources and intellectual potential will be strengthened by the added diversity that more women leaders and digital professionals would bring to digital fields.  
	A special issue of the ACIG journal will be produced to increase visibility of women in the sciences and help disseminate research. This will focus on creating a competitive workforce, especially in cyber security and artificial intelligence (AI). Research conclusions and project recommendations will also be presented in a scientific publication.

10 May
==========
EWA
Η Πηνελόπη προτεινει να αναμέιξουμε κιαλλους partners apo Ελλάδα για να βοηθήσουν στην συλλογή και στην  αναλυση Τ2.2. - Τ2.5 

γιατι ειναι αρκετή δουλεία για μας μόνο, αλλα φανταζομαι οτι φαινεται και λιγο μονοπλευρη με ενα ερε. ινστιτουτο στην Ελλαδα

stakeholders also we need which do not need a budget and we will sent them the questionaires. The translations cannot be shared with REWIRE propably
Ayth h prtash fanetai na einai 2 vhmata prin to REWIRE oute training exei oute cyberranges 


9 May
==========
EWA

WP1 1 PMs   6000
WP2 4 PMs  24000
WP3 7 PMs  42000
WP4 8 PMs  48000
WP5 3 PMs  18000             = 23 PMs total
          138000

Travel 
WP1 4  7500 euro
WP2 
WP3 ? 
WP4 1  3000euro
WP5 1  1500 euro

      12000

Budget  = 150.000-->  23PMs x 6000 PMs + 12000 (travel) 




8 May
==========


 Meeting about EWA - Girls and Women in Digital - Minutes
 ----------

		posa atoma 8a pane sto kick -of ? 
		8a prepei na apofasisoume pws 8a katanimoume to budget sto travelling. 

		exoume ena taxidi sto kick off 
		WP 3, WP 4, kai WP5   isws na mporousn na dwsoun kati parakatw. 


		exei kai sto WP5 pou mporoume na to apofigoume

		Epishs 8eloun an eimaste coordinator of some task . We have to be responsible for a TASK from a commission perpsective.   

		 To kickoff λενε να γινει καλυτερα στην Πολωνια για μικροτερο κοστος. 

		Ask Anya kouposvka 

Meeting wih Manos
----------

		Μολισ τελειωσε η συναντηση και αρχικα με ρωτησαν πως θα κατανειμουν το budget για τα ταξίδια. 

		Θα πρεπει να δουμε ποσα ατομά θα πάνε στο  kick off ? Υπολογίζουμε περιπου ~3000 ανα ατομο/ταξιδι ; Εχουμε αλλο ενα ταξίδι στο WP3 + 4 και το meeting στην Κρητη ( για μας 0) . Εχει και το WP5 ταξιδι αλλα μπορουμε αν δεν φτανει το budget να μην μπουμε καθολου. Καποιο meeting apo WP3,4 θα είναι online.

		Επίσης θελουν να ειμαστε coordinator σε καποιο task from a commission perpsective.  
regarding the task we could be leaders how about T4.3 - Analysis of the gender gap (M3-M18)?


(from mail Anna)

		 
		In the context of the budget for non-personnel costs, we decided at NASK to organise two meetings physically and a third online as part of WP1.

		We can do the kick-off at NASK. We assume 2-3 people will come from each Partner (as many as necessary). From the NASK side there will be more people involved, so it will be cheaper for us to organise it at NASK. So here you have to plan some travel costs.

		 

		We can arrange a second meeting to discuss the results of the research either again in Warsaw or, for example, at your place in Greece. Please let me know if this would suit you. This is important in order to plan the cost of travel or organising the meeting.

		 

		In the context of WP4, we are planning to organise 3 lectures/webinars of experts, for which we have assumed a budget of EUR 1.5 thousand each. In addition, we would like to organise a meeting of people from different countries on the occasion of the organisation of the international Women in Tech conference in Poland in June 2026 (we are checking what the costs will be). We also assume the presence of partners, if they find it valuable.

		 

		In WP5 - dissemination we assume participation in 4 international and 3 national events. In addition, I would also like to write a scientific article with the results of our work and take part in some scientific conference - here I assume the cost of the conference fee of about EUR 1 000.

Budget allocation

PMs/WP
	WP1 1
	WP2 0
	WP3 6
	WP4 8 (TUC lead T4.3 - Analysis of the gender gap (M3-M18))?
	WP5 0? is this ok ? so we have to contribute in dissemination?


Travel cost
 
WP1 -2 physical meetings +1 third online  . These also include the kick-off right? Is the meeting in Crete part of WP1?  So 4 * 1500 = 6000 + 1000 periseuei 7000
WP3 - is there a meeting? 0
WP4 - one physical meeting 1500 * 2 people
WP5 - No allocation budget for TUC    

7 May
========


regardinhg the plan of action are you referring to the Work Package 3: National best-practice networks for women empowerment in cybersecurity- here we assume that each consortium member will do:

·         Overview of the national strategies and actions (M1-M2)

·         National network community (M1-M24)

·         Analyses of the gender gap (M2-M12)

·         Providing a set of recommendations (M13-M24)

Work Package 4: International hub for best practice exchange

here we assume that consortium (as a whole) will do:So assume

·         Overview of the international strategies and actions (M1-M10)

·         International network community (M1-M24)

·         Analysis of the gender gap (M3-M18)

·         Providing a set of recommendations (M13-M24)

 

Work Package 5:  Dissemination and Exploitation

So I So assume
you want to knwo how we diviede 100.00 to these WPGs . Assuming thsi liite budget we will not lead any WP so we will contribute . We will talk with Manos to arrange the budget and come back to you . 

30 April 
========

vale dexrcription TUC sto https://docs.google.com/document/d/13qzfGXcHm6oaMKEskSdop40oy5Uc669V/edit?exids=71471469,71471463
sthn selida Consortium cooperation and division of roles (if applicable)
 from folder of proposal TUC_General_profile 


Dr. Despoina Antonakaki has obtained her PhD from Computer Science department of University of Crete in association with FORTH-ICS as Marie Curie Candidate, with main research interests on focused on Social Network Analysis including Sentiment and Topic Analysis, Bot and Malware
Detection via Natural Language Processing, and Machine Learning with several publications in peer-reviewed conferences and journals, including PLOS One, BMC,  IEEE/ACM ASONAM, Expert Systems, and SNAM. She has been active in  Cybersecurity EU projects since 2016 inluding EUNITY CONCORDIA and ECCO . 

in TUC collaborating with colleuages actvve / coordinating REWIRE / CyberSecPro 
…



29 April 
=========
1) Meeting with Anna about new prposal : Girls and Women in Digital, DIGITAL-2024-ADVANCED-SKILLS-06-WOMEN call:

https://ec.europa.eu/info/funding-tenders/opportunities/portal/screen/opportunities/topic-details/digital-2024-advanced-skills-06-women?status=31094501,31094502&frameworkProgramme=43152860&callIdentifier=DIGITAL-2024-ADVANCED-SKILLS-06&order=DESC&pageNumber=1&pageSize=50&sortBy=startDate

2) timologia 

3) new members in WG skills

4) SI leei as to afhsoume gai to meeting sthn A8hna . 

5) esteila mail Anna gia ta nea atoma kai to background mas (projects : REWIRE / CONCORDIA ...) file in 

6) reveiw : https://www.qeios.com/read/X0E9AF


1_the dataset seem to be limited in Phoenix, and there no reference of the volume of the instances . How is the dataset acquired?
2_ Literature review:  Important highly cited studies missing  (e.g. “Senator, We Sell Ads”: Analysis of the 2016 Russian Facebook Ads Campaign , R Dutt, A Deb, E Ferrara)
3_There are missing important references to alternate methodology to support author arguments like in subchapter: "Using NLP model for analysis". 
4_  In subchapter Data classification and labeling there is upset/ very limited information on the actual methodology for classification. 
5_ The analysis is very primitive and the results should not be shown through screenshots of the code, but actual graphs and plots derived though your methodology. See here: 
6_ The study should not demonstrate the actual code, which btw does not make sense, and the outcome are non existent!\
7_ This seems like a random generated paper with non existent scientific or technical content   :) 




24 April 
=========
OK ANNA felkner mail sent 
scholarship info sent to Pangiota
reveiw : A Comparative Analysis of Advertising in the 2020 Presidential Elections & Phoenix Mayoral Elections using Natural Language Processing
		aPo ta comments apo katw 
1
		The screenshots presented cannot be understood.
		The sources and explanations for the screenshots are missing.
		Comparative graphs are missing.
		The bibliography is insufficient.
		There is no discussion of the specialized literature on the topic addressed in the study.
		I recommend improving the study according to the recommendations.
2
	  1.Insufficient study from the Introduction to references.

		2.For example, the Introduction itself does not draw me to read the paper because of poor storytelling.

		The authors can consider writing the Introduction on these lines-

		Backdrop on Microtargeting
		Explain microtargeting with reference to political advertising.
		Elucidate its origin as a strategy for targeting specific voter groups.
		b.Significance of Political Advertising
		Highlight the importance of political advertising in electoral campaigns.
		Discuss its role in contributing to public opinion and influencing voter behavior.
		c.The Evolution of Political Campaigns:
		Provide an overview of how political campaigning has evolved, particularly with the advent of digital media.
		Discuss the shift towards targeted advertising and its implications.
		d.Scope of the Study:
		Introduce the specific focus of the investigation, which is comparing microtargeting usage in the 2020 US presidential campaign and the Phoenix 2020 mayoral election.
		Highlight the reasons for selecting these campaigns and the significance of studying microtargeting at the local level.
		e.Research Question and Objectives:
		Clearly state the research question: "How extensively is microtargeting used for political advertisement in the city of Phoenix 2020 mayoral election compared to the 2020 US presidential campaign?"
		State a framework that aims/objectives of the research, such as analyzing patterns in microtargeting usage and assessing its impact on voter engagement in both campaigns.
		f.Potential Contributions:
		Discuss the potential merits of the study to the existing body of knowledge on political advertising and campaign strategies.
		Accentuate how the findings could inform future electoral campaigns and academic research in this field.
		g.Structure of the Paper:
		Provide the flow of the paper along with the sections that follow.
		3. There is no Discussion mentioning the studies that refute or align with this investigation.

		4.Managerial, Theoretical, Societal implications should be considered.

		5. Conclusion should be presented along with Limitations and future directions.

		The topic of study is interesting and can be considered after a major revision.



HTgs elections 
US Elections 2024
@2024USELECTIONS

https://twitter.com/OurShallowState



22 April
==========
Hashtags 
19 April 
==========
Start collecting Twitter dataset on US Elections - set to be held on Tuesday, November 5, 2024

Notes . 

Potential connection with alt-right teams on any open sN 

Trivia
----------
Voters will elect a president and vice president for a term of four years.
Joe Biden, a member of the Democratic Party, is running for re-election
 Donald Trump, a member of the Republican Party, is running for re-election for a second, non-consecutive term, after losing to him in 2020.
 Of course we cannot NOT tTAke  into consideration that :
    The election notably comes after Trump's prior attempts to overturn the results of the 2020 election and the January 6 United States Capitol attack.

    Abortion,[13][14][15] immigration, healthcare,[16] education,[17] the economy,[18] foreign policy,[19] border security,[20] LGBT rights,[21] climate change,[22][23] democracy[24][25][26] and lawsuits against Donald Trump[27] are expected to be leading campaign issues.

18 April
------------
Meeting about proposals 
ellada 2.0 Karafotis. mikro programma . asfali metafora data apo spiti ktl 
epistimonikh aisteia , ereynw kainotomw 
trust you stars 

Ai call 
Ai ac reguration opws 8a ftiaxeis sthn europe AI eframogh + ENISA odigies 
na ftiaxeis ena Ai regilaory sandbox gai ai security 

2024 _ proposal defriefing 

8eloume ta 100% funding rat e

indicative number of accepted proposals na ienia > 4-5 

horizon ta xeroume kala 
erasmus + 
cef ligo diaforetik aerga  

CALL document 


16 April
=====================
Mentionlytics account with election in US #s

15 April
=====================


Review Designing an Intelligent Push Model for User Emotional Topics Based on Dynamic Text Categorization in Social Media News Dissemination

	Dictation :

		2.1 Text sentiment anlysis based on sentiment lexicons and statistical method
		e input of at current time. 
		BI-LSTM exhibit significant advantages
		 to heightened interpretability of the model.
		 negative emotion on Weibo datasets
The langueage is complicated/ too scohisticated worda, hard to follwo. PLease use simple technical langage 

  is unnecessarily complicated language used: The exploration of social media comment analysis has garnered considerable scholarly attention in recent epochs, precipitated by the pervasive ubiquity of social media platforms and the copious volume of commentaries engendered by their users

  OMG !!! the abstract is 100% AI generated !!!!Also for all introduction 

12 April 
=====================
paper uthors : Ioannis Lamprou, Alexander Shevtsov, Despoina Antonakaki, Polyvios Pratikakis and Sotiris Ioannidis
Title :   Exploring Crisis-Driven Social Media Patterns: A Twitter Dataset of Usage During the Russo-Ukrainian War
Number :  24 submitted ASONAM


244 

83 

stavroula 83,63 perusi  --- kwdikos hlektronikhs plhrwmhs ...afm ...

sunanthsh webinar 		Building Youth Communities for Cybersecurity through Competitions, 12 April 2024, Webinar
		TRAINING AND WORKSHOPS
		
		Introduction from Nina : 

		On behalf of ECSO we would like to welcome you to this knowledge sharing event . 

NINA presenattion  
		1 slide
		------------
		About community groups (see photo )
		objectives of six community groups. all of them are organizing webinars so please stay tuned fo rupcoming webinars

		slide 2
		------------
		community group on skills 
		objectives + topics for presentation 
		currently 33 members (ainly from universities)

		slide 3 
		------------
		agenda of today 
		name small description 
		note please write your question in the chat or raise  hand 

		That's for introduction. Here we have Jans ... from university ... Jans the floor is yours

1st 	presentation from Jans 
		--------

		NINA 
		Thank you Jens for the presentation and for being on time !and for sharing with us the Danish example ...
		Please   write your question in the chat. Without further ado I will give the floor to our next presenter ...

2nd * 3rd 

QA vocal questions : 
1) Ruben  asked in chat so nothing. 


2) Jacov NCERT (Croatia)
To all speakers from which age do you think young people should be exposed to CS ?

Joe) Saame ages they start interesticng with the internet, so mailny primary school ? 10-12? all risks are hidden they should be aware. 
Birgy ) Some younger ages (2-3) are already exposed to tablets !! but real CS 5th to 6th grade is ok . we shoud start at this age to discuss hard staff, hacking abuse . and the fact that kids is the next generation of defence :) 


Jens) Last year for the first time they had this challenge in primary school which was very challenging since techer do not have a strong background in CS . So no hacking tools . We plan on similar chalenges 
like how to make strong passwords/how to browse SN/ what to share in SN/ aware of risks in SNs. 

question from chat


			Peter Van Hoorenbeeck | Davinsi Labs • General question for all speakers: (How )do you transition and raise interest from red team activities like CTF/hacking to the defensive side? For years there is a big focus in the education system on CTF and (ethical) hacking but if you ask even experienced ethical hackers, there seems to be a knowledge gap.

			Joe PICHLMAYR - CSA CyberSecurityAustria • excellent question -  addressing a really critical topic - the majority of our talents are in favor for RED because BLUE requires a lot more Experience and knowledge on the on hand and on the other hand it´s much more difficult to provide "blue-team-challenges" (as a service) to raise particpation and interesst

Jens/  We only show a small part of CS technical part, and hide the side about humans and organizations . But this is a good way to attract people, and explore the abilities . need also to be better at preparing challenges . more about the defencing side of CS 

Birgy/This is boring staff but this is how we attract girls :) initially we had regulation / we need discussion games , kame them feel secure in school ..how do we make a websit secure etc. NEED DEMOS and environments We LACK demos!!



Note from Paolo Alzeti 
In primary schools we should start with the teachers and  competitions . Competitions are a great was to promote CS also nded additional initatives.  All schools should get exposure to CS but with no competition yet .  

NINA indeed we need a range of other activities 

Jens Myrup Pedersen • I think we need different kind of initiatives - gamification and competitions is one part of it 🙂

*chat*
ECCO • Hello everyone! Welcome to our webinar! Please do not hesitate to introduce yourselves here in the chatbox. All the best, Alexandra Madsen from the ECCO Team
You can also use the chat for any questions or comments on our speakers' presentation. We also kindly remind you to mute  your microphones for the duration of the call.
Please be mindful to keep your microphones muted

Ruben Gonzalez • Will the slides be shared afterwards?

ECCO • Hello! Yes we will send out an e-mail with all slides in a pdf 

Ruben Gonzalez • What does your "beginner track" look like and how do you assure a level playing field?

Rasa • Thank you Jens for the great presentation! Please elaborate on how the government and the private sector contributes into building the community? From what I understood the university is the main driver of the initiative. Thanks!

Ruben Gonzalez • (Question for Denmark ^)

Rasa • One more for Jens: have you noticed any trends if the young ones prefer the online or live events?
 

[hr] Jakov Đogić - NCERT • Question for Joe: What's the difference between Unterstutzer and Sponsors?

Dino Nejašmić • Question for Joe: since you mentioned the salary problem for computer science teachers, how do you deal with it in Austria?
Dino Nejašmić • Question for Joe: since you mentioned the salary problem for computer science teachers, how do you deal with it in Austria?

Joe PICHLMAYR - CSA CyberSecurityAustria • in austria we have speficic form of HighSchool called HTL - means higher technical school - there students representing the majority of participants in our challenges - but the teachers their want earn more than in other highschool - so the sallarys in our highschools are okay but nevertheless NOT comparable with equivalents in Indudry :-(

LOJNITA Octavia • Thank you for spotlighting the importance of psychographics!

Peter Van Hoorenbeeck | Davinsi Labs • General question for all speakers: (How )do you transition and raise interest from red team activities like CTF/hacking to the defensive side? For years there is a big focus in the education system on CTF and (ethical) hacking but if you ask even experienced ethical hackers, there seems to be a knowledge gap.

Joe PICHLMAYR - CSA CyberSecurityAustria • https://global.joinhackshield.com/
hackshield address this topic at a very early age !

-----========================
ECCO • Hello everyone! Welcome to our webinar! Please do not hesitate to introduce yourselves here in the chatbox. All the best, Alexandra Madsen from the ECCO Team
You can also use the chat for any questions or comments on our speakers' presentation. We also kindly remind you to mute  your microphones for the duration of the call.
Please be mindful to keep your microphones muted

Ruben Gonzalez • Will the slides be shared afterwards?

ECCO • Hello! Yes we will send out an e-mail with all slides in a pdf 

Ruben Gonzalez • What does your "beginner track" look like and how do you assure a level playing field?

Jens Myrup Pedersen • The "normal" challenges give between 1.000 points and 100 points, depending on the number of solves. "Beginner" challenges gives between 100 and 20 points.

Ruben Gonzalez • So you can't get to the finals with the "beginner" challenges?

Rasa • Thank you Jens for the great presentation! Please elaborate on how the government and the private sector contributes into building the community? From what I understood the university is the main driver of the initiative. Thanks!

Jens Myrup Pedersen • We actually have a private company as part of the project, who are organizing most of our events and coordinating media/social media campaigns. As a university professor, I feel that they are doing everything that we are not good at! 

And we have the Danish Defense Intelligence Services helping with trainings and bootcamps, which also means a lot for the recognition and brand of our activities.

In our newest project, we have also a university spin-out involved who is working on the technical training platform.

Ruben Gonzalez • (Question for Denmark ^)

Rasa • One more for Jens: have you noticed any trends if the young ones prefer the online or live events?

Jens Myrup Pedersen • It is a mix! Some really prefer virtual events (e.g. because they live far away from university cities), and some prefer physical events. So our Regional championships are held in a hybrid format, where they are basically participating virtually - but with a possibility of meetups in one of the four biggest cities.

[hr] Jakov Đogić - NCERT • Question for Joe: What's the difference between Unterstutzer and Sponsors?

Joe PICHLMAYR - CSA CyberSecurityAustria • Sponsors donate Money - Supporter bring in "inkind" services

[hr] Jakov Đogić - NCERT • Understood, thank you Joe :)

Dino Nejašmić • Question for Joe: since you mentioned the salary problem for computer science teachers, how do you deal with it in Austria?

Joe PICHLMAYR - CSA CyberSecurityAustria • in austria we have speficic form of HighSchool called HTL - means higher technical school - there students representing the majority of participants in our challenges - but the teachers their want earn more than in other highschool - so the sallarys in our highschools are okay but nevertheless NOT comparable with equivalents in Indudry :-(

Dino Nejašmić • Thank you.

LOJNITA Octavia • Thank you for spotlighting the importance of psychographics!

Peter Van Hoorenbeeck | Davinsi Labs • General question for all speakers: (How )do you transition and raise interest from red team activities like CTF/hacking to the defensive side? For years there is a big focus in the education system on CTF and (ethical) hacking but if you ask even experienced ethical hackers, there seems to be a knowledge gap.

Joe PICHLMAYR - CSA CyberSecurityAustria • excellent question -  addressing a really critical topic - the majority of our talents are in favor for RED because BLUE requires a lot more Experience and knowledge on the on hand and on the other hand it´s much more difficult to provide "blue-team-challenges" (as a service) to raise particpation and interesst

Ruben Gonzalez • To be successful in the defensive side, you also need an adversarial mindset that you learn in CTFs IMHO.

Joe PICHLMAYR - CSA CyberSecurityAustria • https://global.joinhackshield.com/
hackshield address this topic at a very early age !

[hr] Jakov Đogić - NCERT • Thank you all for your responses and opinions!

Jens Myrup Pedersen • I think we need different kind of initiatives - gamification and competitions is one part of it 🙂

*chatgpt to pretify* 

			Ruben asked in chat, so no specific question.

			Jacov from NCERT (Croatia): What age do you think young people should be exposed to computer science (CS)?

			Joe: Children show interest in the internet around primary school age (10-12). They should be aware of risks like hacking. [1]

			Birgy: Some kids start using tablets at ages 2-3, but formal CS education should start around 5th to 6th grade to discuss hacking, abuse, and cybersecurity. [1]

			Jens: Primary school challenges are challenging due to teacher's lack of CS background. Topics include strong passwords, safe browsing, and social media risks. [1]

			Peter Van Hoorenbeeck (Davinsi Labs) asked a general question: How do you transition interest from red team (offensive) activities like hacking to the defensive side?

			Joe: Majority prefer red team activities due to their complexity. Transitioning requires more focus on defensive challenges, which are harder to provide. [1]

			Jens: CS education often focuses on technical aspects, neglecting human and organizational factors. To attract interest, there should be better preparation and focus on defensive CS. [1]

			Birgy: Girls are attracted to discussion-based activities like website security. Demos and interactive environments are lacking but necessary. [1]

			Paolo Alzeti's note: Primary schools should involve teachers and competitions to promote CS. All schools should have exposure to CS, even without competitions. [1]

			Nina emphasizes the need for a variety of activities beyond competitions. [1]

			Jens Myrup Pedersen suggests using gamification and competitions to promote interest. [1]

			Ruben Gonzalez asked about sharing slides, and ECCO confirmed they would be shared via email. [1]

			Ruben Gonzalez asked about the beginner track and ensuring a level playing field, but no specific answer is provided.

			Rasa thanked Jens for the presentation and asked about government and private sector contributions. She also inquired about young people's preferences for online or live events. [1]

			Jakov Đogić (NCERT) asked Joe about the difference between "Unterstutzer" and sponsors, but there's no response from Joe.

			Dino Nejašmić asked Joe about dealing with salary issues for CS teachers in Austria. Joe explained the situation in Austrian technical schools (HTL) but noted that teacher salaries are lower compared to the industry. [1]

			LOJNITA Octavia thanked for spotlighting the importance of psychographics.

			Joe shared a link to Hackshield, addressing cybersecurity education from an early age.

			</response>


*chat gpt summary on the above*

Responses varied:

Joe suggested children naturally engage with the internet around primary school age, emphasizing the importance of awareness regarding hacking risks.
Birgy proposed formal CS education beginning in 5th to 6th grade, highlighting the need to discuss cybersecurity alongside hacking.
Jens noted challenges in primary school due to teachers' limited CS background, suggesting topics like password strength and social media risks.
Peter Van Hoorenbeeck inquired about transitioning interest from offensive to defensive cybersecurity activities.

Replies included:

Majority prefer offensive activities due to complexity, requiring a shift towards providing more challenging defensive challenges.
Emphasis on the need for better preparation and focus on defensive CS to attract interest.
Discussion-based activities like website security are appealing to girls, with a call for more interactive environments.
Paolo Alzeti advocated for involving teachers and competitions in primary schools to promote CS, with emphasis on exposure even without competitions.

Other points raised:

Nina stressed the necessity of diverse activities beyond competitions.
Jens Myrup Pedersen suggested using gamification and competitions to foster interest.
Ruben sought information about slide sharing, and ECCO confirmed they would be shared via email.
Rasa thanked Jens and inquired about government and private sector contributions, as well as young people's preferences for online vs. live events.
Jakov Đogić asked about the difference between "Unterstutzer" and sponsors.
Dino Nejašmić queried Joe about salary issues for CS teachers, with Joe explaining the situation in Austrian technical schools.
LOJNITA Octavia expressed gratitude for spotlighting the importance of psychographics.
Joe shared a link to Hackshield, addressing cybersecurity education from an early age.
</response>


after MY edit : 



The presenters based in the audience’s question on which age we should start the exposure to cyber security, they suggested children naturally engage with the internet around primary school age, emphasizing the importance of awareness regarding hacking risks. They also proposed formal CS education beginning in 5th to 6th grade, highlighting the need to discuss cybersecurity alongside hacking.
Regarding the same issue it was noted the high challenge in primary school due to teachers' limited CS background, suggesting topics like password strength and social media risks and the need for transitioning interest from offensive to defensive cybersecurity activities.

The majority prefers offensive activities due to complexity, requiring a shift towards providing more challenging defensive challenges. There is an emphasis on the need for better preparation and focus on defensive CS to attract interest. Aditionally, discussion-based activities like website security are appealing to girls, with a call for more interactive environments. Finally it was advocated involving teachers and competitions in primary schools to promote CS, with emphasis on exposure even without competitions with a stress on the necessity of diverse activities beyond competitions.
One of the speakers suggested using gamification and competitions to foster interest.
 
Additional remarks from the QA inquired about government and private sector contributions, as well as young people's preferences for online vs. live events, the difference between "Unterstutzer" and sponsors and about salary issues for CS teachers, with Joe explaining the situation in Austrian technical schools.

11 april
=====================

Webinar for tomorrow 
[12:13] Nina Olesen
Prepare a follow-up text and email, including main takeaways and next steps (to be sent to Alex and me)
[12:13] Nina Olesen
Track the attention of the participants to identify potential interest for future topics.


ASONAM : https://www.overleaf.com/project/63089ca94bf83c08484e483f 



10 april 

bi-weekly bi-lateral ECCO Task C - *EC meeting*
		 
*Cristian* 
			
			says that he set up started the meeting on c and we as chairs continue the efforts. the groups are becoming largers ...meed for internal governance. chairs are independent /autonomous .
		  some steering groups are set . DO WE NEED? 

		 webinars are continuing . tracking ticking one per month . chairs are leading . 

		 issues to highlight NONE 

		 IN PERSON events ? need for these meetings . not fully scheduled. but chairs are thinking of them. I AM NOT THINKING OF THEM ! who is ?  

*Barbati* whuch meetings are the in person - proto - community ..

  NOT in person
  pace with NCCs should be stronger not one per month . MORE ???

 *Roberto* we will push for more webinars 
 *Barbati* planning try to keep predicable . circulate ahead of time ...


9 April 
============

sent reminder webinar ok 
created presentation for TUC meeting before Easter (Documents/tuc_presentation20204.pptx)



N Braided Bikini - POP UP!

8 April 
============

Proposals? 
nina webinar 

*new for community groups*
			Dear ECCO Community Group on Skills Coordinators,

			 

			I’m interested in joining the group, my contact details are:

			Name
			Gonçalo Cadete
			E-mail:
			goncalo.cadete@inov.pt
			Mobile phone:
			+351 91 999 88 88
			Address:
			Rua Alves Redol, 9
			1000-029 Lisboa
			Portugal
			Organization
			INOV INOV - Instituto de Engenharia de Sistemas e Computadores Inovação
			\			Role:
			Coordinator - Cybersecurity, Governance & Resilience

asked Nina to sent email to invite to Fridays webinar newcomers: subject Invitation to Friday's webinar 


2 April 
============
Stavros meeting diplwmatikh  - DEN mphke 
Panagiota  - egraye kwdika !! me apotelesmata sumfwna me ayto idia https://dylanrandle.github.io/troll_classification/



29 March 
=============
meeting ECCO Community Groups Co-chairs Biweekly Meeting

Create a dedicated steering committee 
maybe also a mailing list 

*TODO* 
see if we can cretae webinare some people could talk about interesting staff based on the defined topics 

but how many webinars do we need ? 

every month until the summer 

rwa thn phneloph pws paei me to webinar 

28 March 
==============
Anna Maria Trawińska, atrawinska@agh.edu.pl, PR Manager, Cybersecurity Centre at the AGH University (WG Skills)

27 march 
==============

Associate Professor

Computer Engineering and Science for Cybersecurity degree Program Director
University of Naples “Parthenope”, Engineering Department
Centro Direzionale di Napoli, Isola E2/B, 3rd floor, room 9

Phone:  +39 0815476702
Mobile:  +39 3396218570

Email: luigi.coppolino@uniparthenope.it
PEC : luigi.coppolino@pec.uniparthenope.it

www.fitnesslab.eu


26 March 
================
1) *TODO*  review Lambrou for submission : https://www.overleaf.com/project/63089ca94bf83c08484e483f

2) review our deliverable locally from : https://ecsorg.sharepoint.com/:w:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B21BD8743-77C4-4EB6-8750-CCA529CF345E%7D&file=ECCO_D-C.1.2_M15_v.04.docx&action=default&mobileredirect=true  into folder task c/deliverable_march24
ECCO_D-C.1.2_M15_v.04.docx

esteile h nina oti 8a to kanei auth !

3) evala ta onomata ki  edw https://ecsorg.sharepoint.com/:x:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BDADADADF-6053-47DF-9488-E534C3B18946%7D&file=Task_C_Members%20Trackers.xlsx&wdLOR=c76C658FD-E368-4889-AF56-FECF51C89904&action=default&mobileredirect=true

4) evala ta onomata edw https://ecsorg.sharepoint.com/:x:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BB60EFB7F-4257-4C9F-98A4-9C241C1864BA%7D&file=Task_C_Activity%20Tracker.xlsx&action=default&mobileredirect=true


				Apanthsan 

					1) 	
				izr. prof. dr. Marko Hölbl | assoc. prof.

				Prodekan za raziskovalno dejavnost  |

				Vice-dean for Research
				Univerza v Mariboru | University of Maribor


				2) Svenja Hertrich

				Siemens Energy Global GmbH & Co. KG
				Siemens Energy
				Cybersecurity
				SE CYS
				SCE M2
				Schuckertstr. 1
				91058 Erlangen, Germany
				mailto:svenja.hertrich@siemens-energy.com


				3) email : jacqueline.kehoe@mtu.ie
				Name : Jacqueline Kehoe
				Organisation : Munster Technological University
				Role: Project Manager - Cyber Skills


				4) Pino Caballero-Gil
				Universidad de La Laguna
				Department of Computer Engineering and Systems.
				Higher School of Engineering and Technology.
				University of La Laguna.
				Full profesor
				pcaballe@ull.edu.es 

				 5) Carlos Fragoso Mariscal
				 Full Name: Carlos Fragoso Mariscal

				Org: Maltego Technologies

				Role: Principal SME and Researcher



				Principal Subject Matter Expert
				Maltego Technologies GmbH 

				Paul-Heyse-Str. 29, 80336 Munich, Germany 

				cf@maltego.com 

				www.maltego.com 

				already added: 

				1) Anna Felkner	NASK	anna.felkner@nask.pl
				2) Arnaud De Vibraye	ECSO	<arnaud.de.vibraye@ecs-org.eu>
				3)Jose Luis Hernandez	<jluis.hernandez@um.es> 
				4)Jens Myrup Pedersen <jens@es.aau.dk>
				5)Nineta Polemi <dpolemi@gmail.com>
				6)Birgy Lorenz <birgy.lorenz@taltech.ee>                                                          7)Pinelopi Kyranoudi <pkyranoudi@tuc.gr>.                                                        8)Imre Lendak <lendak@uns.ac.rs>
				9)izr. prof. dr. Marko Hölbl <marko.holbl@um.si>.                                                
				10)Svenja Hertrich <svenja.hertrich@siemens-energy.com>
				11)Jacqueline Kehoe <jacqueline.kehoe@mtu.ie>
				12)Pino Caballero-Gil <pcaballe@ull.edu.es>
				13) Carlos Fragoso Mariscal <cf@maltego.com >
				14)Joe Pichlmayr	CyberSecurityAustria CSA<Joe.Pichlmayr@cybersecurityaustria.at>.   
				 

				my name is Joe Pichlmayr and I am a board member of CyberSecurityAustria CSA - a non-profit organization whose mission is to sensitize people in Austria to the topic of cyber security

				One of our flagships is the ACSC, the AustriaCyberSecurityChallenge, where, like Birgy and Jens, we give young cyber security talents the opportunity to show off their skills in a national competition.

				This competition has become a beacon for many teachers to "confront" their students with the topic of cyber security and inspire them to participate.




			NINA
			Dear Despoina,

			 

			Thanks. Can you send me the missing emails? Except for Vilius (I have his).

			 

			Regarding the email, I wouldn’t send that as I believe it’s a bit too random to just send out an invitation to be a speaker to newcomers to the group. They are joining the community to follow future activities/events and we are not sending an invitation to speak to every new person we add…

			I think we can keep the control of the speaker situation for the webinars and identify and invite good speakers from within our networks that we know are experts on the different topics.

			The cyber competition webinar has been announced now so you can remove it from the list. The youth in cyber one I can easily find speakers from ECSO’s network, same for most of the other ones. If you have ideas for speakers on the topics, don’t hesitate to send them my way.

22March
================

Apanthsan gia ta webinars, stelnw sugkentrwtiko mail se si kai Nina

Dear Nina, 


I have the following people willing to join the ECCO Community Groups (Skills): 


1) Prof. Pavel Loutocky (loutocky@muni.cz) from Masaryk university, where I am post-doc legal researcher.
2) Prof. Imre Lendak - Faculty of technical sciences, University of Novi Sad  0 Cybersecurity Professor & Consultant- Email: lendak@uns.ac.rs
3) Dr. Vilius Benetis, Director at NRD Cyber Security - vb@nrdcs.lt
4) Punelopi Kuranoudi  - PhD candidate at University of Piraeus (Dept. of Informatics) and Cybersecurity Researcher at Technical University of Crete
5) Prof. Nineta Polemi - Cybersecurity Professor at University of Piraeus | CTO & Cofounder at trustilio B.V.


I have prepared the following template email to ask them if they are willing to give a presentation in one of our topics, 

please let me know what you think!

regards



21 March 
===========

Sunanthsh me Info@ECCO webinars
Thursday, March 21⋅11:00am – 12:00pm

 
Organizer
Set your working location
Penelope Kyranoudi

enhmerwsh gai ecco apo emena erwthsh apo authn sxetika me epikoeimena webinars pou 8a mporous ena kanei auth aki h Ninaet apOlemi . esteile tis exhs erwtsheis sethn Nian 


			I got a couple of questions from a candidate expert. 
			Do we have a date/deadline by which we could organize the webinars? 
			I guess the duration is up to us. Although I guess > 1,5 h will be tiring for our audience.
			Also is it ok to announce the webinar in the social media (Twitter, LinkedIn etc.) and website of their project as dissemination?
			Finally, the webinar is open to the public? I guess since it is announced in  the website of ECCC? 

			https://cybersecurity-centre.europa.eu/events/community-group-skills-knowledge-sharing-webinar-roadmap-cyber-ranges-education-and-skills-2024-03-06_en?prefLang=pt
			  ================

			  kai h Nina leei 

			  For now, the webinar format is of 1hr. I would keep it to that.
			No deadline – we need to organise as many as possible this year but with vetted topics and experts (hence why I sent the list of our current topics to the EC for an ok). So, we need to keep the control and decision on topics for the webinars. We are not just going to accept anyone who sends us an email wishing to speak on a certain topic.
			There is no problem for projects to share the webinar as long as they link to the announcement page on the ECCC website.
			The webinars are public but we do not record and / or upload videos after.
       ====
       sxetika me ta topics apo paliotero mail ths esteila auat kai perimenw epivevaiswh 
       lease find here below a list of topics that we were considering for the next series of the Community Group on Skills Knowledge Sharing webinars (in no particular order):

					 

					•                      Education and awareness (incl. cyber hygiene) for youth.

					•                      Leveraging cyber competitions to engage youth in cyber.

					•                      Impact of AI on skills and the workforce.

					•                      Academia-industry collaboration on skills.

					•                      Awareness of Social Engineering.

					•                      Educational curricula alignment with the needs of the market.

					•                      Tools for hands-on technical education in cybersecurity including fighting cybercrime.

					•                      Security and privacy ‘by design’ approach in training and education for IT professionals.

					 



20 March 
============
"already added: 

Anna Felkner	NASK	anna.felkner@nask.pl
Arnaud De Vibraye	ECSO	<arnaud.de.vibraye@ecs-org.eu>
Jose Luis Hernandez	<jluis.hernandez@um.es> 
Jens Myrup Pedersen <jens@es.aau.dk>
Nineta Polemi <dpolemi@gmail.com>
Birgy Lorenz <birgy.lorenz@taltech.ee>                                                          Pinelopi Kyranoudi <pkyranoudi@tuc.gr>


 
"scheduled to be added:                                                                                                      Felicia Cutas  EIT Digital felicia.cutas@eitdigital.eu EMAIL SENT
Joe Pichlmayr	CyberSecurityAustria CSA< Joe.Pichlmayr@cybersecurityaustria.at>.     MAIL SENT                                                                                                              Alan Briones Delgado <alan.briones@salle.url.edu> MAIL SENT
 "



Sent email to experts 

Ninena Polemi
apo Mano aathanato 

 
 
Jose Luis Hernandez	University of Murcia	jluis.hernandez@um.es
Jens Myrup Pedersen	Aalborg University, Denmark	jens@es.aau.dk
Nineta Polemi dpolemi@gmail.com
 

 
"-------------------

"scheduled to be added: Felicia Cutas  EIT Digital felicia.cutas@eitdigital.eu EMAIL SENT
Joe Pichlmayr	CyberSecurityAustria CSA< Joe.Pichlmayr@cybersecurityaustria.at>.     MAIL SENT                                                                                                              Alan Briones Delgado <alan.briones@salle.url.edu> MAIL SENT
 


15 March 
=============
ECCO WG skils meeting every Friday. 
steile email to experts !!!
TODO !

14 March 
=============
καναμε τελικα συζητηση με τον Σωτηρη και μου ειπε οτι μιλησατε για τους 9 φοιτητες. Του ειπα κι εγω 10 οχι 9 ...:) ξερω οτι βάζεις πολύυυ προσπάθεια για αυτους και αν μπορώ να σου πάρω κάποιους απο αυτους που έχει τωρα ; αλλιως απο τους επομενους ,.  

Sxetikla moe tous neofu foithtes kalo 8a htan na hn kanoume akomh ta xartia sthn grammateia an den exoume mpei se mia sera, na eiamset emeis happy me thn apodosh tous ...kai meta na mprlekoume thn grammateia . lalo 8a htan na afierwnoun mia mera thn evdomada ,, alla 8wro full... 


reveiw sent : 
					 
					Public Attitudes Toward ChatGPT on Twitter: Sentiments, Topics, and Occupations 


					Language

					The manuscript is well written with no significant grammatical/syntax errors 	
					The only issue they should take care of is the past tense which is preferable to be avoided in studies, better use present tense in all manuscript (e.g . We extracted topics from tweets extract topics) . Also two minor typos 
					1.	abstract : Our sentiment analysis result --> results , so indicates--> indicates
					2.	chapter 6 title: Limitation --> LimitationS

					General description
					The study uses 314,645 tweets in order to analyse the sentiment around ChatGPT using topic modeling for the most discussed topics. They extract the occupation of the users sending the tweets and analyze occupation-related patterns in ChatGPT-related topics.
					In order to study public attitudes toward ChatGPT, they applied a Transformer-based sentiment analysis model to extract sentiment from tweets and topic modeling techniques
					to group tweets based on topics. Next, they grouped tweets based on occupation using
					the user description in conjunction with a list of official occupations.

					Related work

					The background work seems to be complete except from the following:
					1.	Fatouros, Georgios, et al. "Transforming sentiment analysis in the financial domain with ChatGPT." Machine Learning with Applications 14 (2023): 100508.
					2.	Kocoń, Jan, et al. "ChatGPT: Jack of all trades, master of none." Information Fusion (2023): 101861.

					They have compared their study to similar work both in literature review and in the discussion section.


					Dataset

					The dataset consisted of 314,645 tweets which is very limited. They could expand their analysis in more datasets:

					1) ChatGPT tweets
					Python · Large Language Models: the tweets https://www.kaggle.com/code/mpwolke/chatgpt-tweets

					Although they refer in chapter 6 Limitation
					“..Some limitations should be taken into consideration when interpreting our results. First, our analysis is limited to tweets collected before June 2023, due to changes in Twitter’s data access policy..."

					but there are more available datasets you can combine from the same source kaggle
					https://www.kaggle.com/search?q=Large+Language+Models+in%3Adatasets

					Data cleaning

					1.	The authors refer in chapter 3.2 “Following the Twitter data cleaning steps in (Loureiro et al. 2022), we removed duplicates,near-duplicates, and tweets from bots to ensure that our analysis of tweets would be more accurate and informative “

					How do you apply bot analysis detection? This task by itself is separate field in Twitter analysis (https://scholar.google.gr/scholar?hl=el&as_sdt=0%2C5&q=bot+detection+twitter&btnG=&oq=bot+detection+)

					Sentiment Analysis 
					1.	The authors use state of the art techniques for sentiment analysis including VADER  , Twitter-roBERTa  and XLM-T.  Twitter-roBERTa was trained on *English tweets only.*

					It would be nice to see extended datasets with the multi trained Twitter-roBERTa on \
					more languages.

					2.	The authors refer:
					"..To generate the ground truth, we randomly selected 1,000 tweets from the cleaned dataset and manually labeled their sentiments.."

					Maybe provide a small sample of the labelling data ? 
					Also, why manually labelling and not consider other techniques like keyword-based labeling/Machine learning-based labeling/Crowdsourced labeling /Semi-supervised learning?

					Topic Modeling

					1.	Preprocessing step is included.
					2.	BERTopic used is better than LDA considering the dataset. Could the authors please indicate the parameter parameter tuning and in brief providing a short justification.
					 https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#bertopic and the briefly how you estimate the sentiment distribution. 

					3.	Is the link 3.3 in the sentence: "..Building upon the sentiment analysis conducted in Section 3.3, we delved deeper intothese chosen topics” 
					correct?

					4.	"The python packages, nltk, contractions,and spaCy were used for processing stop words, contractions, and lemmatization, respectively." OK!I guess no parametrization needed here. 

					Results

					1.	Can you provide a very short explanation (one-two sentences) on the fluctuations of the sentiment? Maybe an event influenced the sentiment ? as provided in section 4.1 (Fig. 3 Sentiment distribution by month from December 2022 to June 2023)

					2.	Table 3 has sum of 60.36% not same as 60.38%


					iN the System submitted 

					Confidential feedback for the Editor
					Edit 
					Your recommendation
					Revise
					Is the experimental procedure or study design appropriate to answer the research question (including the use of appropriate controls)? Are the conclusions supported by the evidence presented?
					Yes
					Please rate the novelty of the research on a scale of 1-5 (1=not at all novel and 5=extremely novel)?
					4
					Is the presentation of the work clear, with regards to language and grammar?
					Acceptable
					Does the title and abstract of this paper clearly reflect its content? And are the keywords representative of the research?
					Yes
					Does the introduction present the purpose of the research investigation and is the purpose supported by the pertinent literature?
					Yes
					Are the methods described sufficiently to allow the research study to be repeated by other parties? Is the software data code provided sufficient to be replicated?
					Yes
					If applicable to the paper? Is the use of statistics and treatment of uncertainties appropriate?
					Yes, it is
					Are the images in this manuscript free from improper manipulation?
					Yes
					Are the tables and figures well designed and necessary?
					Yes
					Are the references provided appropriate and up to date?
					Yes
					Comments to the Editor (optional)
					You have not entered any comments for the Editor.


Ai brainstorming : Lambrou parousiase to https://maartengrootendorst.substack.com/p/a-visual-guide-to-mamba-and-state with no comments 

===============
ECCO Community_skills@list.cyber-ecco.eu mailing list reminder
You are subscribed with the address: dantonakaki@tuc.gr

Your Community_skills password is: caoznoar

Your Community_skills password is: caoznoar

13 March
==============
REVIEW:

		Public Attitudes Toward ChatGPT on Twitter:
		Sentiments, Topics, and Occupations
		Ratanond Koonchanok1*†, Yanling Pan2† and Hyeju Jang3

*Language*
	 grammatical syntax seems ok . 	
	abstract : Our sentiment analysis result --> results , so indicates--> indicates

	Limitation --> LimitationS

*general description*
the study uses X tweets in order to analyse the sentiment around ChatGPT using topic modeling for the most discussed topics. 
They extract the occupation of the users sending the tweets and analyze occupation-related patterns in ChatGPT-related topics.
In order to study public attitudes toward ChatGPT, they applied a Transformer-based sentiment
analysis model to extract sentiment from tweets and topic modeling techniques
to group tweets based on topics. Next they grouped tweets based on occupation using
the user description in conjunction with a list of official occupations.
*related work*
is it complete ? 

All from first pages studies in google scholar (ChatGPT twitter sentiment) are there!! 

from second page missing:
 18 citations : Fatouros, Georgios, et al. "Transforming sentiment analysis in the financial domain with ChatGPT." Machine Learning with Applications 14 (2023): 100508.
210 citations: Kocoń, Jan, et al. "ChatGPT: Jack of all trades, master of none." Information Fusion (2023): 101861.

*they have compared their study to others OK*
	Most similar to our study, Leiter et al. (2023) used a Transformer-based
	model fine-tuned for sentiment analysis to classify each tweet as positive, negative, or
	neutral. Leiter et al. (2023) and Tounsi et a
	l. (2023) also applied emotion classification
	models to examine the public reactions expressed in tweets.

	Most similar to our study, Leiter et al. (2023) used a Transformer-based model fine-tuned for sentiment analysis to classify each tweet as positive, negative, or neutral. Leiter et al. (2023) and Tounsi et al. (2023) also applied emotion classification models to examine the public reactions expressed in tweets.


*Dataset*

dataset of 314,645, very limited. could expand with more datasets
1) ChatGPT tweets
Python · Large Language Models: the tweets https://www.kaggle.com/code/mpwolke/chatgpt-tweets

		ok I see 
		"..6 Limitation
		Some limitations should be taken into consideration when interpreting our results.
		First, our analysis is limited to tweets collected before June 2023, due to changes
		in Twitter’s data access policy..."

but there are more available datasets you can combine  

*Data cleaning*

"tweets from bots to ensure that our analysis" How?? this by itself is separate study/publication!

*3.3 Sentiment Analysis* ws edw 
state of teh art techniques for sentiment analysis

You use VADER  , Twitter-roBERTa   and XLM-T (Barbieri et al. 2022).  Twitter-roBERTa was trained on *English tweets only.*

It would be nice to see extended dataset with the multi trained Twitter-roBERTa on more languages..


"..To generate the ground truth, we randomly selected 1,000 tweets from the cleaned dataset and manually labeled their sentiments.."
Maybe provide a small sample of the labelling data ? Also why manually and not consider other techniques like keyword-based labeling/Machine learning-based labeling/Crowdsourced labeling /Semi-supervised learning?
*Topic Modeling* 
preprocessing included ok!

BERTopic used is better than LDA  considering the dataset.
Please indicate the parameter parameter  Tuning and in brief providing a short justification. https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#bertopic and the briefly how you estimate the sentiment distribution. 

Is link 3.3 in the sentence : "..Building upon the sentiment analysis conducted in Section 3.3, we delved deeper into
these chosen topics correct? .."

"The python packages, nltk, contractions,
and spaCy were used for processing stop words, contractions, and lemmatization,
respectively." OK!I guess no parametrization needed here. 

*Results *

Can you provide a very short explanation (one-two sentences) on the fluctuations of the sentiment ? maybe an event influenced the sentiment ? as provided in section 4.1 (Fig. 3 Sentiment distribution by month from December 2022 to June 2023)

 Table 3 has sum of 60.36% not same as 60.38%

15 March 
==================
*TODO* As einai etoimo to invitation yto experts steilto se 
FW: ECCO Community Groups Co-chairs Biweekly Meeting


How to invite experts (slides)



cxreate presenattion (see photos in iphone )
qa:
ask slides - 
ready text to exw 

12 March 
==============
review

		Hi Nina, Despoina, 

		To invite additional experts, we have prepared a text. Please review it here by tomorrow morning Email_experts.docx
		 or local path: "ECCO Project - General\Task_C-Link_ECCC_NCCs\C.2 - Cybersecurity Community working groups\Email_experts.docx"

		Once the text is finalised tomorrow, you can use it to get in contact with them and invite them. In the meantime, you can identify exactly who you would like to invite as an expert to the community group - and add the info details on the dedicated excel.  Image removed by sender.Task_C_Members Trackers.xlsx [local path: ECCO Project - General\Task_C-Link_ECCC_NCCs\C.2 - Cybersecurity Community working groups\Task_C_Members Trackers.xlsx]

		Let me know if you have further question. I'm also cc-ing Roberto as he's been leading these processes so far.

des experts mail OLA !

Jens Myrup Pedersen <jens@es.aau.dk> CONFIRMED to be added in experts list 


11March
===============

ECCO WG Skills
 		Nina mail Jens Myrup Pedersen <jens@es.aau.dk>
 		Nina infromed him about he series of webinars and asks would like for one such webinar to be on “How to leverage cyber competitions to engage youth”
 		For the Community Group on Skills, I would like for one such webinar to be on “How to leverage cyber competitions to engage youth”. Would you still be willing and available to give a presentation on the DK example? Perhaps you have some time at the end of March or April already (a 1hr slot for the webinar will suffice, I think)? I’m open to suggestions on the title of the webinar by the way and I would also appreciate if you have any ideas for 1 or 2 additional speakers from other countries that could bring their best practice case on the topic. If we have 3 presentations, for example, each person could have 15 mins with 15 mins for Q&A at the end. Depending on availability of speakers, two slightly longer presentations would also be just fine.


 		apanthse 

 		Thanks a lot for getting back to me on this one, and no worries about processes taking time - that is how it is. I am most certainly up for it, but March is tough. I have an opening on March 27, but due to being right before Easter it might not be an optimal date? Otherwise, April 12 (between 12 and 14) and April 17 (whole day) are really good for me. Could any of these work?

 		I like the title you suggest, but we could also make it broader and focus on “Building Youth Communities for Cyber Security”?

 		Other good speakers could be Joe Pichlmayr (joe.pichlmayr@cybersecurityaustria.at) from Austria and Birgy Lorenz (birgy.lorenz@taltech.ee) from Estonia. Joe has put lots of efforts in the organisation of the whole Austrian competition, and was also the main person behind ECSC in Austria in 2022. Birgy has especially done a lot of work on engaging more (young) women in cyber. Both are very intersting perspectives in my opinion.


*TODO?*
from mail :ECCO Community Groups: Onboarding of additional experts and webinars guidelines

AURIO!!!


Follow-up - The co-chairs must prepare a follow-up text and email that will be sent by ECSO's team to the NCCs, together with the slides - please ensure and verify with the speakers that the slides can be publicly shared. Please include in the message the takeaways and next steps. The content will be used for the final deliverables.

8 March 
==========
check with Nina what is next ??
do I need to be in the meeting with EC . ? 
review 
vicky - jadbio ok account JADBIO
				despoina@ics 
				U:5z9`"@3%[`"3M^ 
				alex tutorials 

nea calls? 

REVIEW:

		Public Attitudes Toward ChatGPT on Twitter:
		Sentiments, Topics, and Occupations
		Ratanond Koonchanok1*†, Yanling Pan2† and Hyeju Jang3

*Language*
	 grammatical syntax seems ok . 	
	abstract : Our sentiment analysis result --> results , so indicates--> indicates

	Limitation --> LimitationS

*general description*
the stuy uses X tweets in order to anlyse the sentiment around ChatGPT using topic modeling for the most discussed topics. 
They extract the occupation of the users sending the tweets and analyze occupation-related patterns in
ChatGPT-related topics.


*related work*
is it complete ? 

All from first pages studies in google scholar (ChatGPT twitter sentiment) are there!! 

from second page missing:
 18 citations : Fatouros, Georgios, et al. "Transforming sentiment analysis in the financial domain with ChatGPT." Machine Learning with Applications 14 (2023): 100508.
210 citations: Kocoń, Jan, et al. "ChatGPT: Jack of all trades, master of none." Information Fusion (2023): 101861.

*they have compared their study to others OK*
	Most similar to our study, Leiter et al. (2023) used a Transformer-based
	model fine-tuned for sentiment analysis to classify each tweet as positive, negative, or
	neutral. Leiter et al. (2023) and Tounsi et a
	l. (2023) also applied emotion classification
	models to examine the public reactions expressed in tweets.

	Most similar to our study, Leiter et al. (2023) used a Transformer-based model fine-tuned for sentiment analysis to classify each tweet as positive, negative, or neutral. Leiter et al. (2023) and Tounsi et al. (2023) also applied emotion classification models to examine the public reactions expressed in tweets.


*Dataset*

dataset of 314,645, very limited. could expand with more datasets
1) ChatGPT tweets
Python · Large Language Models: the tweets https://www.kaggle.com/code/mpwolke/chatgpt-tweets

		ok I see 
		"..6 Limitation
		Some limitations should be taken into consideration when interpreting our results.
		First, our analysis is limited to tweets collected before June 2023, due to changes
		in Twitter’s data access policy..."

but there are more available datasets you can combine  

*Data cleaning*

"tweets from bots to ensure that our analysis" How?? this by itself is separate study/publication!

*3.3 Sentiment Analysis* ws edw 
state of teh art techniques for sentiment analysis




7 March 
==========
review TOMORROW TODO
GANTT ok 
JadBio xanaesteila mail 


U:5z9`"@3%[`"3M^ 

JADBIO PASS



6 March
==========
 ECCO 

Community Group on Skills Knowledge-Sharing Webinar: Roadmap & Cyber Ranges for Education and Skills Development, 6 March 2024, Webinar

110 regitsered , 45 mphkan telika 

ola ta onomata ienia edw https://outlook.office.com/mail/category/ca006b2b-6eea-4cae-90cb-df09eeedfc24  subject of email Registrations 6 March ECCO Skills webinar

-----------------------
https://cybersecurity-centre.europa.eu/events/community-group-skills-knowledge-sharing-webinar-roadmap-cyber-ranges-education-and-skills-2024-03-06_en?prefLang=pt
Eisagwgh apo NINA
	
	Synergies from CS . These communities essentially are intended to be forth for discussions and knowledge sharing  between experts from wider CS on strategic topics for interest to the NCC

	important to know that we organize a series of webinars and the discussions that are going to take place indent to be complementary to the ECCC WG5 and not indent to duplicate discussions or tasks that are linked to EU cybersecurity skills academy. So the community sessions are indented to gather the community of experts on skills and the NCC networks and exchange approaches ???.

	these topics we wish to reach the work of ECCC WG5 -   and topics to include roadmaps and cyber ranges covering to use education and so ,,,

	NCCs

	So we wish the current and coming knowledge sharing events will be useful and give opportunity to support the ECCC strategic agenda 
	...   



So today we have two presentation by .. and from TUC ....focused on roadmap ...

feel free to share your questions in chat or after the presentation by raising your hand. So with that I will give the floor to ... you can share you slide ..


*Description from ECCC site*: 
			Community Group on Skills Knowledge-Sharing Webinar: Roadmap & Cyber Ranges for Education and Skills Development, 6 March 2024, Webinar
			The European Cybersecurity Competence Centre (ECCC), supported by the European Cyber Security Community (ECCO), announces its new webinar focused on roadmaps and leveraging cyber ranges for skills development


			Close
			This event has ended.
			The European Cybersecurity Competence Centre (ECCC), supported by the European Cyber Security Community (ECCO), announces its new webinar focused on roadmaps and leveraging cyber ranges for skills development that will take place on 6 March 2024 at 11:00–12:00.

			The ECCO project, in collaboration with ECSO and the main coordinators of the four Pilot projects on Competence Centres (UniBwM and TIS for CONCORDIA; RHEA for ECHO; UMU and Goethe Uni for CYBERSEC4EUROPE; CEA, CNR and Fraunhofer for SPARTA), has established a Community Group on Skills. 

			 

			This event aims to gather cybersecurity experts to address the skills gap through knowledge sharing and strategic planning. As a matter of fact, 500.000 cybersecurity experts are currently needed in Europe, and the rapid evolution of the digital landscape makes reskilling and upskilling paramount. This series of webinars is being organised to engage National Cybersecurity Centres (NCCs) and the broader community in capacity building discussions. The online event will feature a series of informative presentations highlighting ongoing successful education, skills frameworks and case studies from European stakeholders. The event will also present an opportunity for questions and the exchange of ideas and insightful discussions. 



Apanthseis pou esteila sto chat 

me rwthse o tupos apo thn boulgaria an exoume sumperilavei kati sto challenges. ??

an xerw to rewire tous iepa oti to TUC einai meros tou ergou 

kai how do you measure the impact of teh roadmpa ...h NINA den exw apanthsh giatuo 



cerification . estiela se chat 


I am very new to this. What kind of certifications will be made available for professionals?(Antonio Tringali)

With regard to this recommendation: "Increase opportunities for women", which is the action plan?Monica Patricia ARENAS CORREA

Have you considered/are ou aware of the work of the REWIRE project that is building courses and certifications on top o ECSF framework? 

How do you plan to measure the impact of this effort? Do you have a list of KPIs?Harry Manifavas

I might have missed this, so apologies if this was already answered: The project has ended, but it is still possible to provide input to the roadmap. How and where will the roadmap be used now the project has ended?  

Have you considered the European Digital Skills and Jobs Platform as one-stop-shop for training opportunities? https://digital-skills-jobs.europa.eu/en/opportunities

MY answers
The roadmap is available here:  Regarding the certifications schemes from CONCORDIA:https://concordia.monitorboard.nl/roadmap/
With more info + video here: https://www.concordia-h2020.eu/roadmap/
Regarding the certification scheme by CONCORDIA: https://www.concordia-h2020.eu/delivers/c3/

Finally regarding the Women in Cyber initiative from CONCORDIA : https://www.concordia-h2020.eu/wp-content/uploads/2019/09/WomenInCyberMANIFESTO.pdf 

And https://www.concordia-h2020.eu/women-in-cyber-manifesto/

This is my email dantonakaki@tuc.gr . You can contact for any further question regarding the CONCORDIA roadmap. 

https://www.concordia-h2020.eu/delivers/womenincyber/. And https://www.concordia-h2020.eu/women-in-cyber-manifesto/


 Of course full information is available in the deliverable: https://www.concordia-h2020.eu/wp-content/uploads/2021/10/CONCORDIA_Roadmap.pdf


19/2/2024
==========
https://transparency.twitter.com/en/reports/moderation-research.html

apply for me and maybe Sotiris ? 


16/2/2024
====================
Meeting with ECCO for WG ECCO Task C: Community groups

*from me* Just take a look at the small descriptions I have send (agenda). 
 have a limited availability on some days not sure when. Only info I have to be in hospital on a Thursday on March.




===============================
15/2/2024
====================

	Matteo 6th better. 7th is the ECSO board

		Webinar B – 1h - ECCO WG on Skills - Roadmap &  Cyberanges on education and skills 
			-------------------
			CONCORDIA - Despoina Antonakaki - Roadmap for Education and Skills - 20min.
			Q&A 10 min
			ECHO -  Matteo Merialdo- Leveraging cyber ranges for skills and competence development - 20min.
			Q&A 10 min.


	TODO: 

	Can you please prepare (if needed with the help of your speakers) a short description of the session that ECSO colleagues can use when sending the invite?


	Considering the fast evolution of the digital transition and the current unfilled need of about 500.000 cybersecurity experts in Europe, education and training (reskilling / upskilling) are two especially important and urgent objectives for the entire European society. Towards this goal ECCO along with ECSO and the main coordinators of the four Pilot projects on Competence
	Centres (UniBwM and TIS for CONCORDIA; RHEA for ECHO; UMU and Goethe Uni for CYBERSEC4EUROPE; CEA, CNR and Fraunhofer for SPARTA) have formed among other working groups the WG on skills .
	Among the main objectives of this group is to build a strategic planning and roadmapping supporting ECCC objectives and the ECCC Strategic Agenda on Skills, support the ECCC/ NCCs in implementing the tasks on skills and	develop knowledge sharing across stakeholders and NCCs on the main issues of this Community Group. 

	Under this mandate we have organized the next series of webinars:

		 Webinar A - 1 h  - ECCO WG on Skills - Educational & Skills Frameworks 

		 During this webinar

			--------------------
			CyberSec4Europe - Fabio Massacci - Education and assessment framework - 20 min fabio.massacci@unitn.it
			Q&A 10 min.
			CEA - SPARTA;  Armand Puccetti CSF - Cybersecurity Skills Framework  
			 confirmed - 20min.
			Q&A 10 min.

			 


			During this webinar the main coordinators from pilots CONCORDIA and ECHO are going to present some of the most important outcomes regarding education and skills. The webinar will consist of two parts: The first focuses on the Cybersecurity Roadmap for EU including the main challenges - based on findings when assessing CONCORDIA’s courses portfolio -  along with the recommendations answering but also complementing some of the actions put forward by the European Commission in the Digital Education Action Plan (2021-2027) 
			The second demonstrates  A cyber range provides a multipurpose virtual environment, which organisations can utilise for training, prototyping, and certification of new technologies, as well as for creating security testing environments that would otherwise be impossible to build. Cyber ranges are closed and controlled testbeds that contain all the necessary tools, networks, and user simulations that are required for all intended security purposes. Within the scope of the ECHO project, a federation of interconnected cyber ranges form the foundation of the ECHO demonstration cases, providing the host environment in which three demonstration cases will be executed to demonstrate the added value that cyber ranges bring in the development of technology roadmaps, cyberskills development, as well as certification testing.

			Webinar B – 1h - ECCO WG on Skills - Roadmap & Cyberanges on education and skills 

			-------------------
			CONCORDIA - Despoina Antonakaki - Roadmap for Education and Skills - 20min.
			Q&A 10 min
			ECHO -  Matteo Merialdo- Leveraging cyber ranges for skills and competence development - 20min.
			Q&A 10 min.


	*I guess we have to wait until the presenters of the first webinar respond since it it happening before?*


	Working group on skills: 
	The Webinar will cover the presentation 

	12/2/24
	================

	I can create a doodle on 
	*when THEY response about ANNA* TODO 

	TODO reply to ANNA 

	1) Anna felkners added to experts group 
	2) Asked if anna can present the report but Nina suggests that other workforce studies like The one from ISC2 is the most known and quoted one: https://www.isc2.org/research
	OECD also released one this week but it covers France, Germany and Poland specifically: https://www.oecd-ilibrary.org/employment/building-a-skilled-cyber-security-workforce-in-europe_3673cd60-en
	BUT let's see that form Tuesday to focus on Luigi request on the survey 

	3) Luigi survey already filled by me nad sent to experts in WG on skils 
	4) Create doodle for the next 3 webinars  NEXT 

	for the first one we just need the availability of Fabio and Nina/Cristian? 

	14/2/2024
	================

	 fabio.massacci@unitn.it
	armand.puccetti@cea.fr


	  Cybersecurity Skills Framework  

			  Webinar A - 1 h  - ECCO WG on Skills - Educational & Skills Frameworks 
			--------------------
			CyberSec4Europe - Fabio Massacci - Education and assessment framework - 20 min fabio.massacci@unitn.it
			Q&A 10 min.
			CEA - SPARTA;  Armand Puccetti CSF - Cybersecurity Skills Framework  
			 confirmed - 20min.
			Q&A 10 min.

			 

			Webinar B – 1h - ECCO WG on Skills - Roadmap &  Cyberanges on education and skills 
			-------------------
			CONCORDIA - Despoina Antonakaki - Roadmap for Education and Skills - 20min.
			Q&A 10 min
			ECHO -  Matteo Merialdo- Leveraging cyber ranges for skills and competence development - 20min.
			Q&A 10 min.


			You can start organising those two, i.e. 1 for end of Feb and 1 early March. You can pick a time according to speaker availability.


			Fabio’s other presentation we can keep in the locker for a topic-related webinar. It has little to do with the other topics proposed above.

			We can keep that in the future planning list with the rest of the proposed webinars.

			 



	 13/2/24
	 =========

	 *Alex Lamprou meeting* 
	 extend paper for ASONAM 
	  more experiment to extend work 
	  50% extra work 
	  Rerun new model of burt

	 *mail to Nina/Cristian ECCO*
	  ok SENT 
	 
	 *mail for Digital signature* 
		imandalianos@tuc.gr and vaidaki@tuc.gr 




9/2/24
================
1) Sent reminder to Delia : answered ok 
	Just confirming your participation in the webinar with a presentation on Leveraging cyber ranges for skills and competence development for ECHO.
2) Forwarded survey to Despoina Antonakaki via Community_skills <community_skills@list.cyber-ecco.eu>
	and 

3) replied  to Anna 
				Dear Anna,



			It would be great to establish a cooperation on skills.
			As an initial step, we can add you to our experts' group, if it is ok with you ...

			I have added Cristian to the thread as he is the task c leader and is in charge of following the progress of the groups.

4) webinars
			Preparing the email with the presentation to Nina : 

									Webinar A - 1 h 
									--------------------
									CyberSec4Europe - Fabio Massacci - Education and assessment framework - 20 min
									Q&A 10 min.
									Fabio Massacci - Digital Europe and the result on some stakeholder needs in terms of SME/Transport and Manufacturing - 20min.
									Q&A 10 min.

									Webinar B
									-------------------
									ECHO - Delia Ioana Spinu - Leveraging cyber ranges for skills and competence development - 20min.
									Q&A 10 min.
									CEA - SPARTA;  Armand Puccetti CSF confirmed - 20min.
									Q&A 10 min.

									Webinar C 
									----------------------
									CONCORDIA - Despoina Antonakaki - Roadmap for Education and Skills - 20min.
									Q&A 10 min.
								next is to create a doddle.

NINA adds : 
			You can put it as tentative on the list: Sanjana Mehta, ISC2 and then Anna for her report.I also have other ideas and contacts for possible ebinars later in the year:
					Engaging youth through cyber competitions (Jens Myrup Pedersen, Aalborg University)
					Hackshield: educating the future cyber heroes (Emily Jacometti & Tim Murck, Hackshield)

5) 	Meeting with Robert 26/2 3-4
					 

8/2/24
================
Presentations 

1) CyberSec4Europe - Fabio Massacci -  Education and assessment framework   
2) Fabio Massacci - Digital Europe and the result on some stakeholder needs in term of SME/Transport and Manufacturing.

3) ECHO - Delia Ioana Spinu -  Leveraging cyber ranges for skills and competence development -  ECHO  ? not confirmed yet 

4) CEA - SPARTA;  Armand Puccetti CSF confirmed 
5) CONCORDIA -  Roadmap for Education and skills 


Anna Felkner asks info about WG on skills 

				Dear Anna , 

			nice to meet again!

			the main goals of Skills group (or Community Group on Skills: Education, Training, Jobs, Gender Balance) are: 
			1.Build community of experts on skills.
			2.Promote the development of skills and capabilities of cyber- professionals.
			3.Support the alignment of curricula in higher education with the workforce demand across EU-27.  
			4.Provide recommendations on filling the gaps in professional certification and attestation of skills in cybersecurity
			5.Facilitate collaboration and common approaches among relevant stakeholders.

			mainly these goals result in the foreseen activities: 
			•Working Group Meetings (remote / live) – core ECCO team and/or with experts
			 •Identification of relevant achievements / best practices (e.g. developed in the Pilots or other) to address the ECCC Strategic Agenda
			 •Recommendations for future specific priority “Joint Actions” (e.g. DEP projects) and other actions for the ECCC.
			 •Possible cooperation in immediate Joint Actions
			 •Envisaged knowledge sharing events: presentations before EC, NCCs, ECCC

			The participants include: 
			1.ECCO Partners Leaders: TUC & ECSO
			2.ECCO Partners support:  CEA, Goethe, RHEA
			3.List of envisaged experts
			4.Other possible experts (list to be progressively compiled and contacts established when needed): experts from ECSO and pilots and suggested by NCCs/ECCC

			So far we have arranged the following activities: 
			An initial webinar on the main outcomes of 4 pilots (CONCORDIA -  ECHO - SPARTA- CyberSec4Europe) - 19.6.2023
			ECCO Community Working Group on Skills  -  including a selection of external experts as identified in the proposal, where we set based on the feedback from the experts, our next steps.  - 20. 11. 2023
			A keynote speech from the President of Women4Cyber in webinar with the NCCs. on 12.12.2023

			One of these steps that we are pursuing now is to organize a series of webinars for the NCC + a wider audience, with concrete outcomes from pilots and   intriguing topics that may interest the community
			I can provide more information on each of the above, please let me know so I won't overwhelm you :) 

 




7/2/24
================


1) Goethe University representing CS4E; Fabio    Education and assessment framework for CyberSec4Europe - confirmed 

Also ! I can also present something on Digital Europe and the result on some stakeholder needs in term of SME/Transport and Manufacturing.



2) RHEA representing ECHO;  ECHO  -  E-learning platform - RHEA  -  ‘Leveraging cyber ranges for skills and competence development’ who ? Just to be on the same page, Delia will be giving a presentation on Leveraging cyber ranges for skills and competence development for ECHO? 

3) CEA representing SPARTA;  Armand confirmed he will present from SPARTA the CSF
TUC - concordia 

------------------------
  
CyberSec4Europe - Education and assessment framework - 


SPARTA  - Cybersecurity Skills Framework 
CONCORDIA  - Roadmap for Education and skills 
 Youth Education in Cyber
 Leveraging cyber ranges for skills and competence development
 Impact of AI on skills and the workforce
 Academia-industry collaboration
 Cyber Hygiene Practices for Teens  (as also mentioned in the Preamble of our ECCO Community Group on Skills terms of Reference.)
 Social Engineering Awareness
Educational curricula alignment with the needs of the market
 Tools for hands-on technical education in cybersecurity including fighting cybercrime
Security and privacy ‘by design’ approach in training and education for IT professionals 

5/2/24
================

ECCO : we have Fabio Massacci for CyberSec4Europe after March .




2/2/2024
=================

			NiNA mail at 31/1/2024:
			So you can already have a think of a possible work plan according to the initial elements of the group description. I can advise but I have no time to lead on this with all the other work I have in ECCO. I think it would be really great if you as TUC can spend your ECCO effort there😊

			WORK plan 

			CONCORDIA https://www.eitdigital.eu/fileadmin/2023/eu-projects/concordia/roadmaps-05-Education.pdf  https://concordia.monitorboard.nl/roadmap/


			according to our webinar with the experts and the following outcomes from this discussion : /Users/despoina/Documents/ECCO/Users/despoina/Documents/ECCO/TASK C/DeliverableD-C1/

						A meeting of the ECCO Community Working Group on Skills was held on 20 November 2023 including a selection of external experts as identified in the proposal. 

					Objective and target audience: 

					The meeting included the ECCO WG on skills core team and a selection from the level 1 and 2 Experts at ECCO Community WGs. TUC and ECSO were the Chairs. The webinar included an initial introduction on the objectives of the ECCO Community WG on Skills (provided in slides), by TUC followed by a discussion on this with the experts. 
					The aim of the meeting was to discuss the objectives of the WG and how to provide practical outcomes for the Community and the ECCC/NCCs. In order to initiate the discussion and gather the respective input from the community of experts, a set of the following questions were addressed:
					1.	Which actions can we follow to support and grow the professional workforce?
					2.	What are the relevant achievements/best practices (Pilots, ECSO or other) to address the ECCC Strategic Agenda and its implementation Action Plan?
					3.	How is it possible in your opinion to align the educational curricula with the needs of the market and public sector?
					4.	Which approaches can we follow for the harmonisation of professional certification and attestation?
					5.	How can we support efforts to raise awareness, educate, and stimulate an interest in cyber for youth (of all ages and gender): “be ready to be cyber professionals/users!”
					6.	Maybe some recommendations for future specific priority “Joint Actions” (e.g., DEP projects) and other actions for the ECCC

					Outcome: After a discussion with the experts and the core WG on skills team, based on the responses on the question above, we designed our next actions on gender diversity, on raise awareness of the NCC on the main outcomes from the pilots, on potential next joint DEP projects,  that would make sense according to the objectives. 

			our next steps 



 

OK that’s fine for me. You could eventually also ask them if they have ideas for experts to include in the Community Group as we need to populate it.

 

Maybe you can then send a separate email to community_skills@list.cyber-ecco.eu with the second list of 13 topics saying that ECCO wants to speed up the activity of the Community group and asking them what they think of the topics, do they have ideas for other topics and speakers etc. As per my last mail.

 

So you do two emails, one internal ECCO and one more external to engage with the experts. This will help you collect as much info as possible.

 

Thanks!



1/2/2024
=================
1)ECCO - replied on the first mail that we lead the workload and asked for advise as offered from Nina, 


2) ECCO skills task: your help in reviewing translated survey
replied with changes xls translation in Greek 


31/1/2024
=================
ΝΙΝΑ 2 εμαιλσ 

bi-weekly coordination call
ECCO skills task: your help in reviewing translated survey


26/1/2024
=============
Survey paper Alex at Expert systems : https://www.overleaf.com/project/65b38485ba6cd2b3cdae61ef

24/1/2024
==============
reveiw   B-TTDb: A Database of Turkish Tweets for Predicting the
Top One Hundred Emojis

submitted 

23/1/2024
===============
Review from Transaction on the Web : 
B-TTDb: A Database of Turkish Tweets for Predicting the Top One Hundred Emojis


		1. Τhe Language of the manuscript is acceptable. 

2. Very limited dataset if only 158,201 unique tweets. Is this the complete dataset of Turkish tweets? how was it compiled?  Why only Zargan as a dialect ? if other dialexts are available, in order for the dataset to be balances, should be an equal distribution from all of them  

The study should consider to include more international language datasets except Turkish . 


3. Literature review: Important citations missing: 

				A. citations 41: Liu, Chuchu, et al. "Improving sentiment analysis accuracy with emoji embedding." Journal of Safety Science and Resilience 2.4 (2021): 246-252.
				B. citation 126: Shiha, Mohammed, and Serkan Ayvaz. "The effects of emoji in sentiment analysis." Int. J. Comput. Electr. Eng.(IJCEE.) 9.1 (2017): 360-369.
				C. citations 41: Li, Mengdi, et al. "An empirical analysis of emoji usage on Twitter." Industrial management & data systems 119.8 (2019): 1748-1763.
				etc.  
				D. citations 109  Na’aman, Noa, Hannah Provenza, and Orion Montoya. "Varying linguistic purposes of emoji in (Twitter) context." Proceedings of ACL 2017, student research workshop. 2017.
				E. citations 132: McShane, Lindsay, et al. "Emoji, playfulness, and brand engagement on twitter." Journal of Interactive Marketing 53.1 (2021): 96-110.


Citations on *Emoji prediction* not in the study referenced: 

					A. Bansal, Barkha, and Sangeet Srivastava. "Lexicon-based Twitter sentiment analysis for vote share prediction using emoji and N-gram features." International Journal of Web Based Communities 15.1 (2019): 85-99.

					B. Barbieri, Francesco, et al. "Multimodal emoji prediction." arXiv preprint arXiv:1803.02392 (2018).

					C. Ramaswamy, Swaroop, et al. "Federated learning for emoji prediction in a mobile keyboard." arXiv preprint arXiv:1906.04329 (2019).

					D. Cappallo, Spencer, Thomas Mensink, and Cees GM Snoek. "Image2emoji: Zero-shot emoji prediction for visual media." Proceedings of the 23rd ACM international conference on Multimedia. 2015.

I suggest for all references to visit google scholar and look for the most recent and MOST CITED references on the corresponding topic.  
Also provide a categorization of the literature review, highlighting the most related to your work.  

4. Where do your study stand in terms of methodology and results compare to other studies? Please provide a short comparison at the end of the literature review, adding the novelty of your work. 

5. What are the contributions of this work and how is this addressed in the results ? How is it better compare to background work? 

6. the number of experiments and the size of the dataset are very limited . 

7. In line 40 , on phase 5 it is stated that "Afterward, the same tweets, in terms of words included, existing in different emoji classes were removed completely". 
How are the emojis labelled already into classes? 
Is there any prep-labeled dataset used? if so please add a sentence-paragraph explaining this, before stating that you are using it. It is not clear in this step how it is accomplished  

			["Phase #5: It was provided to have unique tweets, in terms of words included, in each emoji class. Afterward, the same tweets, in terms of words included, existing in different emoji classes were removed completely. As a result, PPTD was obtained."]

8. In the Stage 2 (Resampling), where T-Value is the average number of tweets in an emoji class in terms of multiples of 250, why do you pick 250 ? 

			9. 

19/1/2024 
===============
ECCO Working groups  on Skills 


as noted in  the deliverbe and after the meeting we had on 21/11/2023 we had the next point to wokr on : 

1.	Regarding gender diversity, we plan to include a keynote speech from the President of Women4Cyber in the upcoming webinar with the NCCs. The keynote will share best practices and explain the experience with the Women4Cyber Foundation and its 25 Chapters, as well as share knowledge and provide visibility to what Chapters from different Member States are doing, in order to initiate a conversation on gender aspects with the NCCs and hopefully stimulate collaboration at national level.
2.	Make pilot outcomes on skills aware to NCCS. Develop a summary (1-2 pages) of the main outcomes of the Pilots on skills and organise a webinar with the NCCs focusing on topic-specific outcomes and impact (not project by project).
3.	Requested input from experts on the following questions: 
•	Is there any openly available information on certification/attestation on skills in cybersecurity in your country? Is there a certification process that is defined by the government in order to define the skillset and the profile necessary for specific positions and jobs in cyber? A specific process for professionals in cybersecurity to get accredited? Maybe an exam/year of experience in order to get a certain position in cybersecurity? There are specific initiatives in different countries and one example of an exercise from last year in Spain in which relevant stakeholders were brought together in order to define a certification process for certain cybersecurity skills and profiles was brought up. All experts to share such examples from their countries.
4.	Prepare a recommendation to the EC/ECCC for a joint action / DEP project call focused on bringing together academia and industry for knowledge transfer and increased capacity building on education and skills. More input is expected on this


1. The first is accomplished since we already had a meeting with the women4cyber on 
2. ok done and sent to Nina 
3. Input requested on 21/11 with NO response !
4. Porposal 


Armand has sent to me (ff Nina ) the following proposal 
					Project proposal

					Increasing Cybersecurity skills for European Industry

					Programme: FET, possibly Horizon Europe
					Type of action: FET Incubator Action

					1.Topic description

					Scope:

					The aim is to help to bring Industry and Academia together to create ideas for matching the demand of industry in terms of Cybersecurity (CS) skills with the skills and educational courses spent by higher degree education, e.g. Universities. The needs for highly skilled personnel in the CS domain is increasing and a shortage of skilled graduated people in this domain is becoming evident. The cybersecurity of European industries and public organisations is specifically urgent in times of crises such as the current Ukranian/Russian War. Cyberattacks on European industries and organisations have significantly increased due to these events and the needs to counter them have become mandatory with supplementary highly trained and skilled personnel.

					Putting Industry and Academia together can help to solve the shortage of skilled personnel will help to find solutions to this issue by:
					-	Defining the needs of European industries.
					-	Classifying the academic organisations involved in training and skills in the CS field.
					-	Matchmaking events between both groups of organisations to determine how to align CS training with industry needs, and elaborate plans and curricula for trained persons capable to sustain industries’ needs.
					-	Defining adequate training and academic education courses matching these needs.
					-	Elaborating plans for the short and medium term to align them.
					-	Increasing the attractivity of the Cybersecurity domain among younger people.

					This is a newly identified action that is not currently covered by the Horizon Europe Work programme.

					2. Topic destination

					Increased cyber-security (2024 and beyond).



16/1/2024
===============
1) Sent email to Antonio Skarmeta cc Nina 
2) No timesheets yet available
3) review 

						 The study involves creating a dataset that compiles tweets related to significant events in Chile, such as the COVID-19 pandemic in 2020, the October 2019 social uprising, and the wildfires in January 2017 and February 2023. The research introduces new indicators to assess sentiment, inclusivity, engagement, and societal impact, providing a comprehensive toolkit for evaluating social media content. It explores variations in response patterns among influencers, press & radio, and television accounts, emphasizing their unique contributions to the information landscape during emergencies. To enhance sentiment classification accuracy, the study employs Deep Random Variable Functional Link Neural Networks. Additionally, a comparative analysis of classifiers establishes the superiority of RVFL and D-RVFL networks over traditional models in the context of social media sentiment classification . 

						See how the methodology although novel has drwback, or issues that are not handled properly 

						citations missing 

						dataset complete ?

						*english ? Proofreading*

						Some of the grammatical error detected in the manuscript include: 

							line 58 We introduces new indicators
							line 65 We conducts 
							line 102 of certain social phenomenons,
							line 196 This dual approach allow 
							line 215 The third indicator Div analyze
							246 It is design and - [makes no sense]
							311 This may be explained by the number of follower 
							314 However, as the other events did not had a day  
							367  We also observed that depending on the event, the -->characteristic of influencers changed. 
							line 57 fix this "academictwitteR" and add reference 
						 						
						Editorial Criteria
						BASIC REPORTING
						Clear, unambiguous, professional English language used throughout.

							The manuscript needs proofreading. Some of the grammatical error detected in the manuscript include: 

							line 58 We introduces new indicators
							line 65 We conducts 
							line 102 of certain social phenomenons,
							line 196 This dual approach allow 
							line 215 The third indicator Div analyze
							246 It is design and - [makes no sense]
							311 This may be explained by the number of follower 
							314 However, as the other events did not had a day  
							367  We also observed that depending on the event, the -->characteristic of influencers changed. 
						  74 ...management (Chatfield and Reddick (2018)).Studies Use a space in beginning of sentences

						  line 155 do not put URL in text (use citation like this : 

									  @misc{c:23,
									  title        = "Pluto: The 'Other' Red Planet",
									  author       = "{NASA}",
									  howpublished = "\url{https://www.nasa.gov/nh/pluto-the-other-red-planet}",
									  year         = 2015,
									  note         = "Accessed: 2018-12-06"
									})



							I suggest you have a proficient in English and familiar with the subject matter review your manuscript, or contact a professional editing service.

						Intro & background to show context. Literature well referenced & relevant.
							
						[literature - related work]  *CHECK If they have these references !!!*

							1. In line 30-31-32 need more highly cited work to support this, like: 

								1. Sentiment analysis of Twitter data 
								A Agarwal,B Xie et al.  

								2. Semantic sentiment analysis of Twitter
								H Saif,Y He,H Alani et al. 

								I suggest for all references to visit google scholar and look for the most recent and MOST CITED references on the corresponding topic.  

							2. In line 71. 		I suggest for all references to visit google scholar and look for the most RECENT and MOST CITED references on the corresponding topic.  
							e.g. 
								A. Paul, Nayan Ranjan, Deepak Sahoo, and Rakesh Chandra Balabantaray. "Classification of crisis-related data on Twitter using a deep learning-based framework." Multimedia Tools and Applications 		82.6 (2023): 8921-8941.
							  B. Mittelmeier, Jenna, and Heather Cockayne. "Global representations of international students in a time of crisis: A qualitative analysis of Twitter data during COVID-19." International Studies 		in Sociology of Education 32.2 (2023): 487-510.
							  C. Pierri, Francesco, et al. "Propaganda and Misinformation on Facebook and Twitter during the Russian Invasion of Ukraine." Proceedings of the 15th ACM Web Science Conference 2023. 2023.
							  D. Charting the information and misinformation landscape to characterize misinfodemics on social media: COVID-19 infodemiology study at a planetary scale
									E Chen, J Jiang, HCH Chang, G Muric, E Ferrara
									JMIR Infodemiology 2 (1), e32378
								E. Rahman, Shoaib, et al. "Social crisis detection using Twitter based text mining-a machine learning approach." Bulletin of Electrical Engineering and Informatics 12.2 (2023): 1069-1077.


							3. Regarding the related work, you have to highlight your novelty and new contributions compared to background work.	How is this work different from similar background works? Which is the most important / influential work in this field and how are you better compared to them? 

							4. In line 150 you refer that ""no works where RVFL networks are combined for text classification "  BUT what about these ? 

									Henríquez, Pablo A., and Gonzalo A. Ruz. "Twitter sentiment classification based on deep random vector functional link." 2018 international joint conference on neural networks (IJCNN). IEEE, 2018.

									Shi, Qiushi, et al. "Random vector functional link neural network based ensemble deep learning." Pattern Recognition 117 (2021): 107978.

									Chauhan, Vikas, and Aruna Tiwari. "Randomized neural networks for multilabel classification." Applied Soft Computing 115 (2022): 108184.

									--> Again visit google scholar for "RVFL text clasification"


						[Dataset] Size? 
							
						Structure conforms to PeerJ standards, discipline norm, or improved for clarity.
						Figures are relevant, high quality, well labelled & described.
						Raw data supplied (see PeerJ policy)

						METHODOLOGY 
						Some parts of the  methodology  needs more detail.

							Not clear in equation 2 above line 206 where is initially referred how interactions is measured. 
							During the data labeling process (line 232), in SMOTE why did you choose k=5 for KNN? Is there a 

							line 283 : why sigmoidal activation function? Please provide a justification. 

						VALIDITY OF THE FINDINGS
						Impact and novelty not assessed. Meaningful replication encouraged where rationale & benefit to literature is clearly stated.

							Contributions are listed in line 55 but are they accomplished????

						*what about ground truth?*how was is achieved ? line 232 Synthetic Minority
						242 Over-sampling Technique (SMOTE)

						All underlying data have been provided; they are robust, statistically sound, & controlled.

						EXPERIMENTAL DESIGN
						Original primary research within Scope of the journal.
						Research question well defined, relevant & meaningful. It is stated how the research fills an identified knowledge gap.
						Rigorous investigation performed to a high technical & ethical standard.
						Methods described with sufficient detail & information to replicate.

							Please indicate in one-two sentences (line 177) was the preprocessing of tweets included. 

						Conclusions are well stated, linked to original research question & limited to supporting results.


						Conributions 
						Development of a dataset aggregating tweets pertinent to several significant events in Chile,
						56 including the COVID-19 pandemic in 2020, the social uprising in October 2019, and the wildfires
						57 that transpired in January 2017 and February 2023.
						58 • We introduces new indicators to measure sentiment, inclusivity, engagement, and societal impact,
						59 offering a comprehensive toolkit for evaluating social media content.
						60 • The research delineates the differences in response patterns between influencers, press & radio, and
						61 television accounts, highlighting how each group uniquely contributes to the information landscape
						62 during emergencies.
						63 • We use a Deep Random variable functional link neural networks for improving the classification
						64 accuracy of the sentiments of tweets.
						65 • We conducts a comparative analysis of different classifiers, establishing the superiority of RVFL and
						66 D-RVFL networks over traditional models in the context of social media sentiment classification.


						In summary, the interaction between the performance of machine learning classifiers and the analysis of social media yields valuable insights into the reactions and perceptions of different account types in diverse situations. RVFL and D-RVFL excel in efficiently categorizing and predicting patterns in data, a more nuanced understanding of human responses emerges through sentiment and engagement indicators. This becomes particularly significant in the context of influencers and institutional accounts during crisis periods. The superior accuracy of D-RVFL in classification tasks suggests that deeper models are more adept at capturing the intricate nuances of social media discourse, evident in the varied levels of sentiment and engagement observed across different events [[

9/1/2024
===============

Tasks TODO: 

1) Pilots main outcomes (here: /Users/despoina/Documents/ECCO/TASK B/November2023_main_outcomes_on_Skills.docx)
		Nina on chat: [11:25 AM] Nina Olesen
		Hi Despoina, well it's too late for the deliverable but I think it would be a good task to do under the Community Group. To develop something clear and concise as a a "marketing" of what the Pilots have done. You can work with Antonio and the others to build on what already exists
 
 2) timesheets. See how it works for TUC 
 3) Reviews reply 
 4) Panagiota Koutra: pio sugkekrimena detection se social media. 
 5) prosarmose to cv me vsh auto https://www.panagiotisilia.xyz/panagiotis_ilia_cv.pdf
 6) vale ta ranteou mastou sto calendar OK 
 7)  - vale mentrual -a pp kai exetash 3h meras peiodou OK 
 8) ECCO for PMG update . Deliverables returned somewhere in middle of December with minor changes. corrected and resubmitted. εκκρεμμει ενα συντομο report για το outcome των pilots . 
 
 9) instagram threads
 10) TIMESHEETS για ΙΤΕ επομενη εβδομαδα
 11) 

REVEIW paper 


19/12/2023
===============
MISINFORMATION papers
KAPALM: Knowledge grAPh enhAnced Language Models for Fake News Detection 


Fake news on Twitter during the 2016 US presidential election
N Grinberg, K Joseph, L Friedland, B Swire-Thompson… - Science, 2019 - science.org 1564 citations!!
https://sci-hub.se/https://www.science.org/doi/abs/10.1126/science.aau2706
Coronavirus goes viral: quantifying the COVID-19 misinformation epidemic on Twitter - 929

12/12/2023
=============
	Women4cyber meeting NCC ECCCs
	--------

	Annet presentation and Q&A from all 

11/12/2023
=============
Paper : 
ChatGPT-4 Outperforms Experts and Crowd
Workers in Annotating Political Twitter Messages
with Zero-Shot Learning


pou einai ya  data apo twitter . ta eixamame anevasei sto google drive tou si ? 

8/12/2023
=============

dwra 

*ελενη* 110,78
valitsaki zwgrafikhs 23,90 OK info@apothikinikolaidi.gr  OK mallon sta elta STAYROULA 
roloi Xiaomi Smart Band 8 Αδιάβροχο με Παλμογράφο Μαύρο 32,42 ΟΚ σκροθτζ  OK hr8e surtarh SPITI 
Martinelia Kids Makeup 34,46 OK genikh tax ELENH
skoularikia monokeros 20 OK hr8e panw sthn vivlio8hkh SPITI 

*δημητρα* 125,42
skulaki 31,99 ΟΚ hr8e STAROULA 
Mattel Miniature Novelty Toy Polly Pocket Luna Park for 4+ Years Old 58,44 OK  hr8e SPITI
Plush Toy Squishmallows 13cm 7,76 OK hr8e elenh
MGA Entertainment Na! Na! Na! Surprise 26,99 € OK agorasa epetreye!!ok  elenh


ετσυ ψοδε
etsy codes Keep these codes in a safe place. You'll need them to sign in to your Etsy account if you ever lose access to the device you set up 2FA with.

256035478
193071651
814756040
489890701
180685718
405811965
045527639
000848567
305046779
192345583




6/12/2023
============
Twitter Data grant application. 

https://docs.google.com/forms/d/e/1FAIpQLSdo0O-D6Kxa3cV4g1JLz2T_0Sk3hdEnTdv8dJmibagCnzJ7kg/viewform


	Funding
	*
	Please disclose the funding of your research, including amounts raised and direct and indirect sources of funding.
	EU-Commission (CYBERUNITY DIGITAL- ECCC-2022-CYBER-03, GA 101017258 SESAME, Grant agreement ID: 830927 CONCORDIA)
	EU-Commission (CYBERUNITY DIGITAL- ECCC-2022-CYBER-03, GA 101017258 SESAME - Budget total: € 3 376 360, Grant agreement ID: 830927 CONCORDIA - Total cost
	€ 15 998 737,50)

	Commercial Interests
	My organization is completely independent from commercial interest. Our interests rest solely on research . 

	Data Security and Confidentiality
	All data collected are used solely for research purposes, are anonymized and are not distributed or being published . Please note that personal data means, under the relevant legislation (General Data Protection Regulation, 2016/679/EU) .

	My research topics that I wish to use the data are: Topic Analysis, NLP, Sentiment Analysis, Bot detection, fake news and disinformation detection. 

	The data that I will need to conduct my experiments includes user messages, user objects, , potential labeled user infor as spam/non legit/bot and user graph connections' information. 

	The current research is being ongoing for the past 10 years, and I wish to continue at least for the next year, or more if available. 


24/11/2023
============

write *input to roberto's deliverable*. See info in 23/11
See NIna memo on Women4Cyber talk for the NCCs

Roberto need to reports activities from M9-M12
the first meeting with the NCCs was on on 19 June, 2023.

ecco started on 
M1 January 
M2 february 
M3 March 
M4 April
M5 May 
M6 June  - first NCC meeting  
M7 July
M8 August
M9 September
M10 October 
M11 November 
M12 December  - second meeting with experts No NCCs 

28/11/2023
=============

sent reminder for input waiting in ECCO ( Armand and experts ). 


27/11/2023
=============
*TODO* As noted in the meeting with the experts : develop a 1-2 pager summarising the work of the Pilots on skills and organise a webinar with the NCCs focusing on topic-specific outcomes and impact (not project by project deliverables) to make the NCCs aware of what already exists.


23/11/2023
=============

Nina email about Women4Cyber talk for the NCCs

	NINA email) organise a 1hr webinar for the NCCs where we could first present a bit the roadmap of the ECCO Community WG (likely NINA). We would like to organise this before end of the year. early/mid December for .

	Anett) This is an excellent opportunity for Women4Cyber. I am happy to join the event. Best timing for me is 11-12 or 15 December. -	Anett Mádi-Nátor - Vice President

	Nina) I think 11th would be a good option.

   *CC’ing Despoina for info as Community Working Group leader as she should then also work on the other objectives of the WG and prepare the ground for 2024.*



Deliverable D-C.1.2 Organization and animation of the Cybersecurity Community. Activity Reports
		
		meeting  with Roberto: 
		---------
		Jose Luis Hernandez Ramos
		Davide Grison
		Roberto 


		Deliverable till end of year 
		Our deliverable on skills will include also include gender balance

		There is template for input to deliverable 

		governance . list of organizations involved . key stakeholders 

		type of activity meeting ! for us 
		and what you plan to do 
		this need to be connected to roadmap and objectives 

		challenges that you face ..lack of participation ....

		2-3 pages per working group ...

		repository 

		will sent the link https://ecsorg.sharepoint.com/:w:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BC79F756E-79A1-4D0A-92CC-3BD77A653D91%7D&file=Working%20Group%20-%20Deliverable%20Update.docx&action=default&mobileredirect=true


*first version should 4/december...* 

*TODO: add input from meeting on skill WG to this deliverbale"


22/11/2023
=============
prokurhxh ok / 2120Αίτηση Υποψηφιότητας στο παρακάτω σύνδεσμο θα βρεις την προκήρυξη θέσης με αριθμό ICS-2120

File:antonakaki_cv_November2023.pdf was uploaded.
File:ptuxio.pdf was uploaded.
File:metaptuxiako_diplwma.pdf was uploaded.
File:PhD.pdf was uploaded.
File:publications2023.pdf was uploaded.
File:letterOfSupportDespoina_concordiaFrag.pdf was uploaded.
File:potamiasSUSTATIKH__DespoinaANTWNAKAKH.pdf was uploaded.
File:MorrisLoSDespoinaAntonakaki.pdf was uploaded.
File:DavidLetterofrecommendation.pdf was uploaded.
File:Skills_regarding_Required_for_FORTH_November2023.pdf was uploaded.
Your application submitted successfully

Application ID 2657


ECCO deliverable 

Roberto : ECCO D-C.1.2: contribution of the ECCO Community Group chairs



21/11/2023
=============
[ICS-2120] Call for expression of interest for a position of a Research Associate in the Institute of Computer Science (ICS) Foundation for Research and Technology – Hellas (FORTH)
We seek an experienced member for our team, a Research Associate, with strong background in European Research Projects. The candidate will participate in the R&D activities of FORTH in the context of the project “CYBERUNITY: Community for Integrating and Opening Cyber Range Infrastructures that Build an Interoperable CrossDomain and Cross-Sector Cyber Range Federation, funded under DIGITAL- ECCC-2022-CYBER-03”. The candidate will participate in all aspects of the project with focus to training and educational aspects, creating CR scenarios and training material and participate in all management and reporting activities with the aim of developing of an interoperable community of Cyber Ranges, following the concept of the “Cyber-Range-as-a-Service” (CRaaS), along with the first overarching Knowledge Repository for cyber ranges that will be developed.


deliverable ECCO : 

	Despoina to fill in more information on the Community Group and chase inputs for the various tasks related to that (incl. some written input from Armand on the idea he had today). For the two mapping exercises, it would be good if you could make an analysis of the situation (even if brief)) and put inputs from each country in the Annex instead.

	I have made a brief summary for  the three subchapters 2.2.1, 2.2.2 and 2.2.3  (in old version) now moved to Annex as  8.2.1, 8.2.2 and 8.2.3
	I added a brief update on the meeting and outcomes from WG on skills along with the names of the experts.(2.3.2, 2.3.3) 
	@Nina, should I mention the list of participants ???

	I also noticed that the links to the references were broken somewhere in the merge/move process, so I propose fixing them in the final version along with the formatting otherwise we repeat efforts 🙂

20/11/2023
==============
deliverable meeting 
------------- 

Just to summarise from my side (and as discussed briefly now with Marie-Hélène and Despoina):


Laura to include some more information on our efforts for the Pledges (comms campaign, support to EC, etc.).
Despoina to fill in more information on the Community Group and chase inputs for the various tasks related to that (incl. some written input from Armand on the idea he had today). For the two mapping exercises, it would be good if you could make an analysis of the situation (even if brief)) and put inputs from each country in the Annex instead.
Nina to work on the deliverable on Thurs/Fri this week.
Marie-Hélène to do a first review next week.
Nina and Marie-Hélène to catch up Fri 1 Dec at 




20/11/2023
================

follow-up meeting of the ECCO Community Working Group on Skills was held on 20 November 2023 
Participants
----
Despoina Antonakaki  - TUC 
Nina Olesen  - ECSO 
Antonio Fernando Skarmeta Gomez  - University of Murcia -  Sparta 
Armand Pucetti  - CEA

=============
(Nina) A next action on the gender aspect would be a keynote on our webinar from the president of women of cyber to give a keynote. Invite all NCCs 
to share best practices, explain experience with women for cyber for the chapters . The event will be like a sharing of knowledge but also bringing a little bit visibility to what chapters are interesting, as well as from their countries from the NCC point of view in order to initiate a conversation of the gender aspect. 

(Antonio) the kind of this practice ..on of the topics careers . there was a specific group with ENISA and pilots curriculum . ENISA document. update on that? 
resent it by ENISA or pilots ...

There was a group with 4 pilots and ENISA . he has sent the document 

Pilots . a lot of work has been done and we have already presented several times. we can resume the main points from all pilots and present to NCCs . 
We do need to repeat all work from pilots again. The Commission need to be practically minded, they do need reports again. Are the NCCs aware of this document ? 

 

they need engagement with the NCCs, sharing of best practices,  
are the NCC aware of these documents ? 

otherwise present to the NCCs? because in Spain there was a exercise that was done last year between the different stakeholders, university and so on , in order to define a certification process for certain cybersecurity skills.  e.g. critical security officers needs this list of skills etc. certain profile and for this they nees a certain certification process, predefined ...are there similar in other countries ? 

Share this kind of info . 

certain position with certain profile .. we need a homogenous aggregation process. 
Already we are trying to do in the current updates of the deliverable .

(TODO) Presentation to the NCCs  ??  
(NINA) Find a way to frame the joint work of the pilots in a way around the topics. We need a concluding summary based on the work of the four pilots . and on this topics these are the specific outcomes, and there are the recommendations. 

 *Two follow ups based on Antonio's comments* 

1) Package the outcomes of pilots on skills + propose to NCCs a joint discussion/presentation
2) Extend your math with people in this group and leverage their knowledge of there is some like openly available information of certification in cybersecurity 
gather some examples for international certification process in order. 

Define the certification process. 
It is internation certification process that is defined by the government on order to define what are the skills and the profile necessary for specific positions and jobs in cyber; to get accredited through a certain process, exam or years of experience, to get certain position in cybersecurity.


3) Propose the EU commission a proposal/call.  

(Armand)Propose to EU commission to set up a project that will put together all relevant stakeholders. Putting people together to transfer the knowledge between industry and academics . This kind of communication is missing like in France. where the economy is driven by industry. Communication with academy is necessary. Fundamental research that is missing from industry. 

Nina) Try and iterate this issue at hand -maybe one page -with specifics on this and Consortia.  

				This is the national Forum for cybersecurity

				Foro Nacional de Ciberseguridad - Inicio (foronacionalciberseguridad.es)   where the main actors at national level are represented

				This is the WG on skills Foro Nacional de Ciberseguridad - Formación, capacitación y talento (foronacionalciberseguridad.es)

				and here the document
				file (foronacionalciberseguridad.es)

				esquema-nacional-de-certificacion.pdf (redseguridad.com)

follow-up to community group EMAIL 
========
 Despoina Antonakaki  						- TUC 
 Nina Olesen          						- ECSO 
 Antonio Fernando Skarmeta Gomez  - University of Murcia -   
 Armand Pucetti  									- CEA 


Dear all,

after our fruitful conversation today we would like to share with you the main point of our conversation
and ask your input on your point of view on the following issues.

The main main questions that were addressed:
		Which actions can we follow to support and grow the professional workforce?
		What are the relevant achievements/best practices (Pilots, ECSO or other) to address the ECCC Strategic Agenda and its implementation Action Plan?
		How is it possible in your opinion to align the educational curricula with the needs of the market and public sector?
		Which approaches can we follow for the harmonisation of professional certification and attestation?
		How can we support efforts to raise awareness, educate, and stimulate an interest in cyber for youth (of all ages and gender): “be ready to be cyber professionals/users!”
		Maybe some recommendations for future specific priority “Joint Actions” (e.g. DEP projects) and other actions for the ECCC?
	
	The recommendation proposed during the the conversation include the following: 

	1)  Propose a presentation /discussion with the NCCs based on a concluding summary from outcomes of pilots on skills 
  2)  Is there any openly available information on certification/attestation on skills in cybersecurity, a certification process that is defined by the government in order to define what are the skills and the profile necessary for specific positions and jobs in cyber? A specific process for professionals in cybesecurity to  get accredited? Maybe an exam/years of experience in order to get certain position in cybersecurity?
  3) Propose to EU commission to set up a project that will put together all relevant stakeholders in order to transfer the knowledge between industry and academics.  
 

16.11.2023
================
 [ecco deliverable] 
 checked the merged versions Marie Helene sent 
*TODO* table of figures. My figures are not listed. 
added reference to Annex and other cahnges . how do we update the nline version..? overwrite ? 

 rehearse the presentaton ...


15.11.2023
=================
add ORCID id for Maria Koutrouli if responded.  apanthse kai mou eipe oti o elke den exei !!! ok to ftiaxame
*check  Giannis Daskalakis aboout CONCORDIA payment* OK apanthse to prr8hse sthn eleni orf? 
stele ston roerto gia liges apanthseis tso meeting  OK den exei apanthsei 

14.11.2023
=================
check again https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B81AFDCF8-5AE0-4BE9-A1A3-1AE45D303E86%7D&file=ApplicationForm(Part%20A)-SeComCon_TUC.docx&action=default&mobileredirect=true

fill in missing parts in https://docs.google.com/document/d/13Fsz0e-3p-MH-LEMOg6i0S8CELbSK55B/edit OK 
[Twitter colaboration]
literature reveiw for troll detection  .



13.11.2013
===============
[ECCO] Matteo has sent Romania, Bulgaria and Netherlands for B6.3 . 

SEComCon - check part A and other of uoiu have to cut text ...

9.11.2023
===============

Deliverable B6.3 



Narges Arastouei (de, mchar goethe ) - 
	
	Germany
	Spain
	Czech
	Norway
	Finland den eixe mpei !!

next:
	 Here my inputs for CEA.

France den eixe mpei 

matteo 
I included Italy and Belgium. U need other countries?

ok check italy and belgium , a paragraph was missing from belgium. 

8.11.2023
===============
Presentation ready
Webinar date on 20/11/2023
Invitation sent 
Outlook invite sent 
make sure from Roberto if experts are in the mailing list to receive the link *TODO*
Deliverable


MOUY-EBROUSSARD Patricia <patricia.mouy@cea.fr> sent for France 
	Narges Arastouei <narges.arastouei@m-chair.de> JAMK's Bachelor's degree curricula for finland, Germany
Matteo MERIALDO Belgium

epishs sxetika me to deliverabel shmera douleya xan to kefalaio 2.1. Analysis of courses, curricula, and educational standards across the EU-27 at the bachelor level and identification of gaps and new educational requirements opoy eida apo ta mail from scratch an htan swsto to input pou eixa valei. eftiaxa to annex pio omorfo ston pinaka kai enva ta nites tou pinaka san keimeno sto annex. 
evala kai gia thn Finland sthn korugu oxi sto annex . evala sxolio an 8elei h naina na mpei sto annex. 

 

30.10.2023
===============

*SeComCon*
Short brief update. proposal is being written . 
Part B . Chris is writing proposal. 

26.10.2023
===============

covid !!!
*ECCO* created presentation for next WG skills discussion. sent mail to Roberto to sent mail!!!
email to invite these people: 


Dear all, 

regarding ECCO Community Working Groups, that intent to support the work of the NCCs Network and of the ECCC, I would like to invite you to a discussion on 
2 November and 9 November (LINK). 

The agenda is attached: 


Intro by TUC, (7 minutes)
*A round of introduction by eveyone (10 minutes, this can go wrong in terms of time...may omit)*
A small introduction from pilots on main outcomes from pilot project, regarding education and skills 
CONCORDIA (7 minutes)
ECHO (7 minutes)
SPARTA (7 minutes)
CyberSec4Europe(7 minutes)
Discussion on skills (25 minutes)


25/10.2023
===============


gia na kanw akurwsh adeias 8a mpw sto isorioko mou 8a thn epilew kai 8a kanw aithma akurwshs. meta 8a epilexw nea adeia san sxolikh gia thn prohgoumenh hmeromhnia ..,


*Anna* timologia gai anna . Alekos exei steilei hdh   7ο, 8ο, 9ο. Esteila gai 7,8,9 kai timologio taxidiou . 
*ECCO - WG Skills* Thursday 2 November and Thursday 9 November  for the webinar TODO write a draft email to announce the webinar/discussion to the email taht ROberto wil sent 
start the presentation based on the last years presentation + ENISA panel ? or Felicia, from concordia reveiw . 
*ECCO B6.3* CEA sent input 
*ECCO deliverable* start with template Nina just sent 

 

*SeComCon*we do not have any Sensitive information with security recommendations, so I guess we do not need to fill in the "Security Issues Info-Security Section_TUC" form. Is this ok? 



24/10/2023
===============

Meeting with Davide at 1-2

				24 October  2023
			================

			*Meeting for deliverable B5 (task B6)  - Davide Grison + Nina *

			Deliverable has been split up from different contributors. 
			==> what is expected from TUC. what need to be delivered 18 December (deliverable deadline). 

			NIna deliverables need to be concrete - to the point . 
			Nina will lead on structure of the deliverable . 
			listing out according to this task 

			mapping visual 

			Nina: 

			1. Sent a reminder for tehj deliveable pinpointing teh peaols taht have not sent the input
			2. inrernal deadline mid of novermebr for TUC 
			3. be extremely to the point and concrete maybe also a visual to be more digestable 
			4. report also on the WG on skills we already had last year
			5. Even if the new meeting is not yet in place, we have to reference and report it, as well as next steps. 
Meeting with mentionlystics at 12-1
			 
			Minutes 
							product manager ? sumvash ? proxwrhse ...
							gelatous ? productization??


							Πως θέλετε να προχωρήσουμε;
							Ειχαμε ανοιξει καποια θεματα ...
							Να βαλουμε προτεραιοτητες ...

							Αλεξ 

							Θα μπορουσαμε  να κανουμε καποια ειδους αναλυση fake new detection 

						θα prepei να κανουμε μια διερευνητικη αναλυση γαι να δουμε τι υπαρχει στο dataset to sygkemrimeno 
						bot detection 
						topic sentiment analysis στον προσφατο πολεμο , και ισως να αναμοιχθει και η  

			Giannhs Kopanakis: volume based kai oxi subscription based . Ti lene gia mena p.x sthn tade politeia ...IP dieu8unseis olou tou kosmou, dineis 

			alex mpooumena exoume to feedback of the real user? 

			Kopanakis - curation . Taktopoioun to sentiment . pernoun thn anadrash tou sentiment . epanekpedeuoun to montelo sentiment . enhanc to datasase apo to interface. 

			alex emeis parexoume kai explainability . 


			kopanakis . exaitetika to explainability . 

			manos . kommati tou legal 

			alex API based ta data . sto API 8a dw8ei kapoiou eidous pre-processing - anonymization . 

			kopanakis . einai mia genikh proseggish. GDPR  - mono twitter data . exoun data ap ola ta SNs . scrapping apo public xwris na exeis kanei login (facebook, linkind kai queries gooles. eteirias me proxies kai emloutizuon ta data ) 
			upogragoume kati pou leei dinoume anonymized data. 

			alex . predict an an einai human generated content 

			kopanakis : pws 8a xefuge apo ton kikewna twn kanonismwn 

			na ftaixtei kati kalo pou kapoios 8a edine 10 eurw ...



Sent email about : Subject: 2 *concordia*-wp5-taskleaders moderator request(s) waiting
Sent email about *ECCO WG on Skills* - meeting on 17/10/2023/ Set up a doodle or pick a date ? I will need EMAIL addresses. 
*B6.3 deliverable* ? ta esteilan? 
	ekremei m.merialdo@rheagroup.com
	ekremei sparta cea 
	SENT remider OK 

*secomcon* - evale ena sunolo apo meeting gia budget  edw : https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BAA7D025E-6A94-4105-8459-105CDE682397%7D&file=SeComCo_meetings_list_draft.xlsx&action=default&mobileredirect=true


TODO 
======================
TODO: 
	*B63*.Meta apo to meeting me thn Iro dior8wsa to paradoteo. tsekare me thn Iro (skype laptop -to sent) kai meta xanasteitlo thn Nina 
	ekkremei 	rhea  - france cea Belgium 

Tue 10/17/2023 1:30 PM - 2:00 PM
===================================
*Minute from meeting with Roberto and Nina and Sotiris on ECCO WG on skills*

			Robert, we need to set things in motion. Last week was the NCC meeting where we presented the working groups and the NCC working group is up and running but it’s more focused on the NCC activities on the public administration. We need to put in motion, our objectives, and the outcomes of the working group.





			We need to call our experts and potential experts from echo identify, identified in proposal and put things in right pace  with the objectives in milestones 





			We need to share our knowledge with the NCC is through webinar and knowledge sharing events 



			We need to show that we are fully supporting the activities in the working group framework. We are on the time pressure. 



			We need to call the experts what we need to do is to as tuc see the deliverable that Robert will send 



			Which is actually what Luigi has gather together it has a list of names from Ecco, first set of last names that support Ecco 



			Nina asks what will we work on !? and Robert replies about the objectives working groups objectives on skills, which is which are aligned with eccc agenda



			Ncc , need to production for skills but we also need some join ductions collect what is already been implemented by the pilots in by ecso 



			1, put together people 

			2 validate objectives, and deliverables

			3 come up with possible recommendations, possibly with the NCC’s joint actions



			Then send an email to all the experts and inform them about our working group on skills. Maybe add cybersec project. 



			Maybe we do not need as a result a deliverables, but a collection of what has been already done and show this to the NCCs: what  the community has been active all these years



			We need to set up a remote meeting. We need to set a common email to the experts and allocate for the next two weeks a couple of slots to gather the community around and discuss the objectives . 



			So talk will allocate for the next two weeks first week of November and second week of November 2 meetings of one and a half hour . 



			till then we need to talk. We look in the deliverable and start thinking and work around in these ideas . work on the objectives of the working group





			Iare  they interested on these objectives?



			Then we need to go deep and prepare. What are the activities following? We need to plan a timeline and inform the experts we need to find two slots and set up a meeting of one and a half hour and inform what could be the objectives of a working group to do Short presentation of the objectives and what the working group is doing



17/10/2023
===============

*concordia false alarn rejection ....*


*Secocom com AIT nothing yet!*
*ECCO WG on skills meeting at 1330 today*

	ti exei na kanei to TUC : TASK A  - 0 person months 
														TASK B  - 150 
																B6 
																B61 - 
														TASK C 120
															Task C.1. Knowledge sharing and interactions between NCCs at European level (M1-M24) [Leader: ECSO,
															Participants: CEA, CNR, FRAUNHOFER, TIS/TUC, RHEA, UniBwM, GUF)
															
													--> Task C.2. Cybersecurity Community working groups (M1-M24) [Leader: ECSO (T C.2.2; T.C.2.3, T.C.2.4),
															Participants: CEA, CNR (co-leader C.2.1), FRAUNHOFER (co-leader T C.2.1), TIS/TUC, RHEA (co-leader T.C.2.3),
															UniBwM (co-leader T.C.2.3), GUF (leader T.C.2.5); external experts)

																	In Task C.2 we will create a number of Working Groups (hereafter the proposed list) and develop their plan and
																	strategy. This proposal leverages the years of experience of ECSO and the Pilots for dialogue and cooperation
																	among the main communities.
																	List of proposed Working Groups
																	7) R&I Road-mapping
																	8) Critical vertical domains and Trusted Supply Chains
																	9) Synergies between the civilian and defence / space spheres
																	10) Start-ups/Scaleups - SMEs support
																	11) End Users, Consumers’ / Civil society organisations, Human rights and Forensics
																	12) Skills and Gender
																	The WGs will be animated / coordinated by different Members having had a similar task in the Pilots or in ECSO.
																	Other Working Groups or Task Forces (temporary gatherings of experts on specific issues) may be created during
																	the project according to needs and requests from the ECCC and NCCs.
																	There will be a need for a certain flexibility in the governance and in the approach of the WGs proposed by the
																	Strategy Advisory Group and the WGs approved by the Governing Board are substantially different from those
																	proposed in ECCO and the envisaged work sharing and operational rules.
																	Workshops and events to facilitate knowledge sharing and interactions between NCCs (and these working groups)
																	mentioned in the text of the tender will also be part of the animation of the different WGs, linking these
																	communities with the NCCs.

															 
*1230 meeting with kopanakis about Twitter data*

16/10/2023
================

https://www.youtube.com/watch?v=371n3Ye9vVo&list=PLk_jmmkw5S2BqnYBqF2VNPcszY93-ze49
https://www.youtube.com/watch?v=GXtbL8avpik

*meeting me Panagiota Koutra* dataset polemou sxetika me energy crisis kai conspiracy. lda - gephi - network X 
topic analysis  - 8a xanamilhsoume se 10 meres. 


TODO: 
	*B63*.Meta apo to meeting me thn Iro dior8wsa to paradoteo. tsekare me thn Iro (skype laptop -to sent) kai meta xanasteitlo thn Nina + 
	check ton repsonse twn partners kai steile remonder mias kai shmera esteile se olous thank you sthn Narges 8a steilw ayrio remidner 

	rhea  - france cea Belgium 


*cyberGreece* 
		καλημέρα, 

		Δεν υπάρχει κάποια ανταπόκριση απο το group αυτό, θα στείλω ενα reminder και ανάλογα με την διαθεσιμότητα τους να κανονισουμε ενα meeting. 
		Έλεγα να στείλω και στην Nina για να συμμετέχει και αυτή:


		Not sure if Women4Cyber is active at least through this email. 
		Do you have any other ideas on how to continue with this? 
		I suggest setting up a meeting (initially doodle) to kick-start this.  OK !


*WG skills* steile to doc ston si  (ok mesw mail) - stiele kai sto skype . (mobile) OK aurio 10-11 ellados 

13/10/2023
===============

Iro chatzopoulou sunanthsh sxetika me to B6.3 : 


Training is not being certified in Greece. You can have an accredited scheme with an education from a specific - certified education. The calculus can be certified regarding for example the structure and the curricula, as in EU, but the professionals are not certified as individuals, the education they accepted is being certified. Th professional are free to follow any educational scheme and then they get the professional competence. They take an certification exam offered by  OEPPEP
It is important to note that the certification process in Greece applies to the curricula and the calculus and not to the professionals per se for the mentioned educational schemes. After any existing educational scheme that the professional is free to follow, the certification process is a separate procedure that anyone – independently from the education steps- can follow through a specific test. This test is accredited and recognized by Greek government and available through OEPPEP : the National Organisation for the Certification of Qualifications & Vocational Guidance (EOPPEP) (https://www.eoppep.gr/index.php/el/structure-and-program-certification/workings/katalogos-ep)     .

12/11/2023
================
SeComCon call : 
todo des edw https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B2F189F21-6112-489B-AED7-32F16B829DF6%7D&file=Deliverables-Milestones.docx&action=default&mobileredirect=true

an exoume deliverables na sumplhrwsoume 



11/10/2023
================
ECCO - 
B6.2 
nina ask  Narges: Also, for Germany (I guess from Narges), it says “German initiative exists”. It would be nice to know what they are😊 Can you ask her please? OK  - eixe apanthsei o an8rwpos !

B6.2 sent to NIna  OK 
B6.3 reply for Norway sent to NIna ok 



10/10/2023
==============
*alex proposal* : formed research questions  DONE 
*meeting with mentionlytics* 12
ECCO : B6.2 
B6.3 
women4cyber greece ? apanthsan  ?
ananewsebot artist se arxiva kai research gate !


9/10/2023
==============
SeComCon call : 
todo des edw https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B2F189F21-6112-489B-AED7-32F16B829DF6%7D&file=Deliverables-Milestones.docx&action=default&mobileredirect=true

an exoume deliverables na sumplhrwsoume 
6/10/2023
================

				Dimitra Liveri (ENISA) , Fabio Di France (ENISA)  - Anna Sophie EU  -  ECCO   -
				(Anna Sophie EU) Need to touch base on the repositories  - and how we can support ENISA on the repositories  

				(Dimitra) we have run a survey to identify the scope of the requirements for creating repositories for certification & training for the CS skill academy 
				  - the first results of the survey - (she will shares)  
					- draft that will share with NCCs
					- 19 members replied 
					- the scope basically covers almost everything: online/physical trainings, private sector, public sector,  even hackathons Cyber ranges, possible challenges,  ..
					- initial consensus on the criteria for eligibility of the training
					- Got also some indicators for Quality assessment ! for entries in the repositories . 
					- we touched on the governance models . how mechanism works . ENISA role is to be advisors. The platform is suggested to host data and shared by NCC and possibly ECCO  to play a role there . 
					- there is a proposal for governance model, how the eligibilty should take place ,  - how the entry, the inclusion of these training would be in teh repository and eventually hoe twh quality assessment will take place
					-(way forward) the first part is the requirements are hinding a full funcioning platform, from search , user friendly implementation, good flow of information and will be accessible to all CS professionals or students , whoever is interested. wants to follow the role.  So the from discussion with DG-connect running the platform: the platform cannot support these requirements - NEED TO FIND a new platform.  

				(Anne) for the platform  - they renewed the contract for platform - will Polla will have a call with them soon, ask to confirm if platform cannot handle/support . It may not . We do not know what the new feature are . 

				(Dimitra Liveri )  Also we have been using as an example the Security certification roadmap  and if you share this will them, they will have better understanding on this, because some technical requirements are not set there. the technical we understood should be there based on the NCC want. 
				At the same time they want to have some metadata, so that the search is more smart, part of the platform, they don't just want a list with a link. Makes technical needs even more specific. 
				The governance model need to be clarified. It indicated that NCCs should validate the training, propose the training but also validate it at national level but the central level, need to insure coordination of the governance of the repository,  so there has to be a body that will be coordination the repository to ensure harmonization, standardized format,
				this would require of course the agreement for the criteria for eligibility, but also the agreement on the criteria for eligibility but also the criteria of the quality assessment criteria.   
				as a first step define criteria - by end of 2023 -- It is is important that in this endeavour that the NCC will take the lead. So goes beyond Enisa. 
				GM governance all NCC will agree on. So from ENISA have started  collected as an initial step ...

				(NINA ) question this endeavour is publicly driven. Maybe is too ambitious, to build a platform to include everything. If it is more linked to NCC and they need to mobilize their ecosystem, would be maybe better to be categorize per country ? different kind of information per country, training certification etc. So vast to provide everything, difficult to organize. 

				(Anne ) In relation to governance . at end of day the NCCs are deciding - This is a question for the NCCs.  
				(?) Who will do it an EU level? 
				(NINA) NCC are doing a wish-list that is too ambitious. 
				(Anne) Next week Dimitra ask the NCC how do we move forward with that work? the governance model, the criteria, QA criteria, question of the platform will link to these. Ideally from EC perspective if NCC could take the lead would be amazing . 

				(Anne)ECCO support will be there to organize all that work and try to drive them a bit and support. The belgins taht suggested governance model, italians?  What if no volunteers? Importamt to discuss, or more brainstorming ? to see when and how ? 

				(DIMITRA) NCCs should take place now. Our's role finishes here. Maybe sipport and provide more advice? ECSF review maybe ? attestation and indicators?  
				NCC should take over, start taking decisions, they haven't reflected very seriously on what, on what they were answering in the survey, hey will be the ones that need to implement it But somehow they know it because somehow when we asked if they will be able to implement this , so there is a hint here that they will be the ones to do that. 
				But overall maybe increment approach, start small with limited scope and then expand? in this process NCCs' role is crucial .(driven and supported by NCCs)
				In which  format ? In WG5 ? 

				(Dimitra ) yes WG5 works. Maybe they are working on something else ? 
				(Anne ) Theyy should start leading  on this . 
				(Anne ) Will you address it formally at the NCC days? that it should be starting by NCC 
				(Dimitra) We will present exactly this, prior to the meeting on Wednesday. This is a starting point, will be taking over by WG5. 
					
				(Anne EC) the ask how to more forward ask, with the co-chair? concrete? during Ncc day? Nina, the ECCO could support ? for the content ?driving on the governance eligibility, quality criteria? 
				(NIna) - as long as it is confirmed that it will be it driven by NCC. We can structure their work. We down want to end up in a situation that they think that we are doing that because the plan is too ambitious,they need to know that.

				(?) After the NCC day to see if there is some willingness? 
				 
				(Dimitra) ECCO has a very good overview of the NCC and their activities and where they stand with  resources etc. So ECCO has an opinion maybe if this is a more viable option, (taht per country) and share with NCCs. The real reflection should be provided, like this is very ambitious, you are two people how are you going to implement this ? ECCO's opinion is very valuable .  

				(NIna) We will structure of course. Set what is feasible, but still when this repo will live ? but happy to help with that.  


				(Anne)For the integration I think more should be discussed, we should start to work on the criteria and governance model . 
				In terms of planning of events, next week , we will present this, in any case it would be good to approach bilateral ms . Which are from the Enisa's  point of view,  which are the member states that  are more live here? and then maybe approach those members, but  take into consideration that  ECCO has a good view . Will add as an agenda point to discuss there if they agree with the way forward , if we have an NCC to name-drop to co-chair meeting . 

				(Fabio)  - missing of resources from NCC as a key take away. 
				I don't know how we should how to engage them?  See is something that is fisible . 

				(dimitra agrees ) the comment on how ? 5 member states replied - we cannot select some of them. The ones that replies, really replied!

				(Anne - EC) what us next step ? what should ECCO do ? how to continue? Maybe drop this at the end of your presentation ?
				(Nina - no voice - text) agrees but my question was re governance model - To what extent could the EDIC be used for this further down the line? - Or not at all linked?

				(Anne) the problem with EDIC is that we need months to be completely, set up and start working on criteria. We can explore from where the repo will appear.  
				(Dimitra) Agree but we might eventually catch EDIC . EDIC would be one of the most targeted points to have this platform, We will need to have a list of the catalogue aand then identify the gaps and then create curricula- training offers - attestation ...they need a basis - this catalogue ...
				 
				(Anne) ok next week as an option. now complicated with some member states . Edic mission needs discussion with edic people .end of october . 
				Need first to listen and then suggest next steps. 

				Do not know how edic would last ...are we going to loose these ? keep this in mind. We need to catch up after NCC day, 

				(Nina) I just said great if we can catch up after NCC day as I won't be there

				we should still try bilateral (Anne) if we have no one then Nina can support ? try to have an NCC on board ..

				please share the document . 

5/10/2023
==================
ASONAM https://www.overleaf.com/project/624e95402b38b76ba817abd8
submitted step 1 - camera ready 
SeComCon 

search all drive files that are TUC related 

1) budget https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BD4CE2309-C61B-4F5F-9572-9CBD536003C1%7D&file=HE_plan_budget_template.xlsx&action=default&mobileredirect=true

		Personnel costs in project as actual costs 198,000.00
		Travel and subsistence  25,000.00
		Personnel costs (actual or unit)	198,000.00
						Subcontracting	0.00
						Purchase costs	25,000.00
						Other cost categories	0.00
						Total	223,000.00
						Indirect costs (25%)	55,750.00
						Overall	278,750.00
						Funding rate (%) IA 70/100%	100.00
						Total EU contribution	278,750.00
2) Partner profiles
		FORM A 
			exei sumplhrw8ei sthn arxh 
			https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B81AFDCF8-5AE0-4BE9-A1A3-1AE45D303E86%7D&file=ApplicationForm(Part%20A)-SeComCon_TUC.docx&action=default&mobileredirect=true
		ownership 
			*den to exoume sumplhrwsei*	
			https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B6F0E6426-06F4-413F-AFEE-6F68B36512C0%7D&file=ownership-control-declaration_dep-he-edf-cef-dig_en_TUC.docx&action=default&mobileredirect=true
			alla oute to UniBW to exei sumplhrwsei !!

3) Proposal

		https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B6F0E6426-06F4-413F-AFEE-6F68B36512C0%7D&file=ownership-control-declaration_dep-he-edf-cef-dig_en_TUC.docx&action=default&mobileredirect=true
		OK 

		Expertise ok to exoume dei 
		https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B0FC303B4-69EC-497E-A2C3-1C3978DA3EFE%7D&file=Expertise-collection.docx&action=default&mobileredirect=true


    Proposal part B
		https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BCDF4D727-D039-4AB4-AD2F-B995291D33A9%7D&file=2023-09-08-Proposal-PartB.docx&action=default&mobileredirect=true			


		sto https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BCDF4D727-D039-4AB4-AD2F-B995291D33A9%7D&file=2023-09-08-Proposal-PartB.docx&action=default&mobileredirect=true 
		prepei na mpoun ta telika dates apo to WP-Task_Overview ....



===============================
3/10/2023
==================
an den exeoun si manosapanthsei seteile ta mail !


2/10/2023
===========================
747.84 xenidoxeio 
364.67 pthsh
400 apozhmiwsh 

an valeis ayta : 
184 timologio 

======
1328,511


1/10/2023

===========
*ecco suports ENISA*

from email of Anna Sarri <Anna.Sarri@enisa.europa.eu>

	In our previous call we discussed to redraft the indicators taking into account what can be integrated into DESI.  

	To attachment anaferei 2 grammes . to exna leei 1. % of professionals per sector within each MS
2. % of women professionals per sector within each MS.

		gia kapoio logo eyaxa phges ...


		https://ecs-org.eu/unlocking-our-potential-cybersecurity-education-and-workforce-needs-in-europe-2/





*SeComCon*
me evale kai evala to schma mas se neo katalogo UC. To vgalame teliak me ton Alex afou emeis DEN 8a orisoume kanena UC diko mas . To valame sto RAINWAY telika to valame sto Koncar-railway.
29/9/2023
===========================

B62 - educational standards - uplaod teh excel in teh driucve ??

*B6.2. sent reminder OK *
*B6.3 started WORD survey . TODO *


*OK sent initial email  σι + Νινα for Women 4 cyber . * 

*NINA sent comment, now TODO SENT TO WHERE ????*

		============================================

			Apo thn sunanthsh ths Tetarths 
			Maybe motivate women4cyber in Greece and notify the Greek NCCs in order to build something towards skill. 

			(S) We need also a back up plan . Maybe something like a report ?
			(N) We already have the deliverable for ECCO 

			 We start with  women4cyber in Greece and also sync with the other partners towards this goal.
			 (N) webinars would work in order to show work/results from pilots to NCCs . Also something like Cyber competition? at national level ? 
			 (S)We need to amplify work from other activities as well.  


			 Eftaixa omada sto teams women4cyber + ECCO 

			 epishs si leei na vgei ena white paper me women4cyber + cybersecpro (KAI) kai na energopoihsoume ekei ena group ...

			 vazoume eva despoina anthi kai zhtame na kinhtopoihsoume women4cyber me webinars se ellhnika NCCs gia skills building ena common event > me apotelesma ena white/position paper
			promoting skills building for women, PARASKEUH !


				Dear collueges

				στα πλαισια του έργου ECCO, και συγκεκριμένα το TUC σαν lead του task Task B.6 Community for Education, Training, and Gender Balance (leader TIS/TUC) θα κινητοποιήσουμε το 
				women4cyber στην Ελλάδα και θα χρειαστούμε την βοήθειά σας. 

				Η agenda είναι να δημιουργησουμε μια ομάδα απο experts on skills και να δούμε σε πως δραστηριοποιέιται το women4cyber στην Ελλάδα ώστε σε ενα δευτερο επιπεδο να μιλήσουμε με τα NCCs (National Cybersecurity Coordination Centres) 

				Το επιθημητό αποτέλεσμα θα μπορούσε να ειναι ενα white/position paper σχετικά με τισ δράσεις της ομαδας, τα ενδεχόμενα προβλήματα αλλα και κατευθύνσεις που μπορέι να παρει στο μέλλον. 
				============
				regarding ECCO project, and specifically as TUC leads Task B.6 Community for Education, Training, and Gender Balance (leader TIS/TUC) we will mobilize the
				women4cyber in Greece and we will need your help.

				The agenda is to create a group of experts on skills and to see how women4cyber is active in in Greece so that on a second level we can talk with the NCCs (National Cybersecurity Coordination Centers).

				The final result could be a white/position paper about the women4cyber actions, potential problems and directions it can take in the future.


28/9
===========================

regulatory panel 3 

14.30-15.00 KEYNOTE: EU REGULATORY AGENDA 
AND EXPECTED IMPACT Raluca Stefanuc (DG CNECT, European Commission)


revision of NIS directive  - transposition perido now 
measure reinforcement - obligation - administartion for critical entities in NIS2

supply chain main priorities 


skills is also a priority 

digital eu programs - SMEs


ENISA Panel 
================


*Héctor Laiz Ibáñez (NCC-ES, incibe) den emfanistike*  

NOTE for eccco ! See NCC of spain and follow  similar actions 

SME workshop 

*3rd panelist : Dan Cîmpean (Romanian National Cyber Security Directorate)* 


strengthening EU cybersecurity [Policy, Technology Tools, Education, Technology Pilots, Certification and Research( > 300 scientific publications)]

CONCORDIA & pilots ecosystem positioned in a Cybersecurity Competence Network with leading research, technology, industrial public competences to build the European Secure, Resilient and Trusted Ecosystem, 


need guidance - couching

need for skills - experienced !this gap is increasing...great need considering the increasing market needs 

universitys are easer to create professionals .
ukrain attacks...

it is a community after all ! it is a shared responsibility 

ECCC in romania ...

not coordinating enough ... 


*Miguel Gonzalez-Sancho (DG CNECT, European Commission,
ECCC)*


*Bertrand Lathoud (Luxembourg House of Cybersecurity)*

lack of maturity of market 
lack for [rofessionals? ]

awereness campains started
need for support for SMEs(small, no resources, no competence --incident occurs and then no security provider --)
allow the market to operate in readiness 
\
not agile enough 



Q1) how to envision role CS CC  - 

coordination collaboration and leveraging with open eyes in new threats 

Q2) bertran question . 

final comment . please communicate with us for ECCO 


27/9/2023
=====================
ECCO meeting NIna, Si, Luigi


(N)There are a lot of expectation on skill from ECCO. This call is to touch base with TUC, on actionable results. There are a lot of tasks that need to be done for this goal. 

(S) We have a great number of activities, as is every partner in this group that is related to skills. For example along with Kai there is CyberSecPro and REWIRE that can be leveraged and amplified.  
(N) Our "client" does not care about parallel projects/activities. They need from ECCO some actionable results, considering the "little" time left. 
(L) We need to touch base with the NCCs. How?
1) bringing together the different members and show the existing community (that is reflected in the technical offer as well) 
2) Pass this message to NCCs and then propose something to them. 

(N)This will strike the right balance with the technical offer, also through the working groups on skills that we already have proposed.
the webinars will be the next level. Maybe at this point we can append with the material/activities available from REWIRE and CyberSecPro. 
(S) What does the client really want to see from ECCO.
(N) We already have to improve the skills strategy and then organize the webinars. 
(L) Maybe say to NCCs that this is happening in your country regarding skills (per country) and maybe show the way for the NCCs ? activate somehow towards this goal?
(N) NCCs are already activated towards their goals.
(L) We recommend something smarter. Make a list and give the action. 
(S) Well this can happen , or they say ok and nothing happens or they neglect us .

Maybe motivate women4cyber in Greece and notify the Greek NCCs in order to build something towards skill. 

(S) We need also a back up plan . Maybe something like a report ?
(N) We already have the deliverable for ECCO 

 We start with  women4cyber in Greece and also sync with the other partners towards this goal.
 (N) webinars would work in order to show work/results from pilots to NCCs . Also something like Cyber competition? at national level ? 
 (S)We need to amplify work from other activities as well.  


 Eftaixa omada sto teams women4cyber + ECCO 

 epishs si leei na vgei ena white paper me women4cyber + cybersecpro (KAI) kai na energopoihsoume ekei ena group ...

 vazoume eva despoina anthi kai zhtame na kinhtopoihsoume women4cyber me webinars se ellhnika NCCs gia skills building ena common event > me apotelesma ena white/position paper
promoting skills building for women, PARASKEUH !

21/9/2023
====================
*presenattion gia ENISA*
*SeComCon*  - update  topics in 
check again everything : 

		T6.2 

					Evaluation of Cyber Shields (Leader TUC???) 

					Duration: M??-M?? involved ???  AFTS , Calirad d.o.o. 

					Description: This task will  gather the appropriate input, based on the implementation of WP3 and the threat scenarios described in WP4, to provide a review and designated package for the evaluation. This procedure mainly depends on T6.1 and the defined evaluation scenarios. The developed methodology of the four cyber shields depends on the attack vectors, resulting in 3 technical parts that will have to be evaluated to ensure that they are secure and robust. WP3 will provide the development of the security shields, and our evaluation steps will be guided by this. WP4, which provides the threat scenarios, will feed into T6.1 which will be implemented in this task. Based on the provided implementation of the Cyber Shields developed during WP3, combined with the described threat intelligence from WP4, we will evaluate the provided solutions according to the methodology and evaluation specifications outlined in task 6.1. 

					 

		Duration: M??-M?? not filled !
		σε αυτό θα βοηθούσε ενα gantt

		A Gantt-Chart with todays available information is also online as a
		second tab in WP-Task-Overview.xls.

		βέβαια το WP6 είναι άδειο :P

architecture schema : alex sent me :) 
*ECCO*


20/9/2023
====================

mono presenattion gia ENISA 


19/9/2023
====================

 
an den exei apanthsei si + Manos steilei to excel ! OK 

Task B.6.2: Education via the analysis of the main curricula and courses available, as well as of existing educational standards across the EU-27 at the bachelor level and identification of gaps and new educational requirements. It is foreseen to involve external experts.

ECCO - des presentation ! 

Task B.6.2: Education via the analysis of the main curricula and courses available, as well as of existing educational standards across
the EU-27 
Collect input on existing educational standards across EU-27, also via webinar with external experts, and draft report providing baseline requirements for “Cybersecurity Education Made in Europe”) // Lead: TUC / Participants: ECSO, CEA, Goethe, RHEA (ongoing) – this is in our technical offer . We are only on bachelor level . We need to create a table for all countries, at least a table what education standards exists in each country. Then locate commonalities , gaps and credit systems …Can you tranfer for example the credits from one counfrty to another, or at leas in the same country. 
Support ENISA in the development of the repositories of the Academy, i.e. turning NCC recommendations into actionable outcomes and creating a governance model // Lead: ECSO / Participants: TUC, CEA, Goethe, RHEA (not yet started)
Support ENISA in the review of the ECSF // Lead: ECSO / Participants: TUC, CEA, Goethe, RHEA (ongoing)
Task B.6.3: Training and support to standardisation of curricula for professional training and establishment of European 
cybersecurity professional certification schemes. 
Provide recommendations for standardisation of curricula in professional training // Lead: TUC/ Participants: ECSO, CEA, Goethe, RHEA (not yet started) – I say that there are a lot of sources from concordia, but they need not long texts. We need to answer how is the verification of the the accreditation in each each country ,if it exists . Again a table with every country. . Start with partners are there professional programs in your countries ?, if there exists , how it works?  If NA ,..We should recommend an agile, regular accreditation mechanism . Maybe be based on other countries, and adapt in each country? We create something in small scale and  give to the NCC who will continue this...  

*rwta thn Nina poio einai which is the task/subtask that we are lead? (TUC) that you mentioned that it was not mentioned in the technical offer ...
*ENISA panel* 

			Dear Panelist,

			Firstly let us thank you again for your preparedness to support the ENISA Conference on Cybersecurity Market.
			You may now find attached the agenda of the event. An updated version might follow.
			Those who will join the event physically are kindly asked to book their itinerary over the web page set by the contracted travel agent (https://eu.eventscloud.com/200264697, password enisa2023). Please note that you have to book over our travel agent, in order for ENISA to reimburse travel expenses.

			In case you have already registered via the abovementioned link, please disregard this part of the email.

			Furthermore, in the coming days, we plan to discuss with the panel moderators some generic thematic guidance (e.g. questions, mode of discussion flow, etc.). Then, this information will be disseminated to you in order to prepare your presentations. Presentations can be with or without slides.
*In  , panelists will have the opportunity to make a short initial presentation (ca. 10-15 minutes). A discussion among the panelists will follow based on questions to be prepared by the moderator* The questions will be communicated to you in advance. Then we plan ca. 20 minutes for Q&A from the audience. *
At the time being, we assume the following mode of participation (see “Panelists and assumed participation mode” below).
			Should be any mistaken assessments, please let us know, ASAP.
			We thank you again and we are looking forward to receiving news from you.

			With best regards,



18/9/2023
====================
*check trip in Athens with webinars for NCCs!! and other in projects !add in agenda*

ECCO .
	Sent the Σχετικά με το δικό μας task Task B.6.2. θα πρέπει να συγκεντρώσουμε απο όλους τους partners "...existing educational standards across EU-27... "
	resent reminder to si 

	https://op.europa.eu/en/publication-detail/-/publication/f4784939-1f15-11eb-b57e-01aa75ed71a1/language-en/format-PDF/source-224632675
		https://education.ec.europa.eu/el/education-levels/higher-education/inclusive-and-connected-higher-education/european-credit-transfer-and-accumulation-system

	ekkremei allo ena ! Task

*SeComCon*
	ola ok se budget, WP Proposal Part B
				https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BCDF4D727-D039-4AB4-AD2F-B995291D33A9%7D&file=2023-09-08-Proposal-PartB.docx&action=default&mobileredirect=true


	*meeting*
		* AFTS dicussion fixed about registration . 
		* Croatian railway will join 
	  * WP-Task_overview : 
	  			https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B6B1B4CC5-EA6B-4731-AF42-19A07947A68F%7D&file=WP-Task-Overview.xlsx&action=default&mobileredirect=true
	  			green means ok !
	  			PM? are committed ? check 

	  			WP2 some open think here ? who will lead ? telefonica ? 6.3 

	  			T6.1 AIT  - 

	  			T6.3 open  - telefonica ? 

	  			epomeno meeting 2/10 


*meeting students : 	george V Valavanis George (ptuxiaki)
* 
	projects hospitals ML  - models state of the art NN - federated ML https://featurecloud.eu/ - https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU



ENISA!
		make presentation 
		find all references of ECCC in CONCORDIA 				

		[11:36 AM] Antonakaki Despoina (Guest)

		Hello Nina, hope you are fine !!! I will be in the Panel in the 2nd ENISA Cybersecurity Market Analysis Conference. Is it ok If I mention ECCO ? that Task C is connected with the ECCC (and NCCs) ?

25/9/2023
=================
asonam acks? pou 8a xrew8ei ? o alex to koitazei 
SeComCon sxhma ?  mail apo alex 
[Staff] Γνωστοποίηση Στοιχείων Συζύγου/ΜΣΣ Υπόχρεου Πόθεν Έσχες--ΠΡΟΘΕΣΜΙΑ ΕΩΣ 22/9/23 den xreiazete
phga sthn Elenh thn [Staff] Δηλώσεις Εξαμήνου Ελεγκτικού Συνεδρίου - Α ΄εξάμηνο 2023 ΔΙΕΥΚΡΙΝΗΣΕΙΣ OK 
SeComCom architectural schma des kai mail apo alex TODO 

adeia gai a8hna OK 



14/9/2023
====================
paper bot artist 
panel!!! presentation
nina tasks (excel sent to partners  - inform si !)



Current tasks
==============================
[NINA] TODO : add rewire in questionaires . DONE 
sent the "ECCO Task A - Deliverable D-A.2 - National R&I programmes input request" to si + Manos . see response and sent !

PANEL ENISA : TODO: check the deliverable from concordia (5.5) for references in ECCC and market . 


========================================
 


ECCO meeting 13 /9 ECSO premises Brussels - day 2
==============================================

*In the ECCO Working Groups we present the common proposed objectives from our skills strategy , the ACADEMY and the    ECCC Strategic Agenda* 
In the ECCO Working Groups we present the common proposed objectives well connected to the ECCO's skills strategy, the ACADEMY focused also on aspects linked to the ECCC Strategic Agenda. 

Notes from the meeting . 

ECCC people Paula(connected online) just joined ECCC,

Communication has been presented with no comments from EU . 
Project management is then presented by Sopra. 

Task A , 

Barbati: it is time to start  on the webinars 




Workshop 
task A3. 
========================================
Market observatory scope  [ECCC]


users 
Eu, ECCC NCCs 


==================================================
	SEComCon
	Alex
		apo emas 8eloun na valoume start-end month 

		kai na apo8asisousme ean 8a einai 2 report h ena 

		kai to last report mas prepei na einai sto telws tou ergou 

		+ osoi kanoun technical pragamata prepei na dwsoun images me to architecture 

		pou logika prepei na to kanoume kai emeis gia to iot attack pou grapsame 

		kai na doume ti allo technical exoume dilosei 


		εισαι σίγουρος για αυτό; ειπε ονομα ; ισως καποιο αρχειο που πρεπει να γινει και μας έχει κάνει pinpoint? 



ECCO meeting 12 /9 ECSO premises Brussels - day 1
================================================

 hotel : zye@UHJ3

 ecso  wifi W31c0m3Т03cs0!  


		the workshop after lunch : Workshop 1: Uptake of R&I Solutions (Sub-Task and Deliverable B4) led by Armand – NO EC Participation
		[required ECCO partners: CEA, ECSO, Trust-IT, RHEA, TSI, Goethe]
		Tentative Planning: 
		Key point - we request that all participants review the deliverable submitted in June before the meeting 

		https://ecsorg.sharepoint.com/:w:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B8DD04CBE-0C25-401B-9F94-E4EC1E1FA02F%7D&file=ECCO_D-B.3-results-uptake-strategy-v0.6.docx&action=default&mobileredirect=true



		Luigi. 

				meeting with NCCs Warshaw . NCC asked why we are here? we dont need ECCO - pilots ...etc 
				we need to earn their trust .
				luigi - we are pissed off with meeting with Bucharest !


				EC changing priorities ...and requirement, no delay for the deliverable , end of March --18/12 teh deliverable payment them delays 

				keep the contract - 
				ncc are still discussing how to register the memmber of the communities, so untill then there is no community. we were supposed to be a community for CS , and we just support NCCS!!!

				so the National Coordination Centres HAVE set up their owns strtategic agenda ! 


				we should give reccomendations on joint actions  about capacity building 

				difference on the different nccs on diverse countries 
				service contract to help commission implement the NCC approach.

				other QA: do we need some mid term adjustment.?  


				TASK A .

				what kind of data ? research purpose ? Mallon oxi  sanitize? format ? in which purpose are they going to be present ? 

TASK B 
Nina preseting ...


B1, B2, matchmaking event great! EU happy 
B5. Info day ok , EU happy

B6. string emphasys on skill by EU !


	Support to education, training and gender balance in cybersecurity by designing a strategy and a set of tasks for the education, training, skilling and reskilling, human resources, students and gender issues communities, to stimulate collaboration within the Community. In agreement with the EC, the initial ECCO skills strategy has been *reinterpreted* to align with the EC Communication on the Cybersecurity Skills Academy as well as other ongoing developments in the skills domain 



		WORKSHOP  B4. deliverable B3. : Armand Ruccetti 


		--------------------

not much to say . 

Notes for presentation at ECCO : 
=================================

In the technical offer we refer: ECCO will follow the community-building methodology outlined in Task B.1 in order to develop and grow the
subcommunities. For most of the subcommunities covered in this Task, several of the steps have already been
undertaken meaning the communities are already in existence and are there to be leveraged. In those cases, ECCO
will simply pick up from the relevant steps of the methodology to further the work.

How have we achieved this? 
We have given 

7 September
===========================
ECCO presentation 


As appears in the conclusion of the SKILL academy : 

The GOAL in the *short term* is to support the Commission in further developing the Academy and its surrounding objectives,
 in the *medium term* to structure the European cyber skills community (making sure that a link is firmly established with the ECCC and NCC network once fully operational), 
and in the *longer term* to provide useful input for the harmonisation of approaches and introduction of possible standards on cybersecurity skills, education and training. 

The ECCO skills strategy shall also *inform the ECCC Strategic Agenda and Action Plan, to help define the future research & innovation priorities on cyber skills in Europe.*

As it appearsin the Executive summary : 
The main strategic goals and current updates on ECCO’s skills strategy can be summarised as follows:
•	Mapping Trainings and Certifications
o	Supporting ENISA in building up training and certification repositories 
•	Workforce Needs and Pledges On The Cybersecurity Skills Academy
o	Status: around 40 Pledges
•	Skills Attestation
o	Input to ENISA’s feasibility study on a pilot attestation scheme
•	Indicators
•		Support to ENISA on defining indicators and collecting data from NCCs	





6 September
===========================
SeComCon : 

*TUC profile for Secomcon*

telika sto SeComCon evala :

TUC is actively engaged in basic and applied research, with projects funded by the European Union, General Secretariat for Research and Technology, Ministry of Education, Region of Crete, local organizations, and private businesses. TUC's research covers various fields, including telecommunications, networking, machine learning, and more. It's a key player in FP6, FP7, and H2020 projects, often as a coordinator, and promotes commercializing R&D results through services like consulting and partnerships with industrial partners. Prof. Ioannidis specializes in coordinating and participating in security-related H2020 and INEA-funded projects. His team excels in systems and cyber security, producing cutting-edge research, tools, and solutions for RIA, IA, and INEA projects, published in top security conferences.  


			has experience in previous successful projects in cybersecurity, security threats, IoT frameworks, like CONCORDIA, CYRENE, EDGELESS, SecOPERA etc. Additionally TUC has numerous publications in these areas and  implemented infrastructure and equipment to support the needs of the proposed research.  

			Prof. Ioannidis has a vast experience in Coordinating and participating in security-related H2020 and INEA-Funded projects. His team is active in a various areas of systems and cyber security, producing high-end research results, published in the most distinct security conferences, creating beyond state of the art R&D tools and operational production solutions, in the context of RIA, IA and INEA projects.  


			Despoina   sent me one 
*TUC profile *

		The Technical University of Crete (TUC) is a state university under the supervision of the Greek Ministry of Education and was founded in 1977 in Chania, Crete. The Technical University of Crete is particularly active in conducting basic and applied research.The research and development projects, managed by the Research Committee, are funded by the European Union, the General Secretariat for Research and Technology, the Ministry of Education, the Region of Crete, local administration organizations and many private businesses. A large number of TUC undergraduate and postgraduate students are employed in these projects; in this way, they benefit from the best possible training and they familiarize with conducting research.
		It is entirely funded from external research and development grants and contracts in telecommunications and allied areas: telecommunication systems/networks and network services, networking hardware, sensors, RF, and high-performance computing systems, machine learning, information systems, big data analytics, signal processing for telecommunications, speech, language and image processing, and biomedical applications. Funding mainly comes from the European Commission, international industry, National Funding Agencies, and DARPA. TUC has had significant experience in FP6, FP7 and H2020 projects, including FET, acting in many occasions as coordinator. It has also adopted a strategy of promoting the commercial exploitation of R&D results, by providing services (e.g. consulting) and contracting with industrial partners for specific products.

		Related expertise / experience: 
		Prof. Ioannidis has a vast experience in Coordinating and participating in security-related H2020 and INEA-Funded projects. His team is active in a various areas of systems and cyber security, producing high-end research results, published in the most distinct security conferences, creating beyond state of the art R&D tools and operational production solutions, in the context of RIA, IA and INEA projects.

As it appears in ECCO technical offer 

			Group Member: Telecommunication Systems Institute of the Technical University of Crete
			(TSI / TUC)
			The Telecommunication Systems Institute of the Technical University of Crete (TSI)
			is a National Research Institute founded by the Greek Ministry of Education in 1995.
			TSI operates within the framework of the Technical University of Crete (TUC) as an
			administratively independent and financially self-sustained entity. Its mission is to
			spearhead basic and applied research in telecommunications and allied areas,
			contribute to graduate education, service, and outreach activities, and promote
			technological development at the regional and national level. It contributes to the
			graduate program of the Electrical and Computer Engineering (ECE) Department at TUC, and in turn draws senior
			researchers and graduate students. TSI has sufficient space and other baseband infrastructure. It is entirely funded
			from external research and development grants and contracts in telecommunications and allied areas:
			telecommunication systems/networks and network services, networking hardware, sensors, RF, and highperformance
			computing systems, machine learning, information systems, big data analytics, signal processing for
			telecommunications, speech, language and image processing, and biomedical applications. Funding mainly comes
			from the European Commission, international Industry, and National Funding Agencies. TSI has had significant
			experience in FP6, FP7 and H2020 projects, including FET, acting on many occasions as coordinator. It has also
			adopted a strategy of promoting the commercial exploitation of R&D results, by providing services (e.g. consulting)
			and contracting with industrial partners for specific products. More information on our team’s active projects can
			be found in: linkhttps://www.parasecurity.edu.gr/#h.ra4rby8j7jv

			Research
      Our group is producing high quality research in a number of areas, including

      Systems & Hardware Security: Our group’s main research expertise lies in the field of Systems &
			Hardware Security with publications in all major conferences. Up until now, we have coordinated and
			participated in numerous FP7 and H2020 funded projects developing innovative security solutions for the
			protection of computer systems and networks. link
			• IoT & Industrial Security: The Industrial Internet of Things (IIoT) refers to the extension and use of the
			Internet of Things (IoT) applications in industrial sectors. The wide adaptation of IoT broadens the attack
			surface against the OT sector, as new vulnerabilities arise. This creates the potential for industrial process
			interruption, manipulation, or espionage. We have participated in numerous H2020 projects providing
			IoT and OT security solutions for different industrial sectors. link
			• Big Data & High-Performance Processing: Big data processing is a set of techniques or programming
			models to access large-scale data to extract useful information for supporting and providing decisions.
			Our research focuses on the exploitation of high-performance processing for Big Data analysis, with the
			use of commodity hardware like GPGPUs or novel high performance hardware designs tested with the
			use of FPGAs. link
			• Analytics & Machine Learning: Data analytics is the science of analysing raw data in order to make
			conclusions about the processed data, extracting novel information. We are actively exploiting data
			analytics along with the use of Machine Learning and Artificial Intelligence in the context of social network
			analysis, security applications and healthcare applications for health. link



2023-08-08-Proposal-PartB.docx

evala to *profile* sthn selida 34 : 

TUC is actively engaged in basic and applied research, with projects funded by the European Union, General Secretariat for Research and Technology, Ministry of Education, Region of Crete, local organizations, and private businesses. TUC's research covers various fields, including telecommunications, networking, machine learning, and more. It's a key player in FP6, FP7, and H2020 projects, often as a coordinator, and promotes commercializing R&D results through services like consulting and partnerships with industrial partners. Prof. Ioannidis specializes in coordinating and participating in security-related H2020 and INEA-funded projects. His team excels in systems and cyber security, producing cutting-edge research, tools, and solutions for RIA, IA, and INEA projects, published in top security conferences.  


*WP-Task-Overview*

 
								WP1	   WP2	WP3	  WP4	   WP5	WP6	  WP7	  Total
								1.00	3.00	11.00	12.00	3.00	3.00	3.00	  36.00
								subtasks 
								t1.1 1

								WP1	Coordination and Management  																	0
								T1.1	Project Coordination  																			1
								T1.2	 Technical coordination of consortium 											0
								T1.3	Scientific coordination of consortiums											0
								T1.4	Risk and data management & Quality assurance and ethics 		0
								WP2	Ecosystem screening
								T2.1	Use-Cases Specification																			3
								T2.2	Market Analysis and Sustainability													0
								T2.3	Threat landscape Investigations															0
								T2.4																															0
								WP3	Cybersecurity Shields (for the Infrastructure)
								T3.1	Cloud-Shield
								T3.2	Edge-Shield
								T3.3	Endpoint Shield
								T3.4	IoT/OT Shields																							11
								WP4	Threat Intelligence, Verification, Monitoring
								T4.1	Threat scenarios																							3
								T4.2	"Proactive and automated detection and analysis of threats 		9
								T4.3	Life-cycle Management (device base = IoT/OT and Endpoints)
								T4.4	Cyberssecurity resilience, awareness
								T4.5	
								WP5	Piloting
								T5.1	Coordination of pilots
								T5.2	Mapping of stakeholder requirements and needs”								3
								T5.3	Specification of trainings and awareness raising strategies
								T5.4	
								WP6	Evaluation, validation
								T6.1	Specification of evaluation scenarios
								T6.2	Evaluation of Cybersecurity Shields														3
								T6.3	Cybersecurity recommendations and standardization
								T6.4	
								WP7	Dissemination, Exploitation and Communication
								T7.1	Dissemination and communications															3
								T7.2	Business Exploitation and Innovation Management
								T7.3	
								T7.4	


								Financial plan 
								Personnel costs (actual or unit)	198,000.00
								Subcontracting	0.00
								Purchase costs	25,000.00
								Other cost categories	0.00
								Total	223,000.00
								Indirect costs (25%)	55,750.00
								Overall	278,750.00
								Funding rate (%) IA 70/100%	100.00
								Total EU contribution	278,750.00


*LEAD TUC T6.2*

					Evaluation of Cyber Shields	Comments: ... Gather appropriate input (WP3, Wp4) to provide evaluation. Evaluation will be based on task 6.1.	We gather the appropriate input, based on the implementation of WP3 and the threat scenarios described in WP4, to provide a review and designated package for the evaluation. This procedure mainly depends on T6.1 and the defined evaluation scenarios. The developed methodology of the four cyber shields depends on the attack vectors, resulting in 3 technical parts that will have to be evaluated to ensure that they are secure and robust. WP3 will provide the development of the security shields, and our evaluation steps will be guided by this. WP4, which provides the threat scenarios, will feed into T6.1 which will be implemented in this task. Based on the provided implementation of the Cyber Shields developed during WP3, combined with the described threat intelligence from WP4, we will evaluate the provided solutions according to the methodology and evaluation specifications outlined in task 6.1.				TUC 


*Σχετικα με το lead mas sto 6.2. : Duration: M??-M??*

 involved AFTS 2, Calirad d.o.o. 3, 

 start later than T3.4 [Corihhna] but 3.4 is still blank so wait . Not sure about the duration ...

 		You are responsible for your lead. So you can decide. Partners who committed in the task PMs will contribute. OK 
 		I would suggest to start later than T3.4 as the idea of WP6 to summarize gained results from WP3-6 in total. All task in WP3 will work in parallel as they must be all ready when WP4 and 5 will start. I also expect a two phase strategy to involve the feedback from first tests.
		So it is up yo you on a first glimpse. As soon as we have all together we will check if it will make sense and may contact you for updates.


*ECCO*
prova parousiash ???


	As stated in the technical offer in task B6, in brief provide support to education, training and gender balance in cybersecurity by designing a strategy and a set of tasks for the education, training, skilling and reskilling, human resources, students and gender issues communities, to stimulate collaboration within the Community. 
		This will be achieved through the following tasks   !
		Task B.6.1: Education thanks to the mapping of the academic and professional cybersecurity educational offer in the EU
		Task B.6.2: Education via the analysis of the main curricula and courses available, as well as of existing
		educational standards across the EU-27 at bachelor level and identification of gaps and new educational
		requirements. It is foreseen to involve external expert.
		Task B.6.3: Training and support to standardisation of curricula for professional training and establishment
		of European cybersecurity professional certification schemes. It is foreseen to involve external expert.
		Task B.6.4: Gender inclusion and growing the workforce through skilling/upskilling/reskilling
(next slide) This actually means helping   EC deliver on commitment to fill the skills gap in cybersecurity across the EU. 
 this will be done by Leveraging the  experience of four pilots:
				CONCORDIA - TUC
				CyberSec4Europe (CS4E) - Goethe University Frankfurt 
				ECHO- , RHEA 
				SPARTA - CEA 
				ECSO with its competence derived from WG5 on education, training and cyber range, 
				NCCs and ENISA, and the list of ECCO’s external experts from industry, educational institutions and public bodies. 
through the following steps : 
List of tasks :
		Task B.6.1: Create education catalogue based on mapping of academic and professional cybersecurity educational offer in  EU.
		Task B.6.2: Analyse of Cybersecurity education in Europe via review of :
		main curricula and courses available, 
		existing educational standards across the EU-27 at bachelor level and
		identification of gaps and new educational requirements. [external experts].
		Task B.6.3: Provide training and support to standardisation of curricula for professional training and   establishment of European cybersecurity professional certification schemes. [involve external experts, liaise with relevant European standardisation and certification bodies.]
		Task B.6.4: Provide insights on Gender inclusion and grow  workforce through skilling/upskilling/reskilling.
		In line with latest developments at EU level for purposes of developing the ECCO skills strategy, these tasks have been aligned with the wider priorities and responsibilities on skills within the institutional landscape (EC/ECCC/NCCs and ENISA).

The past six months 

			We have designed the D-B.5 Skills Strategy (Task B.6) including:
			An introduction to the context and the importance of pushing for a strong skills agenda in Europe
			A section explaining our approach to the skills strategy
			The results of the initial analysis 
			A plan for how to implement the skills strategy by providing actionable insights to the Commission
			A conclusion with a few short term initial suggestions on the next steps .
		The main strategic goals and current updates on ECCO’s skills strategy:
			Mapping Trainings and Certifications
			Supporting ENISA in building up training and certification repositories 
			Workforce Needs and Pledges On The Cybersecurity Skills Academy
			Status: around 40 Pledges
			Skills Attestation
			Input to ENISA’s feasibility study on a pilot attestation scheme
			Indicators
				Support to ENISA on defining indicators and collecting data from NCCs	
 The next steps (as indicated in B.6.2) include:
			The analysis of courses and curricula 
			The analysis of existing educational standards across the EU-27 at bachelor level
			The identification of gaps and new educational requirements
			Coordinate with ENISA towards this goal  
			[B.6.1 Education catalogue] Support ENISA in the development of the repositories of the Academy // Lead: ECSO / Participants: TUC, CEA, Goethe, RHEA
			Gather input from available resources: 
			Coordinate with pilots 
			Other projects, resources (REWIRE, The Cybersecurity Higher Education Database (CyberHEAD))
			REWIRE project to transfer the content of the map on their CyberABILITY platform .   https://rewireproject.eu/cyberability/ - CyberABILITY is expected to be delivered in *September 2023*
			Concordia map of courses
			Set up knowledge-sharing event  
			Report outcomes from these events providing baseline requirements for “Cybersecurity Education Made in Europe”


5 Sptemeber 
============
back to ITE!!!

			concordia xekinhse Start date
			1 January 2019
			End date
			31 December 2022


1) Fw: ECCO Task B6: Your input requested for survey on mapping funds on cybersecurity skills // deadline: 29/09
2) ECCO meeting next week presenattion 
3) CONCORIA 5.5 comments 
4) SeComCon budget + task leader description 
5) paper alex gia 15/9 


16 Auguts
=========================
phd proposal alex 239 line 

Nina aurio telco : 






14 Auguts 
input for 6.2 in SecomCon + decripton 

ECCO /...mail to ninan about reveiw comments : Of course, this knowledge-sharing event meeting is not covered by the NCC webinar series we have initiated. We did not received any feedback :)  should be an extra event to collect input? should be set by TUC/ECSO/ ENISA? Virtual/physical? There is no time of course before 12/9, so later?
10 August 
============================
ECCO support to ENISA on Academy-related tasks


Meeting 10 august 

Dimitra , Anna 

indicators parts 

how to support this effort from ENISA . 

Enisa wil require the support from ECCO . the expects of t he collaboration for support ECCC 
what theya re

the indicators 
pillar 4 
measurenebts and monitoring 
cretae two sets of indicators 

collect data againts . stages of SHORTAGE (markets etc ) 

and KPIs the commission would use 
inidcators will be created by ENISA (conatct with NC cooperation , )

indicators will need to be shared with NCCs THIS IS WHERE we come in ...
how to collect this data. RECOURCES (human, ) how the data canbe coleected. we are in VERY early steps ,

DAISY digital 



we are happy thay we are aligned . 
Dimitra . Anna has started working on the indicators . shared with cooperation group . THEY WIll decide 

the first resut will be the idnidcators themselves, 


NINA . what about the repositories... how can ECCO suppotn there ? 
   Dimitra : currently 3 parallel . what is the scope of the repositories ? so they ask NCCs ..after that there come up with teh schema , (Rosso is tehre)

   the ad hoc work 

   the same with teh attestation schema . they are colecting requirements . and then they will draw conclusions 


   end of septemeve nice coopertion group will be presented

   nina is also in ad hoc group 

   try to be teh embesedor multiplier to make them understand whta is the role ..what we are have in mind to do , 
   try to explain . 


   we will work together toward these goals . 
   beginning of september speak again, 

   they need some input from us , by end of august  . 

-----
			Dear Dimitra,

		 	I hope all is well.

			I’m contacting you to see how ECCO can support ENISA in some of the ongoing tasks related to the EC COM on the Academy.

		 		ECCO’s skills strategy stipulates two tasks that are inherently linked with the work of ENISA in this context, namely:

			*       Education catalogue and mapping the academic and professional education offer.
			*       Training and support to standardisation of curricula for professional training and the establishment of European cybersecurity professional certification schemes.
 
			I would therefore be grateful if we could connect on how ECCO could support you in the work of the repositories for the Academy and the attestation scheme.

			We could also lend our support to the task on defining indicators and gathering data for those.
 			Tomorrow is my last day before going on holiday for a couple of weeks (and probably you are also out at some point) so maybe we could schedule a catch-up call upon our return? FYI, I’m out from 20th July until 7th August and then again 18-25th August. I let you suggest a convenient date as maybe you also want to confer internally and involve the needed people ahead of such a call.
 			For now, just know that ECCO is ready and willing to support😊
 			Speak to you soon and have an excellent summer in the meantime.
 			Kind regards,
 		Nina
			-----Original Message-----
			From: Dimitra Liveri <Dimitra.Liveri@enisa.europa.eu>
			Sent: Thursday,20 July, 2023 12:36
			To: Nina Olesen <Nina.Olesen@ecs-org.eu>
			Cc: Anne-Sophie DIEHL <Anne-Sophie.DIEHL@ec.europa.eu>; Anna Sarri <Anna.Sarri@enisa.europa.eu>; Chloe Blondeau <Chloe.Blondeau@enisa.europa.eu>
			Subject: RE: ECCO support to ENISA on Academy-related tasks

			Dear Nina,

			Thank you so much for lending a hand, much needed and appreciated.

			I am putting in copy the two Academy ladies, Anna will lead the indicators project and Chloe the attestation one. We greatly appreciate the support offering by ECCO so as you proposed to make things clearer lets arrange for a call when everyone is back to discuss. I will be off from beg of August almost throughout the entire month with few breaks- I see one possibility for the 110th or 11th of August. If not then the week after the 20th would also be ok. I leave it to Anna and Chloe to share preferences and availabilities.

			Again thank you very much
			Dimitra
			From: Anna Sarri <Anna.Sarri@enisa.europa.eu>
			Anna Sarri <Anna.Sarri@enisa.europa.eu>
			Anne-Sophie DIEHL <Anne-Sophie.DIEHL@ec.europa.eu>;Chloe Blondeau <Chloe.Blondeau@enisa.europa.eu>
			Dear Anna,
			Dear Dimitra,

			Thanks for your replies! Sounds good.
			I'm available for a call on 10-11 August. If not, the week starting 28th.

			Actually, I would like to include my ECCO colleague Despoina Antonakaki from TUC (in cc) as TUC is leading the skills task in ECCO with us. @Despoina, please let us know your availability for a call around the dates proposed.
			I'm leaving on holiday after EOB today so if Despoina reverts back while I'm away please do not hesitate to pencil in a time on one of the dates proposed as they are currently quite open for me.

			Thanks everyone.
			Have a great summer and looking forward to speaking soon.

			Kind regards,



7 August SeComCon
============================

https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BD4CE2309-C61B-4F5F-9572-9CBD536003C1%7D&file=HE_plan_budget_template.xlsx&action=default&mobileredirect=true&cid=56c08e78-c9ac-4ecf-8fe9-f73d1874acf5

===exei anoixei to drive kai leei ok gai ta PMs kai oxi ta X pou exoume valei edw : 

https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B6B1B4CC5-EA6B-4731-AF42-19A07947A68F%7D&file=WP-Task-Overview.xlsx&action=default&mobileredirect=true&cid=1b5b9db5-126f-4eb3-a443-948409ce0149

ok dior8wsa to WP1 se 1 oxi 2

need teh lead for cloud - shield

avoid subcontracting , otherwise we have to justify 

use case templates 

20 parnters 


10 August 
============================
ECCO support to ENISA on Academy-related tasks
-----
			Dear Dimitra,

			 

			I hope all is well.

			I’m contacting you to see how ECCO can support ENISA in some of the ongoing tasks related to the EC COM on the Academy.

			 

			ECCO’s skills strategy stipulates two tasks that are inherently linked with the work of ENISA in this context, namely:

			*       Education catalogue and mapping the academic and professional education offer.
			*       Training and support to standardisation of curricula for professional training and the establishment of European cybersecurity professional certification schemes.

			 

			I would therefore be grateful if we could connect on how ECCO could support you in the work of the repositories for the Academy and the attestation scheme.

			We could also lend our support to the task on defining indicators and gathering data for those.

			 

			Tomorrow is my last day before going on holiday for a couple of weeks (and probably you are also out at some point) so maybe we could schedule a catch-up call upon our return? FYI, I’m out from 20th July until 7th August and then again 18-25th August. I let you suggest a convenient date as maybe you also want to confer internally and involve the needed people ahead of such a call.

			 

			For now, just know that ECCO is ready and willing to support😊

			 

			Speak to you soon and have an excellent summer in the meantime.

			 

			Kind regards,

			 

			Nina
			-----Original Message-----
			From: Dimitra Liveri <Dimitra.Liveri@enisa.europa.eu>
			Sent: Thursday,20 July, 2023 12:36
			To: Nina Olesen <Nina.Olesen@ecs-org.eu>
			Cc: Anne-Sophie DIEHL <Anne-Sophie.DIEHL@ec.europa.eu>; Anna Sarri <Anna.Sarri@enisa.europa.eu>; Chloe Blondeau <Chloe.Blondeau@enisa.europa.eu>
			Subject: RE: ECCO support to ENISA on Academy-related tasks

			Dear Nina,

			Thank you so much for lending a hand, much needed and appreciated.

			I am putting in copy the two Academy ladies, Anna will lead the indicators project and Chloe the attestation one. We greatly appreciate the support offering by ECCO so as you proposed to make things clearer lets arrange for a call when everyone is back to discuss. I will be off from beg of August almost throughout the entire month with few breaks- I see one possibility for the 110th or 11th of August. If not then the week after the 20th would also be ok. I leave it to Anna and Chloe to share preferences and availabilities.

			Again thank you very much
			Dimitra
			-----Original Message-----
			From: Anna Sarri <Anna.Sarri@enisa.europa.eu>
			Sent: Thursday, July 20, 2023 11:54 AM
			To: Nina Olesen <Nina.Olesen@ecs-org.eu>
			Cc: Anne-Sophie DIEHL <Anne-Sophie.DIEHL@ec.europa.eu>; Chloe Blondeau <Chloe.Blondeau@enisa.europa.eu>; Dimitra Liveri <Dimitra.Liveri@enisa.europa.eu>
			Subject: RE: ECCO support to ENISA on Academy-related tasks

			Dear Nina,

			Happy to talk to you.
			Please let me know also your availability and I will try to schedule a call when possible for all of us.

			I am currently working on the market indicators for cybersecurity skills and it will be great to know how ECCO could support us in this effort.

			Best regards,
			Anna
			
			This message was sent with High importance.
			This message was sent with High importance.
			Nina Olesen <Nina.Olesen@ecs-org.eu>
			Anna Sarri <Anna.Sarri@enisa.europa.eu>
			Anne-Sophie DIEHL <Anne-Sophie.DIEHL@ec.europa.eu>;Chloe Blondeau <Chloe.Blondeau@enisa.europa.eu>
			Dear Anna,
			Dear Dimitra,

			Thanks for your replies! Sounds good.
			I'm available for a call on 10-11 August. If not, the week starting 28th.

			Actually, I would like to include my ECCO colleague Despoina Antonakaki from TUC (in cc) as TUC is leading the skills task in ECCO with us. @Despoina, please let us know your availability for a call around the dates proposed.
			I'm leaving on holiday after EOB today so if Despoina reverts back while I'm away please do not hesitate to pencil in a time on one of the dates proposed as they are currently quite open for me.

			Thanks everyone.
			Have a great summer and looking forward to speaking soon.

			Kind regards,




============================
11 July 

https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=mabd5b213f71471aa7ddd81f2daab219c NEOO
SeComCon
https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=ma370ab833c9c04df47375feda97e20f6

https://www.google.com/url?q=https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID%3Dm5a89fd4f1462ab5b912cfb1359983d4b&sa=D&source=calendar&ust=1687752718373831&usg=AOvVaw1KOGuFK0ImL6SfLpuJTyu6

https://www.google.com/url?q=https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID%3Dm5a89fd4f1462ab5b912cfb1359983d4b&sa=D&source=calendar&ust=1688456734573623&usg=AOvVaw3UZec6Pfli13tGwNJ7frcp

https://www.google.com/url?q=https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID%3Dm5a89fd4f1462ab5b912cfb1359983d4b&sa=D&source=calendar&ust=1688456734573623&usg=AOvVaw3UZec6Pfli13tGwNJ7frcp



SeComCon - WP calculatioon to PMs
=======================


proteinei  o σι
5.5  36 mhnes = 198  + 30.000 gia taxidia = 228  1,25 (overhead TUC diaxeirιsh) = 285

ποσα PMs εχουμε συνολικα και σε ποιά WPs κατανέμονται; 

WP1	Coordination and Management  																	0
T1.1	Project Coordination  																			2
T1.2	 Technical coordination of consortium 											0
T1.3	Scientific coordination of consortiums											0
T1.4	Risk and data management & Quality assurance and ethics 		0
WP2	Ecosystem screening
T2.1	Use-Cases Specification																			3
T2.2	Market Analysis and Sustainability													0
T2.3	Threat landscape Investigations															0
T2.4																															0
WP3	Cybersecurity Shields (for the Infrastructure)
T3.1	Cloud-Shield
T3.2	Edge-Shield
T3.3	Endpoint Shield
T3.4	IoT/OT Shields																							10
WP4	Threat Intelligence, Verification, Monitoring
T4.1	Threat scenarios																							3
T4.2	"Proactive and automated detection and analysis of threats 		9
T4.3	Life-cycle Management (device base = IoT/OT and Endpoints)
T4.4	Cyberssecurity resilience, awareness
T4.5	
WP5	Piloting
T5.1	Coordination of pilots
T5.2	Mapping of stakeholder requirements and needs”								3
T5.3	Specification of trainings and awareness raising strategies
T5.4	
WP6	Evaluation, validation
T6.1	Specification of evaluation scenarios
T6.2	Evaluation of Cybersecurity Shields														3
T6.3	Cybersecurity recommendations and standardization
T6.4	
WP7	Dissemination, Exploitation and Communication
T7.1	Dissemination and communications															3
T7.2	Business Exploitation and Innovation Management
T7.3	
T7.4	
*Total = 36*
=================

Project Coordination 1
T1.1 

Use-Cases Specification 1

IoT/OT Shield 9 

Threat scenarios 2

Threat scenarios 3



todo plan budget HE plan budget template 

eipe poi 8a einai ta taxidia alal den apanthse sthn erwthsh mou 
https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BD4CE2309-C61B-4F5F-9572-9CBD536003C1%7D&file=HE_plan_budget_template.xlsx&action=default&mobileredirect=true

stion pinaka edw 8a poun travel ktl rooms ktl 

CFS certificate (audit) only for ..wil be zero only for UniBW



sentinel: Grant agreement ID: 101021659
jcop 82516
emeralds 101093051

24 July 
=================================

ALEX PROPOSAL !
asonam 

https://www.overleaf.com/project/624e95402b38b76ba817abd8 prospxh asonam forlder ....

bot detection petsoikommα 


SeComCon
5.5 * 36 mhnes = 198  + 30.000 gia taxidia = 228 * 1,25 prepei na doume me vash to call (overhead TUC diaxeirosh) = 285

https://ec.europa.eu/info/funding-tenders/opportunities/docs/2021-2027/horizon/wp-call/2023-2024/wp-13-general-annexes_horizon-2023-2024_en.pdf
apo edw 
					lat-rate (i.e. costs calculated by applying a percentage fixed in advance to other types
			of eligible costs) for:
			– indirect costs (25% flat-rate of the total eligible direct costs, excluding eligible
			direct costs for subcontracting, financial support to third parties and any unit
			costs or lump sums which include indirect costs);

			==> 25% extra 

Excel : 
T4.2 den exoume valei  (snort)  giati den exei mpei kapoios allos kai isws na mas valei lead - 

T4.1 -  
P23 SGX - Memory encryprion  (Task 3.2 )

T3.4 ioT/ Shield  --> Alex . ML IoT

21 July SeComCon
=================================

Tim Stuchtey BiGS
https://www.bigs-potsdam.org/en/about-us/team/tim-stuchtey/

WpTask overveiw (in drive) 




20 July 
=================================
*SeComCon*		
		Dear Manos,

		as earlier mentied budget-wise we cannot name numbers at the moment. 1 FTE equals 1 position (junior or PHD candidate) for 36 PMs (project duration). the extra costs are not allowed to exceed 15% of the staff costs. You can split them.

		But feel free to spend less PMs.

		Regards,

		Corinna




		Am 19.07.23 um 14:15 schrieb Athanatos Manos:
		Dear Corinna, 
		Could you please provide the exact numbers that you have in mind for our organization as the 1 FTE is not clear enough for us as we need to align and get approval for our department. We need to have this in mind before filling in our contribution to tasks/WPs etc. 
		Kind Regards

*ECCO*

meeting 10 August 


10 July 
================================
ECCO September 12,13/9 


30 June 
 ===============================
meeting SeComCon

notes in https://fhnw365-my.sharepoint.com/personal/christopher_scherb_fhnw_ch/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2F00%2DMeeting%2DMinutes%2F2023%2D06%2D23


todo vale gia ta projects pou einai sxetika to TRL level tous !


TODO: 

1.
add part A in https://fhnw365-my.sharepoint.com/personal/christopher_scherb_fhnw_ch/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2F01%2DProposal%2DDocuments%2FProposal%2FProposal%2DPart%2DA

the part A frm tuc is filled in folder : /Users/despoina/Documents/SeComCon/ApplicationForm(Part A)-SeComCon_TUC.docx
ΟΚ 

2/
τιμολογιο ΟΚ  einai apol8hkeumeno sto 5b80310c-117e-4b40-a2f9-ac1c0426e760 ΟΚ 

3. timesheets steile Paraskeuh  ΟΚ sent





SeComCon 

*TI MAS ZHTANE*

		In the main directory HORIZON-CL3-2023-CS-01-01 you will find the table Contacts.xlsx. Please check contact data related to you/your colleagues/organization, and remove or add someone if necessary. According to this list, we will try to make a mailing list. We do not wish to spam anyone.

		checked again OK 

		Related work program and call text you can find in the directory Call-Document.

		All documents related to the proposal and submission process will be stored in 01-Proposal-Documents. For now, please check if your organisation’s logo is current and available in “Partner-Logos”. If not, please upload high quality image.
		checked again OK 


		In 01-Proposal-Documents/Partner-Profiles you will find the table PartnerOrg_basic_data.xlsx. Please fill in the missing information related to your organization.
		checked again OK 

		Further in 01-Proposal-Documents/Partner-Profiles/FormA you will find a template for submission FormA related to your organisation.
		When we open the submission process in the funding portal, these information will be copied into respective FormA. It is a job that takes time, therefore we prefer to have these information in place asap. Approaching the submission deadline, it will be more important to concentrate on FormB, the narrative part of the proposal. 

		just uplaoded . also here : https://drive.google.com/drive/folders/1cKs3Q-J-JoR9cQ3vJqWf0UA2BBc-sihS
28 June 2023
==================
SeComCon
INtaLK use case 
Our first objective is to identify interesting hardware/software and communication standards for
the input networks handling different data input from technologies used in farming area to collect
data and triggering actions. 

		Hardware:

*Internet of Things (IoT) Sensors*

			These sensors can be deployed in fields, greenhouses, or livestock areas to monitor environmental conditions such as temperature, humidity, soil moisture, and air quality.
			Drones: Unmanned aerial vehicles equipped with cameras or sensors to capture aerial images or collect data on crop health, irrigation, and pest detection.
			GPS (Global Positioning System): GPS technology is used for precision agriculture, enabling farmers to precisely track the location of vehicles and machinery, optimize planting patterns, and monitor field conditions.
			Robotics and Automation: Automated machinery and robots are used for tasks like harvesting, planting, spraying, and weeding, reducing manual labor and improving efficiency.
			

			Software:


*Farm Management Software:*
			
			 Comprehensive platforms that integrate various data sources and provide tools for planning, monitoring, and decision-making in farming operations. Examples include FarmLogs, Agworld, and Climate FieldView.
			Geographic Information System (GIS): GIS software allows farmers to analyze and visualize spatial data, enabling them to make informed decisions about field management, crop rotation, and resource allocation.
			Crop Monitoring and Analysis: Software solutions that use data from sensors, satellites, or drones to monitor crop health, detect diseases, predict yields, and optimize irrigation and fertilization. Examples include CropX, Taranis, and Prospera.
			Livestock Management Software: Platforms specifically designed for managing livestock, tracking individual animal health, monitoring feed consumption, and optimizing breeding programs. Examples include Allflex SenseHub, HerdX, and CattleMax.
			

			Communication Standards:

*Wireless Sensor Networks (WSN)*

		: Networks of interconnected sensors that communicate wirelessly to collect and transmit data from various points within a farming operation.
			LoRaWAN: Low-Power, Wide-Area Network (LPWAN) technology that enables long-range communication between IoT devices and gateways, even in remote areas.
			MQTT (Message Queuing Telemetry Transport): A lightweight messaging protocol commonly used in IoT applications to facilitate communication between devices and the cloud, ensuring efficient data transfer.
			5G: The fifth-generation wireless network technology offers high-speed, low-latency communication, which can support real-time data transmission and enable advanced farming applications.
			These are just a few examples of the hardware, software, and communication standards used in the farming industry. The field is rapidly evolving, and new technologies and standards continue to emerge, driving innovation and efficiency in agriculture.

27 June 2023
==============
ECCo task B meeting . 
		deliverable still on. 

		info days 
		we are on track 

		is there a doodle deadline for us to book tickets  ? professor Ioannidis will be there as well .  

		next week i will be off . for the whole week . hope everything will be ok , 


		maybe a topics to talk about the skils strategy , how to continue with the webinars but maybe no presenattiomn 
		Davide will check with Roberto  



		12 of July last meeting 

		22 July - 7 august . Nina will be away . 

		take a look a the skills strategy . 

		more info  will be coming 


		M12 update on the skill strategy . focus on community group on skill .  





ECCO trip ? den xeroume akomh 
when ? 
twiter telos data 
reveiw stis 2  ΟΚ DONE

*TODO* TASK A steile to  gia SeComCon

Alex manos meeting about SeComCon

				After Friday meeting 23 June. 

				Use cases - how to contribute for TUC  


				IDS

				T1

				snort - 

				T3: Secure integration of untrusted IoT in trusted environments


				sugkekrimena sta use case 
				1. https://fhnw365-my.sharepoint.com/personal/christopher_scherb_fhnw_ch/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2FUC%2DDescriptions%2FCalirad%2DAICam%2DUC%2Epdf&parent=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2FUC%2DDescriptions

				Calirad AI 

				suport sto Ai ? Ml gia toprwto me thn camera ? 

				---------------------------------


				store data  - presprocessing  -  isa isa pou akompamw 
				secure protocols epinkoinwna +  netwokr and authentication sto use case (Eva ) 







				---

				SHIFT Use case

				Mpamphs IDS 

				Device security  - Alex + proptyxiako [model ai trained se polles suskeues - ML model pou einai trained gai attacks kai kanei attack predicts . ]


				====
				smart grid 

				Implement a combination of AI-based automation tools and traditional cybersecurity methods to ensure robust cybersecurity resilience and preparedness. This will involve regular threat hunting and vulnerability assessment exercises to identify and fix weaknesses in the system.


				oxi data kai Cloud Infrastructures and Vulnerabilities Mitigation​
				aonly contributio to tranidtiomal CS methods. 



				--
				https://fhnw365-my.sharepoint.com/:p:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BDC1313C3-AD26-4D83-A949-A7D43AD9B5FE%7D&file=Usecase%20Smart%20Grid.pptx&action=edit&mobileredirect=true
				Integration of Untrusted IoT in Trusted Environments - no matcj for TUC 

				Secure Lifecycle Management of IoT Ecosystems - match for TUC ? NO match - talk me to petro sto edgeless  -  Alex  na milisoume ?  tha mas pei kai o Petros ...

				AI-Based Automation Tools for Cyber Threat Intelligence -  potential match 
				 den exoume expertise se auton 

					anomaly detection  - na ta kanoume ligo existing ergaleio pou 8a ginoun improves 
					exoume kai ena neo paidi pou phrame twra 
				deploy sto snort se open source detecttion suystems  - 


				network Segmentation 
				etokmo component apo EVA . 


				Minimizing the Attack Surface​ ises san sunepeoai pianwei auto 

				Improved Visibility and Control​

				Zero Trust Architecture​

				Secure Integration of IoT devices kai edw kapws ...an kaneis secure communication kanalo san apotelemsa ola ta device kanei secure  . 



				======

				https://fhnw365-my.sharepoint.com/:p:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B2DBA52A8-6361-412D-BA11-38EDFBA5DDBB%7D&file=UCs-mapping-topics-v2.pptx&action=edit&mobileredirect=true

				134567

				T1: Tools to support cybersecurity resilience, preparedness, awareness, and detection within critical infrastructures and across supply chain
				Network Segmentation

					TUC: IDS, snort 
					Έχουμε δηλώσει συγκεκριμένα 

						End point detection 									x							Xania  - snort 
						Deception tehnologies/honeypots									x		 has been already set up in Chania 	


				T2: Cloud infrastructures vulnerabilities mitigation​

						Cloud/Fog/Edge computing	x								x							-  SNORT -  based ISD 
						Monitoring / Consistency									x							tools/modules set up in XANIA 

				T3: Secure integration of untrusted IoT in trusted environments​
					Trustanchor  / Attestation - Trusted Computing	x								x				Xania 		SGX - trust zone  - 	alla feugoun oi foithtes ,,, 
					(TPM/PUF) - Hardware Security 									x							  tools/modules set up in XANIA  - 
					Blockchain / Distributed Ledger Technology									x					tools/modules set up in XANIA 		



				T4: Use of Zero-Trust architectures 

					Architecture									x							key chain  - already available  open source tools  - 
					Network Security									x		 - 			EVA module	
					protecting resources									x						honeypots  - snorts - extend tou proposal ti akrivws 8a graftei . 	
						Authentication and authorization	x								x	 EVA module	 						



				T5  - Trust & Security for massive connected IoT ecosystems & lifecycle management; - 
				Security Orchestration

					AI model me secure resilience  - ML models - Verification

				T6 - Secure interoperability and integration of systems;
					Έχουμε δηλώσει monitoring  - snort 

				T7 AI-based automation tools for cyber threat intelligence;
						Έχουμε δηλώσει Machine Learning approaches – vulnerability detection									x							


				Topic 8	 - Secure infrastructure, secure Identities and usability for a security chain covering communication, data collection, data transport, and data processing.

				Έχουμε δηλώσει 	Data Handling (Anonymization, Aggregation, Evaluation)	x					HORIZON-CL3-2023-CS-01-0			x							

26 June 2023
==========================
ask manos to see form A kai auta pou zhtaei h Ivana : 
ToDos for the upcoming week until next meeting on June 30:

·      Fill out the different administration forms

·      Think of where you find yourself in the PPT of the UCs [1]

·      Checkout WP/Task Document [2]

o   add here Buzzword

o   add small descriptions

o   add new tasks in the WP if you miss something

o   Think/commit leaderships (WP and/or Task level)

o   Commit to works in the tasks


reveiw paper with alex

==================================================================
https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=ma370ab833c9c04df47375feda97e20f6

OLD 
https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=m5a89fd4f1462ab5b912cfb1359983d4b


23 June 
==================

asonam lambrou
SeComCon

	in which reference was I asked to answer ? smart farming companies in greece

	let's see the minutes NOTHIG!
 
ECCO 
	si ok gia brussels 

si ok gia smart farming 8a rwthsei spais  - brika ki egw kapoia online doc : https://docs.google.com/document/d/1Y2PZKvepb6md92O0Kqyw6vEFDJduJlE7RwiDCLfFxZQ/edit

rwthse gai bart https://blog.invgate.com/gpt-3-vs-bert? TODO !

tou eipa gia vicky einai akriva ola auta . mou eipe ekleise mia sundromh . ok jadbio 


manuscript gia asonam , check all day  . submit to vrady . 

22June
==============
paper giorgos lambrou
reveiw 
ecco meeting in brussels 
sumplhrwse form A 


21June
=================
Paper asonam , dataset paper.

20 June 
=====================
epomenh tetarth 20 June xania pgm 


19 June 
=============================
cerene + Nccs 

CERENE OK 
xekinhsa tis formes me SeComCon

NCC: 

16June 
=============================
SeComCon meeting .
    please fill in information . she will send an email in the end 
    
Legal question Ivana : 

3 use cases 
logistics 
TRL6+ (with prototypes ready) and introduce the ideas of the use cases, because they have to be first. they are important for the proposal . So today this and also introduce to the drive.  

Ivana : leave  ehealth apart from the use cases 

logistics nad transportation 

IVANA
find the use case that are not covered and are important to EU 
EU would NOT like to repeat in between projects !


smart farming 

IN drive UC-description in siemnets and other to add for transport 

and other ideas can go there .. isws kai ta dika mas ? 

Ivana : the partners shoudl collaborate between us ...synergies ....

we make a stop in research onstritutions , we need more sme instrustry oriented partnters 

datacenter (Tamara )

6 Million budget so more can be part 

TODO : if we have any use case or instrusty parnter interested . maybe WE SHould FINDn 

den xreiazete mono germania farming also from greece ...

strategy ? from proposla side..are we agrresive with many topics or on topics focused ? 

we cannot cover everything . Where are we strong ? maybe deeper in some topics 

eu is intreseed in a large pallette ,,,not only focused only in one . 

we cannot covering everythin g. 

todo : vale kai sto excel ta topic 


29 will open so etry point and regitser proposal with name , we should find the name . make the working version and later change . 

https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BFCCB9503-02A3-424B-93CE-330E87E06320%7D&file=2023-06-09-Expertise-consolidated_SeComCo.xlsx&action=default&mobileredirect=true

partnet logo as well . jpeg, 
kai edw 
https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BD17E1B00-F2AE-4A2C-8F1E-EC4CD5EB0B06%7D&file=PartnerOrg_basic_data.xlsx&action=default&mobileredirect=true

https://fhnw365-my.sharepoint.com/:x:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BD17E1B00-F2AE-4A2C-8F1E-EC4CD5EB0B06%7D&file=PartnerOrg_basic_data.xlsx&action=default&mobileredirect=true

https://fhnw365-my.sharepoint.com/personal/christopher_scherb_fhnw_ch/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2F01%2DProposal%2DDocuments%2FPartner%2DProfiles%2FFormA

https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7B2CF1E8C6-71A3-431A-8C87-9DF8FF7DD96C%7D&file=ApplicationForm(Part%20A)-Template_Dienekes.docx&action=default&mobileredirect=true

till mid of July ...

https://fhnw365-my.sharepoint.com/personal/christopher_scherb_fhnw_ch/_layouts/15/onedrive.aspx?ga=1&id=%2Fpersonal%2Fchristopher%5Fscherb%5Ffhnw%5Fch%2FDocuments%2FProject%2FAntr%C3%A4ge%2FHORIZON%2DCL3%2D2023%2DCS%2D01%2D01%2F01%2DProposal%2DDocuments%2FSubmission%2DHelp%2DDocuments

15June 
=============================
presentation for Nccs to CONCORDIA format 2 wres
deliverable ECCO in template format 2 wres


=============================

AAAAAAAAAAAAAAAAAAAAADwc3QAAAAAAM5Mi80gdF0f6NkowBDj7ykRGKbw%3DRDG2lZ8jo5r0RW4ZDQEWqo2vdflir93BQGTZXudEYD7dEw2JTM 
bearer token Twitter 

14 June 
====================================
deliverable ecco review address comments . 

Notes from deliverable 

is r European Cyber Competence Network  still on ? Yes? 
https://cybersecurity-centre.europa.eu/index_en


from skills startegy 
-	October 2023: 
o	Second webinar of the ECCO Community Group on Skills
o	Support to ENISA’ Cybersecurity Month


13 June
====================================
Update cv and applied for FORTH job : Application Form for possition [ICS-2048]
CERENE: registered for 19 June 10 CEST
	Skills regarding Required_for_FORTH_June2023.pdf
	OK ekana aithsh meta apo 4 wres !


friday Fri 6/16/2023 2:00 PM - 3:00 PMNo conflict SeComCon, HORIZON-CL3-2023-CS-01-01, Brainstorming
		Meeting-Link:
    https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=ma370ab833c9c04df47375feda97e20f6

		Meet virtually with Cisco Webex. Anytime, anywhere, on any device.
		Simple, modern video meetings for everyone on the world's most popular and trusted collaboration platform.
		code-unibw.my.webex.com

		Meeting-Kennnummer:
		    2365 685 7989
		Passwort:
		    sB2qbGmJa22 (72272465 über Telefon- und Videosysteme)


ECCO deliverable . starting addressing comments. *TODO*IN THE END ADD ORMATTING OF ECSO !

12 June
====================================
Εχω το pdf απο ενα βιβλιο
	θελω για καθε κεφαλαιο να μου φτιαξει διαφανειες


	chat gtp 4
	https://docs.google.com/presentation/d/1wbEfbZEr0E9K4GL1SqeKzoURkfO4Vcq6EEGuCItXsV0/edit#slide=id.p

	δεν ειναι καλο λεει 

Concordia - CYRENE¨
		και οταν λέμε senior τι εννοούμε; 
		Εγώ αρκεί να τα παρακολουθήσω; 

		Επίσης στις 19/6 στις 15-17 eest έχω μια σημαντική παρουσίαση στο ECCO. 
		Τι ώρα εινια το demo ?

		Αναφέρεις "..σχετικά με το ποιο section του CYRENE θα μπορούσε να προσφέρει στα άλλα έργα και το αντίστροφο .." Απλά έπειδη εχει ληξει το concordia, πώς θα προσφερουν αποτελεσματα ;

CONCORDIA 
	[CONCORDIA] bank account for balance payment
Drive @ TUC: 

	ECCO upload
	CONCORDIA: confluence / gitlab upload 
	https://drive.google.com/drive/my-drive


Alex for 	


8 June 
====================================
Arxiv finally live. 
*SeComCon*
	sunanthsh 16/6  
	took a look in the https://fhnw365-my.sharepoint.com/:w:/r/personal/christopher_scherb_fhnw_ch/_layouts/15/Doc.aspx?sourcedoc=%7BE1A48160-5DC1-4462-A956-C2710D345941%7D&file=Minutes.docx&action=default&mobileredirect=true

	to get an idea

	in this meeting will like to give you a short intro to the Drive and request some basic information from your side.:

	lets check the excel and what we have inserted : 




7 June 
====================================
ECCO deliverable, after review we will need a conclusion for education skills results on concordia 

from 

CONCORDIA overall have contributes in education and skills diverse outcomes, 
from the governance model encaspulating the expertise and understanding throughout the project's various education-related initiatives,
the roadmap in EDUCATION  gathering challenges and the respective recommendations , 
to Skills Certification Framework and C3 certification scheme for education 
to maps, to courses,  structured curriculum, hands-on exercises, case studies, and practical assignments fro CS profsional,  Methodology and Guidelines for high-school teachers 
until maps of courses ...providing a holistic overview in the current momentum for education in cybersecurity CS in EU. 

CONCORDIA overall have contributes in education and skills diverse outcomes. From the governance model encaspulating the expertise and understanding throughout the project's various education-related initiatives; to the roadmap for education  gathering challenges and the respective recommendation; to Skills Certification Framework and C3 certification scheme for education; to courses,  structured curriculum, hands-on exercises, case studies, and practical assignments for CS professionals,  methodology and guidelines for high-school teachers; until maps of courses; CONCORDIA have provided a holistic overview in the current momentum of cybersecurity  for education in EU landscape

2 June
====================================
arxiv ok : https://arxiv.org/abs/2306.00037

1 June
====================================
1. followup actions for HORIZON-CL3-2023-CS-01-01". set up a new skype group. set up a meeting metaxu mas? sumplhrwsa doodle tous. 
2. Nina esteile to meeting gia NCC webinar: 
ECCO Community Group on Skills - Webinar for NCCs
Mon 6/19/2023 4:00 PM - 5:00 

*Meeting B6 ECCO*
deliverable is fine. maybe take another look also in all sections, but NOT THIS WEKEK>NEXT 
also please freeze the meeting fro the summer. We will merge the updats on the task B call.  

parousiash!
*TODO*
			****************
			* Next steps *
			****************

			- @ all: 
				- Mail Chris (Christopher.scherb@fhnw.ch) your contact to create Drive Access
				- Check your information in the EU Portal
				- Announce Ivana all information need for the portal
				- think about the 3 ICs
			- @ Corinna/Ivana
				- prepare template
				- request initial input
				- propose WP structure

31may
====================================
1. timologio? 

2. proetoimasia gia to meeting proposal tou apogeumatos 
		From TUC we have some experievce with previous projects , research whre I can be more detaled . see 

		Meeting link - meet.google.com/jnr-nfyt-pkm
		Federated Learning is a distributed machine learning approach where models are trained on decentralized data sources without transferring the data to a central location. To address classification tasks in federated learning, one state-of-the-art solution is:
		
		Federated Learning with Secure Aggregation: Secure aggregation is a technique that ensures privacy and confidentiality while aggregating model updates from multiple participants in a federated learning setting. This approach combines cryptographic techniques, such as homomorphic encryption or secure multi-party computation, to allow the aggregation of model updates without exposing individual data. Secure aggregation ensures that sensitive data remains protected during the learning process.

		By employing federated learning with secure aggregation, classification models can be trained collaboratively on distributed datasets without compromising data privacy. Each participant trains a local model on their data and shares only the encrypted model updates, which are then securely aggregated to generate a global model. This federated model can then be used for classification tasks while maintaining data privacy and confidentiality.

		State-of-the-Art ML/AI for AI-Based Automation Tools for Cyber Threat Intelligence:
		AI-based automation tools for cyber threat intelligence leverage machine learning and artificial intelligence techniques to enhance the detection, analysis, and response to cyber threats. Here are some state-of-the-art ML/AI solutions for such tools:

 
-----------------meeting ------------------------

cybershield 

shield for hardening infrastructure and endpoints using layers defence 

cloud edge endpoint iot 

marco Caselli . life cycle managment what do we mean ?part of teh proposal ? 
life cycle managemnt : Chris start from development to how to guarantee get devices out of system , put endpoint and iOT , 
stpread on al shields, 

[Marco siemens ] - regulatory aspects in the callthe solution , what abou the  regulatory aspects? 

depend on the use cases, other regulations for each 
lets start and add later aditional regulatory  

standardazation will support the regulatory aspects ,

Innovation --. results close to the markets + SMEs yilo TRL... 

contact to apply the infrastructure in the end ? any contacts? ay ideas who to approach 

They  have Chris, from the same organization ..maybe Bosch ? is not connected cars, maybe connected buses? 

potential parnters : praetorian horizon https://praetorian-h2020.eu/

[sba Markus Klemen] - Austria..use case . security academic tools,  for licencing human resource capacity, universities in Austra maybe intrested. 
electric? uptime engineering + risk management of sustainable energy ..

[Stjepan Gros] 

electric production not interfrated yet, 

[Reinhard] - 

TRL but I would expect we should aim for 6 or higher for IA at least for some parts of the project



Yes, 6+ is anticipated for innovation actions


Marco Caselli, Siemens - how to contact without money ?
CODE - we shoudl be fluent on how agree on the budget . maybe at the end of summer ? when we finalize . 

[Ivana] We have to estrablish a contact initially ? 
resources are minimim, give the explained case, and we develop show them as a case of solution . or the y come as associates , and invenst in a good solution in the end, or agreee in a minimum amount. not spread everywhere , learn from each otehr , interaction  

sent email with contacts if any (to corina/ivana)see if budget is left and if we want t o incorporate them 

stjepan gros cyber shiels is very general name espceially in google ...maybe rename (CODE)


[IVANA]
structure of WPs
dissemination? 
explotable results and close to market . 

[CODE Corina ]
reuse a lot of stuff 

they will give us think to fill . general parts are in there so lets all tick in ..objects , explitable results etc 

on share drive ..all will put ideas ... 
coordinator ? CODE? IA --> might be good in industry ...but CODE have experience ... maybe split ...with industry ?

is EU interestes in 4 projecs doing the same thing ? 


[chat]
from Stjepan Groš to Everyone:    4:30  PM
Končar Digital
from Stjepan Groš to Everyone:    4:30  PM
https://www.koncar.hr/en/business-segments/digital-solutions/koncar-digital/
from Chris to Everyone:    4:31  PM
christopher.scherb@fhnw.ch


[Ivana]
We have to use our expereicnce and produce something good to be used in idstry ..


[Ivana] when we split the WP maybe try to 

create deliverables are describing the technical part  not report what you did in which month . 

task have to interact . task are iteractinh . keep the flow . dynamic flow .. update task 

not same structure as in conrodia . 

in two weeks another call to see what do we have 

smaller groups ?? to meet maibe [ivana]

They will need our ideas. 

they will spread the i nformation and wai.for 

-------------------
------------------------------

3. mail Kai OK 
4.parousiash ECCO 
	mallon 19 June 
5. hackathon puzzle? ok 

				Event Timing: June 2nd, 2023, 11.00 A.M.
				Event Address:  
				Foundation for Research and Technology – Hellas (FORTH)
				Main Building
				Ν. Plastira 100, Vassilika Vouton
				GR - 700 13, Heraklion, Crete
				Contact us at: info@puzzle-h2020.com

6. metafora pateras ok 

7 check trip fro ecco Notification: ECCO events, July 18 evening CyberSecPro panel in Brussel... @ Wed May 31, 2023 10am - 11am (EEST) (antonak)

8 ml new trends tutorial basic concepts 

9. arxiv fix name at both papers OK 


30May
=====================================
No internet at home! allagh apo cosmote se NOVA 
Last night Ivana sent three emails for CONCORDIA: one technivcal 

1. Why underspending for FORTH and deviations in PMs? 

==============
 meta apo sunenohsh me Maria kai Mano o Manos mou esteile auto :

						 			"The underspending reported by FORTH, is  due to the fact that in the first reporting period of ASCAPE, senior researchers, that are in the permanent payroll, were contributing to the project’s activities. Also, due to the pandemic the recruitment process lasted longer than expected for hiring the appropriate personnel for ASCAPE."

									PM Deviations as explained in original document
									FORTH had overall 2.54 PMs above those planned during the proposal writing phase (30,54 PMs consumed vs 28 PMs planned), representing approximately a 9% difference. This is mainly attributed to the fact that during the second half of the project, a less experienced personnel composition had to be employed in order to carry out the completion of the technical tasks as well as the integration and deployment tasks. This is reflected in increased PMs in work packages 2, 3, 4, 5 and 6. However, since less senior researchers were employed, the increase in PMs is balanced by their decreased rate and therefore there have not been any deviations in the overall budget. The increased time consumed in the technical work ensured that no impact manifested on technical objectives.
									Remarks by EU: 
									Personnel Costs - Thank you for the explanation provided. This would be enough for WP 2,3 and 4. But for WP 5 and 6 where the deviations are 169.5 % and 200 % respectively, please detail what were the problems encountered that they needed such an extra effort.

									Response:
									As mentioned in our original person effort deviation explanation, during the second half of the project, FORTH had to rely on less experienced personnel undertaking the effort of completing the project. This contributed to more PMs consumed, as the junior researchers had first to be trained on the tools developed and then to finish the development tasks, support the partners that relied on the tools developed and finalise the integration, evaluation and demonstration tasks. 
									On top of this, FORTH was actively involved in WP5 and WP6 activities as integration issues not encountered during initial stages of the project, had to be resolved. This has been reflected in FORTH continuing to work for WP5 related tasks till the completion of the relevant tasks and deliverables (T5.3 and D5.5 respectively). Furthermore, FORTH provided assistance and additional effort to certain aspects of both WP5 and WP6 deliverables. For example, it has worked with REN to redefine certain aspects of the TEE usage as part of the work that has been done when the TEE environment was updated to reflect recent updates in the industry (adoption of opTEE instead of the originally used Trusty OS that its support has been dropped by the supplier of the chosen SBC boards used in the project). Additional work was also carried out with all the industrial partners that employed the honeypot solutions and integrated them in their deployment environments. Lastly, FORTH has been involved in the evaluation tasks in WP6 more than originally planned during the project proposal time as it was actively leading the validation and evaluation of a number of CSRs/KPIs/iKPIs reported in deliverable D6.3 and also supported all partners that deployed solutions supplied by FORTH in their premises. 



opote antistoixa gia to CONCORDIA egraya : 

	The total budget underspending of 115.885,29€ by FORTH is due to the pandemic which cause limited traveling for the events of the projects, and due to the lower rates in salaries for Greece.

	 

	FORTH regarding PMs for M1 to M51 planned 24 PMs for WP1 and used 36,14; planned 12 for WP3 and used 18,98; planned 12 for WP5 and used 16,77; planned 18 for WP6 and used 24,51. In total FORTH planned 72 PMs and used 103,03. These differences are mainly attributed to the fact that the personnel recruited for the completion of the tasks of the project was not on the same expertise level for the whole project. This is reflected in a different amount of effort and consequently PMs. Also, the diverse rates in salaries for the different expertise levels of personnel were reflected in the total underspending of the budget. 


	2 
	* Fwd: WG: dein teil für technical report*

		Εδω το report πρεπει να συμπληρωθει απο την Gaby αλλα μαλλον με προλαβε το επομενο mail της Gaby που το συμπληρωσε. 
		Ωστοσο απ' ότι ειδα στο σχετικό mail της Ιvana για το financial report εκκρεμουν απο  UT, TELENOR
		and Arthur’s legal  οποτε αν δεν καταφερει η Gaby να ειδοποιήσει την  PO για την καθυστερηση θα πρεπει να το κανουμε εμεις. 
	============	

---

=====================================
#29 May
=====================================
*TODO* mail apo si gai proposal. xanaxupnhse to !

*TODO* vale adeia se calendar kai site . nomizw oti mphke ΟΚ 

*Arxiv*: BotArtist: Twitter bot detection Machine Learning model based on Twitter suspension OK submitted in arXiv
				 Russo-Ukrainian War: Prediction and explanation of Twitter suspension OK submitted in arXiv

*ECCO TODO* παρουσιαση ECCO: 
ECCO_skills_strategy_v0.8 allo ena anagnwsma

#26 May 
=====================================
*TODO* ftiaxe timologio OXI mexri enhmerwsh apo ELKE
*TODO*: vale sto arxiv ta papers arxiv: botArtist , Ukraine OK 

meeting with new graduate student Giorgos Koutras : undefined [undefined:gkoutras1@tuc.gr]

	Steilame apla ta papers mas 8a ta dei kai vlepoume an endiaferete . 
	Yajame me ton Alex to arxiv and mporw na ton kanw endorse. Mallon akomh den exw privilages na kanw. 
	Kaname link ola mas ta paper sto arxiv me ta antistoixa sta journals. 
	8a mou steilei ta reveiws sto WASSA pou egine reject. 
*TODO* des ta reveiws


#25 May 
=====================================
meeting with Manos Athanatos about SeComCon 
See https://outlook.office.com/mail/category/4bf3b155-71df-4130-a804-d704d82dcb30

about 

created file /Users/despoina/Documents/SeComCon/SecureComputingContinuumIoTEdgeCloudData.md
where we list our related projects/tools/publications

We say we have these. After they sent their idea, we declare we stand within this idea. 
The meeting is on : 
"...The meeting will take place May 31, 2013 from 14:00-17:00. The calendar information with bridge information will be distributed during the day. ...""
		here : Dear all,

		in preparation for the meeting think about items you like to do or
		investigate on based on on the call description. We hope to send an
		initial idea around at the weekend.


		Dial-in information will follow.
		https://outlook.office.com/mail/id/AAQkADY5MjA5N2U4LWYxYTgtNDk3OC1hMjViLTQ3OGIzMjdkMTY5ZAAQAAIGjPpi%2F9lBgnJv3s57dzk%3D


						Dear all,

				in preparation for the meeting think about items you like to do or
				investigate on based on on the call description. We hope to send an
				initial idea around at the weekend.



				Dial-in information:




				Meeting-Link:
				https://code-unibw.my.webex.com/code-unibw.my/j.php?MTID=mafea26c051b1b61d345c90375f88bfe5
				Meeting-Kennnummer:
				2360 976 4958
				Password
				ApWQXTXm355 (27979896 via phone)
				Dial-in via Phone
				+44-20-7660-8149 United Kingdom Toll
				Access Code: 2360 976 4958

				Globale Einwahlnummern


See also this : https://docs.google.com/document/d/1QoSwNkzAi38lh9Svn4ljosGZ3MYzJTxVNwPERx4xCgY/edit

#23, 24 may 2023 CONCORDIA final review
======================================
concordia wp5 presentaton 

mu  Masarykova univerzita
MUNI)
Masaryk University MARTIN Mgr. Martin Horák
TID – Telefonica Research & Development  NICOLA KOURTELIS

========================================

review concordia 
how is the concordia will be continued by eecn?

gaby 
ECCN - monitoring board, 

strategy investment maybe educational ecosytem will be continued build 
sustainability in other projects 


====================================

*[CONCORDIA] publishable project summary*

1 Summary of the context and overall objectives of the project (For the final period, include the conclusions of the action)

Europe needs to step up its efforts and strengthen its security capacities to secure its digital society, economy, and democracy. It is time to reconquer Europe’s digital sovereignty and autonomy to prevent Europe turns into a digital colony. The vision for Europe is to build digital ecosystems by joining forces across Europe’s research, industry, and public sector and to include all human assets. The area of cybersecurity is geographically fragmented across Europe for competencies and often also technically fragmented with problem-specific development of security solutions. Europe needs to build its IT champions out of digital ecosystems. CONCORDIA addresses this by building a European secure, resilient, and trusted ecosystem for innovation in cybersecurity. CONCORDIA has officially accepted more than 50 partners, balanced by industry and research. The new partners complement even better the competencies provided by CONCORDIA. Building the ecosystem means understanding that all stakeholders have their KPIs, bridging among them, and fostering the development of European IT products and solutions along the supply chain. A uniqueness of CONCORDIA is that new partners joining the project bring their resources, which are not EU-funded. CONCORDIA is providing a blueprint for building digital ecosystems, bridging between communities, foster the growth of IT champions to ensure that Europe is gaining its digital sovereignty. Even more, Europe should strive to become a digital power.
------------------------------------
2. Work performed from the beginning of the project to the end of the period covered by the report and main results achieved so far (For the final period please include an overview of the results and their exploitation and dissemination)

CONCORDIA started on 1/1/2019. All work packages (WPs) run in parallel and we will briefly describe the main results and highlights. More information can be found on the website. WP1 aim was to build a European secure, resilient, and trusted ecosystem for innovation in the area of cybersecurity. CONCORDIA published more than 320 papers exceeding the initial objective. Close collaboration with the 3 pilots led to the organization of schools on cybersecurity.  CONCORDIA researchers have published more than 240 workshop, conference, and journal papers and contributed to 3 Internet RFCs and 1 Internet draft. Beyond the traditional academic venues, a continued effort led by CONCORDIA researchers in 2022 has contributed to the “societal impact” of their work. Concrete examples are research papers developing methods for detecting Twitter bots, inappropriate behavior on YouTube, and the impact of the Russo-Ukrainian War on Twitter. WP2 comprises 5 sector-specific “pilots”. Threat Intelligence Platform (TIP) for the telecom sector and the finance sector, privacy and security in the e-health sector, security of unmanned aerial systems and cybersecurity in the supply chain of the automotive sector. WP2 successfully established collaborations with WP1 cybersecurity experts. In the last year, the main objective was to ensure that the outcomes were utilized and sustained. To achieve this, CONCORDIA improved upon the work accomplished in previous years, engaged more stakeholders, and conducted dissemination activities to reach a wider audience outside of the consortium. Despite the challenges posed by the pandemic, Work Package 2 surpassed its target and completed all the milestones and deliverables within the specified timeline collaborations have also been set up with WP3 which deals with the community impact and sustainability. The WP3 has established the groundwork for information sharing of cyber threats. The cross-sector pilots TIP is progressing and the architecture of the DDoS Clearing House is in place. A significant outcome was the establishment of the legal data-sharing agreement that will form the blueprint for the broader agreement needed for effective deployment at the EU level. Cyber range platforms and training offerings have been created to form a cybersecurity ecosystem to foster cybersecurity trainings. The EU's educational portfolio has been assessed to develop the initial methodology for creating cybersecurity courses and an associated certification schema. The overall WP3 achievements include the "CONCORDIA Platform for Threat Intelligence”, the DDoS Clearing House in the Netherlands and in Italy, the "CONCORDIA's Ecosystem: Virtual Lab, Services, and Training",   the "Establishment of a European Education Ecosystem for Cybersecurity" and the conclusion of the Governance model for the European Education Ecosystem. WP4 provided an overview of the cybersecurity threat landscape and also provided an outlook of emerging threats and evolving attacks from various perspectives (technological, legal and economic). WP4 created working groups and established liaisons with the relevant stakeholders to develop and implement a cybersecurity roadmap for Europe. WP4 has produced the CONCORDIA service catalog as a main entry point for a stakeholder to engage with CONCORDIA. The CONCORDIA Open Door events have attracted the attention of stakeholders from all over Europe. The important subject of Women in Cybersecurity has shown significant advances with the organization of a dedicated workshop which produced the “Women in Cyber-a Manifesto for TODAY”. The newsletters have been delivered quarterly as planned to 668 stakeholders from 281 different organizations, while the final  CONCORDIA Open Door event 2022 successfully took place physically in Munich during the European Cybersecurity Month, counting 108 registrants from 19 countries. WP5 produced preliminary results on exploitation, dissemination, communication, certification, and standardization. Several key achievements of the consortium were fulfilled: ( collect and reachable 32 incubators/accelerators, (b) disseminate the various activities of the consortium, including 60 events/conferences, 40 blog posts, communication of the contribution through  35 infographics, and 43 videos, 304 Twitter posts / 290 Facebook posts / 301 LinkedIn posts, and 17 800 of total engagements across social media platforms, 24 announcements posted on the CONCORDIA website, 9 communication campaigns focused on CONCORDIA outcomes and 2 successful modules of Horizon Results Booster service   (c) identification of the connection between CONCORDIA tasks and existing standards by identifying 36 Standards Developing Organizations.
WP6 had many heavy and stressful tasks to accomplish due to a large number of partners (currently 56) to better complement the competencies provided. Careful governance processes led to achievements like (i) Fast growth, (ii) Knowledge transfer, (iii) Building the Cybersecurity Community, and (iv) Women in Cyber. WP6 also produced (and regularly updates) the Data Management Plan and also analyzed the existing best practices in innovation management which will be organized in several iterations placed in a concentric spiral model. The respective Data Management Plan was updated with the information from new partners. Overall, the project ended towards its end well, all milestones were been met by March 2023, and all Key Performance Indicators (KPIs), as defined in the DoA, were reached. 
-----------------------------------

3 Progress beyond the state of the art, expected results until the end of the project and potential impacts (including the socio-economic impact and the wider societal implications of the project so far)

Progress beyond the state of the art, expected results until the end of the project and potential impacts (including the socio-economic impact and the wider societal implications of the project so far)
Major CONCORDIA state-of-the-art advances and innovations are:
WP1 brought together partners from academia and industry to stimulate collaboration and increase the impact of European research. From the publications so far it seems that CONCORDIA researchers and their work is focused on venues where security is applied within a specific context. This focus. is a strong indicator that CONCORDIA research is inspired by, and wants to have impact on, real-world security problems.Additionallyresearchers in 2022 has contributed to the “societal impact” of their work.
Major advances in WP2 included the establishment of a customized TIP for sector-specific pilots. The e-health pilot focused on privacy and data protection in the health sector, while another pilot showcases the authentication of unmanned aerial systems. Each of the aforementioned pilots succeeded in presenting a first prototypical demonstrator and establishing a well-working collaboration with the researchers.
WP3 utilized WP1’s technology developments and WP2’s industry pilots. Through its activities (TIP and DDoS Clearing House) WP3 set the basis to reinforce Europe’s cybersecurity leadership.. WP3 also developed an EU-wide cybersecurity educational ecosystem and also support them by the appropriate certification schema.
The final outcome of WP4 is something like a “one-stop-shop” threat landscape suitable for awareness and information exchange initiatives. The innovation advancement included that all these technological issues are also viewed from the legal perspective and the economic perspective. WP4 also provided a detailed catalog of CONCORDIA services.
WP5 with its exploitation and certification results complements other WPs to maximize their impact. To further advance the value of the results incubators and accelerators were identified and information was collected for each one of them. On the certification front, 36 standards-developing organizations were identified and we advanced all this information by providing our own certification schema.WP6 created an advanced Data Management Plan based on information provided by the CONCORDIA partners. The innovation-related task developed a unique innovation strategy for CONCORDIA by deeply understanding the Specific challenges of the cybersecurity market, the diversity of the stakeholders, the cultural differences, the dynamics of relationships that have a direct impact on trust, and, the threats that can emerge from data sharing
--------------------------------------------




di76gen\



ConcT6_2_1611
!...concordia


Eco Nina send document to review. Notes
---------------------------------

House took what further actions do you want us to do in order to support Community group on skills?


Work package five reset a song presentation for review in concordia
--------------------------------------------

check task names in slide 2

51 51 exploitable results that can lead to separate start-ups or new business units within the partners reporting them
 (Nicolas corrected)


maybe sotiris should  mention everything in ste slides.. maybe key points blogs ...etc  ...

10 minutes presentations 10 minutes questions ?




30/3/2023
-----------
reveiw concordia . 

 Βλέπω έχουμε δύο παρουσιάσεις η μία είναι 30 λεπτά για το roadmap και οι άλλη 5 λεπτά για το WP5 . Είπατε κάτι σχετικά την δεύτερη μέρα για την πρώτη παρουσίαση; Εσύ έκανες μία παρουσίαση gia to radmap. Aυτό που θα παρουσιάσουμε στο review είπατε πως θα πάει;κάτι λιγότερο κάτι περισσότερο κάτι πιο στοχευμένο; τι feedback πήρες;



Dear all, 

You have addressed the comments and Nicolas noticed that Annex A was changed in the previous version but this version of the file had the older annex.
Anyway now it is ok, but maybe you used the previous version for the review ?


1/3/2023

CONCORDIA meeting for teh final event,

Gaby informs us about the people on panel. Despoina Spanou maybe in order to have more women in panel. 
Vaggelis from ENISA. ? maybe . maybe remotely in sessions. 


1.0	28/2/2023	Yair Meidan(Ben-Gurion University *), 
Burkhard Stiller (University of Zurich)	Second round of reviews sent to deliverable leader. 





proposal meeting. 

si:

exoume periorisei to experstise sto na grafoume protaseis, 
na ftiaxoume upoomades  apo miaprotash h ka8e mia . na broume to provlhma/objectives / luseis / 
core protash na ginei lead apo emas. 

ka8e omada na vrei mia protash kai na thn xekinhsei . 
 sto call  tou iouniou ? vrceite eseis . 
 noevbrio . ? 

 visibility mesa sthn idea na koitame ta call pws mporei na kollhsei mia dikia mou idea/upotask / 

 vlepw ena call.. vazw kati pio geniko apo auto pou skeftomai ..kai auto to poulu sugkekrimeno pou kanw 8a to valw mesa sto call . 



6/2/2023
-------
todo: 

todo 
backup CONCORDIA confluence better save as pdf. As a whole site it need the admin. does it make sense to ask Ivana?

add ecco deliverables in calendar  OK 
rewire conf OK 
meeting sg new projects 1300

*aneiipero debug fasaria:* 

htop
watch sensors


covid backup 

 ht_COVID19_287.gz
 ht_COVID19_203
 ht_unknown7
 ht_COVID19_279
 ht_COVID19_294
 ht_COVID19_291
 ht_unknown6
 ht_COVID19_284
 ht_COVID19_276
 ht_COVID19_259
 ht_unknown5
 ht_unknown4
 ht_COVID19_297
 ht_unknown2
 ht_COVID19_247
 ht_COVID19_248
 ht_COVID19_249


*CONCORDIA meeting about final event. Notes.* 
FORTH will be there . Noted in confluence 
Need to register. 
This will be also used for preparation for the final review. So we use second day for that . 
Not an open event. restriction  FROM specific country will be selection. 

bring your postsers.. only highlights. best pposter/paper awards. 

==================================================================================================================================================
===================================================================================================================================================
==================================================================================================================================================
==================================================================================================================================================
===================================================================================================================================================


ECCO Log
===================================

Project Director= Luigi Rebuffi
Project Coordinator= Roberto Cascella (Technical Supervision Office)
Project Manager = Edouard Dumonceau (Management and Quality Office)
Project Manager = Marie-Hélène Wisecup (Management and Quality Office)

Given the central role of the Project Director, it is essential to ensure that there is a back-up available with sufficient knowledge to support Dr Luigi Rebuffi to fulfil his role, as and when needed, specifically in case of illness or absence. For this role, we propose Dr Roberto Cascella, Head of Sector at ECSO.

*Task leaders* WP leaders
------------------------------
task A - Ulrich Seldeslachts (LSEC)  - [task Members: CEA RHEA, LSEC, Deloitte, ECSO UMU]
task B - Nina Olesen (ECSO)          - [task Members: CEA RHEA ECSO TSI GUF Trust-IT]
task C - Joanna Świątkowska (ECSO)   - [task Members: CEA RHEA CNR TSI GUF ECSO Fraunhofer UMU Trust-IT UniBwM]


Effort in DAYS:
----------------------------
TSI: 
task A 0
task B 150
task C 120 

subtasks leaders
---------------------------------
TASK B
B1, B2 ECSO will drive the execution of both tasks

B3 -   task will be carried out by ECSO 

B4 - This task will be driven by CEA (as representative of SPARTA) for the definition of strategies and frameworks and by TRUST-IT for the use of tools and the     development of a repository (to make consistently available the results and deliverables of the H2020 pilot projects)

B.5 will focus on the “Organisation of Info Days -  ECSO will lead this task

*B.6* will provide “support to education, training and gender balance in cybersecurity by designing a strategy and a set of tasks (education, training, skilling and reskilling, human resources, students and gender issues communities)” to stimulate collaboration within the Community.* 
Task B.6 will be driven by *TUC/TIS* leveraging upon the experience of CONCORDIA and will be performed in cooperation with other Group Members: Goethe University representing CS4E, RHEA representing ECHO, CEA representing SPARTA, and ECSO with its competence derived from WG5 on education, training and cyber ranges.
The subtask on *gender inclusion will be driven by ECSO*

B.7 This task will be driven by ECSO in cooperation with ENISA and the NCCs



Timeline
----------
M1  Jan-23  ... M2  Feb-23  ... M3  Mar-23
M4  Apr-23  ... M5  May-23  ... M6  Jun-23
M7  Jul-23  ... M8  Aug-23 ...  M9  Sep-23
M10 Oct-23  ... M11 Nov-23  ... M12 Dec-23
M13 Jan-24  ... M14 Feb-24  ... M15 Mar-24
M16 Apr-24  ... M17 May-24  ... M18 Jun-24
M19 Jul-24  ... M20 Aug-24  ... M21 Sep-24
M22 Oct-24  ... M23 Nov-24  ... M24 Dec-24

M6 D-B.5: Skills Strategy (Task B.6). Reports.
M12 D-B.5: Skills Strategy (Task B.6). Reports. Update of M6 deliverable.
M18 D-B.5: Skills Strategy (Task B.6). Reports. Update of M12 deliverable.
M24 D-B.5: Skills Strategy (Task B.6). Reports. Update of M18 deliverable.

M1  Dec-22
m2  Jan-23
M3  Feb-23
M4  Mar-23
M5  Apr-23
M6  May-23  M6 D-B.5: Skills Strategy (Task B.6). Reports.

M7  Jun-23
M8  Jul-23
M9  Aug-23
M10 Sep-23
M11 Oct-23
M12 Nov-23 M12 D-B.5: Skills Strategy (Task B.6). Reports. Update of M6 deliverable.

M13 Dec-23
M14 Jan-24
M15 Feb-24
M16 Mar-24
M17 Apr-24
ECCO: M18 May-24 M18 D-B.5: Skills Strategy (Task B.6). Reports. Update of M12 deliverable.

M19 Jun-24
M20 Jul-24
M21 Aug-24
M22 Sep-24
M23 Oct-24
ECCO: M24 Nov-24 M24 D-B.5: Skills Strategy (Task B.6). Reports. Update of M18 deliverable.


connection to CCNs
-------------------------------------------------
As stated in the Governance model (CONCORDIA) [see file folder ECCO: CONCORDIA Governance model for an European Education Ecosystem in Cybersecurity - draft]

"...The pilots representatives came mainly from academia but also from certification organization and business network organisations and were based in different EU countries. Although over the 3 years of collaboration individuals participating in the groups changed, the pilots’ main representatives were unchanged and constituted the core of the focus group. Every start of the year, together with ENISA, the group determined the themes of prime concern for the period, based on an analysis of the individual projects’ priorities. In view of taking this decision on the group priorities, we have attached to each of the topics a maturity of collaboration level using the scale: undefined / limited/ progressing / mature / optimizing. The main topics for collaboration over a year were selected from the categories ‘progressing’ and ‘mature’ while those under the heading ‘optimizing’ were used for communication purposes.

This model will be further exploited within the European Cybersecurity COmmunity ECCO project  commissioned by the ECCC end of the year 2022 to support activities needed to develop, promote, coordinate and organise the work of the Cybersecurity Competence Community at European Level, within the scope and operations of the ECCC and NCC Network. The ECCO project is led by ECSO and brings within the consortium 13 cybersecurity stakeholders from the public and private sector.  Importantly, representatives of all the 4 pilot projects CONCORDIA, SPARTA, ECHO and CyberSec4Europe are part of the consortium, thus ensuring the legacy of the pilots’ outcomes and communities.


============================================================================general info==================================================================================
==========================================================================================================================================================================


As stated in mail 

Task A (market) has been recognized as one of the most challenging part as we need to develop a sustainable and harmonised European  approach for market analysis. The market study should be built in a flexible way with a mix of qualitative and quantitative research also with the support of the NCCs (they should possibly use a common methodology). This is because not all NCC will be operational since the first day and the research will need to be progressive.

* There is a *first working group of ECCO meeting on skills on the 23 January 2023 (2023 is the EU year of Skills)* and the Commission is asking for some ideas to prepare the ground for future work.  At this meeting the Commission will mention the Cybersecurity Academy that is preparing for next year. Nina Olesen will start working on this, possibly in cooperation with the partners envisaged in ECCO dealing with skills *(Task B6)*. The Commission said that for the moment such WG is composed by representative from MS (public admin), not necessarily expert, and our input would be very welcome. Composition will evolve once the NCCs will have defined some representatives on their side (and we will introduce our ECCO experts)

            *Σε αυτό το σημειο αναφέρει για το  (Task B6).
            Ελεγα να ρωτησω αν χρειαζεται κατι απο εμας μιας και το   working group of ECCO meeting on skills on the 23
                 January 2023   ειναι κοντα ...
            ektos ki an anaferete sto Task B.6.4: Gender inclusion44 and growing the workforce through skilling/upskilling/reskilling.
              leei sto G.A. : 
            The subtask on gender inclusion will be driven by ECSO and its “spinoff”, the Women4Cyber -W4C Foundation, in cooperation with other initiatives for participation of women in the cybersecurity sector of the E.C., ENISA, the
            Pilots and at national (e.g., W4C national chapters across Europe) or international level (e.g., ITU).*




============================================================================log===========================================================================================
==========================================================================================================================================================================
*8/2/23*
meeting gia NGs
 

apla auth th stugmh uparxei ena an8rwpodiktuo kai sto concordia kai stous allous pilotes (an kai oi alloi pilotoi exoun paradowsei ta outcomes )poy douleuoun gia to outcome tou concordia kai pws auta 8a paradws8oun sto ecco. 8a to anakoinwsoun o si + gaby sto final event 
emeis ulopoioume sto b6 ena startegy kai epeidh eixe arxisei ne me agxwnei to ti prepei na ginei kai uphrxe mia xalawrhtha tiu sthl ti 8a kanoume kai pote  eprixa ligo thn WP leader kai valame ena anyway kanonisame ena bi-weekly meeting gia to task B . 

NCCs what have the pilots contributed ...will be presented in final event of CONCORDIA . + epishs exoume to CONCORDIA Governance model for a European Education Ecosystem in Cybersecurity  apo Felicia Cutas (htan sto concordia)


*2/2/23* 
[10:42 AM] Antonakaki Despoina (Guest)
Dear Nina, do you think it makes sense to organize a bi-weekly meeting for each subtask in task b? so I should set up a bi-weekly .. meeting in b6? are there already set up any regular meeting in task B (as there are for task a)? or should we wait input from task a? sorry to bother again ..:) 


[10:44 AM] Nina Olesen
Hi Despoina, I will set up a regular meeting for Task B. Just need to find the time...:( Currently travelling. Task B6 is quite big so it would also make sense to have separate meetings for that. But maybe you can launch that after our first Task B meeting. I will send out a calendar invite asap
 like 1

 καθε τριτη 5-5¨30 






*20/1/23* 

Work package number 9 WP3 Lead beneficiary 10 13 - TUDA of CONCORDIA :

Objectives: Build an open-source Threat Intelligence platform for Europe for sharing Cybersecurity information across academic,
industrial and other organizations, involving especially the European CERT community. The development will include
sector-specic threat intelligence modules
*Pilot a DDoS Clearing house with European industry for Europe to protect the European data traffic flows
*Develop the CONCORDIA Cybersecurity ecosystem with virtual labs, services and training activities. Develop
mechanisms for stakeholders engagement and value over technologies, solutions and services
*Create a sustainable CONCORDIA European Education Ecosystem for Cybersecurity for outreach to students,
industry, professionals and other stakeholder groups
*Develop mechanisms for community building, support and incentive models*
D3.4 : Final report on community building and sustainability [48]
Final report on community building and sustainability


Sotiris: οκ αν δεν χρειαζεται, δεν μπαινεις (task A meetings)



=====================================================================Meeting minutes======================================================================================
==========================================================================================================================================================================



*ECCO TASK B meeting 30/1/2023*
Also here: 
https://ecsorg.sharepoint.com/:w:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B96F4A82F-B165-44BB-A0C3-C252757E6A08%7D&file=Minutes_of_Task%20A%2C%20B%2C%20C_Meetings.ECCO%20-%20European%20Cybersecurity%20Community.30-31-01-2023.v0_0%20-%20MH%20Input.docx&action=default&mobileredirect=true
--------------------------------------------------------------------------------------

    Notes before meeting. 

    Which is M1 ? January or December so we set travelling and deliverables.

    We lead B.6 and coordinate all partners [ Participants: GUF, RHEA, CEA, ECSO:
        Goethe University representing CS4E, 
        RHEA representing ECHO, 
        CEA representing SPARTA, 
        and ECSO with its competence derived from WG5 on education, training and ranges. 

        A collaboration is also envisaged with the NCCs and ENISA, together with the list of pools of external experts of ECCO from industry, educational institutions and public bodies. ECCO will be able to directly leverage the work of the Women4Cyber Foundation.


    activities towards our goals 
    do we set up meeting? how often ? are they needed?

        Task B.6.1: Education thanks to the mapping of the academic and professional cybersecurity educational offer in the EU
        Task B.6.2: Education via the analysis of the main curricula and courses available, as well as of existing educational standards across the EU-27 at bachelor level and identification of gaps and new educational requirements. It is foreseen to involve external expert.
        Task B.6.3: Training and support to standardisation of curricula for professional training and establishment of European cybersecurity professional certification schemes. It is foreseen to involve external expert.
        Task B.6.4: Gender inclusion and growing the workforce through skilling/upskilling/reskilling
        Task B.6 will be driven by TUC/TIS leveraging upon the experience of CONCORDIA and will be performed in cooperation with other Group Members: Goethe University representing CS4E, RHEA representing ECHO, CEA representing SPARTA, and ECSO with its competence derived from WG5 on education, training and ranges. A collaboration is also envisaged with the NCCs and ENISA, together with the list of pools of external experts of ECCO from industry, educational institutions and public bodies. ECCO will be able to directly leverage the work of the Women4Cyber Foundation.

    ----------------------------------------
Meeting minutes:

relevant invitations are being sent . 

COsmina is comming . 
Barbato Franscesco
+ Cosmina  (CNET )

one by one the tasks 
time line 
and then information for milestones . 

4 matchmaking events 
when? 
info day 

advertising campaigns we need to make. 

task a : comunity buidling . no input yet. 

practical aspects . 
[nina oelsen] Milda is responsible for matchmaking 
[barbato ]do something for startups, plan today what to do 

start with matchmaking events : 

   [nina]. we discussed roadmap. at least 4 matchmaking events . plan them strategically . 
   *who needs to attend???*
    maybe co-located . what is the timeline? 

    [milda] what are the needs from the commission side . 
    [barbado] dont mix ecso ecco the branding . create boundaries. 
    [milda] we have partners identifies. happy to organize under ECCO brand . 
    [barbato] service contract . list of tasks that need to be executed. lets create today a list of todos and fill in later. 
    [milda] events ...2 different types of events . 
    [nina ]  location ? maybe strategically take advantage of ncc or multiple nccs to be there ..european brand though not national . 
            some potential dates or events ...
            no details now

    [barbato]        digital innovation hubs. exploit some of those events ?
    [milda] poland ..organzie back to bck event to involve slovakia , romania + burlaria include them? mid June . 15/16 june governing board also 
    digital assembly  in stockholm ? June...


*communication meeting tomorrow??* 
    
    fic is very soon . ecso is in cyber inventment day 
    how do you charge to teh potential customers?

    principal : organize events in different geographical to reach more people 

    [cosmina] maybe southern eastern europe . 

    how do you select the investors ?   
    [milda] registration forms. no specific requiremnt . 

    [barbato] 4-6 events . timeline? 


    MIA WRA GIA TA EVENTS . kanoun explote ta date kai ta places ..alla den katelhxan kapou 


    scout interference with events . wait to hear something more concrete . either poland 15,16 or compenhagen 9 so people can join the conference or both ? too close?
    Catovice 

that's all for matchmakng events 

info day : 6 --> 3 per year ? 

multiply events . people do not travel so often.

----
my thoughts: B.6 
we have in hand the CONCORDIA Governance model for a European Education Ecosystem in Cybersecurity
we work with partners towards our goal 
maybe set up a wekly or as often it is neededn 
 activities towards our goals 
    do we set up meeting? how often ? are they needed?

    As part of the project, and in the context of the CONCORDIA Cybersecurity Roadmap for Europe , a specific education related chapter was developed. The CONCORDIA Education & Skills roadmap  is looking into the challenges related specifically to the cybersecurity professionals and their needs for up-skilling or re-skilling. It complements the efforts of the other pilot projects (SPARTA and ECHO) which are looking into the cybersecurity education at university level. 
---

ECCO WP3 Nina EGCONNECT : blouillaerd mollina, Anne-Sophie Diehl
Policy Officer, European Commission, Angeliki Alina Moraiti

mainnly brainstormig. see notebook.  agenda hmera 15 ferbuariou !SELIDA!


ECCO - WP1 follow-up 30/1/23
--------------------------------------------------------

folow up with commission . get a feeling for the activiteis in task 1 /A 
level of expectations 

tehy will have a dicussion tomorrwo with EU + ENISA to sdicuss task A .operational mode 

[roberto] discussion about taxonommy . make a planning. ofload to JRC / ENISA . work in collaborative way . 
JRC/ ENISA are not aligned. 


WE have the governance model for education for concordia .
CONCORDIA Governance model for a European Education Ecosystem in Cybersecurity

--> support to education, training and gender balance in cybersecurity by designing a strategy and a set of tasks for the education, training, skilling and reskilling, human resources, students and gender issues communities, to stimulate collaboration within the Community.

---
parking lot: 
set up expectations with EU, and limit to what we can do in this limited time. MANAGE EXPECTATIONS> the client is EU , 
retroplanning towards first deliverable ..

kick off meeting 25/1/2023
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Round of introductions.
EU commision has been waiting long for this meeting. 
Date . 1st session governance issues. 
large consortium, we cannot al l problem now..be sure relevant issues, algin agenda, plalnning for year . 
from tommorow more details per task. 

Luigi: started from ppp, now next level. 
What has to be done ...serioulsy ..priorities (scope of the project).


EU. strategic project, 
its a process to set up ECCs, community we have to build/press.

    *EU.*
    1)set up a coordination office 
    2)They will set up a steering commitee


    several tasks 

    dedicate Project Officer(day to day communication)
    keep all task leaders coordination in loop 


    Miguel 
    fransence barbaro 
    cosmina 
    Alina (aggeliki)
    JRC + ENISA 



    B6. Alina , James JRC 

    6 progress meeting . every three months (meeting)

    bi kweekly meting , 

    4 management and activieis reports (M6, M12, M18, M24)
    deliverable list (EC approval of reposrt and deliverables within 20 days)
     strict with deadline with reports and deliverables. 

     M12 50% and M24 teh rest , 



   Roberto : starting date of project ? 
    
    EU M24 is decemver !!M1 can be January but M24  last  month has to be December.

  EU important thinks : 
        SOS-->   support the secretary of the Governing Board (middle of March first meeting.) Report first months of activiteis .  Physically meeting in trhee months. Warshaw . 
         
        engagement rules: 

        NCC Event Warshaw march 2023 --> *15, 16 17 March WARSHAW*
        suport to working groups 


        from tomorrow we strat bilateral meeting to solve specific issues for each task. 


        24/1/2023 minute from meeting about kickoff preparation for task B. 
        Paola has communication with NCCss        

        There are activities they tend to overlap. We want to avoid overlapping and build . talk with colleagues in EU ENISA JRC. 




        ECCo is a service provider not a grant!! We are purchasing services! evolution of landsacpe. list of task we expects services to be delivererd to comission . 
        ECCO hat ! 

        When in trouble ask EU !! 
        Laising with stakeholders is a core task of the contract . decisions especially 


        decisions should be taken with EU not with collegeus. 

Roberto 

        page 193 with task leaders . in the begining more frequenst meetings . 

        discuss today maybe the communcation plan . 
        match what EU expects, and push it through our internal channels. Maybe a confluence (platform) to share content?
        Deliverables should be sent officially be email . 

        set up a clandar of events. (at least for 1st six months).


        info days. 

next ecco welcome 
        events plan for discussion 

        2 february cyber investor days barcelona 2/2nd of  task B activities

        7, 8 march , ECSO startup award bilbao march ECSO bilbao 

        may Copenhagen 
        9 may 
        10 , 11 May brussels 

        key national events 
        16/17 /2 munich germany, 

        5.7 arpli lille france 
        3,5 May Bari Italy 

        16, 17/2 february    Munich
        5,7 April Lille France
        3, 5, May Bari Italy  

            https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B61F0FD61-C225-4280-B068-DC45E0C641AE%7D&file=CNCT0033_KoM_06_Communication.pptx&action=edit&mobileredirect=true    

(EU) what to do with these events (EU)
    maybe there is feedback. 

    how do we struct? 

    @FIC not sure ..need confirmatoin (Paula)

    will create large spreadshwet as calendar of the year. 




European Commision people. 

    * Cosmina from EU for task B 
    * Peter Diry for C tasks 
    Alina moraiti + Jame galan, Paola for communictaion communication coordinator + women 4 cyber 

    Steering comitee willbe set up . 


roberto presentation slides ...
        https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BC863B8E4-73E6-456E-89CE-2CC0EFDBF97F%7D&file=CNCT0033_KoM_01_Introduction%26Overview.pptx&action=edit&mobileredirect=true
    

overview : 
        https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BC863B8E4-73E6-456E-89CE-2CC0EFDBF97F%7D&file=CNCT0033_KoM_01_Introduction%26Overview.pptx&action=edit&mobileredirect=true


TASK A. 
        https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B1E4925A4-D28A-472C-A161-23935230D96D%7D&file=CNCT0033_KoM_02_Task_A.pptx&action=edit&mobileredirect=true

        
        question to EC what do you expect?

            fill gaps in defined procedures and material (from ENISA etc. )
            ENISA: commmited to make effective all this contribution. what research need to prioritize. very committed. 
                    they need a consolidated view ..and see contribute to the strategy ..where to invest ...    
                    there are different need that need to be fulfilled. find theses and act accordingly. 

                    (Igor) it is not only the data you get from this feedback it is how you interpret the data.     
                     are e.g these gaps have an impact . is it a real value to the EU/ ECCs ? 

                    roberto : Taxonomy,     

                    Pascal: curation of data?standards ? expectations? 
TASK B . 

        https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B80C0DB40-A2D4-46F3-88B5-C5D2A57C0E30%7D&file=CNCT0033_KoM_03_Task_B.pptx&action=edit&mobileredirect=true

        Luigi comment on Nina's slides. 
            there are alot of communities and role communities, very different . Very different from one to the other role communities. 
            there is not ONE communitiy 


        EC:  Sybersecurity filed is large. So we should have thematic / targeted events. 
        A very large event should have streams.     

        Pascal: benefit from all events . start up and SMEs are VERY different ., cannot mix , cannot generate interest. 
        Luigi : we are following the definition of EU commission .  maybe adapt 250 people SMEs...


        EU: regarding academy timing is going to be advance. will be n touch still need to define this will goi. 
        good we have expertise. Actions proposed by comission . for sure cc + ENISA what twill be proposed. 

        give feedback on what we KNOW aki then tehy communicat the project will be affected . 

        we know the task , and we fine tune . 

        Communication Plan for discussion


Communcation Robert presents :

        https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B61F0FD61-C225-4280-B068-DC45E0C641AE%7D&file=CNCT0033_KoM_06_Communication.pptx&action=edit&mobileredirect=true&cid=cd75e456-6ba6-4762-bb0f-98106aebbf4b

        Paola : 
        Robert we need to discuss how this could be build. 
        Nick Ferg: website has just the description of tasks. 


        (EU) we need to discuss architecture+ website of competence centre . website : Document of Competence Center  + jobs ..staff 
        This will be a centre point of dissemination activities. 

        People from outside need to know what we are doing . Newsletter (need to discuss). come up to the content ..socila media ..

        cartography of communication strategy . there should be a technical meeting for the website. 
        Luigi. if is a indepentent website from EU: cons: uniformity
        pros: visibility

        roberto : atlas should be linked ,,different kind of aspects ..we need online tools/maybe linkedIn for EU, or create somthing completely different ?

        paola : competence center entry point 

        use google team space ...

        follow up will take place on these issues. 


EU comment *use ECCO as your hut for communication*

presentation of C : 
https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B9083898B-92E7-4831-941E-EE7B90756A6E%7D&file=CNCT0033_KoM_04_Task_C.pptx&action=edit&mobileredirect=true

https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7B9083898B-92E7-4831-941E-EE7B90756A6E%7D&file=CNCT0033_KoM_04_Task_C.pptx&action=edit&mobileredirect=true

        
        EU. everything look ok according to what was proposed. 
        expose to the NCCs the projects. middle of February , they had already several meeting. they had meeting about how to organize, but without resources. experimental. 

        there might be a mix of structural and on demand . aggregate demand!
        exited about funding , strategy agenda...maybe come up with a couple of ideas and ...

        buidling trust ? RISK ..

        we are here to stimulate / accelerate the process/ we do not do tasks for them . . 


project management 
    https://ecsorg.sharepoint.com/:p:/r/sites/ECCOProject/_layouts/15/Doc.aspx?sourcedoc=%7BE083FE7D-796C-4B42-8AB5-A08DD7A2991C%7D&file=CNCT0033_KoM_05_PM%26QM.pptx&action=edit&mobileredirect=true

    iterative + collaborative approach . 


    *SEE slide 16: Next steps for task B* 


other slides (offline?) 
task A: interaction with stakeholders

task B : interaction with stakeholders

ECC  skills
NCC  skills
ENISA  den prolava ...sta slides!
JRC EU ?

task C : interaction with stakeholders

EU: 
*what is in the scope of this project . SC is huge . 
focus getting together comunities. connecting people.  we want to mobile, stimulate skills .* 

----------------------parking lot: 

why teams ...find somthng else ....
they will share the minutes ...








Task B before kick off meeting 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------------------
* Nina invites to meeting along with slides for the kickoff (on Tuesday 12:30, but I will be travelling. ) She references in slide for B6 that on 23/1/ there was a first working group of ECC skills group. 

I managed to join the meeting : 

the draftv slisde have been sent 

the idea here is with task b to go through overveiw and focus on matchmaking events + skills and awereness, 

ECCs skills meeting (50 people on call) yesterday . 

EU comission has plan of the implementation of the academy . soon we will have new . idea : platform online. 
EU try to push this earlier . 

B.4 CEA leader 
B.6 TUC/ TSI . leading . 

*What actually has to been done ?* 
Is month one DECEMBER ? question for tommorrow ....

About the repository . There is already (B4) one. should we reuse? We have a db of outcome of the project..we need to focus to R & D , need to plan carefully to not to overcomeete to services and platforms , but to work on the strategy that we need to define here for the results . 

it is for discussion for the consortium ,... maybe focus on the strategy . We cannot think to solve ALL  the issues. Maybe mantion tommorrow , how at best to use what is already use and how to use it to build the strategy . 

B4 should simplify resuse for market observatory and then point out possible examples . this is for task A and we need to focus in task B in the strategy.  

roadmap for info days . link teh planning of info days. timeline of publication of calls. how EU comission be involved in the organization of these events.  

B6 is for building up the stategy . 

B7. awereness aspects 

very clear slides. 








task A meeting ECCO  18/1/2023
---------------------------------------------------------------------------------------------------------------------------------------------------------------------------

organizer of meeting LSEC (leader of task A)

1) Some have started working. 
2) It is an expectation meeting. 
3) To know everybody here. (background - activities). 
4) We had a round table to introduce each other. 
5) what you plan to do , specific tasks . who is missing ? 
6) *LSEC*: They introduced themselves. CS industry, help on market innovation,  support end users , market analysis, analysis in terms of different partners, form an ecosystem.

    a)Which are the major steps? 
    b) what to discuss on kick off meeting. 
    c) what to expect?
    d) ..but also stick to what we have offered.

    Task A will listen to the clients. 
    LSEC worked with the teams in SOPRA focused on WPA. some ideas to discuss. 
    e) LSEC better to reach them mobile. too many emails. 

    *Richard Chrisnal.* senior member in ECSO, worked in research projects. background with security in business for  set up SMEs, cluster in ENgland, advisory board, technical background, commercial fellow @ Cambridge. currently project management. 
    messsage: what people write is not usually what they have in mind. They usually need to expand. He came in this point to advise. 

    *Nil Adams* his principal role in ECCO: analyst of the team. background, mathematician, research in defence CS
7) TRUST -IT: 
*Nick Ferguson* Italy based, coordinator , @ cyberwatching. 
    visualization, bringing together , identify ho to visualize results in ECCO . . will work on interface for activities in task A. 
*Alexandro 1..*chiegf technology officer, harmonize data, in the platform : links + join data + visualize, 
*Alexandro 2, rafael...* define uses of platform who? how? will discuss with commission next week. try to gather together people who have and ho DONT have see the platform in order to build it. 
have started on website. maybe ready next week. 
partners logo


also in team Joane Ahern, Julie,.

8) ECSO Luigi: 
secretary general ECSO
We need to understand  the market. commission wants to understand stakeholders, how to invest? what to invest in?
what need to be done?
define the structure, tell the market story , we need a structure breakdown. Also in task B . How to structure different actors. 
Actually with SIMA gave his contribution with NUMBERS. 
You have to give the correct/acceptable  numbers! not to low --> shareholders think market is not interested, also not too high. 
We have to fit the reality. can be justified : we have to find the justification + cooperation!--> update evolution of the market. 

ULRICH comment on this: tried to build, gave market analysis, commission needs to keep the ball rolling. 
American view of European market ? it should start form the need of the countries. top -down approach .  

8)Roberto Cascella@ ECSO, project coordination . Will be part of task A , coordination , build taxonomy. 
all activities Luigi references . project results what has to be done. 
TASK A . who ? 
francesco Bordone > from last March in ecso . relation with NCCs

9) Deloitte Susanna , Jake Stephan + Barbara Julio, 
update data internal data design + design survey [scope chime study ?]
reports what is CS, provide questions, no signed contract yet!
Susanna : legal (lawyer) work on strategy and support to Jake . in review , more strategic perspective. how to help NCCs to DIG info!identify stakeholders. 
Vitoria Durazzano: supporting Jake, coordination 


10) SOPRA  Davide Grison 
Monitoring deliverables , QA Support Marion 

11) Gaby + Ivana 



------------------------------
internal kick off meeting 17/1/2023
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

1) We went through the agenda for the kick off meeting /practicalities/strategic plan for next months
2) No presentation for TUC 
3) quick introductory presentation for tasks (ABC)
4) QUestion: ULRICH commission/client should have enough time. 
TASK A we need a lot of input. need more time. 
5) is there max #people? No
6) ENISA key for task A, contractor for that.
7) they will create team channels/mailing list /slide template / ecco logo/ share point space 
8) Nick : they have created a landing page for the website and will ask if commission wants static or basic website . Maybe finished untill kick off meeting, 
9) Dumonceau : 
            tomorrow task A meeting. 
            WISECUP will also attend meeting . 

10) three months task B  - there are matchmaking events within first three months 
11) task leaders . what are the 4/5 action point for next months . 
12) weekly touchpoint sight structure. checkpoint, address links
13) evaluator report
14) Ulrich we need feedback from clients . nothing in contract. when will be delivered? 
    potential changes! We have to have this under control!
    client validation
15) periodicity. What are we delivering, QA. timeline quality planning. key deliverables BUT depending on ENISA + working groups
    So what happens in case of delay? How to handle ?  
16) Still waiting for internal agreement . Final contract will be sent when ready. 
17) Luigi. The kick-off meeting is to see with the commission , ask questions. a lot of interpretation is going so we need to ask question, Maybe they wont be answered ...Questions have to be build up. and forward to NCCs
We need a common understanding. How do we satisfy the customers. key questions at end of slides. OR ask directly . 
18) logistical question. Delloite. task A. 
How are we going to work from a logistic point of view? provide input. weekly meeting? brain storm? 




-------------------------------
===============================================================================TUC========================================================================================
==========================================================================================================================================================================




TUC: 

Υγηται h ECSO   European Cyber Security Organisation (ECSO) se sunergasia me olous tous pilotes 

Η ECCO αποτελείται kapoies omades  στον τομέα της κυβερνοασφάλειας:
ECSO, ο Ευρωπαϊκός Οργανισμός Κυβερνοασφάλειας (ο επικεφαλής της ομάδας)
οι κύριοι συντονιστές των τεσσάρων πιλοτικών έργων για τα Κέντρα Ικανοτήτων
UniBwM και TIS (TSI?) για το CONCORDIA.
RHEA για ECHO.
UMU και Goethe Uni για το CYBERSEC4EUROPE.
CEA, CNR και Fraunhofer για τη SPARTA).
Υποστηρίζεται από άλλους συνεργάτες στην ECCO, ο καθένας ειδικός στον τομέα του:
Trust- IT, συντονιστής του έργου Cyberwatching.eu και ειδικός στις πλατφόρμες Ε&Κ της ΕΕ και στη διάδοση.
LSEC, ειδικός στην ανάλυση αγοράς κυβερνοασφάλειας
Deloitte, ειδικός στη μεθοδολογία της αγοράς. και Sopra Steria, ειδική στη διαχείριση έργων και τον ποιοτικό έλεγχο.

ECCO - «Η Ευρωπαϊκή Κοινότητα Κυβερνοασφάλειας» kοινότητα για την εκπαίδευση  κατάρτιση και gender balance 


Υποστήριξη για την εργασία Γ.2.5: Ομάδα Εργασίας για τους τελικούς χρήστες, τους καταναλωτές / οργανώσεις της κοινωνίας των πολιτών, τα ανθρώπινα δικαιώματα και την εγκληματολογία


-----------------------

We will start the analysis of the market in Task A.

selida 4 



Initial EMAIl:

On 21/12/22 1:38 PM, Felicia Cutas wrote:
> Dear Gabi and Sotiris,
>
> I understood that you will be part of the ECCO project. Congrats!!
>
> I am now working on the *Concordia governance model for the education ecosystem*  and I would like to introduce some references to the ECCO.
>
*Would it be possible to share some details on this project? I am mainly interested in the Education and Skills angle.*
>
> Thanks,


-----------------------------------------------------

 Dear all
>
> On 20 December 2022, Luigi Rebuffi and representatives from the ECSO
> Secretariat had an informal meeting with the European Commission (on
> their request) for a first introductory meeting.
>
> On the European Commission side there were Miguel Gonzales Sancho (head
> of unit of DG CNECT H.1. and ECCC Director ad interim) and Francesco
> Barbato (ECCO project officer).
>
> Key messages from the European Commission:
>
>    * This is a procurement contract, it is more rigid than a research      contract (less paperwork / reports, more concrete actions: services
>      should be provided, not necessarily papers). *The Commission is interested in real activities not so much in reporting (that will be needed but only in short form)*
>    * ECCO is about providing services to the Commission, MS and the>      Community. ECSO has a different role even if, as the other ECCO
>      partners, will take benefit from ECCO.
>    * This contract can be a good multiplier for existing activities.
>    * It is important to coordinate with other institutions (ENISA, EIB…)>      but the Commission will always be in a leading role.
>    * The activities of ECCO will be negotiated with the Governing Board
>      of the ECCC (e.g. we have proposed certain working groups, we will>      have these WGs approved by the GB of the ECCC – apparently the
>      Commission will support the views of our proposal).
>    *ECCO will need to prepare the input for the WGs and the WGs (+ the  Governing Board of the ECCC) will decide on how to proceed.
>    * On 21 December, there will be an informal meeting with the NCCs and>      the Commission will give them an initial explanation about ECCO.
>    * *The ECCO kick-off meeting will be on 25 January 2023 in Brussels>      (the date is fixed)*. This will be an operational meeting, in a
>      hybrid form. Only key people should participate in person and the>      rest can assist remotely (to keep it efficient). ECSO, as leader of
>      ECCO, will propose the agenda of the kick-off meeting. We will come>      back on this as soon as the Commission will give us more details.
>      Consider that the meeting will take the full day. *Please let us know at the earliest if you plan to come physically or you‘ll be in remote connection*
> All practical matters (administration, project management, functional
> mailbox, data storage…) will be dealt with during the kick-off meeting.
> Of course, also content matters will be tackled (i.e. interpretation of
> the work to do, as it is been said that during the preparation of the
> proposal not every objective or approach was clear – the Commission
> admitted that also on the public side not all is necessarily clear and
> the help of ECCO partners will be needed).
>
>    * Task A (market) has been recognized as one of the most challenging
>      part as we need to develop a sustainable and harmonised European
>      approach for market analysis. The market study should be built in a
>      flexible way with a mix of qualitative and quantitative research
>      also with the support of the NCCs (they should possibly use a common
>      methodology). This is because not all NCC will be operational since
>      the first day and the research will need to be progressive.
>    * There is a *first working group of ECCO meeting on skills on the 23
>      January 2023 (2023 is the EU year of Skills)* and the Commission is
>      asking for some ideas to prepare the ground for future work.  At
>      this meeting the Commission will mention the Cybersecurity Academy
>      that is preparing for next year. Nina Olesen will start working on
>      this, possibly in cooperation with the partners envisaged in ECCO
>      dealing with skills (Task B6). The Commission said that for the
>      moment such WG is composed by representative from MS (public admin),
>      not necessarily expert, and our input would be very welcome.
>      Composition will evolve once the NCCs will have defined some
>      representatives on their side (and we will introduce our ECCO experts)
>    * The next meetings of the Governing Board of the ECCC will be on:
>        o 16-17 March 2023 (15 March there will be a meeting with the
>          NCCs) in Warsaw.
>        o 8-9 June in Bratislava
>        o 12-13 October in Athens
>
> We (ECCO) are requested to present in these occasions results to the
> ECCC (results of actions that will also be developed in cooperation with
> the NCCs, hence they will not be “surprised”), also Task C.4 on ECSO. We
> do not know who the ECCC will request to participate at these meetings
> (apart from ECSO as leader of ECCO). Good question for the kick off (as
> many other questions you can prepare for January 25^th )!
>
>    * Other meetings of NCCs will take place during the year and our
>      contact with NCC will be requested to attend (task C.5 on ECSO).
>
>    * When WGs will be defined by the ECCC there will be other meetings
>      with participation of ECCO members. It could be suitable to have as
>      soon as possible an ECCO meeting on WGs to better develop our views
>      on WGs and make recommendations to the ECCC, in order to be
>      consistent with our proposal.
> In ECSO we will start working in the coming days to be ready to start
> beginning of January. We’ll let you know how we can get organised to
> start the different tasks, even before the formal kick off (note that
> the project has officially started on December 19^th and the time for
> deliverables are already running: again, this is not a research project!).
>
> I wish you all the best for Christmas and end of year with your family
> and friends.
>
> We’ll have the opportunity to cheers the New Year in the coming mails
> (and meetings 😉)
>
> Regards
>
> Luigi
>
> Ing. LUIGI REBUFFI, PhD
>
> SECRETARY GENERAL
>
> _luigi.rebuffi@ecs-org.eu <mailto:luigi.rebuffi@ecs-org.eu>___
>
> www.ecs-org.eu <http://www.ecs-org.eu/>
>
> Mobile (Belgium) : +32 479 39 02 61
>
> --



Abbreviations: 

NCC National Cybersecurity Competence Center
European Cybersecurity Centre of Excellence (ECCE)RHEA Group and IDELUX are building a new European Cybersecurity Centre of Excellence at Transinne, Belgium.
Unique in Europe,
> ---

-===========================================================
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

*DELIVERABLEs* 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------



Meetings Reports Month
Kick-off Meeting Kick-off Presentation M1
Progress Meeting I Project Progress Report I M3
Management/Activity Meeting I Management/Activity Report I M6
Progress Meeting II Project Progress Report II M6
Management/Activity Meeting II Management/Activity Report II M12
Progress Meeting III Project Progress Report III M12
Progress Meeting IV Project Progress Report IV M15
Management/Activity Meeting III Management/Activity Report III M18
Progress Meeting V Project Progress Report V M18
Management/Activity Meeting IV Management/Activity Report III M24
Progress Meeting VI (Closing Meeting) Project Progress Report VI (Projectend
Report)
M24


*Task B.6. Community for Education, training and gender balance (M1-M24) [Leader: TIS/TUC,*
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------


 Participants: GUF, RHEA, CEA, ECSO)*

    In Task B.6 we will provide support to education, training and gender balance in cybersecurity by designing a strategy and a set of tasks for the education, training, skilling and reskilling, human resources, students and gender issues communities, to stimulate collaboration within the Community.


    This task will allow to design a strategy and a set of tasks consistent with the following list:
    • Task B.6.1: Education thanks to the mapping of the academic and professional cybersecurity educational offer in the EU

    • Task B.6.2: Education via the analysis of the main curricula and courses available, as well as of existing educational standards across the EU-27 at bachelor level and identification of gaps and new educational requirements. It is foreseen to involve external expert.

    • Task B.6.3: Training and support to standardisation of curricula for professional training and establishment of European cybersecurity professional certification schemes. It is foreseen to involve external expert.

    • Task B.6.4: Gender inclusion and growing the workforce through skilling/upskilling/reskilling 
    
    • Task B.6 will be driven by TUC/TIS leveraging upon the experience of CONCORDIA and will be performed in cooperation with other Group Members: Goethe University representing CS4E, RHEA representing ECHO, CEA representing SPARTA, and ECSO with its competence derived from WG5 on education, training and ranges. A
    collaboration is also envisaged with the NCCs and ENISA, together with the list of pools of external experts of ECCO from industry, educational institutions and public bodies. ECCO will be able to directly leverage the work of the Women4Cyber Foundation.


    *Deliverables / Outputs*
    M6  D-B.5: Skills Strategy (Task B.6). Reports.
    M12 D-B.5: Skills Strategy (Task B.6). Reports. Update of M6 deliverable.
    M18 D-B.5: Skills Strategy (Task B.6). Reports. Update of M12 deliverable.
    M24 D-B.5: Skills Strategy (Task B.6). Reports. Update of M18 deliverable.


*Task C.1. Knowledge sharing and interactions between NCCs at European level (M1-M24) [Leader: ECSO, Participants: CEA, CNR, FRAUNHOFER, TIS/TUC, RHEA, UniBwM, GUF)*
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------

    
    Task C.1 embraces all the following tasks of Task C and will serve as support to the NCCs and the ECCC and their
    deliverables providing an overall view and a good level of coordination, linking the different tasks. It will facilitate
    the knowledge sharing and interactions between NCCs at European level, in support of the NCCs and ECCC
    operations, through the structured organization of thematic working groups, workshops and events.
    In this task we propose the creation of a body to streamline and facilitate the interaction with the NCCs
    representatives (or any other delegated representative from NCCs), the chairs of the Working Groups, and the
    Strategic Advisory Group of the ECCC to include the recommendations and suggestions from the public side in the
    review of the Working Groups activities.
    Deliverables / Outputs
    See Task C.2


*Task C.2. Cybersecurity Community working groups (M1-M24) [Leader: ECSO (T C.2.2; T.C.2.3, T.C.2.4)*
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------


    In Task C.2 we will create a number of Working Groups (hereafter the proposed list) and develop their plan and
    strategy. This proposal leverages the years of experience of ECSO and the Pilots for dialogue and cooperation
    among the main communities.
    List of proposed Working Groups
    7) R&I Road-mapping
    8) Critical vertical domains and Trusted Supply Chains
    9) Synergies between the civilian and defence / space spheres
    10) Start-ups/Scaleups - SMEs support
    11) End Users, Consumers’ / Civil society organisations, Human rights and Forensics
    12) Skills and Gender
    The WGs will be animated / coordinated by different Members having had a similar task in the Pilots or in ECSO.
    Other Working Groups or Task Forces (temporary gatherings of experts on specific issues) may be created during
    the project according to needs and requests from the ECCC and NCCs.
    There will be a need for a certain flexibility in the governance and in the approach of the WGs proposed by the
    Strategy Advisory Group and the WGs approved by the Governing Board are substantially different from those
    proposed in ECCO and the envisaged work sharing and operational rules.
    Workshops and events to facilitate knowledge sharing and interactions between NCCs (and these working groups)
    mentioned in the text of the tender will also be part of the animation of the different WGs, linking these
    communities with the NCCs.



    Deliverables / Outputs
    M3 D-C.1.1: Organization and animation of the Cybersecurity Community, Strategy and Planning (Tasks C.1,
    C.2).
    M6 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports
    M9 D-C.1.2: Organization and
    M12 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports.
    Update of M9 deliverable.
    M15 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports.
    Update of M12 deliverable.
    M18 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports.
    Update of M15 deliverable.
    M21 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports.
    Update of M21 deliverable.
    M24 D-C.1.2: Organization and animation of the Cybersecurity Community (Tasks C.1, C.2). Activity reports.
    Update of M24 deliverable.

======================================================================================================================================
======================================================================================================================================
MISC Notes

What is Atlas :

https://cybersecurity-atlas.ec.europa.eu/cybersecurity-taxonomy
Cybersecurity Taxonomy
The European Cybersecurity Taxonomy

The taxonomy is based on a comprehensive set of standards, regulations and best practices, and has been validated by different EU cybersecurity stakeholders, such as the European Cyber Security Organization (ECSO). It was further enhanced based on feedback provided by the four cybersecurity research and competence network pilot projects (CONCORDIA, ECHO, SPARTA and CyberSec4Europe), which embrace over 160 partners including companies, SMEs, universities and research institutes. 

A similar knowledgebase, if integrated with other existing databases (e.g., patents, European projects, research production, scientific profiles), will be also extremely relevant in the assessment of the R&D cybersecurity position of Europe. This would provide useful information to identify weaknesses and where and how to act to reach a homogeneous development of the cybersecurity domain.

The cybersecurity taxonomy is based on four dimensions, namely domains, sectors, technologies, use cases (see picture below). More information about the taxonomy and the related EU Vocabulary can be found at the following link:

JRC CYBERSECURITY TAXONOMY 


username/password: despoina@ics, !ecas

concordia roadmap: 

https://concordia.monitorboard.nl/roadmap/details/research%20and%20innovation



Cybersecurity ATLAS together with the Women4Cyber initiative from the European Cybersecurity Organisation (ECSO) have committed last year to create a registry of European women in cybersecurity.

Women4Cyber Registry was created to identify and build the community of women professionals in the field of cybersecurity.


 
====================================concodia relevant results ========================================================================
======================================================================================================================================

https://www.concordia-h2020.eu/concordia-service-community-pact/





==================================================================================================================================================
===================================================================================================================================================

=================================================================================================================================================
===================================================================================================================================================
==================================================================================================================================================
===================================================================================================================================================
Trith 13/12/2022


NEW topic for research: 

@gia thn epomenh sunanthsh: suspension of non suspendable accounts 
ena paradeigma 
to afhnw edw isws 8a mporouse na vrei paromoia ...
... he and similar scientists remain suspended!...
exoun kai hashtag : https://twitter.com/search?q=%23ReinstateScientists


mporoume na tous vroume apo to #ReinstateScientists



alla mporoume apla na arxisoume na katevazoume ola ta @elonmusk ..

Please reinstate the twitter accounts of:

1- Dr. Peter McCullough
2- Dr. Mary Talley Bowden &
3- Dr. Robert Malone

#BringBackPeterMcCullough
#DrMcCulloughSavedLives
#ThankYouDrMcCullough

#BringBackPeterMcCullough


-------------------

concordia accepting file in https://lists.lrz.de/mailman/admindb/concordia-t6.2
WG: [EXT] concordia-t6.2 post from walter-erhard.thomann@ruag.ch requires approval


user : concordia-t6.2
ConcT6_2_1611

====================
22/11/2022

D5.5

Who is conrtibuting ...?
 mail christou: "wp5-taskleaders@concordia-h2020.eu" <wp5-taskleaders@concordia-h2020.eu>

 	Apo to word (comments): 

 	apo mail me MArtin :
 		Partly yes -  I will add the numbers that are relevant to dissemination and communications.
   vTable 1: Performance of CONCORDIA against specific KPIs 8a to ananewsei autos 


============

Ayto einai to teleytaio email sxetika me to poios 8a paradwsei kai pote.


https://mail.google.com/mail/u/0/?zx=9s3x4c9j5bj#search/cpapachr%40ics.forth.gr/FMfcgzGqQSMgRzKCmTMFHZtWxtGKQCXx?compose=lqrsmGgrzlbwxdRLHHFxvtPLcRnXDjvzwKgxPdbBnPDBKnmlDTXhTJHsLJcWxtxqmQxCFTVFDWGjfPLsz

*2 review processes*: 
pws epilegoun ta nea reveiw teams gia to M51?
Prepei na doume poioi  partners exoun meinei sto extension.(8a apanthsoun sto mail an 8a kanoun submit the  deliverable on M48 or M51)
Me vash to excel tou Xrhstou me tis fores pou exei kanei o ka8enas review 8a epilexoune ta reveiw teams. poio exoun kanei  posa reviews ? alla assign new reveiw teams 8a ginoun gia ta paradoteo tou M51. 
Osa ginoun apla update ton M51  (p.x. .D5.5 diko mas) 8a kanei review mono to updates kommati to IDIO reveiw team tou M48 . 
8a ginoun review sto M50 osa paradw8oun exoloklhrou ton M51, ara osa den 8a ginoun update opws to diko  

			Στήλη 3 Leader = Deliverable Leader
			QA1 έως 4 είναι το review team 
			με * είναι ο review team leader 

TODO gia shmera: rwta tous delivevable leaders an (vale onoma organismos, einai sto 6.2 oti 8a kanei reveiw to  deliverable )


*pros deliverable leader send mail :* 
*todo : upen8unhs se olous all@concordia oti plhsiazei h hmeromina paradwshs twn delieberable . * 

https://mail.google.com/mail/u/0/?zx=9s3x4c9j5bj#search/cpapachr%40ics.forth.gr+review+team/FMfcgzGlkPXLkdGHvQWXqRFKGfrZxVSK?compose=dwRftRHjPjdSjgKtlwVcMdvTxSbBTLkGgstzdVmMtdqLLfljxPDlCztlBVbMTBnQJWcldkSjvxsZXVpwhbcdRhjVPMpZCTBhMXbDVXwZxnzBVbnsGHGMgmgvBCVgnbZfRwbXqhQfBwmgCBPdQqVhcxgcvnxMrLLLHJHbMBpvV


				all@concordia-h2020.eu, Ivana, Sotiris, Dreo

				Dear all,

				This is the review schedule for the M48 deliverables [1].
				The respective deliverables and the review teams that will be involved in each deliverable are as well presented on the T6.2 confluence page
				https://confluence.lrz.de/display/CONCORDIA/Task+T6.2+-+Quality+Management

				Before proceeding to the review, each deliverable leader should declare whether they intend to submit the deliverable on M48 or M51.

				The deadline for the release of the deliverables from each deliverable leader is 11/11/2022.
				The leaders of each deliverable and the corresponding review team leader are:

				Deliverable    Leader          Review team leader 
				-----------------------------------------------------------
				D1.4 -           CUT              Secunet Security Networks 
				D2.4  -          RUAG            CaixaBank 
				D3.4 -           ATOS            UiO 
				D3.5 -           SAG             University of Insubria
				D3.6 -           UT               SIDN
				D4.4 -           TUDA           University of Maribor 
				D4.6 -           UI                University of Passau
				D4.10 -         UL                Telenor
				D5.5 -           FORTH          Ben-Gurion University
				D6.7 -           UNIBW          TUBS  


				regards, 
				Despoina Antonakaki


        [1]

				M48 deliverables schedule

				–The deliverable leader releases the final version of DX.X 11/11/2022 and notifies qm@concordia-h2020.eu


				    Review process (1st round): start 14/11/2022 end 23/11/2022 (10 days)

				All comments from the review team will be sent to the review team leader (indicated by *) who creates 1 file and sends it back to the deliverable leader (cc: qm@concordia-h2020.eu)

				    Address comments by the deliverable leader: start 24/11/2022 end 30/11/2022 (7 days)

				Deliverable leader releases a new version and notifies qm@concordia-h2020.eu

				    Review process (2nd round): start 01/12/2022 end 07/12/2022 (7 days)

				All comments from the review team will be sent to the review team leader (indicated by *) who creates 1 file and sends it back to the deliverable leader (cc: qm@concordia-h2020.eu)

				    Deliverable leader (final pass): start 08/12/2022 end 14/12/2022 (7 days)

				Deliverable leader releases the final version and notifies qm@concordia-h2020.eu and CODE.


				Note: In each step of the review process

				    the assigned review leader (indicated by *) should create a consolidated version with all the review comments (including her/his comments) and send it back to the deliverable leader. There is no need to process the comments received by the review team. This is something that the deliverable leader will do.
				    To review leaders: For the integration process of all the comments received by the review team please consider using the procedure described here.
				    https://support.microsoft.com/en-us/office/combine-document-revisions-f8f07f09-4461-4376-b041-89ad67412cfe


				The excel below contains names and email addresses in case you want to identify the contact points for each organization involved in the review process. Please also (cc:) qm@concordia-h2020.eu in the respective emails.

				https://gitlab.lrz.de/concordia/general_information/blob/master/wp_participation.xlsx


an 8elei na padwsei sto M48 kai an 8a xreiastoun updates mexri ton M51 8a review ta updates ton M50 TO IDIO REVIEW TEAM. 


etoimase ta draft emails (peripou 10) pou 8a steileis gai ta reveiws ootan ta steiloun: 
p.x. 
							Dear review members of the D1.3 deliverable,

							according to the initial quality assurance plan that was presented during the second plenary meeting in Brussels
							you have been appointed to review the D1.3 deliverable: 3rd year report on designing and developing an ESRTE (M36)
							https://confluence.lrz.de/display/CONCORDIA/Task+T6.2+-+Quality+Management

							The  D1.3 review members are:
							- DFN-CERT
							- Telefonica I+D
							- University of Milan
							- Imperial College London *

							The deliverable is in gitlab: https://gitlab.lrz.de/concordia/wp1/-/blob/master/D1.3/CONCORDIA-D1.3.pdf
							Note from deliverable leader: it is best if the reviewers compile the file from the source latex files
							before starting the review, to get the latest version .

							The indicative review schedule for the deliverable is the following (PLEASE SEE UPDATED DATES BELOW):

							M36 deliverables schedule
							The deliverable leader releases the final version of on 30/11/2020 and notifies qm@concordia-h2020.eu

							- Review process (1st round): start 12/11/2021 end 22/11/2021 (10 days)
							UPDATE: - Review process (1st round): start 22/11/2021 end 30/11/2021 (8 days)
							All comments from the review team will be sent to the review team leader *( Imperial College London)* who creates 1 file and sends it back to the deliverable leader (prevelakis@ida.ing.tu-bs.de, j.najar@tu-braunschweig.de) (cc: qm@concordia-h2020.eu)

							- Address comments by the deliverable leader: start 22/11/2021 end 29/11/2021 (7 days)
							UPDATE: - Address comments by the deliverable leader: start 30/11/2021 end 05/12/2021 (5 days)
							Deliverable leader releases a new version and notifies qm@concordia-h2020.eu

							- Review process (2nd round): start 29/11/2021 end 07/12/2021 (6 days)
							UPDATE: - Review process (2nd round): start 05/12/2021 end 10/12/2021 (5 days)
							All comments from the review team will be sent to the review team leader *( Imperial College London)* who creates 1 file and sends it back to the deliverable leader (prevelakis@ida.ing.tu-bs.de, j.najar@tu-braunschweig.de) (cc: qm@concordia-h2020.eu)

							- Deliverable leader (final pass): start 07/12/2021 end 14/12/2021 (7 days)
							UPDATE: - Deliverable leader (final pass): start 10/12/2021 end 14/12/2021 (4 days)
							Deliverable leader (prevelakis@ida.ing.tu-bs.de, j.najar@tu-braunschweig.de) releases the final version and notifies qm@concordia-h2020.eu and CODE.
							The review members should create a consolidated version with all the review comments and send it back to prevelakis@ida.ing.tu-bs.de, j.najar@tu-braunschweig.de
							which will address the comments and send it to CODE ready for submission.

							Please ACK the well receipt of this email.

							Regards,
							Christos Papachristos.
							FORTH

							Note: In each step of the review process

							- the assigned review leader (indicated by *) should create a consolidated version with all the review comments (including her/his comments) and send it back to the deliverable leader. There is no need to process the comments received by the review team. This is something that the deliverable leader will do.
							- To review leaders: For the integration process of all the comments received by the review team please consider using the procedure described here.
							    https://support.microsoft.com/en-us/office/combine-document-revisions-f8f07f09-4461-4376-b041-89ad67412cfe

ena email ana paradoteo me to review team kai cc gabi, ivan si

NA EXW TA EMAIL ETOIMA (10 mail) oxi se oleous alla  gia osousn poun oti 8a dwsoun ton M48  

graye gia olou tous 
 
an kapoios den apantaei,  ena mail reminder kai meta ivana! Vasika thn ivana kane thn panta cc . 


*D3.2 * 

  exoume dwsei to inpuy kai den 8a xreiaseti gia to M51 . 
  meeting ka8e teutaio pempth . 

  link : https://meet.jit.si/TelcoTask3.2CONCORDIA


D5.5 : 

  exoume zhthsei input kai perimnoume na mas ta steiloun , sun8esh .mporei na einai to idio file epi treis fores apla kanw merge .  


στειλε μαιλ; 
ekei vale kai oti 8a ginei to reveiw process alla prwta na apanthsoun pioio 8a dwstoun ton m48 gai na xeroume an 8a summetexoun sto review.

* kai ena alert se olous oti 8a akolou8hsei reveiw 

 



*deliverables* 
D4.4 and D3.6: οποτε για τα παραδοτεα που θα γινουν submit to 48 (opws D4.4 and D3.6) mporei na xanaginoun submit ston M51 (Deliverable lead will participate in extension, opote den 8a uparxei update,  οpote 8a graftoun, 8a ginoun reveiw kai 8a ginoun submit ton M48)

D1.4, D3.4, D4.6, D4.10, D5.5, D6.7, D3.5: Yes to extension 8α παραδoσοyν στον M48 kai M51 ?   8a mas apanthsoun ! emeis twra kai update ton M51. 

D2.4: No As T2.1, 2.2, 2.3. and probably t2.5. will continue during the extension, there will be a need to report that in final deliverable and thus lead the deliverable till M51 – we cannot count on RUAG for that

-----------------
*ta dika mas deliverables* 
D5.5: diko mas lead ton M48 
D5.5  Planed due date 48 --> 51 
opote grafete twra M48 kai 8a ginei update kapoia kommatia argotera kai submit ton M51. 
   exei graftei kai 8a ginei update ? start from scratch .


*2 review processes*: 


8a doume poio exoun meinei partners sto extension . me vash to excel poio exoun kanie posa .... gia M51 exoloklhre

1) start 14/11/2022 end 23/11/2022 (10 days) 


2) start 10/2  ews 20/2 

		To paradoteo einai gia M48 (12/22) opote  to review arxizei 14/11/22 kai to paradoteo perepei na exei stalei sta review teams stis 

*review teams* 

	Ποια θα ειναι τα review team για ολα τα deliverables ?
	Ναι απ’ όσο κατάλαβα θα διαλέξω εγώ πιο θα είναι το review team για το δικό μας μόνο deliverable ; Με τι κριτήριο διαλέγω ποιος θα το κάνει review;



Ποια εινια ολα τα meeting που πρεπει να μπαίνουμε; 3.2 . 

Ειναι κατι αλλο που πρεπει να γινει εκτος απο τα 2 review processes και το deliverable 


–The deliverable leader releases the final version of DX.X 11/11/2022 and notifies qm@concordia-h2020.eu


------------------
D4.4 and D3.6 seems clear: Deliverable lead will participate in extension, opote den 8a uparxei update
                                           Opote 8a graftoun, 8a ginoun reveiw kai 8a ginoun submit  ton M48  ? 


D1.4, D3.4, D4.6, D4.10, D5.5, D6.7, D3.5: Yes to extension 




D2.4: No As T2.1, 2.2, 2.3. and probably t2.5. will continue during the extension, there will be a need to report that in final deliverable and thus lead the deliverable till M51 – we cannot count on RUAG for that








11/11/ steloyn se emas OLA ta paradotea kai qm@concordia-h2020.eu kai emeis steloume ta emails sta review teams .
prin apo tis 11/11 steloume ena notifiation (isws stis 1//11) oti exoume akomh 10 meres.  





Poiow einai o M48 wste na doume poso pio nwris kanoume to review ? 


06/12/2018
Μ1 12/2018 
Μ1 1/18
Μ12 12/19
Μ24 12/20
Μ36 12/21 

Μ47 11/22 
Μ48 12/22
Μ49  1/23
Μ50  2/24 
Μ51  3/24 

12/2022 (? 

οποτε αφου για το Μ48 12 dekembrios  καναμε το review ston 11/11  θα prepei gia 
	            ton M51 3/24  μαρτιος να καναμε το review ston 10/2 φεβρουαριο και τα παραδοτεα να δωθουν μεχρι 1 φεβρουαριου   ...
# meeting με cp σχετικα με το cocnordia 


t3.2 το παραδοτεο εχει ηδη input apo cp kai 8a parado8ei ton M48 . 
opws uprxei kai sxetikh perigrafh edw: http://139.91.70.57/doku.php


	exoume ena dashboard apo to opoio 1) kanoume epi8eseis 2) dexomaste epi8eseis . sousiatsika mettrame to traffic kai to kanoume report sto paradoteo 

	to input exei hdh dw8ei sto paradoteo. 


			apo to blog tou cp : Linux VM with a DENY-ALL firewall which records connection attempts and creates a top10 potential attackers file under the
			/var/www/html/ directory
			The file is then retrieved by the MISP Server


	t3.1 MISP@ICS : honeypot. reports IPs and pushes theses address to MISP of concordia 	
			Linux VM with a DENY-ALL firewall which records connection attempts and creates a top10 potential attackers file under the
/var/www/html/ directory
The file is then retrieved by the MISP Server

http://139.91.70.57/doku.php?id=misp_server


Σχετικά με το QA: 
https://confluence.lrz.de/pages/viewpage.action?spaceKey=CONCORDIA&title=Task+T6.2+-+Quality+Management
Με το που παραλαμβάνω τα deliverables στις 1/11 στελνω τα deliverables σε ολο το  review team.
Στην συνεχεια τα στελνουν σε σε εμενα και εγω τα προωθώ στο reviww team leader : 

		All comments from the review team will be sent to the review team leader (indicated by *) who creates 1 file and sends it back to the deliverable leader (cc: qm@concordia-h2020.eu)


mail from last year 

https://mail.google.com/mail/u/0/?zx=9s3x4c9j5bj#search/cp/FMfcgxwKjKmVhLxXkKfSDHZXdxmkDDWS?compose=lqrsmGgrzlbwxdRLHHFxvtPLcRnXDjvzwKgxPdbBnPDBKnmlDTXhTJHsLJcWxtxqmQxCFTVFDWGjfPLsz

https://mail.google.com/mail/u/0/?zx=9s3x4c9j5bj#search/review+process+/FMfcgzGlkFrgpxGfGkrHGvPQNqzTtgCS?compose=lqrsmGgrzlbwxdRLHHFxvtPLcRnXDjvzwKgxPdbBnPDBKnmlDTXhTJHsLJcWxtxqmQxCFTVFDWGjfPLsz


		M48 deliverables schedule

		–The deliverable leader releases the final version of DX.X 11/11/2022 and notifies qm@concordia-h2020.eu


		    Review process (1st round): start 14/11/2022 end 23/11/2022 (10 days)

		All comments from the review team will be sent to the review team leader (indicated by *) who creates 1 file and sends it back to the deliverable leader (cc: qm@concordia-h2020.eu)

		    Address comments by the deliverable leader: start 24/11/2022 end 30/11/2022 (7 days)

		Deliverable leader releases a new version and notifies qm@concordia-h2020.eu

		    Review process (2nd round): start 01/12/2022 end 07/12/2022 (7 days)

		All comments from the review team will be sent to the review team leader (indicated by *) who creates 1 file and sends it back to the deliverable leader (cc: qm@concordia-h2020.eu)

		    Deliverable leader (final pass): start 08/12/2022 end 14/12/2022 (7 days)

		Deliverable leader releases the final version and notifies qm@concordia-h2020.eu and CODE.


		Note: In each step of the review process

		    the assigned review leader (indicated by *) should create a consolidated version with all the review comments (including her/his comments) and send it back to the deliverable leader. There is no need to process the comments received by the review team. This is something that the deliverable leader will do.
		    To review leaders: For the integration process of all the comments received by the review team please consider using the procedure described here.
		    https://support.microsoft.com/en-us/office/combine-document-revisions-f8f07f09-4461-4376-b041-89ad67412cfe




# concordia meeting 

chistos proposed : transfer quality check at 51 

move all deliverables to M51 

even if deliverable will be ready on 48 it will be commited on 51 

reviewers will not be working on 51 
people may be gone 

may be go to every task leader and ask 
maybe ask when the resourcses wil be used , but maybe people will not be there 

upload deliverable when it is ready ...earlier 

or finish evertythin 48 and update 51 ? 

# Tuesday 4/10
1.1.3.1	Ambition in Certification & Conformity Assessment (Objectives 1, 2, ..) @ICT Systems, ICT Services, and ICT Processes (ICT-SSP) 
1.1.3.1	Ambition in Certification & Conformity Assessment (Objectives 1, 2, ..)



*Paper* :
A Supply Chain Service Cybersecurity Certification Scheme based on the Cybersecurity Act  - Alexandra Michota- Nineta Polemi

		1) They Propose a Cybersecurity Certification Scheme for Supply Chain Services (EUSCS).

		2) a European cybersecurity certification scheme shall include at least the following elements: 
		the subject matter and scope of the certification scheme,
		including the type or categories of ICT products, ICT services
		and ICT processes covered

		conformity assessment is
		based on ISO 15408 and ISO 18045 [19]

		Article 54(g) of the CSA highlights that a European cybersecurity certification scheme shall include the specific evaluation criteria and methods to be used, including types of evaluation, in order to demonstrate that the security objectives referred to in Article 51 are achieved.

		Assessment flow for Level Basic. As seen in Fig. 1, the certification scheme shall assess how the SCS that participate meets the requirements of a predefined set of security control objectives and a related set of measures, when used according to security recommendations they have agreed upon.


 A Procedure for Conducting Conformity Assessment of AI Systems in Line with the EU Artificial Intelligence Act - Luciano Floridi


 		developed capAI, a conformity assessment procedure for AI systems, to provide an independent, comparable, quantifiable, and accountable assessment of AI systems that conforms with the proposed AIA regulation.
 

 
Conformity Assessment in the PublicProcurement of Accessible ICT 
Loïc Martínez Clas  Thorén
      *towards accessibility requirements!*


froms spyros 1st round: 
The Challenges of Software Cybersecurity Certification
opws einai !: 

						The realization of the cybersecurity certification framework promoted by the CSAHowever, requires the joint effort of certification bodies, manufacturers, and software providers so that an ICT system is certified according the cybersecurity of its software components. 

						How? through the inclusion of cybersecurity requirements in the development, maintenance, and operation of software components in certification schemes, as mentioned by a recent report from the EU Agency for Cybersecurity (ENISA).

						Also :However, other challenges also need to be addressed. Thus, our main goal is to increase the awareness of the challenges of cybersecurity certification so that the accreditation’s benefits can be leveraged by end users through a more trustworthy digital ecosystem. 

					Definition and certification under
					different assurance levels; those
						levels are defined by the CSA and
					need to be considered by certification
					bodies and manufacturers
					when certifying their systems.
					■■ Software composability and software
					updates, which impact the
					certification of a whole system
					and its components during their
					lifecycle; these aspects are of interest
					to manufacturers and software
					providers as well as cybersecurity
					certification practitioners for
					defining the relationship between
					different certification schemes.
					■■Development of coordinated
					vulnerability disclosure (CVD)
					procedures, which must be followed
					by vulnerability providers
					(e.g., a certain company or cybersecurity
					researcher) to maintain
					software providers’ control of
					their systems.

*projects*
https://www.spear2020.eu/Objectives
 
ta phra opws einai!!!
   To build attack detection mechanisms and promote resilience operations in ICT 

   To increase situational awareness in ICT

   To create and maintain an anonymous repository of ICT

   To provide smart network forensics subject to data protection and privacy

   To empower EU-wide consensus of cybersecurity in ICT

   To validate our architecture capabilities in proof-of-concept Use Cases

   To design an innovative business model and conduct a techno-economic analysis to strengthen the role of European smart grid and cyber-security industry in the global market.




# Monday 3/10

Work programme topic addressed: HORIZON-CL3-2022-CS-01-04 Development and validation of processes and tools used for agile certification of ICT products, ICT services and ICT processes

•	Unstructured Data from Open Intelligence Data Sources: The model will integrate data from open intelligence sources as well as from different trusted digital platforms, including GDPR scheme, cybersecurity standards, scientific papers and journals, social networks and crowd-sourcing data sources. In particular, specialized security-related knowledge will be uniquely extracted from textual content using advanced Natural Language Processing (NLP) techniques, such as sentiment analysis. Multiple sources of social media streams will be harmonised and exploited to increase the efficiency and effectiveness of such analyses. Social media meta-data will additionally be incorporated to complement this information, whenever they are available. 




FOR the call todo: Certification and conformity assessment process for ICT Systems, ICT Services, and ICT Processes (ICT-SSP),

State of the art 
Taxonomies (isws se surveys)

sta kefalaia 1.1.3.1	Ambition in Certification & Conformity Assessment (Objectives 1, 2, ..)
State of the art

Beyond the state of the art:   



1.1.3.2	Ambition in Taxonomies for Certification-related Information (Objectives 1, 2, ..)
State of the art

mish selida to ka8e ena !



refrences apo emena

https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9850323&casa_token=TV4RCkCBV4sAAAAA:K6cMmvAWNrdicu-70Mw-W8t9d6MfkclRS13IfiLwvenuRjDaWwGohTRneSe97xmY0AYL7hN0
https://link.springer.com/article/10.1365/s43439-021-00043-6
https://www.mdpi.com/2079-9292/11/6/965







call 
CONCORDIA: Monthly coordinator's call with WP and Task Leaders

Please join my meeting from your computer, tablet or smartphone.
https://meet.goto.com/671290829

Join via browser: https://app.gotomeeting.com

 

Access Code: 671-290-829
This meeting is locked with a password: mw3dt6

-----------------
Please join my meeting from your computer, tablet or smartphone.
https://meet.goto.com/549179405
Join via browser: https://app.gotomeeting.com

 

Access Code: 549-179-405
This meeting is locked with a password: xw7fd2

#1.5 mmeting 28/9 

Agenda
Status T1.5
COD2022 
Poster session https://opendoor.concordia-h2020.eu/2022/most-innovative-research.html
CONCORDIADelivers videos (deadline 16.10 for T1.5)
Deliverable D1.4
Best,



#3.2 
meeting 
demo at concordia open door
action update cookbook . 


supplementary services FORTH? 

# new thingds to explore 

*public sentiment dataset*

Stanford Sentiment Treebank 2
Twitter Sentiment SemEval (SE)


#new ideas for twitter

*bot detection* 


*rumor detection* 
https://link.springer.com/article/10.1007/s11042-022-13595-4 
*Refining Word Embeddings with Sentiment Information for Sentiment Analysis* 


*COVID ideas:*
-*content analysis* 
 # deep learning in covid* 


(Deep Learning-Based User Privacy Settings Recommendation in Online Social Networks - Sohaib R Rufai, C

 atey Bunce - )
	Eight out of nine (88.9%) G7 world leaders had verified and active Twitter accounts, with a total following of 85.7 million users. Out of a total 203 viral tweets, 166 (82.8%) were classified as ‘Informative’, of which 48 (28.6%) had weblinks to government-based sources, while 19 (9.4%) were ‘Morale-boosting’ and 14 (6.9%) were ‘Political’. Numbers of followers and viral tweets were not strictly related.rufai2020world

# COVID-Twitter-BERT
	In this work, we release COVID-Twitter-BERT (CT-BERT), a transformer-based model, pretrained on a large corpus of Twitter messages on the topic of COVID-19. Our model shows a 10-30% marginal improvement compared to its base model, BERT-Large, on five different classification datasets. The largest improvements are on the target domain. Pretrained transformer models, such as CT-BERT, are trained on a specific target domain and can be used for a wide variety of natural language processing tasks, including classification, question-answering and chatbots. CT-BERT is optimised to be used on COVID-19 content, in particular social media posts from Twitter.


# σεντιμεντ https://publichealth.jmir.org/2020/4/e21978 Public Perception of the COVID-19 Pandemic on Twitter: Sentiment Analysis and Topic Modeling Study

 
@ASPI_org
@Nrg8000
@Jerry_grey2002 (blocked, to prwi htan dia8esimos!) 
@ColinTTWSYF, 
@DanielDumbrill (in the context Additionally, in the China-sphere there are 3 specific paid propagandists who are most prolific in coordinating this abuse & harassment:
)
 
@aaronjmate
@MaxBlumenthal
@BenjaminNorton (apo https://twitter.com/Nrg8000/status/1564610201252397060: But it has been used more widely recently by Andy and Jerry to significant success, and by other accounts to less impact. )


@SophieMak1 , @PhilosophyNook, @joshuawongcf (autos ienai fulakh)
(https://twitter.com/Nrg8000/status/1563871667067056130)


apo thn allh pleura : 

@AndyBxxx, 
@SteveWeaverTEFL ?
@EndWarmongering  
des folowers of @AndyBxxx

others: 

 
@xu_xiuzhong
 and 2 others





#σθναντηση με cp σχετικα με το cocnordia 


t3.2 το παραδοτεο εχει ηδη input apo cp kai 8a parado8ei ton M48 . 
opws uprxei kai sxetikh perigrafh edw: http://139.91.70.57/doku.php


	exoume ena dashboard apo to opoio 1) kanoume epi8eseis 2) dexomaste epi8eseis . sousiatsika mettrame to traffic kai to kanoume report sto paradoteo 

	to input exei hdh dw8ei sto paradoteo. 


			apo to blog tou cp : Linux VM with a DENY-ALL firewall which records connection attempts and creates a top10 potential attackers file under the
			/var/www/html/ directory
			The file is then retrieved by the MISP Server


	t3.1 MISP@ICS : honeypot. reports IPs and pushes theses address to MISP of concordia 	
			Linux VM with a DENY-ALL firewall which records connection attempts and creates a top10 potential attackers file under the
/var/www/html/ directory
The file is then retrieved by the MISP Server

http://139.91.70.57/doku.php?id=misp_server

# concordia meeting 

chistos proposed : transfer quality check at 51 

move all deliverables to M51 

even if deliverable will be ready on 48 it will be commited on 51 

reviewers will not be working on 51 
people may be gone 

may be go to every task leader and ask 
maybe ask when the resourcses wil be used , but maybe people will not be there 

upload deliverable when it is ready ...earlier 

or finish evertythin 48 and update 51 ? 






ivana will 

internal review????

review per chapter is difficult 
who will be available till the end ???

most of the partners said most partners will be available ...


-----------------------------

aneipero   !d5f3s789aneipero***$$$@@@



# 17/8/2022 βραδεια ερευνητη
"
Με την εισβολή της Ρωσίας στην Ουκρανία, στις 24 Φεβρουαρίου 2022, γνωστό πλέον ως Ρωσο-Ουκρανικός Πόλεμος, ξεκίνησε μια διαδικτυακή συζήτηση στα μέσα κοινωνικής δικτύωσης. Το Twitter ως ένα από τα πιο δημοφιλή κοινωνικά δίκτυα και έχοντας ένα ανοιχτό και δημοκρατικό χαρακτήρα. επιτρέπει διαφανείς συζητήσεις μεταξύ της μεγάλης βάσης χρηστών του. Δυστυχώς αυτό συχνά έχει ως συνέπεια  την παραβίαση της πολιτικής του Twitter, την διάδοση προπαγάνδας, καταχρηστικές ενέργειες, την παραβίαση της πολιτικής ακεραιότητας με αποτέλεσμα ως και την αναστολή και διαγραφή λογαριασμών χρηστών. Η μελέτη αυτή επικεντρώνεται στην αναστολή των λογαριασμών στο Twitter και στην ανάλυση των χαρακτηριστικών των λογαριασμών αυτών που μπορεί να οδηγήσουν σε αυτό. Για την πραγματοποίηση του σκοπού αυτού, έχουμε στην διάθεσή μας ένα σύνολο δεδομένων (με την χρήση δικού μας crawler) που περιέχει 57,3 εκατομμύρια tweets από το Twitter API, που προέρχονται από 7,7 εκατομμύρια χρήστες. Εφαρμόζουμε μια μεθοδολογία μηχανικής εκμάθησης, συμπεριλαμβανομένου ενός μοντέλου επεξήγησης SHapley, προκειμένου να κατανοήσουμε και να εξηγήσουμε πώς αναστέλλονται οι λογαριασμοί των χρηστών."




\section{Author Contribution Statement}
The authors mentioned above have contributed in the following parts for this work: 
\begin{itemize}
\item  Despoina Antonakaki (corresponding author): Conceptualization, Methodology, Investigation, Resources, Writing - Original Draft, Writing - Review \& Editing, Visualization.
\item Sotiris Ioannidis: Writing - Review \& Editing, Supervision, Project administration, Funding acquisition.
\end{itemize}







Note for PLOS one submission 


if references do not work you have to change the mnuscript.pdf from manuscript to supplementary material
 Hosmer–Lemeshow test is only suitable for logistic regression models. 
  Our model is the random forest, Is there any available for this model? Like any of these?


deyaonnis poio conferene 

TODO : 
isws International Conference on Web and Social Media (ICWSM) ...ti exoun steilei oi prohgoumenoi ...gpu paizoun ...?

F1.4

#grants : 



energy: 
Methods for exploiting data and knowledge for extremely precise outcomes (analysis, prediction, decision support), reducing complexity and presenting insights in understandable way (RIA)
*  first digitally led circular, climate-neutral and sustainable economy

Programming tools for decentralised intelligence and swarms (RIA)

* Develop agile and secure architectures, dynamic programming environments and tools for the compute continuum from the device and edge perspective, including energy-efficient, lightweight AI-based approaches, tools for decentralised device and edge intelligence, innovative mesh architectures with mixed topologies to support concepts like tactile internet and swarm intelligence.




33,90
cosmote 


proposal 

fake news detectors ...too old ..to kanoun oloi 
o skopos mas ienai ..

poios egraye prwtos mias eishsh ...poia media thn uposthrizoun poio stakeholders ...


!d3...susyA

https://susy.mdpi.com/user/register








GRANT proposal IDEAS brainstorming with alex!

biosensors
biosecurity
IOT in health
COVID 
fake news in COViD
haste speech 
sentiment analysis

challenges of NN: 
explainable 
tracability
trustrworthiness
gdpr compliant 
federaded learning (sparse silos-dbs)
generative models (very hot )

if a paper is automaticaly generated MOSS for gdtp


8/2 

GME ws thn grammh 258: 
Vocabulary and artificial neural network implementations are utilized in a wide range of research and commercial solutions including real-time analysis and movies revenue prediction. %including bot detection and analysis. 
%In this particular case, sentiment analysis can be use


Sentiment analysis tools : 
https://paperswithcode.com/paper/xlm-t-a-multilingual-language-model-toolkit
BERTweet
RoB-RT
RoBERTa-Base
RoBERTa-Twitter
SVM
FastText
LSTM

concordia 1.1  #zoom meeting for 1.1 task

Access:

    Meeting URL https://us02web.zoom.us/j/81171979468?pwd=VGZwNnBWQ0RWV1RmUjRQeC9ac1pFZz09

    Meeting ID: 811 7197 9468

    Passcode: 189948


pattern matching module gpus 

exoume parei lexika apo alla paper sentiment anaylis score 
implementation wise etoimoi ....


NAS: 

http://139.91.71.12:5000/

NAs : ssh -p 22599 despoina@139.91.71.12
aneipero
ssh -p 2222 139.91.71.13

scp -P 22599 test 139.91.71.12:./volume1/despoina/
scp -P 22599 ht_COVID19_160.gz  139.91.71.12:./volume1/despoina/COVID19



edw anevazei to 8914.copy_nas2 output_graph.heuristic.final.uniq.gz 


!..NAS



8    Twitter bots GME
____________________


pws mporoume na sugkrinoume na ftiaxoume ena area ander the vurve me to actual mortality pou exoume twra apo ton pinaka 

antistoixa papaer pou kanoun ayto kai na doume pws to kanoun .   



Christos Papachristos
Mon, Oct 25, 11:27 AM (9 days ago)
to Sotiris, Despoina

Καλημέρα Δέσποινα,
όλα τα παραδοτέα του CONCORDIA θα πρέπει να είναι έτοιμα 12/11/2021
οπότε σιγά σιγά θα έλεγα να αρχίσεις να μαζεύεις το input για το D1.3
Ο,τι χρειαστείς μου λές,

==============


* COVID dataset fake news, data analysis, start experimenting with large dataste  aroud 

aneipero: 

despoina$ ssh -p 2222 despoina@139.91.71.13


	Dcs people invovled in concordia :

	*Task 1.1*

		Hatzivasilis (exei fugei)
		Petroulakis (exei fugei?)
		Lakka
		Papoutsakis 


	*Task 1.2*

		Eva Papadogiannaki

	*Task 1.3*



	*Task 1.4*

		George Christou, Eva Papadogiannaki, Michalis Diamantaris,
			Livia Torterolo, and Panos Chatziadam

	*Task 1.5*

				Despoina Alex


	*All:*
	Eva, Alex, Diamantaris, Christou, Deyannis 






TODO list : 1) vgale plots apo to manuscript OK 

2) check again to google docs an eiani to idio  OK

3) include the file with teh whole list of hts [all_hashtags.txt] OK 

4) run latexdiff

5) vale ola ta review answers apo to google docs sto manuscript OK 

6) anevase nea figures OK 

7) anevase kai pdf 
8)diff latex trexe 




ls -lh ht_COVID19_4?.json |wc -l

*VICKY*
	#για φλεβικη θρομβοδη η βικη ειχε χρησιμοοιηεσει τησ mimic αυο στελιςο θα χρησιμοποιεισηε τησ icu
	#na voh8hsw me to poster ? deadline gia to poster 27/10? 8a mepei se ena google presentation na mou steilei h vicky to template kai to uliko na mpei sto poster . 

	#den ua exei uema oti oi algori8moi einai kleistoi ? exeis parei kapoies etoimes ulopoihseis gai ta ml modela ? 8a prepei na deixei kapoia original douleia h exoume parei kapoia off the self ulopoihseis ml algorismwn ... ? gia to oti einai genika praktikh ? OXI ola kala 

	#mortality prediction or readmission (den uparxei xronomogilh seira en mporei na ginei sto eicu )

	#ta arxeia ta exoume ftiaxei . oi as8eneis me tis arthriakes 8romvwseis tous exoume kathgoriopoihsei /meta na ermhneusoume ti features 8a vroume 
	#oloi oi as8eneis einai sthn entatikh


	#Το τεστ Hosmer – Lemeshow είναι ένα στατιστικό τεστ για την καλή προσαρμογή στα  logistic regression models.  Χρησιμοποιείται συχνά σε in risk prediction models. Το τεστ αξιολογεί εάν τα παρατηρούμενα ποσοστά event ταιριάζουν ή όχι με τα αναμενόμενα ποσοστά event σε υποομάδες του μοντέλου πληθυσμού.
	#It is used frequently . The test assesses whether or not the observed event rates match expected event rates in subgroups of the model population.

mortality prediction in arterial and vinus thrombosis 
Mortality prediction in patients with arterial or venous thromboembolism in icu patients 

mail ... jadbio

*PLOS Third review*

*Removed NEW paragraphs from abstract*

		[FORM statements and support them 
		A statement about background work regarding OUR problem statement, 1st we have to locate background work, about the ones we mentioned in the previous sentence, let’s see what is relevant for us: 

		Existing studies towards the analysis of the interactions across different platforms during elections period are used for diverse goals. They mainly focus on the observation and investigation of the online discourse, highlighting the main activity of the candidates and the evolution of their online presence \cite{aparaschivei2011use}, evaluate how the candidates are influenced from SNs \cite{effing2016social}[[--ayth ienia h 11 apo ton parakatw pinaka local election in NL] , investigate whether social networks contribute in the democratization of our political systems. , studying online propaganda  [7], or the topics of the content in YouTube videos related to campaigns \cite{Vesnic2014youtube}. 
		-------------------------------

		To our knowledge there is no study analyzing the common ground between two major social networks like Twitter and YouTube, on a representative dataset from the respective APIs during election period (or on pre-elections period).



		Single SN studies intro

		There is a plethora of background on the analysis of political contents during elections period, focusing on a single social network. These studies Studies focusing on single social networks on elections period,  analyze the online discourse, in order to discover the main tendencies and preference of the electorate \cite{antonakaki2017social}, generate patterns that can distinguish users' favouritism towards an ideology or a specific political party, study the sentiment prevailed towards the political parties, [todo add more references from background work] measure political homophily, or even predict the outcome of the elections. Additionally, by using network analysis in this context, we can reveal how ideas and entities in the corpus are coupled with specific political candidates and show ideological tendencies, study how homophily influences political interaction, show party interactions or hidden connections among entities, nodes or even whole social networks via community detection [3]. 

		---------------------
		Και αν θελετε να βαλουμε στο ιντρο και για sentiment: 

		Analyzing the sentiment is an additional step towards the processing of political content \cite{martinez2014sentiment, giachanou2016like, go2009twitter, mittal2012stock, saif2012alleviating}. Sentiment analysis has been extensively applied on Twitter traffic, usually regarding a specific event. Through sentiment analysis, we can visualize the variation of the sentiment of the electorate during a political event \cite{wang2012system, diakopoulos2010characterizing}, a company event \cite{daniel2017company}, product reviews \cite{mukherjee2012feature}, or model the public mood and emotion and connect tweets' sentiment features with fluctuations with real events \cite{bollen2009modeling}. The main task of these works is to predict elections, classify the
		electorate and distinguish posts towards one political party or ideology, although it has been addressed in many works that Twitter is not suitable for election prediction \cite{gayo2013meta, gayo2011limits}



		To our knowledge there is no study analyzing the common ground between two major social networks like Twitter and YouTube, on a representative dataset from the respective APIs during election period (or on pre-elections period).



		==================NEW KIDS ON THE BLOCK!______++++++++++++++++++++++++



		Users on Twitter and YouTube form tight Communities.
		(homophily, communities, content-producers/content-consumers on youtube).

		We are looking for background for Twitter +  homophily - Twitter +  communities - Twitter + YouTube + content-producers/content-consumers on youtube 




*Fwd: [CONCORDIA Communication] I: CCN: FW: FIC 2021 / OFF PROGRAM*

tries enalaktikes gai agglika vivlia 

https://www.ianos.gr/smileys-junior-a-power-pack-0293747?gclid=Cj0KCQjws4aKBhDPARIsAIWH0JVV7g0JjvChruf559J4qJ7viUPb05Xm9RTBSKas8IkRpgQDcXjU39YaAiyHEALw_wcB
https://book-it.gr/smiles-junior-ab-one-year-course-paketo-power-pack-ola-ta-biblia-tis-taksis-neo-me-iebook.html?gclid=Cj0KCQjws4aKBhDPARIsAIWH0JUAyLLDGfD6wV0RDwksAaEsZEZGz2iYLWMQayiHlvocLX93qZ1IKIgaAh4PEALw_wcB

https://www.booksite.gr/books/ksenoglossa/smileys-junior-a-and-b-power-pack.html?gclid=Cj0KCQjws4aKBhDPARIsAIWH0JVT81Co0bIoM_ldZSvyYALmTVspIB9LiW_0D3yPY6BQmn7b8N4tTeUaAvKZEALw_wcB


*ssh kantale@yperthen.ics.forth.gr*
AD6FA287FE06 


*eICU Hosmer-Lemeshow* 
me kapoies allages  kai  pip install pysal
apo https://jbhender.github.io/Stats506/F18/GP/Group13.html
in /Users/despoina/GitHub/vicky/Hosmer–Lemeshow IT IS UP and RUNNING!


		
		Hosmer and Lemeshow proposed a goodness-of-fit test on the basis of dividing the sample into strata on the basis of
		the predicted probability of the outcome [9, 10].


		In practice, subjects are often divided into ten, approximately equally-sized, groups on the basis of the deciles of risk. 

		A chi-squared test is then used to compare the observed versus predicted probability of the outcome across the strata.

		Alternatives:

		While the Hosmer–Lemeshow test is based on grouping subjects on the basis of the predicted probability of the outcome, Tsiatis proposed a test on the basis of grouping subjects on the basis of the predictor variables [11]. 
		Le Cessie and van Houwelingen proposed tests of goodness-of-fit on the basis of smoothed residuals [12]
		Royston proposed tests to detect nonlinearity that used partial sums of residuals [13].
		Stukel proposed a generalized logistic model that permits testing of the adequacy of a fitted logistic regression model [14].

		Other alternatives: 
		While the tests described previously allow one to formally test the goodness-of-fit of the fitted logistic regression model, other authors have proposed methods to qualitatively assess model calibration: 

		Cox proposed a recalibration framework, in which the observed outcome is compared with the linear predictor [15]
		An intercept and slope are then estimated, which are related to calibration-in-the-large and the calibration slope [8].
		A two-degree of freedom test can be performed to test for miscalibration [16].
		Harrell and Lee extended Cox’s recalibration framework to allow one to derive indices denoting the lack of calibration,
		discrimination, and overall quality of prediction [17, 18].
		Dalton recently extended Cox’s recalibration framework to provide for a flexible recalibration of binary prediction models [19].
		Furthermore, the use of this method permits the derivation of a relative measure of miscalibration for
		comparing two competing prediction models.

*Gia na to trexoume 8eloume na exoume trexei ena montelo gai na doume poso kala ta exei paei stis binary metavlhtes*
	gai na testaroume to fitness of model : 

λοιπον το τεστ αυτό εφαρμόζεται σε  binary μεταβλητές, οπότε για οποιες δεν ειναι binary τις αφήνουμε απέξω.
vicky danilatou
vicky danilatou
11:29 AM Jul 2
Δες σε παρακαλώ και αυτό το paper. https://onlinelibrary.wiley.com/doi/full/10.1002/sim.5941
Aν το καταλαβαίνω καλά το τεστ αφορά έλεγχο μοντέλων με binary outcome, κάτι που αφορά τη δική μας περίπτωση.



#twitter covid dataset

cat ht_coronavirus_*_tweet_ids.txt |wc -l
208.566.475

 cat ht_COVID19_*_tweet_ids.txt |wc -l
392.867.066


error in zenodo: 

ht_COVID19_10_tweet_ids.txt
ht_COVID19_112_tweet_ids.txt	
ht_COVID19_115_tweet_ids
ht_COVID19_116_tweet_ids
ht_COVID19_160_tweet_ids.txt	
ht_COVID19_1_tweet_ids.txt	
ht_COVID19_23_tweet_ids.txt	
ht_COVID19_78_tweet_ids.txt	
Συναλλαγής:PX211452218660
Συναλλαγής:PX210765454442

#Twitter Content redistribution
The best place to get Twitter Content is directly from Twitter. Consequently, we restrict the redistribution of Twitter Content to third parties.  If you provide Twitter Content to third parties, including downloadable datasets or via an API, you may only distribute Tweet IDs, Direct Message IDs, and/or User IDs (except as described below). We also grant special permissions to academic researchers sharing Tweet IDs and User IDs for non-commercial research purposes.

In total, you may not distribute more than 1,500,000 Tweet IDs to any entity (inclusive of multiple individuals associated with a single entity) within any 30 day period unless you have received written permission from Twitter. In addition, all developers may provide up to 50,000 public Tweets Objects and/or User Objects to each person who uses your service on a daily basis if this is done via non-automated means (e.g., download of spreadsheets or PDFs).

Academic researchers are permitted to distribute an unlimited number of Tweet IDs and/or User IDs if they are doing so on behalf of an academic institution and for the sole purpose of non-commercial research. For example, you are permitted to share an unlimited number of Tweet IDs for the purpose of enabling peer review or validation of your research. If you have questions about whether your use case qualifies under this category please submit a request via the API Policy Support form.

Any Twitter Content provided to third parties remains subject to this Policy, and those third parties must agree to the Twitter Terms of Service, Privacy Policy, Developer Agreement, and Developer Policy before receiving such downloads. You may not enable any entity to circumvent any other limitations or restrictions on the distribution of Twitter Content as contained in this Policy, the Developer Agreement, or any other agreement with Twitter.

gunzip -c ht_COVID19_136.gz |    egrep -o '[A-Z][a-z][a-z] [A-Z][a-z][a-z] [0-9][0-9] [0-9][0-9]:[0-9][0-9]:[0-9][0-9] [(+*)][0-9][0-9][0-9][0-9] 202[0-1]\", "id": [0-9]+' > ids


1,500,000 Tweet IDs 
emeis exoume 
cat ht_coronavirus_?_tweet_ids.txt |wc -l
20.434.667

split file : 

head -n 1500000 input-file > output1

head -n 1500000 ht_coronavirus_1_tweet_ids.txt > ht_coronavirus_1a_tweet_ids.txt
tail -n +1500000 ht_coronavirus_1_tweet_ids.txt > ht_coronavirus_1b_tweet_ids.txt


#JADBIO 
U:5z9`"@3%[`"3M^
despoina@ics

#dataset covid

*gia na valeis mesa kai hmeromhnia* 
\grep -o -P '.{0,63}id_str.{0,0}'
gunzip -c ht_COVID19_1.gz |  grep -o -P '.{0,63}id_str.{0,0}'  > ht_COVID19_1_tweet_ids.txt &

PARE TOUS protous 100 xarakthres

gunzip -c ht_COVID19_136.gz |    egrep -o '202[0-9]\", "id": [0-9]+' > ids

cat ids |wc -l gia plh8os tweets 

*old*
	strip only ids
	echo '{"created_at": "Thu Feb 11 07:04:40 +0000 2021", "id": 1359760245439012866, "id_str": "1359760245439012866"' | egrep -o '"id": [0-9]+'


	gunzip -c ht_coronavirus_*.gz "created_at"  |wc -l > ht_coronavirus_count

	STRIP ONLY the ids to separate file : 
	    gunzip -c ht_COVID19_21.gz  |    egrep -o '202[0-9]\", "id": [0-9]+' > ht_COVID19_21_tweet_ids.txt &

	    {"created_at": "Tue Mar 30 11:33:08 +0000 2021", "id": 1376860038279610369, "id_str": "1376860038279610369", "full_text": 

		gunzip -c ht_COVID19_136.gz |    egrep -o '202[0-9]\", "id": [0-9]+'

	TOTAL count for hashtags: cat ht_coronavirus_*_tweet_ids.txt |wc -l 

#dataset covid paper 

exei data kai edw 
ssh kantale@yperthen.ics.forth.gr

AD6FA287FE06

zgrep -Ec "created_at" ht_coronavirus_58.gz | wc -l
cat count_numbers |   sed 's/.*://' > a
ls -lh ht_COVID19_5?.gz

nas : <li></li>

#orkg.org/orkg/open-call-curation-grant

Describe your experience with semantic knowledge representation
I have published a Survey paper in Expert Systems: "A survey of Twitter research: Data model, graph structure, sentiment analysis and attacks". 




Describe 3-5 research questions you plan to document in the ORKG *

Twitter Bot detection
Twitter Analysis on Political Content/Elections (sentiment analysis, topic analysis)
Twitter Spam Analysis
Twitter Graph analysis in terms of growth of Average Degree



#nas 

scp -P 22599 test 139.91.71.12:./volume1/despoina/

ssh -p 22599 despoina@139.91.71.12


antonak_Nas1

gunzip -c ht_coronavirus_*.gz "created_at"  |wc -l > ht_coronavirus_count

zgrep -Ec "created_at" ht_coronavirus_58.gz | wc -l
cat count_numbers |   sed 's/.*://' > a


(base) despoina@aneipero:/storage2/coronovirus/test$ echo '{"created_at": "Thu Feb 11 07:04:40 +0000 2021", "id": 1359760245439012866, "id_str": "1359760245439012866"' | egrep -o '"id": [0-9]+'
	

#covid dataset paper: 

https://arxiv.org/pdf/2004.03688.pdf


1. count tweets

zgrep -Ec "created_at" ht_coronavirus_58.gz | wc -l


#parler: 

*parler analysis*
run lda and word cloud for part of the data. 
All results in cavalier /media/shevkov/parler/results and locally in /Users/despoina/GitHub/riotWhiteHouseHateSpeech/cavalier/

the number of the folder is the number of files scanned. 

sentimenyt analysis: sentiment_analysis_parler notebook locally /Users/despoina/GitHub/riotWhiteHouseHateSpeech/sentiment_analysis_parler


cavalier: 

cavalier ssh 
ssh despoina@139.91.90.29 !29

#remote sublime from aneipero 

ssh -i /Users/despoina/.ssh/id_rsa_aneipero -p 2222 139.91.71.13 
 ssh -R 52698:localhost:52698 -i /Users/despoina/.ssh/id_rsa_aneipero -p 2222 139.91.71.13




poia einai ayta ta exei wtse na valw egw to upoloipa na katevasw to covid 
8a to xanadiavasw kai vlepoume ti mporw na allaxw



28 April 2021
http://139.91.71.12:5000/

NAs : ssh -p 22599 despoina@139.91.71.12
aneipero
ssh -p 2222 139.91.71.13

scp -P 22599 test 139.91.71.12:./volume1/despoina/


edw anevazei to 8914.copy_nas2 output_graph.heuristic.final.uniq.gz 

antonak_Nas1

7/4/2021
PLOS review   :
This study based on a dataset acquired from Twitter applies an NLP analysis on the agenda-setting power.
Typos and small corrections:-------------1) The manuscript should be considered for proofreading. Some of the typos:a) There is an extra change of line in the text: “...framing strategically....”b) Is there a missing end of a sentence or is 'but' capitalized by mistake at "...unclear [19], But at the very least,.."c) Is there another missing end of a sentence in "...can select a topic, read. and..."d) There is a typo(I wrote) in a sentence: "...instance, I wrote a computer program to estimate the valence and arousal evoked by texts based on word measures..."
2) There are two figures numbered 9.

Minor comments:-------------3) Considering the Literature review:
a)It is not clear why you reference some of the background work. Where does your study differ from this, how is better it than the background work?Point out your difference, your novelty, and new contributions to the field.
There is a long and confusing part in this section, with scattered works and your study is not mentioned till the end: "...Our contribution belongs to the former category about the issue-volume aspect from diverse actors in the hybrid media system..."
b) There is some part in the literature review that is referenced in brackets. More preferable would be to make a short summary of the parts and points of the work that relate to your study. It is also important to compare your work with the current background work.c)About the fake news section: there is an important part of background work about fake news on Twitter that is missing. Please consider updating your background work with the most important and cited work (https://scholar.google.com/scholar?hl=el&as_sdt=0,5&q=twitter+fake+news)The same comment applies on the part of "influential individuals on social media". [Examples are: Everyone's an influencer: quantifying influence on Twitter, E Bakshy, JM Hofman, WA Mason, Measuring user influence in Twitter: The million follower fallacy]
d) There is also missing literature concerning emotion recognition [https://scholar.google.com/scholar?hl=el&as_sdt=0%2C5&q=emotion+recognition+on+twitter&btnG=]. If you are referring to sentiment analysis there is an important part of the literature that is also missing.
The literature review is long and scattered, not necessarily focused on the areas of this study, or at least not very clear how it is connected.
Major changes:-------------4) There is no section methodology, but a small dedicated part in results. This makes it hard to show how the results and some of the plots are generated, as I mention below in comment number 6.
5)Considering the dataset: "The data is gathered using an R-based program that interrogated the streaming Application Programming Interface (API) of Twitter. The database contains 482,869 messages from September 9, 2012, to December 16, 2015.”
a)Dataset is really limited …b)How is this dataset collected? Based on topics/ trending topics/keywords?c)How do exclude there is a bias and there is a relevance to your research topic that you are investigating?d) Considering the chapter “The Refugee Crisis in Europe” is this based on a different collected dataset based on the popular topics, since you mention: "In line with our central research objective, we limit our investigation to popular topics and conversations on Twitter relating to the refugee crisis in Europe“?
6) It is not clear how are the following figures were produced in terms of dataset acquisition, processing, and analysis: “Figure 6: Proportion of Tweets”, “Figure 7: Frequency of Tweets by Twitter Users”, “Figure 8: The Hashtags Network”, Figure 9:Emotion recognition, Figure 9: Emotion recognition,
7) How do you apply emotion recognition and Polarity? Do you use a package? a specific algorithm/methodology? [Figure 9: Emotion recognition]
8) Please expand the part of the polarity classification of tweets. Which classification algorithm do you choose? There are no classification metrics reported [Accuracy, Precision, Recall]
9)StructurePlease reconsider the numbering in chapters/sub-chapters.















This study based on a dataset acquired from Twitter, applies an NLP analysis on the agend-setting power. 

Typos and small corrections:
-------------
1) The manuscript should be considered for proof reading. Some of the typos: 
  a) There is an extra change of line in the text: “...framing strategically....”
  b) Is there missing end of sentence or is 'but' capitalized by mistake at: "...unclear [19], But at the very least,.." 
  c) Is there another missing end of sentence in "...can select a topic, read. and..."
  d) There is a typo(I wrote) in sentence: "...instance, I wrote a computer program to estimate the valence and arousal evoked
by texts based on word measures..."  

2) There are two figures numbered 9.


Minor comments: 
-------------
3) Considering the Literature review:

a)It is not clear why you reference some of the background work. Where does your study differ from this, how is better it than the background work?
Point out your difference, your novelty and new contributions to the field.

There is a long and confusing part in this section, with scattered works and your study is not mentioned till the end: "...Our contribution belongs to the former category about the issue-volume aspect from diverse actors in the hybrid media system..."

b) There are some part in the literature review that is references in brackets. More preferable would be to make a short summary of the parts and points of the work than relate to your study. It is also important to compare your work with the current background work.   
 
c)About the fake news section: there is an important part of background work about fake news in Twitter that is missing. Please consider updating your  background work with the most important and cited work (https://scholar.google.com/scholar?hl=el&as_sdt=0,5&q=twitter+fake+news)
 
The same comment applies on the part of "influential individuals on social media". [Examples are: Everyone's an influencer: quantifying influence on twitter, E Bakshy, JM Hofman, WA Mason, Measuring user influence in twitter: The million follower fallacy] 

d) There is also missing literature concerning emotion recognition [https://scholar.google.com/scholar?hl=el&as_sdt=0%2C5&q=emotion+recognition+on+twitter&btnG=]. If you are referring to sentiment analysis there is an important part of the literature that is also missing . 

Literature review is long and scattered, not necessarily focused on the areas of this study or at least not very clear how it is connected.

Major changes:
-------------
4) There is no section methodology, but a small dedicated part in results. This makes is hard to show how the results and some of the plots are generated, as I mention below in comment number 6. 

5)Considering the dataset: "The data is gathered using an R-based program that interrogated the streaming Application Programming Interface (API) of Twitter. The database contains 482,869 messages from September 9, 2012, to December 16, 2015.”

a)Dataset is really limited …
b)How is this dataset collected? Based on topics/ trending topics/keywords?
c)How do exclude there is a bias and there is a relevance to your research topic that you are investigating?
d) Considering the chapter “The Refugee Crisis in Europe” is this based on a different collected dataset based on the popular topics, since you mention: "In line with our central research objective, we limit our investigation to popular topics and conversations on Twitter relating to the refugee crisis in Europe“?

6) It is not clear how are the following figures were produced in terms of dataset acquisition, processing and analysis:  “Figure 6: Proportion of Tweets”, “Figure 7: Frequency of Tweets by Twitter Users”, “Figure 8: The Hashtags Network”, Figure 9:Emotion recognition, Figure 9: Emotion recognition, 

7) How do you apply emotion recognition and Polarity? Do you use a package? a specific algorithm/methodology? [Figure 9: Emotion recognition]

8) Please expand the part of “polarity classification of tweets.  Which classification algorithm do you choose?  There are no classification metrics reported [Accuracy, Precision, Recall]

9)Structure
Please reconsider the numbering in chapters/sub-chapters. 
















---------------------------


Our main contribution is the connection of the two social networks. This is the novelty of the study. In order to accomplish this we use common used techniques like sentiment analysis …++


This is not a study of prediction elections result, we acknowledge the bias that is in these kind of dataset (reference ...sto kommati mou lesei gai toi bias), our main goal is to connect the two  social networks

We are not focusing on the prediction of the electoral outcome, or sarcasm detection, but rather exploring the connection between YouTube and Twitter though a series of steps including volume and sentiment analysis.

although the dataset is biased and this make the task of prediction challenging, there is still a lot if information taht could contribute towards the connecton of the two datasets.  

*10/3/21*

PLOS ONE : Regarding demographics, Twitter users belong to a specific social group that is not necessarily
representative of the whole electorate. Specifically, studies have indicated that Twitter
users belong to a certain age [20], social [21] and ideology demographic group and, therefore,
express a partial opinion of the society at best. A study of 2011 concluded that, due to its demographics,
Twitter is by far inferior compared to opinion polls for elections prediction in the U.
S. [20]. Another study reported that existing political party classification systems, based on
sentiment analysis, are no better than random classifiers [22]. This indicates that sentiment
analysis methods are in their infancy and that they should be coupled with more sophisticated
methods that incorporate rich lexical properties and context indicators specific to each campaign
[7]. Fortunately, existing techniques can effectively assess and correct these biases [21].


Twitter and YouTube users do not fully represent the electorate during an election period, which consequently introduces a bias in the electorate dataset. Previous studies have shown that Twitter users belong to a specific age \cite{gayo2011limits}, social \cite{preoctiuc2015studying} and ideology demographic group. This means that the public opinion is not fully expressed through social media. 
*8/3/21*
#metakomish
#skype gia plos review comments
# perspective api gia parler 
#parousiash gia parler:An Early Look at the Parler Online Social Network
#new dataset from papaer Strigini https://zenodo.org/record/4442460#.YEYdU10zadZ

taxis net : 

user103281846
81846

antonakakidespoina
!d..gsisB

3/2/2021

*fake news dataset* 
labelled https://github.com/KaiDMML/FakeNewsNet

*parler analysis*
run lda and word cloud for part of the data. 
All results in cavalier /media/shevkov/parler/results and locally in /Users/despoina/GitHub/riotWhiteHouseHateSpeech/cavalier/

the number of the folder is the number of files scanned. 

sentimenyt analysis: sentiment_analysis_parler notebook locally /Users/despoina/GitHub/riotWhiteHouseHateSpeech/sentiment_analysis_parler
*covid*
sentiment labeled dataset for covid :https://ieee-dataport.org/open-access/coronavirus-covid-19-tweets-sentiment-trend-global
https://www.kungfu.ai/tracking-coronavirus-disinformation-on-twitter/
https://www.researchgate.net/post/Fake_news_dataset_for_COVID_tweets_or_text


21/1/2021

review

ANALYZING AND ESTIMATING POLITICAL ORIENTATION USING SENTIMENT ANALYSIShttp://ijai.iaescore.com/index.php/IJAI/reviewer/submission/36774

The dataset is old.  

poor english language (syntax grammar and expression, repeating words and unnecessary capital letters, punctuation marks in wrong place) 
These are some of the examples that show the poor quality in the expression, the text is really hard to read [abstract: 'Almost' repeating, In This research,"media and it has become ",intro: peoples, events.by, we are witnessed, Very Often , . And all are related about opinions, In the early eras, made the people, . The process of data preprocessing will be bone in May?.., A Tweets cane contains several emoticons, Remove it all the quotes from the sentence., Remove it of stop words is so important because these stop words are meaningless for classification process emoticons Removal , ]

Long introduction out of scope, 

Poor background work: important studies missing, like: 

		Liu KL, Li WJ, Guo M. Emoticon smoothed language models for twitter 405
		sentiment analysis. In: Aaai. vol. 12. Citeseer. Paris, France: Citeseer; 2012. p. 406
		22{26.

		Wang H, Castanon JA. Sentiment expression via emoticons on social media. In: 408
		2015 ieee international conference on big data (big data). IEEE. Santa Clara, CA, 409
		USA: IEEE; 2015. p. 2404{2408.


		Zhao J, Dong L, Wu J, Xu K. MoodLens: An Emoticon-Based Sentiment 411
		Analysis System for Chinese Tweets. In: Proceedings of the 18th ACM SIGKDD 412
		International Conference on Knowledge Discovery and Data Mining. KDD '12. 413
		New York, NY, USA: Association for Computing Machinery; 2012. p. 1528{1531.

		On Using Twitter to Monitor Political Sentiment
		and Predict Election Results
		Adam Bermingham and Alan F. Smeaton
		CLARITY: Centre for Sensor Web Technologies
		School of Computing
		Dublin City University  

		Prediction and analysis of Indonesia Presidential election from Twitter using sentiment analysis
		Widodo Budiharto & Meiliana Meiliana 

		Prediction of Indian election using sentiment analysis on Hindi Twitter, Parul Sharma; Teng-Sheng Moh

		Application of location-based sentiment analysis using Twitter for identifying trends towards Indian general elections 2014, O Almatrafi, S Parack, B Chavan

		Can Collective Sentiment Expressed on Twitter Predict Political Elections? Jessica Chung, Eni Mustafaraj

		Buzzer Detection and Sentiment Analysis for Predicting Presidential Election Results in a Twitter Nation, Mochamad Ibrahim; Omar Abdillah; 


		A sentiment analysis of Singapore Presidential Election 2011 using Twitter data with census correction
		Murphy Choy, Michelle L.F. Cheong, Ma Nang Laik, Koo Ping Shung

		Predicting elections with twitter: What 140 characters reveal about political sentiment A Tumasjan



References need reshaping, follow the same format for all of them, according to the journal .


Poor methodology . 

No results presented.  (The results are plotted in r studio automatically by plot libthe rary for a better view, their word clouds are also generated which are briefly described in the next section.)



13 January 

tempur (hrakleio) 041333782908 OK 
koorelloo 041194295142 OK
massimo 3724179830 taxudromikh OK 

dwro xari OK 
dpam mpoufan (hrakleio) OK 

maison scotch ? https://wwwapps.ups.com/WebTracking/processInputRequest?sort_by=status&tracknums_displayed=1&TypeOfInquiryNumber=T&loc=en_GR&InquiryNumber1=1ZX9425F6838635726&track.x=0&track.y=0&j=1498746&sfmc_sub=83842909&l=940_HTML&u=39077054&mid=7209203&jb=10209&utm_source=newsletter_trigger&utm_medium=email&utm_campaign=ao_transactional_r_OrderShipped_email&utm_content=tracklink&hem=a8eb06047c7888b018a020354113daac22feb22b982118bd21eb9f0fd3e92d9f&requester=ST/trackdetails
zini pros 8esal acs 5406722823 OK 

2 apostoles massimo genikh https://www.taxydromiki.com/track/3726332890 3726332901 
mia apostolh zara gemikh https://www.taxydromiki.com/track/3726362065
https://www.public.gr/checkout/public/orderComplete.jsp?_requestid=24403927





#BOT DETECTION papers: 


*from Detecting Social Bots on Twitter: A Literature Review*
-Three categories of methodologies graph-based, crowdsourcing, and machine learning 
-retrieving data from the Twitter stream
-next step involves preparing this data for the chosen classifier by extracting and selecting the features that
can be studied through statistical methods, or those that can be
manually labelled using previous work,

--In studies that have focused on machine learning methods:  combination of privately obtained
accounts and the public datasets
-public datasets as a ground truth baseline for testing their techniques
-Feature selection methods are commonly applied to increase
the speed of the classier, reduce the training time, improve generalization, and
avoid the overfitting problem.
--used a correlation-based system in combination with a principal
components analysis method



features 2D UMAP  dimensionality reduction . clustering me DP scan pernei mono ta components pou > 30 users panw apo 50% bots .


dialegouem clusters apo to db scan  panw apo 30 users mesa , estw kai ligo megalutera kai en aexei panw 


meta metrame an auto to cluster an anoikei sta bots 

true positive purity ..>83%   

10/2 review concordia

*bot detection* 
#  paper Deep neural networks for bot detection : SnehaKuduguntaa Emilio Ferrara b

Most works proposed to date detect bots at the account level, 
by processing large amounts of social media posts, 
and leveraging information from network structure, temporal dynamics, sentiment analysis, etc. 

Ferrarra  propopses 1) deep neural network based on contextual long short-term memory (LSTM) architecture that exploits both content and metadata to detect bots at the tweet level: contextual features are extracted from user metadata and fed as auxiliary input to LSTM deep nets processing the tweet text. 2) synthetic minority oversampling to generate a large labeled dataset, suitable for deep nets training, from a minimal amount of labeled data (ro




#21/12/2020

#CovidVaccine
#CovidVaccines
#GetVaccinated
#VaccinesSaveLives #GetVaccinated

#concordia: 

		Missiing from confluence : Pythia: Scheduling of concurrent network packet processing applications on
		heterogeneous devices [17]



		G. Giakoumakis, E. Papadogiannaki, G. Vasiliadis, and S. Ioannidis. Pythia: Scheduling of
		concurrent network packet processing applications on heterogeneous devices. In 2020 6th
		IEEE Conference on Network Softwarization (NetSoft), pages 145–149. IEEE, 2020.


		but papershttps://confluence.lrz.de/pages/viewpageattachments.action?pageId=130392628&metadataLink=true  is not editable!



elections georgia 

@ElectionGeorgia


In the context of the third pillar of T1.5, CUT is developing a machine learning method for detecting disinformation diffusion in Twitter.
As a first step, we collect the tweets IDs from github repository (\url{https://github.com/echen102/COVID-19-TweetIDs}). The repository contains an ongoing collection of tweets IDS associated with the novel coronavirus COVID-19, which commenced on January 28, 2020. The tweets IDs are collected from specified accounts and also collect in real-time tweets that mention specific keywords. The second step starts at the end of each month and includes the collection of all the extended information of all tweets IDs of the previous month. During the third step, we analyze all of the newly collected tweets information, extract any included URLs, identify those that are using URL shortening services and expand them into their long URL format. At this step we also collect all the keywords associated with the detected URLs. Overall the dataset includes around 850 Million tweets.


#Gvote 
#gvote2020
#Gvote2020
#Gvote20 
#Georgia today


#TbilisiProtests

 gunzip -c ht_coronavirus_*.gz |  wc -l

gzip: ht_coronavirus_71.gz: unexpected end of file
49632575

gunzip -c ht_coronavirus_*.gz |  wc -l
53.749.836 tweets 

gunzip -c ht_COVID19_*.gz |  wc -l
146.738.332


200.488.168 tweets
31.483.123 apo json 
###-------


scraper conspirancy theories  na kanoume ena scraper kai analusou,e 

social sciences , how conpirace propagete ktl . .. 








s$ gunzip -c  *.gz |  wc -l

gzip: ht_coronavirus_71.gz: unexpected end of file
49.632.575	

	ls -1lht *.json | head -17
	ls -1t *.json | head -16 > a
	cat a  | xargs -I '{}' mv {} new/
	cd new
	scp *.json  despoina@139.91.90.29://media/disk2/usElection/data


media/shevtsov/usElection/data   
	mv * ../

	(\#2020election(s), \#2020usaelection, \#Biden, \#BlueWave2020, \#donaldtrump, \#Election2020, \#Elections\_2020, \#MyPresident, \#November3rd, \#NovemberIsComing, \#trump2020, \#VoteBlueToSaveAmerica, \#Vote etc.)


ls -1t ht_donaldtrump_* ht_Trump2020_* ht_Biden_*  ht_BlueWave2020_* | head -17 
ls -1t ht_donaldtrump_* ht_Trump2020_* ht_Biden_*  ht_BlueWave2020_* | head -17 > a
cat a  | xargs -I '{}' cp {} code/
*
    

	cat states  | xargs -I '{}' grep -o {} ht_Biden_*  |wc -l  
	cat states  | xargs -I '{}' grep -o {} ht_donaldtrump_* ht ht_Trump2020_*  |wc -l  
    grep  -o Georgia ht_Biden_* | wc -l






(base) despoina@aneipero:/storage2/coronovirus$ grep -o 'I got infected'  ht_COVID19_*.json |wc -l
(base) despoina@aneipero:/storage2/coronovirus$ grep -o 'I got infected'   ht_COVID19_98.json |wc -l
(base) despoina@aneipero:/storage2/coronovirus$ grep -o false negative'   ht_COVID19_98.json |wc -l
> grep -o false negative'   ht_COVID19_98.json |wc -l^C
(base) despoina@aneipero:/storage2/coronovirus$ grep -o 'false negative'   ht_COVID19_98.json |wc -l
18
(base) despoina@aneipero:/storage2/coronovirus$ grep -o 

*17/11/2020*

"The Seven Deadly Sins of the HTML5 WebAPI: A Large-scale Study on the Risks of Mobile Sensor-based Attacks", TOPS'20
Publication:ACM Transactions on Privacy and Security July 2020 Article No.: 19 https://doi.org/10.1145/3403947

H parakatw paragrafos sou kanei?

My research focuses on investigating the privacy leakage in modern smartphones since their ubiquitous nature has rendered them a treasure trove of sensitive user data and personally identifiable information. I have also worked on how mobile sensor data can be used for a plethora of attacks using the HTML5 WebAPI. Currently, my research focuses on identifying security and privacy threats that mobile users face and designing protection mechanisms for better protecting users.


Wed, Jul 15, 2:47 PM

1) I am working with different security and privacy issues in the Android OS (internals) as well as its applications.
2) "The Seven Deadly Sins of the HTML5 WebAPI: A Large-scale Study on the Risks of Mobile Sensor-based Attacks"
    Publication: ACM Transactions on Privacy and Security (TOPS) July 2020 (Received September 2019; revised February 2020; accepted May 2020)
3) None

Sorry for the delay
diamant

 + phd symposium



*16/11/2020*


On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks


This paper presents a study on unsupervised technique to detect growing-up behavior of malicious accounts in WeChat (a Privacy-centric mobile social networks (PC-MSNs),). The results are satisfactory (90% and an AUC of 0.95) , it has been compared with three state-of-the-art techniques and outperforms these techniques (achieves 2x recall than these methods with similar precision). They have studied well similar works and provide a thorough comparison, they inspect accounts from multiple perspectives by using multiple behavior , provide 3 kinds of evasion strategies for each behavior and  a propose a robust detection technique.  They also provide a reason why use unsupervised ("existing behavior-based detection techniques are unable to detect such growing-up accounts because they cannot capture the slight differences between growing-up accounts and benign accounts") 
and they conduct feature analysis to prove this. 

The language and expression is fine with no error in dictionary or structure. 


Some minor comments: 
 
1) As noted in the text : "These accounts pose strong malicious intents and thus are easily detected by off-the-shelf behavior-based detection methods..."" which off-the-shelf behavior-based detection methods do you use?


2) Not clear why use random walk and how does this help ? How overcome the disadvantages : 
We discuss the applicability of this query and show that its direct evaluation using existing methods on RWR-based similarity
search has very high computational and storage demands.



Other question that are addressed in the paper :


4)They claim it is the first but there is previous work which is referenced [28]on WLink,: Characterizing and Detecting Malicious Accounts in Privacy-Centric Mobile Social Networks: A Case Study
https://dl.acm.org/doi/abs/10.1145/3292500.3330702. How do they differ from background work, novelty ? 


*12/11/2020* 

*review* On Detecting Growing-Up Behaviors of Malicious Accounts in Privacy-Centric Mobile Social Networks


This paper presents a study on unsupervised technique to detect growing-up behavior of malicious accounts in WeChat (a Privacy-centric mobile social networks (PC-MSNs),). The results are satisfactory (90% and an AUC of 0.95) and has been compared with three state-of-the-art techniques and outperforms these techniques (achieves 2x recall than these methods with similar precision). They have studied well similar works and provide a thorough comparison, they inspect accounts from multiple perspectives by using multiple behaviors , provide 3 kinds of evasion strategies for each behavior and  a propose a robust detection technique.   


1)They claim it is the first but there is previous work which is refrenced [28]on WLink,: Characterizing and Detecting Malicious Accounts in Privacy-Centric Mobile Social Networks: A Case Study
https://dl.acm.org/doi/abs/10.1145/3292500.3330702. How do they differ from background work, novelty ? 


2) "These accounts pose strong malicious intents and thus are easily detected by off-the-shelf behavior-based detection methods..."" which off-the-shelf behavior-based detection methods do you use?

3) In chapter 3.2 you are referring to malicious accounts, growing-up accounts, and benign accounts, but you have not mentioned the methodology by which you recognize  these types of accounts: 

e.g. " ...We observe that growing-up accounts tend to frequently reuse IP addresses, while benign.."" 

You should first mention how you label the accounts growing-up accounts/malicious/benign (e.g in plot 1.a you mention malicious but is not clear yet how you identified? manually ? dow you identify by conduct malicious activities? still not clear, it is first mentioned in 3.2 last paragraph before client version )==> The labels are provided by WeChat and obtained
by inspecting accounts’ information such as illegal head
image, offensive nickname or illegal post contents, etc.


4) Nice they provide also a reason why use unsupervised : 

4.1 Therefore, existing behavior-based detection techniques are unable
to detect such growing-up accounts because they cannot capture
the slight differences between growing-up accounts and benign
accounts

and conduct feature analysis to prove this!


5) not clear yet how the bipartite graph of the account - behavior graph is contricted : Each node in the
bigraph represents either an account or an attribute of a behavior.
Each edge between an account and an attribute means the
account has the attribute.

6) not clear why use random walk and how does this help ?


how overcome disantantages : We discuss the applicability of this query and show that its
direct evaluation using existing methods on RWR-based similarity
search has very high computational and storage demands. T?


7)However, the random walk method also has some major disadvantages
 First, it does not exactly conserve the mean position of the vorticity in free space. Next, the computed solutions are noisy due to the statistical errors. In flow control studies, the statistical errors could mask the effects of varying the control parameters. The statistical errors can also cause symmetric flows to turn asymmetric erroneously. To reduce the statistical errors requires a very large number of vortices.


8) Very nice for Therefore,
we propose to combine the account’s three malicious scores into
a single one. We also note that such a combination enhances the
robustness of Muses against evasion attacks,


9) How you considered, how addressed :  RMSE gives a relatively high weight to large errors. This means the RMSE should be more useful when large errors are particularly undesirable. ? 
*ideas for OUR bot detection : * 

(i) How many IP addresses one account has ever
used? This answer indicates the mobility of the account. (ii) How
many accounts have ever used the same IP address? This answer
indicates the aggregation of accounts.  cumulative distribution function (CDF) of the number of IP. benign accounts is
between that of malicious accounts and growing-up accountsIntuitively,
benign accounts use a small set of IP addresses because they
have fixed daily routines and therefore tend to stay in a relatively
small number of places. Malicious accounts may maintain a large IP
pool to ensure the diversity of IP address and frequently switch the
IP address so as to evade IP-based detection or blacklisting.. However,
growing-up accounts would pretend to be benign in the early
growing-up period and tend to reduce the number of activities,
resulting in using a relatively small number of IP addresses.

10 ) Louvain or Leiden? 

  algorithm is faster than the Louvain algorithm and uncovers better partitions, in addition to providing explicit guarantees.

Louvain (LV), Fast Greedy (FG), MarkovCluster (MC), InfoMap (IM) and Walktrap? why not MarkovCluster
InfoMap  which accounrinf to 

Similarity of accounts Twitter with Random Walks


https://towardsdatascience.com/similarity-of-documents-with-random-walks-98f94fd2c76c
https://medium.com/walmartglobaltech/demystifying-louvains-algorithm-and-its-implementation-in-gpu-9a07cdd3b010

*bot detection sto elections 2020 dataset* 
	
	Mia polh kalh texnikh gia unsupervised bot detection einia h exhs: 
	vhma 1) 
	apply random walk technique sto grafo twn accounts wste na metatreyeis to bipartite graph se weighted graph gia na montelopoihseis ths sxesh twn accounts metaxy tous
	vhma 2) efarmozeis community detection gaio clusterinf sto weighted grafo 
	kai exeis set of communities 
	kai ekei efarmozes mia metrikh gia to poso exei sumperifora bot ena account 
	telos les gia ka8e account exeis exa score me vash to score tou community pou enoikei 
	moiazei polu me ayto pou mou eipes to prwi 
	autos o grafos mporei na einia kai o RT grafos
	(to xerw oti eipa na to doume meta to ekloges paper) alla h8ela na sto steilw na mhn xa8ei stis shmeiwseis mou 


*MIMIC*  

telco 6/10/2020  
extract features apo drugs (Alex)- mail vinzenzo - download se xronoseires 



*IDEAS*: 

#sentiment paradox in Twitter* 

#30/10
POluvios : 
Note that (i) there was a lot of traffic generated by the debate, (ii) the total sentiment shows that the extra traffic was not just proportionaly loaded with sentiment, and (iii) the normalized sentiment confirms that not only was there more traffic, but the discussion was more heated too.


#20/10
bot detectoin works: : IEEE Transactions on Dependable and Secure Computing , International Conference on Social Informatics, arxiv , Icdm, 


#14/10

texnikh yphresia
τεχνικη υπηρεσια

IP 
IITEIP


for tweeting
@Guard_Project @SMESEC_EU @CE_IoT @Ideal_Cities @certcoop @cybersure_eu @VisorSurf @semiotics_eu @ArrestThreat @Ibidaas
@project_resist @concordiah2020  @c4iiot @ROXANNE_project @CyberSANEH2020 @spiderh2020_eu


#8/10
	* arxiv : den dexontai to paper bot detection xwris onomata 
	* script gia to state trump: /Users/despoina/Github/elections2020/final_count_states.py 
	* 





#2/10 
	* stamathsame na vazoume sata ekloges sthn vash tou election paper
	stamathsame na metaferoume sto media/shevtsov/usElection/data    kai twra pane sto //media/disk2/usElection/data
	neo hashtag #DEBATE
	neo anazhthsh ana politeia kai plot ana politeia: grep  -o Georgia ht_Biden_* ht_ | wc -l (SCREEN name: count_states)
	neo hastgas #VoteBlue2020  321M Oct  2 11:46 ht_VoteBlue2020_1.json
	new HT #TrumpHasCovid

#1/10 

	attached 8a breis to quarterly report gia to FORTH gia thn periodo Q2 (01.04.2020-30.06.2020)
	Kane ena update gia to WP1 kai meta 8a to steiloyme sthn Ivana.

	Shmera 8a etoimasw kai to Q3 (01.07.2020 - 30.09.2020) kai 8a soy to steilw na to kaneis ki ekeino
	update (WP1).

#29/9
* todo : vale figures marias 
* des ta results na pame telos 
* ftiaxe lda



#28/9 

	

	1. use combination of Hashtags 
	2. Diurnal patters 
	3. Bursts/spikes in traffic
	4. Profile completeness automation 

	https://www.nortonlifelock.com/blogs/research-group/identifying-sockpuppet-accounts-social-media
	https://twitter.com/botometer?lang=el
	https://botometer.iuni.iu.edu/#!/
	Botcheck.me
	https://github.com/mkearney/tweetbotornot 


#24/9 
* paper elections: *TODO* Apo MAria mporeis na deis auta ta grafimata sto carv git YoutubeAnalytics/plots/figures 8es na anevasw ta grafhmata sto diko mou git ?


* ekloges , 
	crwil tweets me vash 

	kanoume extract ta you tube links ..mono osa ienia videos. mateyame data gia ayta ta viedeos kai commeter , phrame sample apo commentrers 

	opote exoume grafo commenetrs/channels .
	trexame page rank kai clustering modularuty 

	vgalame ena cluster graphnng

    *TODO* github vale collaborators - DONE  

	*TODO* arXiv to bot detection - nomizw oti den ginetai na anevasoume to bot detection dedomenou oti to exoume kanei submit sto journal - *TODO* mail ston editor
	* arxizoume to keimeno mexri Sabbato kai arxika to anevazoume sto ArXiv to prow8oume mesw sns an den exoume sxolia to steloume WWW 12/10 

*mimic* 
   #Trith 15;00 epomenh suanthsh sto mimic 
   #perl tool apo Dimitri 


#hashtags on US elections 2020 study 

			2020Election
			#2020Election
			@2020ElectionPo1
			iVoted
			#Elections2020
			@USAElect2020
			JoeBiden
			2020election10
			NeverTrump
			#RVAT2020
			#BidenHarris2020
			#VOTE2020
			@Vote2020M
			#Vote
			#iVoted
			USAElect2020
			elections.2020
			elections2020
			#Elections_2020
#22 September 2020
* review Concordia 
...comment for WP1:  Congrats! You have done an amazing work in research! just some food for thought and possible  further discussion later: Covid-19 can help in the aspect of increased cyber-attacks. It is an interesting case scenario also for further research, to have a research scenario base on..eg. *profiles of  Covid-19 cyber attacks and attackers* 


#21 September

* us elections : check these: https://blogs.microsoft.com/on-the-issues/2020/09/10/cyberattacks-us-elections-trump-biden/
older: https://www.boxcryptor.com/en/blog/post/social-bots-detection-examples-of-political-impact/
	* sent Alex about bot detection in us elections DONE
		1. use combination of Hashtags 
		2. Diurnal patters 
		3. Bursts/spikes in traffic
		4. Profile completeness automation 

			Βρήκα και αυτά: 
			1. https://www.nortonlifelock.com/blogs/research-group/botsight-tool-detect-twitter-bots

			2. https://twitter.com/botometer?lang=el
			3. https://botometer.iuni.iu.edu/#!/
			4. Botcheck.me
			https://github.com/mkearney/tweetbotornot
			5. BotSlayer [5] is an application to detect and track potential manipulation of information on Twitter;
			6. the Bot Repository [6] is a centralized database to share annotated datasets of Twitter bots.

https://pushshift.io/twitter-user-search/

#18/9/2020
*concordia review rehearsal*

9:00 review 
13:40 FORTH 


*TODO : see simon ML 
start literature review for elections study - 
write short bio*


ΝΕW
NEW 
Access:

    Meeting URL https://us02web.zoom.us/j/81171979468?pwd=VGZwNnBWQ0RWV1RmUjRQeC9ac1pFZz09

    Meeting ID: 811 7197 9468

    Passcode: 189948

Join Zoom Meeting
https://us02web.zoom.us/j/82043214709?pwd=Z0JkUktkajVUS3FNUEs3SFFTaHUzdz09

Meeting ID: 820 4321 4709
Passcode: 959052


OLD #concordia 1.1  #zoom meeting for 1.1 task
  https://us02web.zoom.us/j/87165775340?pwd=b24rS0RjcWE2RmJvQ1J6L2RBaGlwQT09
  Meeting ID: 871 6577 5340  Password: 643291



#JAD BIO sunanthsh
* platforma gia analush dedomenwn (kuriwn iatrikwn-genomikwn) me polu filiko perivallon gia to xrhsth.
* den upostirizei big data se klimaka ekatomuriwn samples all exei dokimastei  se mikra iatrika dataset (exei paradeigmata sethn selida)
* gia ti dataset milame se auta ta project?  8elw ena input sxetika me thn fush kai ton ogko twn dedomenwn wste na doume kata poso kanei fit se ayto to ergaleio 
* 
*Smart bear project providesdata aggregated from IoT devices from subjects dealing with issues like hearing loss, cardiovascular diseases, cognitive impairment balance disorders and mental health conditions.
The analysis of this data requires sophisticated machine learning techniques and state of the art algorithms. JADBIOoffers an autoML solution that is mostly tailoredfor biomedical andclinical data.JADBio platform takes as input a CSV file. Rows are patients and columns are features (i.e. age, gender, systolic pressure, disease, ...). Users select a "target" column as the desired feature for which they want to have a prediction model. This model can be one of the following three: (1) Classification for binaryfeatures (i.e. DISEASE, NORMAL), (2) Regression for continuous features (i.e. severity of disease) and (3) Survival analysis for time to event features (i.e. time between diagnosis and death). The AutoML mechanisms of JADBio investigate a range of multiple machine learning algorithms with another range of ML parameters (called hyperparameters). After applying multiple combinations of these parameters JADBio reports the "winning" algorithm and parameters. JADBio investigates three major families of ML algorithms: SVM, Decision Trees and Forest Trees (XGBoost). At the end JADBio reports all known ML efficiency indicators such as precision, recall, accuracy, sensitivity, specificity, truth tables (TP, FP, TN, FN), F2 and AUC. It also provides very useful interactive plots with these measurements. One major feature of JADBio is that users DO NOT have to split their data in train/test datasets. Instead it applies its own cross validation schema which according to JADBIo is (1) unbiased and (2) reports conservative estimations of the efficiency indicators. This means that not only it does not inflate indicators but the "real" values are usually higher than these reported. Also JADBio has options to report only interpretable models (i.e. decision trees) instead of black-box models. Other features include: (1) ability to download a java executable (jar) with the trained model which users can apply to new samples, (2) extraction of equivalent features (set of features with equivalent classification ability), (3) extraction of CSV files that contain the datapoints of the plots for further refinement during plotting in publications. JADBio comes with a team of ML and statistics experts that can help you use the platform, interpret the models and apply optimal analysis pipelines. This supporting team of the platform was very helpful.
Some consideration regarding JADBio are:We are not sure if the platform will work with datasets that have more than 50000 samples. In case of datasets in this scale it could be a good idea to consult the JADBio team.JADBio is a proprietaryplatform which means that reviewers and paper readers will not be able to reproduce the analysis. This might be a "blag flag" during paper review. In medical journals this might not be the case since it is common to perform the analysis with closed source tools (i.e. SPSS). Nevertheless in Computer Science journals this might raise concerns.

The nature of the data provided by smartBear, as well as the volume of them are appropriate for this platform. JADBIO has been tested successfully for this kind of data and the usage of thisof it will be a benefit for the project.*

*smart bear* : xreazete clibnical study . gia ena giatro tou dinei ena indication alla 8a prepei na gineie validation. 
  pateraki : 5000 samples apo diafores xwres ? 
 ta data exoun polles glwsses?
 ti dedomena? episkeyeis ara natural text?
*
-->  pros to telos tou ergou 4mish xronia  (logw covid) 8a gienie to call gia na exoume data . isws gia testing 8a mporouse na dokimastei kati . 


*  dedomenwn rologiwn (smart watches. zigaries , 8ermokrasia ktl. ) balance --> akoustika 
cognitive impairment, depression ktl. 
* sullogh apo giatrous 
* exei kleisei to 8ema ths arxitektonikhs ...epilogh devices ...kalo timing 
* diaforetika patient groups ..

*ena allo ergo* einai sta misa einai ston deutero kuklo . 


* API, mporei na douleyei san module..? oxi .

*ASCAPE* ..: federated learning breast cancer . mesw escape node mpou mpainei mesa sto nosokomeio . noumera apo exetaseis ...
algori8mo apo partner . Ara den vlepei fit. Emeis eimaste sto kommati tou security. 8a vgaloun ena deytero open call ..isws se authn thn fash 8a mporousan na sunergastoun   --> quality of life interventions. 

*AI for health sec* ...apo onktwmvri akomh den xeroume . 
*cybersane*  : ML intrusion ...sugkekrimenoi partntners me ergaleia tous. oute ekei teriazei . encrypted traffic data .  -- den uparxei oute ekei dataset. 



alex: 8a xreiastei regression . random forest sunu8ws xrhsimopoiei to jad bio . 






piatsrtakia malliwn 
fanelakia
paoutsia a8lhtika elenhs
athanat@ics.forth.gr>
cc:	Maria Pateraki <pateraki@ics.forth.gr>,
Andreas Miaoudakis <miaoudak@ics.forth.gr>,
Christos Tzagkarakis <ctzagkarakis@gmail.com>,
Sotiris Ioannidis <sotiris@ics.forth.gr>

#15/9/2020 skype vicky, christon, alekos , dimitris

* simon https://genular.org/simon-machine-learning-tool/
* completed forms for survey paper ! we are ready to publish !https://authors.elsevier.com/authorform/landingpage/selection.do?aid=114006&jid=ESWA&md5key=c177f4f7c4ccbb6d8708430ee61d9d89&lang=English
* completed proof reading for survey paper



#10/9/2020 

* submitted bot paper to *social networks* journals 
*  https://github.com/kantale/eicu_forth/blob/master/task_1.ipynb
* diafores ayths ths vashs me mimic me vash ta ICD9 
* https://eicu-crd.mit.edu/about/eicu/ istoria ths vashs 
* https://github.com/MIT-LCP/mimic-code/tree/master/concepts
* Trith 22/9 16:00




#9/9/2020 skype vicky, christon, alekos , dimitris

died_not_in_admission
died_first_admission
NOT_DEAD
died_later_admission
vicky: maybe we just need 2 categories: died later, now - 8a to doume kai argotera 

ti open source uparxpoun AUTO ML
na exeis to mualo sou thn vicky an einai user friendly

lda tutoria steile
Trith 10:00 
apalagh efka afou to plhrwnei to ite - mhniaies tis plhrwnei ....  


8/9/2020
1) copy dataset eklogwsn ston alex cavalier
2) xekina literature review gia do_COVID19
3) des plots paidiwsn gai ekloges..
4) dhmhtrhs - skype - vicky 
5) bot detection proof reading :
ask for comment in the text : 
comments : 
		 explain why we choose 5% threshold.	
		 Alexander: Some of bul- lets are al- ready used in section 2 and section 2.4. Solution remove bul- let 2-3 and describe it as filtering
	 	be consistent in tense past or present? 

6) more often skypes- poke foithtes - ti exoun kanei sxolia 
7) literature review gia ekloges paper 
8) physionet nea vash vickys



Alex pws paei me ta grafph sto eklodges? pws paei me to sentiment ? rwta ton gia ta sxolia sto bot detection 
cavalier ssh 
ssh despoina@139.91.90.29 !29



#29 July 
if ps -ax |grep -v "grep"| grep "do_COVID19" ; then echo "vrethike"; fi 

trexei sh 2020election.sh
evala enw etrexe sto idio para8uro 
trexei to sh 2020elections.sh
evala enw etrexe sto idio para8uro 
sh Election2020.sh 

evala na trexei enw etrexe sto idio para8uro Trump2020.sh
dUSElection2020.sh

#28 July 
script running for : 

2020election (.sh)
Election2020.sh
USElections
USElection2020
Trump2020
2020elections
uselection
USElections.sh


#24 July 


US elections 2020 : 
hashtags: #Election2020, #2020election, Election 2020 Polls
#TrumpConspiracy
#2020election
2020 Election Ride Home Podcast
#uselections

Election2020
@myelection2020
#uselection
#USElection2020
#Trump2020
#MAGA
#teamjoe #election2020

#23 July - concordia input for periodic report: 

*task 1.1*
*task 1.4* gchristou 

During this period we focused on the enhancements of our existing framework for Liability based trust. We studied the integration with state of the art tools and methods, in order to tackle the challenges of cuber insurance.  

We continued the development of our framework for creating and managing
cyber insurance policy for cyber systems, through the necessary policies and necessary tools. 


carvgit 
Despoina:bot_detection_2019 despoina$ git pull https://despoina@carvgit.ics.forth.gr/Social-Network-Analytics/BotDetection.git master 

#TODO : vale sthn parousiash tis dior8wseis tou markatou ok - presengtation : presentation_FINAL.pptx
#survey paper 
# aithsh eptamelous 
# hotel vienna



Type of publication*
Open access? (Yes/No)  if yes - give green or gold Open access**
Peer-reviewed?(Yes/No)
Public-Private Publication***? (Yes/No)
Explicit ACK to Concordia?


(Yes/No)

# 7/11/2019
	*finally fixed Greek in latex :*
	\usepackage[utf8x]{inputenc} 
	kai \textgreek{} 


ελληνιακ αστο Λatex: http://string-functions.com/encodedecode.aspx

vale apo iso8859-7 se iso 8859 - 1

#elearn

csdp826@csd.uoc.gr
https://elearn.uoc.gr/
face γιψργοσ g14021964a


#######################

engine for TexShop : 
Library/TeX/texbin

changed to /Library/TeX/texbin

ok xelatex plays!!
then download https://fontlibrary.org/fr/font/source-sans-pro
and type in commandline: sudo unzip /Users/despoina/Downloads/source-sans-pro.zip  -d /usr/local/texlive/texmf-local
https://tex.stackexchange.com/questions/49736/font-installation-in-texshop-on-a-mac
sudo texhash
mktexlsr
sudo updmap-sys --enable Map=cmu-serif.map


kai pali den epaixe opote egkatesthsa to xeLatex apo edw http://www.texts.io/support/0001/

kai meta den epaize oute to latex. !! oute commandline oute texShop!!

munhma out to texshop: munhma: multirow.sty not found
Apo edw https://tex.stackexchange.com/questions/298794/latex-error-file-multirow-sty-not-found

 opote egkatesthsa to  tlmgr install multirow 
9afou prwta ekana updateto  tlmgr me tlmgr update --self


######################


erwthseis :

You want to play musical chairs with your kids and do not know how to make your mac mute the music after a random number of seconds? Open Terminal and type: sleep $((15 + RANDOM % 25)); sudo osascript -e "set Volume 0"

44 domains =(GMF) domains. RBL blacklists withthe word \follow" a=62 domains. GMF spam=62+44=106
 RBL:, 1,911 domains flagged as spam--1429 IPs . BUT 91 false positive [manually]

epishs ftiaxe ta upokefalaia tou plos paper .
40748 users referendum (arxeia sto ▸ ⁨github⁩ ▸ ⁨phd⁩ ▸ ⁨jupyter> referendum_user_stats.csv⁩)19093 users electionselections_user_stats.csv (downloads)

να αχς ανοικτα καποια τςεετσ παραδειγματα απο πλοσ πειπερ και σπαμ;



*ite apozhmoiwsh*
ρςμη 460 + ημερησια 200 = 640  ==> katreas gia loyx TELIAK 665 
λυουξ 231+381 =612 eishthria (KATREAS) + 400 jenodoxeio + 240 hmerhsia = 640 
250 acm 

25/10/2019

#concordia WP leaders telco  at 11: https://global.gotomeeting.com/join/317660845 
   		
	yaxe meta giati den pernw ayta ta mail . xanagrayou se oles tis listes !
	WP1: Aiko  we had a nice meeting in Lux. regarding deliverable sis in control !
	WP2:  WP2 is ok  also . pilot are well except one. good shape . BMW use case silence!!!no participation in telcos. 
		end of month. 
	WP3: Neeraj everything on schedule .
	WP4: Felicia  Gaby	with summary report. progress as planned . 
	WP5: (christos) daily activities and other activities of concordia , 
	      blogs and mini website ...many exploitable results , collaboration with SPARTA with TOC 5.1 all task of WP5. 

	WP6:       (christos) review of deliverables 1/12 - 15/12 maybe short Felicia says. 
  
  sotiris  about quality control.   


  22/1 rehearsearl  
  23/1 review


  si: progress in project? demos of things that work. demos in pilots. we have to make sure that we show progress. 
  tangible. program running. or drone .. e.g for WP1 technologies :    
  we have to see beforehands the technical works. not one day before . to select the best demos. 
  Ivana schedule a date to show the demo. initial selection of demos. 

  5 vertical 5 horizontal . 

  task leaders from pilots : get together the technical peoples with the ones that the are working . 
  this is already happening 

	80 people . coffee places. with rooms you can rent. 

	WP1 phd students . Aiko. get them togetehr to real collaborate . ?? how ? 

# telco MB

review agenda? 
sotiris: we have an agenda, maybe not final . 
Suri: maybe demos take a lot of time, community building, 
doa indepenent ethic advisors: one name : 

#chech if Faraz has the iban 




winter school ! 6 phd students . 
2nd . selena bruno 

women cyber in spring in brussels ! barbara leads this. all women in concordia and some important people...
not final ...need planning 
mentorships, scholarships, 
cod event german europena agency ?? july 
general assemply  
olso june 



events : 14/11.. Munich telco . sto prohgoumeno . h egw h o xrhstos. o si 8a einia remotely . face to face or remotely . european parliament . 
try to be there but if not possible , connect via video .  

2.5 munich meeting . 


#23/10/2019=========


vale sta comments ths parousiashs
definitions 

The effective diameter of the graph over time,
which is defined as the minimum number of hops in which
90% of all connected pairs of nodes can reach each other.
It has been observed that the effective diameter generally
shrinks or stabilizes as the graph grows with tim


precision tP/TP+ FP  = tweets pou ekane swsta classify sasn sasracs /ayta pou tou dwsame . 
opote deixnei apo ayta pou ekane classify posa ekane swsta


recall = tP/TP+FN = tweets pou ekane swsta classify san sarcasm /ola ta labeled sas sarcasm 
opote deixnei posa ekane swsta classify apo ola pou eixe to dataset. posa exase se ola ta sarcastic. 


f1= 2*precision*recall/precision+recall

it measure the test's acuracy: it tells you how precise your classifier is (how many instances it classifies correct and how robust (it does don misss significant number of instances))

*Apories !*

1) plot the volume of referendum tweets per
hour. We focus only on tweets that contain either voteYES or voteNO entities.

auta ta vote YES, vote No einai apla apo katametrhsh ton YES/NO hts + text . den aini kapoio classification ? oxi den einia classificatin einai ta entity YES kai NO 

2) Fig 3. Variation of YES percentage: h ptwsh twn yes sta capital controls: temporarily strengthened the ªNOº sentiment giati den fainetai sto YES na peyftei ? 

h mple grammi einai to plh8os twn users. 

h mple grammh vgainei ws exhs. pernoume to entity YES kai vglepoume se ola ta tweets pos apo ayta exoun to YES entity . meta vrikame posoi xrhstes antistoixoun. 

h diakekomenh : px. stis 3 ioulioi eixame 500 yes kai 100 no ara to postsoto twn yes  500/500+100


3)This finding is suggestive that ªYESº users were engaged in an orchestrated
campaign to promote ªYESº content. (selida 11)  ara stelnan perissotera YES tweets? gaiti den fainetai auto sto plot fig3

oi YES xrhstes einai ligoteroi!

4) selida 14 pws diavazeis to figure 8?

to kentro tou  koutiu  einai ousiaatika h median timh , olo to kouti mas deinxei thn katanomh kai h kokkinh grammh mas deixnei tis pragamtiske times  
 https://www.simplypsychology.org/boxplots.html

t
5) Fig 10. Change of sentiment between referendum and elections. ti einai o axonas x ,y  enai  h xronika  periodos apo to referendum pros elections? 
To measure this, we split users into two
disjoint groups: the ªYESº voters and the ªNOº voters. We also kept *only* users that have
posted in *both referendum and elections datasets*. For each user in every group, we measured
the average positive and negative sentiment for each entity in both datasets. Finally, for each
entity, user group and sentiment, we applied the Mann-Whitney U test between the average
sentiment of this group in the referendum dataset and the average sentiment of this group in
the elections dataset. In Fig 10 we show entities for which the sentiment was significantly
changed (p < 0.001).

h arxh tou velakiou dixnei to sunais8hma gia to entity sto referendum kai to telos tou velakiou to sunais8hma gai to entity stis ekloges. to mege8os tou velakiou dxienei poso polu allaxe phge px. apo -2.8 mexri -2,1 gai ton suriza enw gai to media phge apo -3,1 mexri 2,1 . 

1) 
	http://www.thesarcasmdetector.com/
	-100...100
	I think you are almost clever :P ! 52sarcasm 
	I think you are  clever :P !41 
	I think you are clever !4 

yes of course you are beautiful 25 

	ti einia auth h klimaka? 

	-100 ..0 einai non sarcastic
	0 ...100 einia sarcastic 

	2) valeparousiash https://en.m.wikipedia.org/wiki/Precision_and_recall

=================

9)poluvios:We are performing incremental measurements of the average outdegree, for every day of the dataset, in both datasets. 
	
	Next, we fit the Leskovec model, to a sliding window" of the average outdegree.
	The size of the window was 200 days and it was moved from the first 200 days of our dataset to the last 200 days, with a time-step of one day.
	2)Figure~\ref{results_2006_2012_OVERALL_1} presents the same plot for the \textit{KWAK} dataset,  pws vazoume se xronikh seira tous xrhstes? me vash to craetion date tou xrhsth? 
 ok 

8) magoutis 8a rwthsei gai systems, pw ulopoh8hkan. isws ta parallelized


7) epishs h grammh an pernoume sample apo p.x sto shmeio 4 exoume 40 ekatomuria xrhstes pernoume sample kai metrame to average outdegree? alliws 8a eprepe na eixame ena fasma an metrousame gia olous? ti akrivws metrame ?  



	exoume polles times apo average degree panw sto plot mas . estw mia timh sto shmeio x,y 8eloume na doume me ti functiona uxanete opote exw treia eidh : super liner growth - logarithmic linear kai mernoume ena para8uro 100 meres mprosta , 100 meres pisw kai vlepoume me ton Levenberg–Marquardtpws kanei fit. pernouem dhladh ta least squeare error kai leme oti kanei kalutera fit h sunarthsh gai thn opoia mas vgazei mikrotero error. 
     eikona 6082 Github/phd/___CSD


     16) of the average outdegree, for every day of the dataset.
Then, we fitted the Leskovec model, to a “sliding window”
of the average outdegree. The size of the window was 200
days, and it moved from the first 200 days of our dataset to
the last 200 days, with a timestep of 1 day. At each step, we
fit all three functions of the Leskovec model to the current
window, with the Levenberg–Marquardt algorithm (Marquardt
1963). πως γινονται αυτες οι μετρησεις΄θα επρεπε να φαινετε εναν συνολο απο μετρησεισ στο Πlot 
epishs h grammh an pernoume sample apo p.x sto shmeio 4 exoume 40 ekatomuria xrhstes pernoume sample kai metrame to average outdegree? alliws 8a eprepe na eixame ena fasma an metrousame gia olous? ti akrivws metrame ?  
(poluvios)



23 Repeat steps 1,2 (100 times), calculate average of sensitivity and specificity. 
sto paper omws leei 10000
fter training the DTR model, we assess the TPR and
FPR metrics of the classication on the test dataset. We repeat this procedure
10,000 times


23) meaning that PTs that are active for
more days contain a lower percentage of spam. How ? We also observe a small downward
trend (rs1 = 􀀀0:24, 95% CI [-0.27, -0.20])


24) Tweets with trends that lasted shorter period of time, contain lower amount of spam but, contain higher amount of spam percentage
lower amount of spam= less URL spam in each tweet
higher amount of spam percentage = less tweets posting at list one URL??


25) table 1 plos: Min Number of Variants per Entity 1 1gia ton varoufaki 1 mono 
Max Number of Variants per Entity 74 px. gia ton vrikame 74 diaforetikeks onomasies NAI 	

26 ) presentation slide : 31: Link and combine entities in text /HTs  (improve precision), annotate dataset
annotate dataset ? vriskw ta entities sto tweet kai to kanw label? OK NAI 
-============================================================
*ite apozhmoiwsh*
ρςμη 460 + ημερησια 200 = 640  ==> katreas gia loyx TELIAK 665 
λυουξ 231+381 =612 eishthria (KATREAS) + 400 jenodoxeio + 240 hmerhsia = 640 
250 acm 


Notes on thesis  :

pols : 
1) plos between Sentiment Analysis in Twitter with Obama's approval ratings polls [2]. The application
of the same method in 2012 U.S. presidential elections outperformed the public opinion
polls [5]. Since then, numerous other studies have performed similar analysis in other countries
like Austria [1], UK [1] and Italy [5] with varying election procedures and diverse cultural
and language dynamics.  auta ta studies exoun kanei kaluterh anaulsh apo poll. prediction omws?  
Alex: 


1) In our public repository [44] we show some examples of “NO” and “YES” tweets  DEN DEIXNW!

2)  the outgoing and incoming degree follow a power law, with exponents 1.95 and 2.13: Ti einai to exponents? 

	exeis ena grafo enos Sn, kai metras to plh8os  twn komvwn (nodes) pou exoun to mikrotero va8mo. me

	taxinomw to plh8os komvwn me  vash to va8mos 
	 300 [a, b, c, ..] komvous me va8mo 2
	 500 [f ,g, ] komvous me va8mo 3


	 |
	 |60     x
	 |
	 |
	 |20                y
	 |_______50________100______________- x=node degree
	 y=plh8os komvwn  


	estw y = ax^(-n)  oles oi grafikes parastaseis  einai power law . opote to exponent einai to N!!
	https://www.wolframalpha.com/input/?i=y%3Dx%5E-00.5


	an to exponent einai mikrotero h megalutero n < 2 ή n > -2 ,τοτε δεν οριζετε ο μεσος ορος . ποιανου; 
	αμα παρω ολους τους κομβους τους δικτου, ποιο einai average degree. a1 + a2 + ../n   katw apo 2 den orizete 

	an orisoume to power law san y = ax^(-n) katw apo 2 .   
	esyw to https://www.wolframalpha.com/input/?i=y%3Dx%5E-00.5 auto den orizete gaiti h grafikh parastash 8a kanei gia panta na plhsiasei ton axona x, kai den mporeis na upologiseis to emvadon pou einai kai to average degree.  
	enw oso pio megalo enoa to n p.x https://www.wolframalpha.com/input/?i=y%3Dx%5E-7h grafikh parastash peftei panw ston ajona x panw to shmeio 1. opote to emvadon pou einia kai to average degree mporei na upologistei. 
	sthn prwth periptwsh pou to n einai polu mikro uparxoun elefantes pou mporei na mhn tous vreeis pote . opote to average degree pou exeis einai polu makkria apo to pragmatiko . 





4) posa deleted accounts exoume apo to dataset tou kwak. 
	
	OXI den xeroume . alla ta plots me to #nodes sto axona x anevainoun panw apo to #nodes pou leme oti exoume giati oson afora to kwak o grafos pou metrhsame kai kaname sample EINAI TELEIWS DIFORETIKOS APO AUTON opws htan so 08/2009. eginan inactive xrhstes, dhmiourgh8hkan nea following ktl . 

potential ptuxiakh se foithth: 8a mporouse na metrh8ei pws sxetiete to modelo tou lescovec stous inactive xrhstes (apo to kwak dataset)

5) sto figure 4: efoson to nodes ienia 90 million giati paei pera apo to 10 ?

	einai ta friends kai ta followers allla den shmainei oti mexr thn grammh 90 ekatomuria deixnei nodes kai apo ekei kai meta friends kai followrs auto 8a htan adunato na suvmei . einai anamoiktoi nodes, freind and followrs. 


6) omoiws giati sto figure 5 paei pera apo to 4 efoson exei 40 million xrhstes. 

	
	einai ta friends kai ta followers allla den shmainei oti mexr thn grammh 90 ekatomuria deixnei nodes kai apo ekei kai meta friends kai followrs auto 8a htan adunato na suvmei . einai anamoiktoi nodes, freind and followrs. 

7) epishs h grammh an pernoume sample apo p.x sto shmeio 4 exoume 40 ekatomuria xrhstes pernoume sample kai metrame to average outdegree? alliws 8a eprepe na eixame ena fasma an metrousame gia olous? ti akrivws metrame ?  



	exoume polles times apo average degree panw sto plot mas . estw mia timh sto shmeio x,y 8eloume na doume me ti functiona uxanete opote exw treia eidh : super liner growth - logarithmic linear kai mernoume ena para8uro 100 meres mprosta , 100 meres pisw kai vlepoume me ton Levenberg–Marquardtpws kanei fit. pernouem dhladh ta least squeare error kai leme oti kanei kalutera fit h sunarthsh gai thn opoia mas vgazei mikrotero error. 
     eikona 6082 Github/phd/___CSD 


8) magoutis 8a rwthsei gai systems, pw ulopoh8hkan. isws ta parallelized

9)poluvios:We are performing incremental measurements of the average outdegree, for every day of the dataset, in both datasets. 
	
	Next, we fit the Leskovec model, to a sliding window" of the average outdegree.
	The size of the window was 200 days and it was moved from the first 200 days of our dataset to the last 200 days, with a time-step of one day.
	2)Figure~\ref{results_2006_2012_OVERALL_1} presents the same plot for the \textit{KWAK} dataset,  pws vazoume se xronikh seira tous xrhstes? me vash to craetion date tou xrhsth? 




10)plot:  3.4 giati eoxume gramh me ta to 4 afoiu oi xrhstes htan 40 million?  ayth einia h apanths? 

	The last user subscription of KWAK happened when this dataset had 37 million nodes so the large drop of the growth exponent after that is an artifact and not a real event. an einai tote to parakatw den vgazei nohma:  The small gap that is noticeable at the \textit{KWAK} approximately at 06/09 nodes coincides with the death of Michael Jackson which caused a disruption in Twitter's online service.



12) dikia mou) “preferential attachment”, and the “copying model”? ti lene?


		A well-studied family of models are the “preferential attachment”, and the “copying model” (Kleinberg et al. 1999).
		These models can generate scale-free networks, where the average degree of the network remains constant, and its effective diameter slowly grows. Leskovec et al. (2007) noticed that these assumptions do not apply in many modern social networks.
		In contrast, they suggested that, as the number of nodes increases, 
		the average degree also increases (the graph becomes more dense), whereas the diameter decreases (the graph shrinks).
		These significant differences may originate from the possibility that the outdegree distribution of these networks is not always a power law.
13) Why not diameter? 
		
		Diameter : O(|edges||nodes|), sufficient size sample : A 15% sampling size is enough for measuring the graph properties of a graph as it grows and evolves  
		twitter has nodes approximatelly  600 million , edges? as poume 2 fores ta nodes pou kai pali einai poluuu liga 600.000.000 = 6*10^8 ==> 10^20
14) gia tplot me to density pou meiwnete (poluvios): 

	The density Q of a network is defined as the ratio of the number of edges E to the maximum possible number of edges and is defined as (2E)∕(N(N − 1)) , where N is the number of nodes.o 

	 . 

	Maybe : 
	The density Q of a network is defined as the ratio of the number of edges E to the maximum possible number of edges and is defined as (2E)∕(N(N − 1)) , where N is the number of nodes. 
	This is in contradiction to what Leskovec suggested although Leskovec is not using this metric to measure how dense a graph is.
	Leskovec is using the diameter which cannot be evaluated in very large OSNs. 

	Leskovec performed some calculation on some small OSNs (i.e. citation networks)  with ~10.000 nodes

	It might be the case that effective diameter decreases and the density metric also decreases, as time goes by. This sounds like a contradiction but is possible
========
		
	see picture density_of_graph.jpg (Github/ph/thesis...)  2 γράφοι ο δεξια είναι ένα evolution του αριστερα ο αριστερα έχει diameter: 3, density 0.267
	 o δεξιά έχει diameter: 2, density: 0.23 Δλδ το diameter έπεσε, αλλά ΚΑΙ το density έπεσε


15) gia to plot fig)1 average degree , gia to KWAK . meta to 2009 leme oti   Since all users in KWAK have subscribed in Twitter before that date, a fair proportion of them were inactive when the sampling happened (5–6 years later). 

	Jeroume posoi htan inactive se sxesh me tous posous htan active? giati oi active pi8anwn na dhmiourgousan nees sxeseis opote na anevene gia  autous to outdegree. to opoio to leme vevaia sto caption to plot : 

		Inactive users do not add new followers; therefore, the
		measurement of the average outdegree past that date (August 2009)
		with the KWAK dataset is not representative of the real average outdegree
		value of Twitter. Nevertheless, this demonstrates that the influx
		of new users after 2009 compensated this effect and resulted in the
		increase of the average






15) what is a sufficient sample size in Twitter ? 

	The same study that suggests random walk as an efficient sampling technique, (Leskovec and Faloutsos 2006), also addresses the issue of sufficient sample size for capturing graph metrics. A 15% sampling size is enough for measuring the graph properties of a graph as it grows and evolves. It is estimated that when the sampling happened (from September 2015 to April 2016), Twitter had 500–600 million users, who half of them were active users. Therefore, we reckon that 92 million users are a sufficient sampling size, since it  constitutes 15% to 18% of the complete network.	

16) of the average outdegree, for every day of the dataset.
Then, we fitted the Leskovec model, to a “sliding window”
of the average outdegree. The size of the window was 200
days, and it moved from the first 200 days of our dataset to
the last 200 days, with a timestep of 1 day. At each step, we
fit all three functions of the Leskovec model to the current
window, with the Levenberg–Marquardt algorithm (Marquardt
1963). πως γινονται αυτες οι μετρησεις΄θα επρεπε να φαινετε εναν συνολο απο μετρησεισ στο Πlot 
epishs h grammh an pernoume sample apo p.x sto shmeio 4 exoume 40 ekatomuria xrhstes pernoume sample kai metrame to average outdegree? alliws 8a eprepe na eixame ena fasma an metrousame gia olous? ti akrivws metrame ?  
(poluvios)

17 ) This is why we notice that the outdegree distribution drops after the end of 2009, 

logarithmic ginete meta to 9/12. einai oi xrhstes pou uparxoun hdh kai oti to average degree ayxanete giati ayxanontai oi following relationshios. emeis ti data exoume meta to 2009? apo ta user objects? ti kanoume plot meta to2009 afou meto to 2009 einai ta data? 


18) why 200 day window? 

19) ti kanei o Levenberg–Marquardt kai pws mas voh8hse
 leei sthn wikipedia The primary application of the Levenberg–Marquardt algorithm is in the least-squares curve fitting problem: given a set of m empirical pairs  exoume emeis tetoia zeugaria? pws ton efarmosame? 

	 		Then, we assigned the midpoint of the window to the model with the lowest root mean square error. 
	 		Οποτε εχουμε μια τιμη γαι καθε παραθυρο και αυτην την τιμή κανουμε πλοτ;
	 The Levenberg–Marquardt algorithm also produced estimations for the b and c parameters.

20) magoutis 8a rwthsei gai systems, pw ulopoh8hkan. 


	The only computational challenging part is sorting all edges of the network, which can be easily parallelized. The rest computational part can take place in a single workstation. Overall, the complete computation required approximately one day, in a high end workstation (single 4-core Intel i7 processor, 3.4GHz, 16Gb RAM).	 

=====*SPAM*===========
21) We observe that approximately 90% of trends are associated with less than 1,000 URLs.
see cdf of 1b ligotera apo 70% sxetizontai me 100 ULRS. 

	to opoio shmainei oti ligotera apo ta 70% twn trends periexontai so idio tweet me 100 diaofretika URLS ? ligotera apo 70% trends susxetizontai me 100 URLS, (periexontai sto idio tweet)

22) isxuei oti oi GMF einai probably compromized account kai oi RBL einai spammers?  NAI !

 


=============
ftiaxame ena rxeio mia suugole me entities (exei ginei to entity identifucation) kai 

evolution:   1_ slide intro 1 slide dataset  11 slides total 

spam :  1 slide introduction , 1 dataset kai meta arxizei ta apoteesmata en merh kai ehghsh methoodlogias .  total  10 slides 

varoufakis : 1 slide inyto about ? 

	Data collection 1 slide & 
	1 slide Entity Identification
	Volume Analysis for prediction of referendum result,
	 Co-occurrence of pairs of entities in tweets 
	Sentiment analysis using a novel sentiment dictionary tailored for the specific period and domain, 
	 Topic modeling(LDA): clustering of topics for each identified entity
 


# could be nice to be published  -- dashboard 


#meeting for 1.1  
	1)talked about logistics for Vienna, whether if we should meet again. 
	2) started presenattion I left for 1.4 

#meeting for 1.4 
	There are data IPs  . labeled as malicious . maybe ML if we want . collaboration also is welcome . 
	data telenor telefonica(anonymization services)  CTI data see photo in phone
	presentation see slides in photos. 



ConcordiaEvt@UL_2019
Evt@UL_2019

#initial meeting all tasks together: 
	information here : https://confluence.lrz.de/display/CONCORDIA/WP1+General+Information * 

	write everything you are working on . not only works of for concordia. * 

FORTH : 

Forensic Data Visualization.

We propose a honeypot and vizualization dashboard of the attacks gathered. Mainly in two VMs and the dashboard provides the agregated information about attacks and highlights the most crucial / highest risk ones. This way user is not overwhelmed by all potential attacks and false alarms 


from https://www.smesec.eu/

WP1 
###****
74% 1350 

#**********###### parousiash poluvios 

ti deixnei to plot filgure 2.  diayedei ton lescovec? peftei einai h diametros? 

posa deleted accounts exoume apo to dataset tou kwak

potential ptuxiakh se foithth: 8a mporouse na metrh8ei pws sxetiete to modelo tou lescovec stous inactive xrhstes (apo to kwak dataset)


sto figure 4: efoson to nodes ienia 90 million giati paei pera apo to 10 ?
omoiws giati sto figure 5 paei pera apo to 4 efoson exei 40 million xrhstes. 

epishs h grammh an pernoume sample apo p.x sto shmeio 4 exoume 40 ekatomuria xrhstes pernoume sample kai metrame to average outdegree? alliws 8a eprepe na eixame ena fasma an metrousame gia olous? ti akrivws metrame ?  


magoutis 8a rwthsei gai systems, pw ulopoh8hkan. 



1)poluvios:We are performing incremental measurements of the average outdegree, for every day of the dataset, in both datasets. 
Next, we fit the Leskovec model, to a ``sliding window" of the average outdegree.
The size of the window was 200 days and it was moved from the first 200 days of our dataset to the last 200 days, with a time-step of one day.

2)Figure~\ref{results_2006_2012_OVERALL_1} presents the same plot for the \textit{KWAK} dataset, 


pws vazoume se xronikh seira tous xrhstes? me vash to craetion date tou xrhsth? 


plot:  3.4 giati eoxume gramh me ta to 4 afoiu oi xrhstes htan 40 million? 

ayth einia h apanths? 
The last user subscription of KWAK happened when this dataset had 37 million nodes so the large drop of the growth exponent after that is an artifact and not a real event.
an einai tote to parakatw den vgazei nohma: 

The small gap that is noticeable at the \textit{KWAK} approximately at 06/09 nodes coincides with the death of Michael Jackson which caused a disruption in Twitter's online service.
#*****************************sotiris 
contribution ana kefalaio sthn arxh na fainetai, as mhn kanoume merge to backgrounf me to related apla na fainetei pio einai to contribution mas kai na to steiloume amesa stous allous


dikia mou erwhsh 
Figure 3.10: The percentages of the Chinese users in Twitter between 2006 and 2015.
giati den exoume grki mpares prin to 2010? den hxeran na grafoun lol mhnpws to paedio auto den uphrxe sto twitter ?  OXI EINAI TO LAST TEWEET META STAMATHSAN!

#*********woemncourage******************
Despoina Antonakaki
Vasileiou Psillaki 17, Heraklion Crete Greece 
0030 694 2977447
gr27 0172 7540 0057 5400 9859 805 
PIRBGRAA
1006 Ampelokhpwn 
PIRAEUS BANK
KHFISIAS AV. 41

#carvgit******************************
Despoina:bot_detection_2019 despoina$ git pull https://despoina@carvgit.ics.forth.gr/Social-Network-Analytics/BotDetection.git master 

#*****************hy335 ssh CSD############################
ssh  gate1.csd.uoc.gr -o HostKeyAlgorithms=+ssh-dss -o PubKeyAcceptedKeyTypes=+dsa -l hy335a

#*********************************************************************************************************************************************
SXOLIA sotiri sto thesis. 1/10/2019
#*********************************************************************************************************************************************

1) to section 1.2 den einai thesis statements, alla erwthseis. prepei na einai ths morfhs:" I can detect spam in in Twitter by studing trending topics. 
"I can detect obfuscated URLs that hide spam in Twitter. "" ok 
Auta ta statements 8a pw   ta kanw (methodology) kai se poio se chapter. ... ok

Isws ena statements ana kefalaio, alla na 8a prepei na denoun metaxu tous. An den mporoume gia to average degree , isws na htan auto mia set the ground ..hints gia na kanw bootstrap ths diadikasia mou. methodoogy, OK 

2) To related work  prepie na enia sthhn arxh, eite na ginei merge, me background work , (kai as einia aniso ) . epishs 8eloume to DELTA me to bbackgroud works. Top 10 (x) kaluteres douleeis ston xwro, ti kanoume emeis kalutera kai ena table pou na deixnei tis diafores mas kai auto ginete se auto to upokefalaio.  


#*********************************************************************************************************************************************
despoina apanthseis  2/10/2019
#*********************************************************************************************************************************************

#to shmantiko paper tou xwrou riai to @spam. autoi kanoun features analysis, to poio kanoume kiemeis , apla emeis ecoume oiasei to momentum twn trends kai thn ekkmetaleush tous. epish kanoum spam campaign kai anakaluptoume to google obfucsation !


# graph analysis. to kalo paper 8ewroume tou lescove modle. vevaia emeis den prosferoume modelo . emeis kanoume fit to hdh katwxurwmeno model tou lescovec + to efarmozoume se ena plhres dataset, kati pou autoi oute kan plhsiiazoune. 

# sentiment analysis 

seminal review in this area is from Gayo-Avello




sxetika me thn provleyh: 

There are contradicting studies regarding the predictive ability of tweets count for
election results (for examples of positive findings see [24, 25] and for a negative see [26]). Nevertheless
most studies agree that tweet count can give valuable information if not for the election
outcome then for the quantitative estimation of the political inclinations of Twitter's userbase.
For this reason we apply Volume Analysis in the referendum dataset because it has a simpler
structure (only two choices: YES/NO). *We found that indeed tweet counts matched the
referendum results and we also associate changes in the temporal variation of the ratio
between `YES' and `NO' tweet counts with real events. The*


#*********************************************************************************************************************************************
erwthseis
#*********************************************************************************************************************************************

*exeis kanei treis polu kales douleeis alal pws sundeontai aytes*

	to twitter san ena zwntano kai sunexws exelisomaneo sn, exei pruxes pou einai allhlendetes. etsi h meleth tou grafou einai polu shmantikh gia na mas deixei pi8anes apeiles , diadosh malixouc content, ketrikous komvous hubs pu mporoun na ephreasoun thn diadosh ths plhroforias pou uparxei mesa sto grafo h thn diadosh yedhd plhroforias. Auto mporei na prolaesei yetikes entupwsesi sthn pio xalarh tou morfh kai na dwoseis taseis stous xrhstes pou einai merolhptikes kai kakovoules eite apo organismous h politikes omades pou exoun tetoieous skopous. 

	eiani polu stratigkh h morfh me thn opoia kinountai autes oi omades (politikes, grasshopping , fake news ktl bias inclibation . ) auth h stratigikh kai domh tou grafou einai polu shmantikh na meleti8ei. 

	oi alles duo meletes apoteloun anapostapto kommati gia na mas wsoun mia oloklhrwmenh eikona tou koinwnikou dikyuou , kai tou periexomaenou tou. 


	meletame t otwitter san ena sunolo. arixka pws einai h domh tou , pws sundeontai oi xrhstes metaxu tous , oi poioi me poious, ti communities dhmiourgoun kai pws kanoun disseminate thn plhroforia metaxu tous. epishs pws exelisete sto xrono, giente pio puknos?  kalutera na mhn anafer8oume sthn arxikh morfh tou paper gia to graph analysis giati 8a mas zhthsoun na ta valoume mesa.! 


		These questions are not discrete. Any finding in one question can give a great insight to
		another. 
		1) For example a popular discussion topic can be exploited for the distribution of a
		tweet containing spam. see paper trening spam 

		2)  Similarly, the structure of the social graph can be also exploited for
		the same purpose. 


			 Poia einai h  dom;h toy grafoy alal kai ths idias ths plhroforias pou periexei ka8s kai h domh me thn opoia ginete disseminatte mesa sto grafo twn xrhstw, pws taxideuei teliak anamesa stous xrhstes , an exei kapoia hubs (kentrikous komvous ) . h plhroforia auth mporei na dwsei insights gai ton elegxo telisk ths diakinhshs ths plhroforias . an einai fully connected component h an exei komvika shmeia

		3) Also, the structure of the subset of the social graph that shows positive
		sentiment towards a given entity (i.e. political party), can give insights of the prospects of
		this entity.
			
			astroturfing, ijection of political bias 

		Like living organisms that can be studied from various interconnected perspectives (i.e.
		physiology, ecology, behaviour), Social Networks are dynamic and complex systems that
		can be studied from many views. This dissertation sheds light in one of the most vibrant
		social network, Twitter, from three main perspectives: threats, social graphs and content.

Introduction: 1.2 ) What structure does the social graph has? 
*What information does this structure conveys? How the social graph changes over time?*
	 Ποια είναι η  δομή του γράφου αλλα και της ίδιας της πληροφορίας που περιέχει καθώς και η δομή με την οποια γίνετε disseminate μέσα στο γράφο των χρηστων, πως ταξιδεύει τελικά ανάμεσα στους χρηστες , αν έχει κάποια hubs (κεντρικούς κόμβους ) . η πληροφορία αυτή μπορεί να δώσει insights για τον έλεγχο της διακίνησης της πληροφορίας . αν είναι fully connected component η αν έχει κομβικά σημεία από τα οποια μπορεί να διακοπεί η διακίνηση


*How was the parallelization of sorting of edges in the average node degree paper  (potential poluvios question*

 	figure caption are two big . .. REMOVED in tex: Dissertation_PRE_toc.tex folder (tex_pre) 

 	figure 3.1 giati kovete  h mple gammh . TOSO einai to dataset (peripou to miso apo to BIG alla den einai paliotero ? oi hmeromhnies peftoun panw sto BIG den aini polu pio palio to kwak? )

 	steile to kai meta vale to journal tou spam trends 


#*********************************************************************************************************************************************

#*********************************************************************************************************************************************
*thesis: //*

γεια σας,
Σας στέλνω στο attachment το thesis report.Μετα απο επικοινωνία μου με την γραμματεία, με ενημέρωσε οτι για να συνεχίσουμε την διαδικασία σε πρώτη φάση θα πρέπει να η τριμελής επιτροπή να δει το thesis σε κλειστή συνάντηση και εφόσον ολα ειναι οκ,μετα να προχωρήσουμε στην συγκροτηση της επταμελής επιτροπής.
Το αν θα γίνει παρουσίαση, εξαρτάται καθαρά απο εμας.Θέλετε να ετοιμάσω slides για την τελική μορφή του thesis?Θέλετε η παρουσίαση να γίνει σε επόμενη φάση που θα εχετε δει το thesis;


Για την επταμελή προτείνω τα παρακάτω επιπλέον μέλη:Ιασωνας Πολάκης Ηλίας Αθανασοπουλος,Πολύβιος Πρατικάκης,Κώστας Μαγκουτης.
ευχαριστώ!
---
regards,Despoina Antonakaki

*thesis* 24/9/2019

	Notes on the ~final version :






 	ta references einia prasina :
	file:  Dissertation_PRE_init
 	 \hypersetup{
	    colorlinks=true, %set true if you want colored links
	    linktoc=all,     %set to all if you want both sections and subsections linked
	    linkcolor=blue,  %choose some color if you want links to stand out
	    %allcolors=black, %uncomment if you want no color in links and TOC
	}

	   colorlinks=TRUE, %set true if you want colored links  <-----




 
#*********************************************************************************************************************************************


*CONCORDIA* 

Kalimera kai pali. Kala eimaste mas trexei o professor Polakis :P .

Oxi exoume kai sto fetino iosec 2019 (ginete auti tin evdomada me to esorics kai exoune paei).

Einai acccepted kai under publication (sta post proceedings).

Title: You Shall Not Register! Detecting Privacy Leaks across Registration Forms.
Authors :

Manolis Chatzimpyrros, Konstantinos Solomos and Sotiris Ioannidis
Abstract :

Most of the modern web services offer to users the ability to be registered to them via dedicated registration pages. Most of the times, they use this method so the users can profit by accessing more content or privileged inside items. In these pages, users are typically requested to provide their names, email addresses, phone numbers and other personal information in order to create an account. As the purpose of the tracking ecosystem is to collect as many information and data from the user, this kind of PII (personally identifiable information) might leak on the 3rd-Parties, when the users fill in the registration forms. In this work, we conduct a large-scale measurement analysis of the PII leakage via registration pages of the 200,000 most popular websites of the web. We design and implement a scalable and easily replicable methodology, for detecting and filling registration forms in an automated way. Our analysis shows that a number of websites (≈ 5%) leak PIIs to 3rd-Party trackers without any user’s consent, in a non-transparent fashion. Furthermore, we explore the techniques employed by 3rd-Parties in order to harvest user’s data, and we highlight the implications on user’s privacy.

*CONCORDIA D1.1* 

		subsection{Fake news detection in Social networks}

		{\bf Work on progress: Identification of false content in Twitter}

		Social networks, along with the billion user’s interactions has lured a plethora of malicious activities, as well. Fake news is a recent and raising vulnerability. Background work shows that fake news and disinformation consist serious threats for users, societies, institutions, democracies and elections, that needs to be mitigated. This study attempts to shed light into a dataset of tweets from European elections, regarding fake news. 
		In this ongoing study we have collected a dataset from mostly Greek-speaking users, crawled
		between August 2016 and January 2018 comprising of about 720 million tweets (part A). 

		 Additionally, we have obtained the complete corpus of tweets referring to the Greek Referendum of 2015 and the subsequent legislative General Elections, the Dutch general Elections (March '07), the French Presidential Elections (April), the French legislative Elections (June), the United Kingdom general Elections (June) and the corpus from the German federal Elections (September) and the Czech legislative Elections (October) (part B). 

		 We have detected synchronized content injection behavior and marked the legit bots (mainly promoting news RSS feeds) and the malicious ones (promoting content), in the first part of our dataset(A). Additionally, we studied the content, the usage patterns, the position in follow graph, the HTs and the interaction with trending topics, the community infiltration and the proximity to known user communities. 
		This follow-up work indents to initially  apply topic modelling and spot the legitimate and irrelevant content from the dataset in order to focus on potential false information. Next, we will detect potential actors of false content (bots, organizations, governments, activists, individuals, trolls etc.) and apply feature analysis for content credibility.   

		Primary results in first dataset have shown that .\% of the tweets contain at least one URL identified in a fake news blacklist. Specifically out of 1851 bot, 687 posts contain at least one URL that is marked by blacklist. %\cite{blacklists-greek}. 

		%We are planning to detect bots injecting content and fake news, promotions and advertisements. 


ai Deytera brady na to dwsoyme mia xara einai.
Bale katw ta tasks kai meta prepei na doyme poia apo ta paidia mporoyn na mas dwsoyn etoimo text
sta t1.1 t1.2.
t1.4 kai t1.5 einai ta dika soy


*20/9/2019*
[CONCORDIA WP1] deliverable D1.1 preparations

In a nutshell, the main part of the deliverable will describe *the many research activities* going on in WP1. 

The document will be *structured by tasks* and *we expect a short summary of each research activity*. 

The task leaders are in charge to identify some highlights (e.g., projects that have led to an
outstanding publication or received an award or whatever) that will
get a bit more space in the deliverable and will be highlighted at the
beginning.  

*Are we leaders?* 

We have already created a structure for the deliverable in
the gitlab repository, which includes comments explaining what we
expect in the various sections. Please take a look at:

*Christo* 


Ta fake news einai mesa sto grant agreement selida 14!!

*from Information Credibility on Twitter* 

#supervised learning 
#event tracking in twitter ; monitoring system which detects sharp increases "bursts": two types of topics : 	
	##news 
	#conversation 
#Randomly we selected 383 topics from the Twitter Monitor collection to be evaluated using Mechanical Turk.
#credibility assessment 
# Labels given byMechanical Turk evaluators were used to conduct the supervised training phase. We

15/10 - 19/10 16-17 18 cod  2 posters 


*fake news concordia poster*  
#intro 
#dataset description 
#potential use cases 
  * political bias detection 
  * bot detetion 


A Predictive Score for Thrombosis Associated with Breast, Colorectal, Lung, or Ovarian Cancer: The Prospective COMPASS-Cancer-Associated Thrombosis Study.

Use ML & AI in clinical data study


 Γεια σου Χρηστο, 

 εχουμε1 ξεκινήσει να συζητηαμε για ενα paper που θελουμε να ξεκινήσουμε με την  Dr. Βίκυ Δανηλατου και τον Αλεξανδρο Καντεράκη σχετικά με ενα study πάνω σε  thrombosis prediction σε  clinical data apo ασθενεις με καρκίνο. Εχει ήδη γίνει μια μελέτη  https://www.ncbi.nlm.nih.gov/pubmed/28550032 και αυτό που θέλουμε ειναι να εφαρμόσουμε τεχνικές ML γιατι εχει γίνει με παραδοσιακές τεχνικές statistical analysis. 
* 
Christos Papachristos <cpapachr@ics.forth.gr>
Tue, Aug 13, 10:43 AM
to Despoina, Sotiris

Kalhmera Despoina,
sto CONCORDIA eimaste involved sta parakatw tasks.
Ka8e task exei kai to diko toy mailing list. To idio symbainei kai ana Work Package (polla mailing lists).

Mporeis na mpeis se ayto to systhma
https://confluence.lrz.de/display/CONCORDIA/Mailing+Lists
me ta parakatw credentials 

username: di39xak
pass: cpapachr_12

kai na kaneis subscribe se ola ta tasks kai ta WPs poy symmetexoyme.
Sth synexeia mporoyme na zhthsoyme na soy ekdwsoyn kai dika soy credentials gia 
1. to confluence collaboration systhma (https://confluence.lrz.de)
2. giltab (https://gitlab.lrz.de/concordia) to git toy ergoy.

Kentrikh lista: all@concordia-h2020.eu apo thn opoia mallon 8a pareis notification

O,ti xreiastei mou les.

thanks,
Christos.

#*********************************************************************************************************************************************
#*********************************************************************************************************************************************
#*********************************************************************************************************************************************

gmail account
username:concordiah2020.eu@gmail.com
password:@_&a#<.2PXU$Glk

twitter account
name:concordia-h2020.eu

username:concordiah2020.eu@gmail.com
password:?^kFm5%4LmAc8qj
l?^kFm5%4LmAc8qj?l
1?^kFm5%4LmAc8qj?1


HASHTAGS for twitter
@EU_H2020 @DSMeu @Cybersec_EU #H2020 #CyberSecurity #CyberCompetenceNetwork

facebook account
https://www.facebook.com/concordia.eu
admin:ανθή,χρήστος,μάνος,σωτήρης, despoina

Linkedin account
username: concordiah2020.eu@gmail.com
pass: @_&a#<.2PXU$Glk

Instagram account
username: concordiah2020.eu@gmail.com
pass: @_&a#<.2PXU$Glk






WP1: European Secure, Resilient and Trusted Ecosystem (ESRTE) (1-48) (PMs 24)
8 - Task T1.1: Device-Centric Security (Lead: JUB) IoT Security Analytics
8 - Task T1.2: Network-Centric Security (Lead: UT)
2 - Task T1.4: Data/Application-centric Security (Lead: TUBS)
6 - Task T1.5: User-Centric Security (Lead: CUT)

WP3: Community impact and sustainability TUDA (1-48) (PMs 12)
5 - Task T3.1: Building a Threat Intelligence for Europe (Lead: SAG)
5 - Task T3.2: Piloting a DDoS Clearing House for Europe (Lead: SIDN)
2 - Task T3.4: Establishing an European Education Ecosystem for Cybersecurity (Lead: EIT)

WP4: Policy and the European dimension EIT-DIGITAL (1-48) (PMs 6)
6- Task T4.6: Liaison with stakeholders (Lead: SnT)

WP5: Exploitation, dissemination, certication and standardization (1-48) (PMs 12)
12 - Task T5.2: Dissemination and communication activities (Lead: MUNI)

WP6: Project,- Risk- and Innovation-Management (1-48) (PMs 18)
9 - Task T6.1: Governance (Lead: CODE)
9 - Task T6.2: Quality management (Lead: FORTH)



#*********************************************************************************************************************************************
#*********************************************************************************************************************************************

*poster womencourage* 

what is the N in window? N-minute windows 
*** Fig. 1. Distribution of synchronized content injection events per account. 	
the majority of accounts being involved in
a very low number of synchronized tweets with the same
content, while a few accounts generate the biggest part of the
synchronized content injection events.


* NOTEs : 
1) Our method initially analyzes individual tweets in the crawled corpus to detect synchronous or near-synchronous
activity. Specifically, we assume a model where botnets of multiple accounts, controlled by the same agent, aim to
promote and diffuse content and affect legitimate users in some way. As noted previously [5], such accounts tend to act
in a synchronized or loosely synchronized way, often aiming to reduce their operational cost by sharing computational
resources, or responding to a single instruction by a common operator.

2) This allows the detection of automated behavior by timing analysis. However, many of these automated accounts
are legitimate bots, openly declaring their objective, e.g., announcements of a news RSS feed on social media. However,
other bots are fraudulent, impersonating human users, aiming to promote content, emotions, or behavior to unsuspecting
users.

3) August 2016 and January 2018. The retrieved corpus includes publicly available tweets of a large percentage of all Greek-speaking
users. The crawler stores tweets, lists, follow relations and favorites that are reachable via the Twitter API. We extract
a large set of features per user, the follow, retweet, reply-to and quote graphs, as well as the list co-membership graph generated from list membership information.

4) We count the total copy events occurred during a time window, where five different windows were created. The
purpose is to find the most accurate and efficient time window in order to spot bot activity and specifically the tweets that they
post. A copy events is when two users post text with similarity over 80%.

5) how do we detect? concurrent content injection

To detect synchronized activity, we use a standard rolling window method [5] to segment the very large body of tweets
into smaller chunks that can be analyzed in parallel and independently, consisting of all tweets in a time window. We
overlap the N-minute windows by N=2-minutes, so that each tweet is visited twice, independently. Each time window’s
worth of tweets (task) is analyzed by mapping each tweet into a bag-of-words, using the standard NLTK tweet tokenizer that
simplifies punctuation, removes URLs, etc. We found URLs specifically to be important, as the exact same content is often
injected by changing simply the shortened URL in the tweet into another, pointing to the same site.

To choose the best size for the rolling window, we repeat the computation for 5 different durations, in a dataset of one
month’s tweets. Bigger window lengths will detect more “concurrent” injection events, i.e. tweets that were independently
posted that contain very similar contents. However, increasing the window size will create bigger sets of tweets and as a
comparison among all tweets within a task is quadratic, larger windows have a drawback of increased computation cost
while also widening the definition of what is a “concurrent” event. 

Specifically, we tried time windows of 2.3 5, 10, 15 and 20 minutes, which detected around 800K, 1.1M, 1.6M, 1.9M and 2.2M pairs of similar tweets, in total over all the time windows of the dataset, respectively. Computation time was around 2, 4, 9, 18 and 34 hours, respectively, on a single 8 core PC, for the window durations listed above. Based on this tradeoff, we selected a time window of 10 minutes, rolled over 5 minute intervals for the complete dataset. For each 10-minute window in the dataset,
*medical data* 

#*********************************************************************************************************************************************
#*********************************************************************************************************************************************
#*********************************************************************************************************************************************

medical data

Για αρχή εχουμε το  UK Biobank  ( a resource health-related and genetic data on about 500,000 individuals and is available to the research community) 
Αυτο εχει οδηγιες πως να τα παρουμε. 
http://www.ukbiobank.ac.uk/wp-content/uploads/2014/06/1000-Naomi-Allen-10am-data-and-access-1.pdf

===================

Το θέμα με αυτά τα δεδομένα είναι ότι ότι μόνο με την ανάμειξη μεγάλων consortiums γίνονται public όποτε ένα καλό αποτέλεσμα ειναι αυτό που έστειλα. 

Γενετικά δεδομένα υπάρχουν εδώ :

Gwas catalogue : ένα αρχείο txt με επιβεβαιωμένες στατιστικά συσχετισεις μεταξύ μεταλλάξεων και φαινοτυπων 

Clin var σε xml εύκολο παρσαρισμα που περιεχει μεταλλάξεις που έχουν βρεθεί σε γενετικές έρευνες και έχουν επιβεβειωθει ιατρικά 

 

Ensemble μετά δεδομένα κυρίως αλλά όχι από πολλά γονιδιώματα αλλά κυρίως για μεταλλάξεις .

One thousand genomes project είναι η καλύτερη πηγή για γονιδιώματα ~2054 ανθρώπους από όλο τον κόσμο 

Tcga γονιδιώματα και φαινοτυπος για διάφορα ήδει καρκίνου


Gene expression omnibus 
Διάφοροι φαινοτυποι (πχ breast cancer) 
Έχει γονιδιακή έκφραση mRNA 

Db gap
Για access θέλει authentication για ερευνητές. Είναι ένα archive samples που έχουν συμμετάσχει σε ερευνεσ με συσχετίσεις μεταξύ γόνοτυπου και φαινοτυπου .


*EUNITY review* 
#*********************************************************************************************************************************************
#*********************************************************************************************************************************************

Af: Are there new collaboration? 
Herve: in management report 


review interrupted by summerschool: 
We will be live streaming https://m.youtube.com/watch?v=HGLAAf7OduE … @9.30 am Brussels time the first session of the #cybersecurity #summerSchool with @ViolaRoberto welcoming also Professor Keromytis @angelosdk  https://www.ece.gatech.edu/faculty-staff-directory/angelos-d-keromytis … and Professor Rijmen https://www.kuleuven.be/wieiswie/en/person/00005695 … #Cryptography


*EUNITy REVIEW* 
#5.5 :

Cybercrimes 

4.5 Presentation in EUROCRIM ’18- Sarajevo/BiH : The number of participants reached approximately 1000k.!!!!! CORRECTED

page 30 
HD comment remove from .tex file 

#2.2 skipped 



final comments from review .
------------------------------
3rd workshop call it as dissemination activity and JUSTIFY !!!!!!!!!maybe get in trouble is not justify . 


Added value (Jouki)
not paid by EC EU-Japan . GDPR was Horizon . they observed GDPR, good period. ? Qulaity visibility in thhis area, for GDPR the issue is minor , Erasmus mundus program ... alot of relationshop with EU, 

*EUNITY rehearsal 23 June 2019* 

# FORTH TODO : 
push analytics for website + twitter  + linked in deliverable 5.5 
MIC ministry of information (japan) app that centralizes information you want to share and dissemination to business groups 
122268086,

#round of rehearsal of presentations - corrections


presenttion 5.5 cybersecirity in large events Youki on FIC tv 
2 -day event 

ONLY latest flyers stay in the website 

FIC: montly industry 


participation 


#EUNITY

Starting date 4 01/06/2017

month 1 : 01/06/2017
month 12:  01/06/2018
month 18:  01/12/2018
month 24: 01/6/2018



month 1 : 01/06/2017
month 12:  01/06/2018
12 -18 : 
June 2018 
July 2018 
Augoustos 2018 
September 2018 
Octobet 2018
November 2018 
December 2018

month 18:  01/12/2018
month 24: 01/6/2019


#PAPERS


#dedousis

	2012 Presidential Elections on Twitter - An Analysis
	of How the US and French Election were Reflected
	in Tweets


	ImageNet Classification with Deep Convolutional Neural Networks



	Detecting and Tracking Political Abuse in Social Media

	The Rise of Social Bots:

	Truthy: Mapping the Spread of Astroturfin Microblog Streams

	Detecting and Tracking the Spread of Astroturf Memes in Microblog Streams

	BotOrNot: A System to Evaluate Social Bots

	Dissecting a Social Botnet: Growth, Content and Influence in Twitter


	Social Bots Distort the 2016 US Presidential Election Online Discussion


#SPAM

	Spamalytics Spamalytics: An Empirical Analysis
	of Spam Marketing Conversion
	Chris Kanich∗ Christian Kreibich† Kirill Levchenko∗ Brandon Enright∗
	Geoffrey M. Voelker∗ Vern Paxson† Stefan Savage


	PAXSON: 
	https://scholar.google.com/citations?user=HvwPRJ0AAAAJ&hl=en

	http://www.icir.org/vern/papers/twitter-susp-accounts.imc2011.pdf

	http://www.icir.org/vern/papers/ccs2010-twitter-spam.pdf




	#INITIAL PAPERS : 

		NDSS 12:
		https://www.internetsociety.org/you-are-what-you-information-leakage-through-users-interests
		http://www.internetsociety.org/towards-online-spam-filtering-social-networks
		http://www.internetsociety.org/blacr-ttp-free-blacklistable-anonymous-credentials-reputation

		Usenix security 12:
		https://www.usenix.org/conference/usenixsecurity12/privacy-preserving-social-plugins

		Security and Privacy 12:
		Hummingbird: Privacy at the time of Twitter - 
		http://eprint.iacr.org/2011/640.pdf

		ACSAC 12:
		All Your Face Are Belong to Us: Breaking Facebook's Social 
		Authentication. - 
		http://www.ics.forth.gr/~polakis/papers/polakis_acsac12.pdf




		BLACR: TTP-free Blacklistable Anonymous Credentials with Reputation & 

		You are what you like! Information Leakage through Users' Interest



===============
#Twitter survey 
	Οποτε αυτό που έχω ξεκινησει ειναι με three-fold: vulnerabilities, sentiment analysis/elections prediction, temporal growth rate of graph of Twitter.  


	1. Gayo-Avello, Daniel. "" I Wanted to Predict Elections with Twitter and all I got was this Lousy Paper"--A Balanced Survey on Election Prediction using Twitter Data." arXiv preprint arXiv:1204.6441 (2012).
	2. Techniques to Detect Spammers in Twitter- A Survey Monika Verma, International Journal of Computer Applications (0975 – 8887)
	Volume 85 – No 10, January 2014
	3. Detection of Suspicious URL in Social Networking Site Twitter: Survey Paper Jyoti D.Halwar, International Journal of Computer Applications (0975 – 8887)
	Volume 110 – No. 8, January 2015
	4. A Survey on Data Security in Social Networking Sites, Pragya Pradhan, International Journal of Computer Applications (0975 – 8887)
	Volume 155 – No 7, December 2016 
	5. A Survey of Spam Detection Methods on Twitter, Abdullah Talha Kabakus, (IJACSA) International Journal of Advanced Computer Science and Applications,
	Vol. 8, No. 3, 2017 
	6. Anomaly Detection in Online Social Network: A Survey, Ketan Anand, International Conference on Inventive Communication and Computational Technologies
	(ICICCT 2017)
	7. Kayes, Imrul, and Adriana Iamnitchi. "Privacy and security in online social networks: A survey." Online Social Networks and Media 3 (2017): 1-21.
	8. Lalitha, L. A., Vishwanath R. Hulipalled, and K. R. Venugopal. "Spamming the mainstream: A survey on trending Twitter spam detection techniques." Smart Technologies For Smart Nation (SmartTechCon), 2017 International Conference On. IEEE, 2017
	9. Ansari, S. S., and T. Diwan. "Survey on Tweet Segmentation and Sentiment Analysis." (2018).






===================

What is Twitter, a Social Network or a News Media?


When Governments Hack Opponents:
A Look at Actors and Technology
William R. Marczak, University of California, Berkeley, and The Citizen Lab;
John Scott-Railton, University of California, Los Angeles, and The Citizen Lab;
Morgan Marquis-Boire, The Citizen Lab; Vern Paxson, University of California, Berkeley,

and International Computer Science Institute

================================
=======================
Ιανουαριο 2014 (1ο εξαμηνο)
Σεπτεβριο 2014 διακοπή (Βαρκελωνη)
Ιανουαριος 2015 (2ο εξαμηνο)
Σεπτεμβριο 2015 διακοπή (Κυπρος)

Ιανουαριος 2016 διακοπή  ---- mish xronia paramu8i 
Σεπτεμβριος 2016 3ο εξαμηνο---- paramu8i 
Ιανουαριος 2017 4ο εξαμηνο ----  paramu8i
Σεπτεμβριος 2017 5ο εξαμηνο  pronhpio 
Ιανουαριος 2018 6ο εξαμηνο  pronhpio 
Σεπτεμβριος 2018 7ο εξαμηνο  nhpi
Ianouarios 2019 8o examhno 


#13May
*Thesis proposal* 

 
Challenges

M: Ορισμό για σπαμ; 
  F: orizete apo thn Μαζικότητα? mpa 
  I: Μετρικes για τον ορισμό και πως τις μετράμε στην δικιά μας δουλειά 

M+S+V:  να βρεθεί Κοινώς παρονομαστής για τις τρεις δουλειές. πολύ σημαντικό να φανείτε τα συμπεράσματα από τις τρεις δουλειές compact και συνδεδεμένο 
S: na mpoun kai oi treis, alla na vre8ei ena story pou na tis 

Despoina : 
https://help.twitter.com/en/safety-and-security/report-spam
"Spam" refers to a variety of prohibited behaviors that violate the Twitter Rules. Spam can be generally described as unsolicited, repeated actions that negatively impact other people. This includes many forms of automated account interactions and behaviors as well as attempts to mislead or deceive people. Behaviors that constitute "spamming" on Twitter will continue to evolve.

There is a list of examples of what constitutes “spamming” in the Twitter Rules. Here are some common tactics that spam accounts often use:

Posting harmful links (including links to phishing or malware sites)
Aggressive following behavior (mass following and mass unfollowing for attention)
Abusing the reply or mention functions to post unwanted messages to accounts
Creating multiple accounts (either manually or using automated tools)
Posting repeatedly to trending topics to try to grab attention
Repeatedly posting duplicate updates
Posting links with unrelated Tweets


*EUNITY 4.2 Jose telco :*

how discrete and different are the project calls for each partners for each area??

check in extend 
two types of input

take all recommendations from 4.1 and update <== calls ?  

section 4: impact.  *extend* 



who to approach, how to build a consortium 

similar to community building ?? Gregory not sure?
Analysis of research

mention collaboration projects with Japan
project that 


methodology to start a collaboration with japan (as a company)
EUROPE: ECSO /ENISA etc (starting points)
JAPAN: ??? (ask our JP partners)

key questions, who to contact ?
for everyone is willing to collaborate with 

*from telco notes*
## Focus on D4.2

JR presented a new document to form Sections 3 and 4 of deliverable D4.2.
Section 3 extends opportunities identified in WP3 and D4.1 into topics of cooperation between EU and Japan in areas of R&I, legal and policy, as well as industry and standardization. 
Section 4 details the impacts of the cooperation.

GB suggest that some of the topics detailed in Section 3 be used to build project call documents (2 pages at most) in order to entice reusability and make the recommendations more actionable towards the EC, ECSO or other relevant entities (e.g., ICT-03 pilots). 
GB proposes to have at most 10 such documents that could form the appendix of D4.2 and be distributed independently.

JR proposes 5 of these topics to be interdisciplinary, i.e., have overlaps between R&I, L&P or I&S areas. 
GB proposes to complete this list of 5 with 5 other topics concerning only one of the areas among R&I, L&P or I&S.

[TODO>All] update Sections 3 and 4 by *Wednesday 15th evening*
[TODO>All] write project call documents on specific topics upon JR's requesttowards the end of the week *(Friday 17th)*
[TODO>JR] provide 5 interdisciplinary topics for project call documents by Tueday 14th morning
[TODO>GB] provide 5 individual area topics for project call documents by Tuesday 14th morning









*EUNITY deliverable 4.2* 
forth contributed to research: 

https://www.sans.org/reading-room/whitepapers/analyst/top-attacks-threat-report-38908
I would need from all of you to check the different sectors (according to your area) and extend the table with more *recommendations* you found since D4.1 was published. Additionally, Section 4 is for describing the *expected impact* the recommendations would have in both areas (Europe and Japan). Please include also your contribution there and I will integrate everything.


alla proteinei o HERVE na mpoun san project call texts in H2020 fashion, opote perimenoume na kanoun to skype aurio kai meta rwtame an 8eloun ola na mpoun etsi . kai an ousiastika einai alla ta prjetc calls pou prepei na vrei o lka8e partner  . 



*womencourage scholarship*
ACM womENcourage is a prestigious scientific event covering networking and exploring possibilities to the attendees. 

It explores the research topics of Computer Science and is mainly focused on women who want to have a big impact on their future world.
It is a great place for networking and presenting your work, receive feedback on your ideas, exchange knowledge and establish collaborations within this community. 
For these reasons I believe that it will be a beneficial and impactful experience for me.
 
=======================
Tsamardinos? Papadopouli ? posous DEP xreiazomaste gia 7melh ?
==================

Could you please check availability for hotel in Kyoto for the dates 25/4 - 29/4
The venue is in Campus Plaza Kyoto so preferably I would like a hotel very close to this location. I have found this hotel in booking: APA Hotel Kyoto Ekimae 

I would also like a hotel in Tokyo for the dates 19/4 - 25/4. 

I am travelling with my husband so we would like a double room but has to be charged as a single room for FORTH and I will cover the difference. 
The same is for the tickets, I will cover the ticket for my husband and FORTH will be charged only with my ticket. 
invitation email
- erwthmatologio
- exoyme zhthsei kostos apo CCBS.


*HY118* 
9 askhseis hmera fronthsthriou paradidoun kai dinoume thn epomenh 
dior8wsh askhsewn kuriws
fronthsthria ta kanei h mamalaki 
gia ka8e seira askhsewn 8a dio8wnoume  kai proodos kai telikos askhsen diowr8wsh 

genika ~5 wres h dior8wsh askhsewn 
*πρώτη διορθωση*  
4 Marth 10:00 sto grafeio tou sthn kouzina  - 
sunh8ws meta thn paradosh askhsewn  - h prwth deutera 






*Mhtsos sunallagh me A8anasia petro *EB190 102 371 650 64 kvdikoys synallaghs 100

2/1/2019 12:25 


 electronic black band call in never called ever 

 1 intro
 1.1 Objectives and Contributions
 1.2 Detailed Description of Proposed Research
 1.2.1 Privacy Leakage due to Conflict of Interests
 1.2.2 Privacy Loss due to Geo-location Information
 2 Related Work
 2.1 Privacy conflicts and access control mechanisms in OSNs
 2.2 Location inference.

#epitroph

1)Sotiris
2)Vivi
3)Markatos
4)Poluvios
5)polakis ?
6)Hlias ?
7)Tzitzikas? Fatourou?

#EUNITY tweets 

https://arstechnica.com/information-technology/2019/01/a-dns-hijacking-wave-is-targeting-companies-at-an-almost-unprecedented-scale/
https://www.zdnet.com/google-amp/article/over-485000-ubiquiti-devices-vulnerable-to-new-attack/
https://www.zdnet.com/article/japanese-government-plans-to-hack-into-citizens-iot-devices/#ftag=CAD-00-10aag7e

https://www.comparitech.com/blog/vpn-privacy/cybersecurity-by-country/?utm_content=84579479&utm_medium=social&utm_source=twitter&hss_channel=tw-2466013141
01/06/2017  30/05/2019


https://hedonometer.org/about.html


#Thesis proposal #thesis proposal : ask pilia poses selides. shoudl we add gme intro text ?\:
  *PIlia says :ena kalo intro, objectives
  * liga pramata ap ta papers
  * kai ena sxetiko related 3-4 selides
  * kanto na fenetai san ena eniaio pragma
  *  dld to intro sou na sindeei ta 3 papers, vale to thesis statement, contributions klp
  * einai ousiastika oti:
  *  vrika afto to provlima, kai tha kanw afta kai afta gia na to liso
*thesis proposal* 
Πρόταση Διατριβής
εγκεκριμένη και υπογεγραμμένη από τη Συμβουλευτική Επιτροπή, μέσα σε προθεσμία τριών (3) εξαμήνων από την επιτυχία στις ΓΜΕ. Αν ο υποψήφιος δεν υποβάλλει την πρόταση εμπρόθεσμα, δεν μπορεί να εγγραφεί στο επόμενο εξάμηνο. 

Η πρόταση διατριβής πρέπει μέσα σε εύλογο αριθμό σελίδων και σε σημαντικό βαθμό λεπτομέρειας και βάθους να αναλύει τη συγκεκριμένη περιοχή που θα δουλέψει ο φοιτητής και το πρόβλημα που θα λύσει. H πρόταση αυτή μπορεί να αποτελέσει τον πυρήνα της βιβλιογραφικής αναδρομής της διδακτορικής διατριβής.


panpap leei oti 8elei introductions + contributions. ousiastika na peis tis 8a kaneis alla mhn valeis noumera.


#IEEE survey paper submitted  - rejected : This manuscript falls outside the scope if IEEE COMST. While communications and networking are underlying technologies for Twitter, this manuscript does not cover communications and networking in detail. Please submit to an appropriate general information processing or social network journal.

#resubmitted in ACM surveys  - https://csur.acm.org/



#EUNITY workshop 



Challenges of cybersecurity certification and supply chain management. ECSO WG1. @eunity_project, @ecso_eu, #eunity_workshop  @eunity_project, @ecso_eu, #eunity_workshop


*Discussion on common approaches and possible synergies.* 

-Japan (minister) cybersecurity certification process. scheme what kind of areas are you prioritizing? 
-ECSo: the is a limit on what to say. as a commission there is not much to say.  They set up some priorities, sector specific .
sector approach is not so obvious. ecso is doing a n interesting work . we are happy that conceptual work is being done. 

ecso will continues to provide scheme and after the implementation , will contact with japan. /?



-Mateo lab europe: joint interests. is this not also a case for a eu-japan collaboration . 
- there is eu japan ict dialogues . partners form industry . thera are also some closed eu - japan dialogues , including iot industry 
there are several programs for discussions. 

-polemi: fp7 supported collaboration eu-japan and horizon 2020 included eu-japan collaboration . learned a lot from these projects, 
exchange program of trainees , horizon europe (next program) is planning to continues collaboration between eu-japan. the upcoming international visibility + collaboration . 

-japan cert : to nis directive. nis directive mandate to report incidents, after few time past the nis is ineffect. doid it help to get the situation awareness ? 
-nis: between may-august only few members reported. they have aggregated info , still useful. 

-herve: visit japan. there are trainees and program , it is very interesting. it would be useful to support these educational procedures. 

-japan : he participated in a internship in uk , very useful for other sectors to see what is happening. 

herve - You need : English, platforms to collaborate and instructors. technology + use case and scenarios + instructors . 

- japan what kind of training ...exercises for managers for corporations. not including technical. international exercise would be useful. infrastructures are dependent on ?.. 
 
-nineta polemi : honey net - honeypot. is this only for governmental bodies?
-japan: limiting environment . cyberattacks. stardust is sophisticated environment. not only for the government .

-business innovation networks: one current issues , no common language between technical people. so the organize exercise with specific scenario : ngs banks. 
technical people find the exercises not so technical and manager find them too technical. barrier: 
- in japan? teh same issue.  national cybersecurity center : give technical expertise to managers  and  they also have a cybersecurity framework       . people have the same level of understanding . 

-japanese minister : need data +
 trust copperation between countries nad companies. 
domestic legislation for cybersecurity. Japanese government have been intense on the discussion on this issues , private sector worries on these issues. new ara  that brings worries  . 

*Evening Session*

-Youki: how are you going to certify
-Herve: Europe is going to define the schemes. The rest of the activities for the Establishment be continued by countries , SMEs, companies ...
-roberto ecso : ECSO is not going to do teh certification schems, this is the job of ENISA but will provide the  tool to be used to compose the certification scheme. 
The certification is voluntary. these will be a regulator sector. and say of a certification will be mandatory. 

-third parties. how could work? using a third party as certification.
-there are some members in ecso taht are certifiers. there are some cases thesre is aneed to be an independent body. (it will be write) 
Also there will be National certification 

*16:15 – 17:00 Discussion on potential cooperation and next steps*

-Herve initial remarks about EUNITY project 

-Nineta: Here is an opportinty to communicate with EU - the final deliverable of EUNITy (reccomendations ), the most important deliveranble  to draw new projects . in order to continues funding . We need specific actions of collaboration . 

We need specific reccomendations. 


--Youki Academic can communicatite in some ways . students - programs - but what about the rest ? industry ? automotive insdustries . they are isolated . digital network of trust . need cyberspecialists . how to support this network trust ...ISP ...and other keyplayers. 

- Herve - 

#dissemination activities for visiting Japan

visit cubersecurity companies (with Jouki) in order to retrieve expertise, material and sources for the completion of a deliverable?
deliverable have been completed and we are (FORTH) not in charge of a deliverable . 
4.1?

present/disseminate the results of EUNITY project to ..some team ?



#HY345
Sto owncloud tou mathimatos (nefos.csd.uoc.gr) yparxei
to spreadsheet gia tin fetinh vathmologia. Kalo tha htan
na exoume olous tous vathmous ton askhseon sto spreadsheet
prin thn deftera oste na mporo na steilo tin telikh
vathmologia meta thn eksetash.

Mporeite na kanete login me to email kai to pass tou
mathimatos. Sto username valte olo to email tis listas mas.

Kathe enas prin perasei tis vathmologies tou as stilei edo
ena lock/unlock oste na mhn exoume conflicts. Gia thn ora
yparxoun oi dikes mou vathmologies kai tou tsirba. Episis,
sympliroste to login tou kathe foithth sto adistixo field
alios to script den tha kataferei na stilei tin vathmologia
kai tha exoume provlimata pou tha prepei na lisoume manually.


------------------


Auth thn paraskeuh 18/1 exo valei 36 slots 11:00 - 13:00
gia thn eksetash ton foithton pou den kataferan na erthoun
prin tis giortes. H eksetash tha ginei sta grafeia ton
metaptyxiakon foithton. An ta slots gemisoun kai exoume
extra foithtes tha sympliroso kiala alla den nomizo oti tha
mas parei meta tis 14:00. To pio pithano einai na teleiosoume
prin ti 13:00 kathos tha eimaste 2 extra auth thn fora.

#14 January 2019 

Twitter Survey paper comments

if the indication of success of real worl entities (movies, ...)
red there are publication that show that these characteristics not not use them to promote spam 

grey as paules
todo  : cite 1, cite 2 ==> cite (1,2) 

table 2. extra comma kai how cetrally am I  OK 
users me kefalaio ok 


table 4 is the machine learning pipeline

uparxoun 4 tasks se ML 
auta ienia ta 7 steps pou xrhsimopoioume to ML workflow oxi mono gia sentiment analysis alla for everything 
#11 January 2019 

*IEEE surveys*

A Survey on Advanced Persistent Threats: Techniques, Solutions, Challenges, and Research Opportunities. https://ieeexplore.ieee.org/document/8606252
"I Wanted to Predict Elections with Twitter and all I got was this Lousy Paper" -- A Balanced Survey on Election Prediction using Twitter Data - https://arxiv.org/abs/1204.6441 
Understanding user behavior in online social networks: a survey  - https://ieeexplore.ieee.org/abstract/document/6588663
Measuring user influence on Twitter: A survey - https://www.sciencedirect.com/science/article/pii/S0306457316300589
A survey of location inference techniques on Twitter https://journals.sagepub.com/doi/abs/10.1177/0165551515602847


*ACM surveys*

I read my Twitter the next morning and was astonished: A conversational perspective on Twitter regrets- http://mykayem.org/pdfs/twitter.pdf https://dl.acm.org/citation.cfm?id=2938640
Like it or not: A survey of twitter sentiment analysis methods https://www.researchgate.net/publication/304916478_Like_It_or_Not_A_Survey_of_Twitter_Sentiment_Analysis_Methods

What do people ask their social networks, and why?: a survey study of status message q&a behavior https://dl.acm.org/citation.cfm?id=1753587
A survey of social media use in software systems development https://dl.acm.org/citation.cfm?id=1809200
Information diffusion in online social networks: A survey https://dl.acm.org/citation.cfm?id=2503797

 
Utilising location based social media in travel survey methods: bringing twitter data into the play https://dl.acm.org/citation.cfm?id=2830660

 
Software engineering at the speed of light: how developers stay current using twitterhttps://dl.acm.org/citation.cfm?id=2568305

Topical semantics of twitter links https://dl.acm.org/citation.cfm?id=1935882

Incremental persuasion through microblogging: a survey of Twitter users in Latvia https://dl.acm.org/citation.cfm?id=2467811

Social media ownership: using twitter as a window onto current attitudes and beliefs https://dl.acm.org/citation.cfm?id=1979103
Entity-centric topic-oriented opinion summarization in twitter https://dl.acm.org/citation.cfm?id=2339592
A longitudinal study of facebook, linkedin, & twitter use https://dl.acm.org/citation.cfm?id=2208671
[PDF] Depressive moods of users portrayed in Twitter http://wan.poly.edu/KDD2012/forms/workshop/HI-KDD12/doc/paper_16.pdf

Twitter as medium and message  https://dl.acm.org/citation.cfm?id=1897860
Processing social media messages in mass emergency: A survey https://dl.acm.org/citation.cfm?id=2771588
On participation in group chats on twitter https://dl.acm.org/citation.cfm?id=2488404

Fragile online relationship: a first look at unfollow dynamics in twitter https://dl.acm.org/citation.cfm?id=1979104








qemu-system-i386 -curses
qemu-system-i386 -hda  hy345-linux.img -curses

 qemu-system-i386 -hda hy345-linux.img -append "root=/dev/hda" -kernel linux-2.6.38.1/arch/x86/boot/bzImage

esc 2 , q enter
csdp826@csd.uoc.gr
WIFI csd


dear Jose, 

I have written the conclusion part of the research the first time you mentioned :) 

It is in svn before the review in Vienna :) 

I sent you an email this morning . I include it in this email :) 


Assignment #1
----------------
-> Na kanei compile kai na exei makefile
-> Na leitourgoune aples entoles (cd, pwd, ls -l ) 
-> Na leitourgie pipe me panw apo 2 "|" me redirection  ">>, <<, >, <" 
-> background process (Ctr-Z) and fg me ena process in background kai me 2-3 process (eprepe na kanoun stack apo auta ta process)
-> Na leitourgei to tab (filename expansion ) 
-> Wildcard (rm*.txt or cat*.txt) 

Assignment #2
----------------

* να κανει compile  
* να τερματιζει  
* να υλοποιουν το  μέσο χρόνο αναμονής και πόσοι πελάτες αναγκάστηκαν να φύγουν. (στην χθεσινη εξεταση καποιος το εκτυπωνε αλλα δεν το ειχε υλοποιησει σωστα - απλα τυπωνε καποιο τυχαιο αριθμο!) 
* να μπορεί να εξηγησει τι κανει και να γνωριζει semaphore + mutex χρηση 



Assignment 3
------------------
* Na kanei compile kai na yparxei to bzimage
* Na exoun ena kalo demo pou eksetazei oles tis periptoseis
* Na exoun kanei traverse tin lista me tis thigatrikes diergasies
    kai na leitourgoun ta syscalls mono gi autes kai ton eauto tous
* Na exoun kanei sosta ta copy from/to user
* Na exoun elenxous gia tis times (px arnitikoi xronoi klp)

Assignment #4
---------------------
* Na kanei compile kai na exoun to bzimage
* Na exoun demo kwdika pou na deixnei me kapoio tropo oti ginete swsta to sheduling (gia processes me diaforetiko soft and hard deadline) gia tis diaforetikes periptwseis tou scheduling policy (closest hard deadline, round robin) 
* Ean exoun ulopoihsei neo scheduling class, na to exoun ylopoihsei plhrws (ean trexei pi8ano na exoun ylopoihsei ola ta structs kai functions pou xreiazete). 
Prepei na tsekarete oti bazoun ta processes tou demo sto swsto class kai oti mpainoun swsta se runqueue
* Tsekarete oti xrhsimopoioun ta system calls ths askisis 3(akousa polles perierges erwtiseis sxetika me auto) kai oti h shedule kaleite ana 5ms gia to diko tous class.
* Ean den exoun ulopoihsei neo class, pi8ano na min trexei opws 8eloume, opote zhthste tous na perigrapsoun ton tropo me ton opoio to
ulopoihsan kai eksetaste ean exei logiki bash kai ean dhmiourgei basika problimata(starvation twn allwn processes). 
Se auto to shmeio ba8mologiste kai thn opoia prospa8eia.


---------------------------------
Atos: 


Thanks for the references you sent me. As they are already in the text as you mentioned I let them in general for all as footnotes. 

Additionally, I created a new subsection 2.2 for knowledge where I have included a paragraph for each of the parts (legal and policy; research and innovation; industry)
 about sources used, methodology, etc. 
 I highlighted a part for research and innovation in yellow. 
 Do you think you could provide me tomorrow a small paragraph for including there? 

 You can use as basis the one of legal and industry already there.

  Also, I do not know if I missed but cannot find your contribution for section 6 (Conclusions). Could you please send me also tomorrow? I highlighted in yellow where to include in the document.

I send you attached also the last version of D4.1 (also in the repository) so you can check.

Please let me know any comment or question.





1) journal PLOS ; 2017 - Social media analysis during political turbulence

2) Conference and Workshop papers 2014 Think Before RT: An Experimental Study of Abusing Twitter Trends
In Proceedings of the Workshop On Social Influence (SI), co-located with the 6th International Conference on Social Informatics (SocInfo)

3) Journal : Exploiting abused trending topics to identify spam campaigns in Twitter 
Despoina Antonakaki, Iasonas Polakis, Elias Athanasopoulos, Paraskevi Fragopoulou, and Sotiris Ioannidis.
In Social Network Analysis and Mining 2016), 6(1).

4) Investigating the Complete Corpus of
Referendum and Elections Tweets 2016

5) Utilizing the average node degree to assess the temporal growth rate
of Twitter 2018 / Accepted: 7 February 2018


13. Annual average number of days dedicated to education and training duties        
2013 10
2014  5 days/week * 6    
2015
2016
2017



===================================
Ιανουαριο 2014 (1ο εξαμηνο)
Σεπτεβριο 2014 διακοπή (Βαρκελωνη)
Ιανουαριος 2015 (2ο εξαμηνο)
Σεπτεμβριο 2015 διακοπή (Κυπρος)

Ιανουαριος 2016 διακοπή  ---- mish xronia paramu8i 
Σεπτεμβριος 2016 3ο εξαμηνο---- paramu8i 
Ιανουαριος 2017 4ο εξαμηνο ----  paramu8i
Σεπτεμβριος 2017 5ο εξαμηνο  pronhpio 
Ιανουαριος 2018 6ο εξαμηνο  pronhpio 
Σεπτεμβριος 2018 7ο εξαμηνο  nhpio 




Put a disclaimer on Twitter and the website is the opinion of the project and not the EU.

 IEEE surveys h ACM surveys na doume ti dhmosieuete ekei kai pou tairsiazei perisootero 
 

DIGIDid
digidID
digiID

Despoina Antonakaki <antonakd@gmail.com>
Jun 25, 2015, 12:58 PM
to Alexandros, Despoina

digid despoina  antonak, aneiP3R00FG!
alekou kantale A^^L1978despoina

19/11/2018
*survey paper typos:*

      This is because the top ranked, Google+, was shut down since 8th of October 2018~\cite{C49C66C6ED30} and also it used to consider as active, all users that had a Google account which is highly misleading. 
      This is because the top ranked, Google+, WhiCh was shut down ON 8th of October 2018~\cite{C49C66C6ED30}, it was also considered as active, all users that had a Google account which is highly misleading.   does make sense....



    For example, in order to request the timeline of a user, a client can perform 900 requests per alloted window

    The seventh is the Random Node-Neighbor where a node is selected randomly along with its neighboring --> neighbouring nodes.
     are the nodes that are neighbors to a node

      prevention, sybil atttacks

      information or rumors.


     strong favoritism towards certain users. 

     content is a crucial precautious step. 

     Several methods are used for data collection and spam labeling of content in social networks.

     An influencial user can alter the spread patterns of information let that be a URL or a single tweet.

    This is reflected in clickhtrough rate which is the percentage of spam links that users are tricked to follow over the sum of the total spam that they receive.

    This belief is based on the signficantly different results returned on users with different search history on sensitive matters like the BP spill and Arab Spring. 

    Interestingly although Social Networks have been criticized for apathy in external efforts to de-anonymize users, they have also been overly secretive in hiding controversial content published from certain  

    Lists --> lists


*EUNITY mid term review comment :* 

The eunity D2.3 containing the 1st workshop proceedings has changed and we have added comments, discussion and feedback in a new chapter: 4. Discussion & Feedback. Mainly they are comments that were kept from our partners that were present in the workshop, describing the feedback from the audience and some main key point from the presentations  . 


        *EUNITY_Interim_Review.txt*
            EUNITY Interim Review
            28th June

            NP = Nineta Polemi (PO)
            AF = Afonso Ferreira (Reviewer)
            AL = Andrea Lanzi (Reviewer)

            The reviewers state that this is an interim review, not the first review. The objective is to get an overview of the project, not to assess the financing aspects

            --------------------------------------------

            Dissemination tools:

            AF asks to specify the "impression" notion on Twitter.

            AF acknowledges the fact that the mechanics for dissemination are there, but gives strong criticism about the content regarding the dissemination tools:
            - Too few tweets (only 1 since October) OK 
            - Only one publication on the website, not related to cybersecurity OK 

            AF: What is the added value/impact of the WP5 for the project?
            D5.2 has very little info about the future plans / relationship with JP partners 
*sto submitted August exei future plans*
     
        Why is it good to disseminate, what should be disseminated?
            The figures should be better, but should also be meaningful
            D5.1 would be rejected if it were the 1st review
            The website does not display any results about the project workshop, does not show the progress of the project.

*oi allages exoun ginei sto site alla to 5.1 den prepei na allaxei?*

            NP: What are the indicators for the success? It is necessary to focus on the KPI and quantitative measures.
            Who is the audience of the website? If the audience is both EU and JP, the pages should be both in English and Japanese.
*OK*

            What do you want to convey in this website? Why does the website look like that? Everything should be justified and explained in the deliverable.
            => Improve content and presentation
            => Add a mirror website in Japan, written in Japanese
*OK*

            NP: What are the security features of the website? Is it compliant with GDPR?
*OK*

            HervÈ states that there is one mention for the GDPR on the website.
            AF insists on the fact that the objective of the website is to raise awareness. It has to display a clear reference to GDPR and to its security features in order to teach good behavior to visitors.
            => Have a footnote or a page that describes how the website is secured.

*OK*
            --------------------------------------------

            Community Engagement Report (D2.1) :

            AL: How was the questionnaire set up?
            AF: Good document, but practically no activity described since October after the workshop 
            HervÈ and Youki add that questionnaires were sent to additional people during a meeting in Japan in January, in order to get more feedback from the workshop.
            AF suggests to add this in the document, but Youki says it is planned for D2.2.

            HervÈ: Plan to go to JP during fall for a follow-up of the exchange with JP partners
            Sotiris: We also have exchanges with JP student that are not reported
            HervÈ and Sotiris give additional examples of exchanges and collaborative activity that happened or that are planned, but were not funded by EUNITY.
            AF: Everything should be included in the document, even if not funded. It should include every kind of exchange, meeting, etc. that happened since the 1st workshop. And everything should also be uploaded on the website.

            NP: This deliverable should be a best practice description of how to set up a EU workshop in Japan, who are the members that are interested, explain who is the community, how you came up with this community, the characteristics of the audience, etc.
            AF: Indeed, the document lacks the methodology for community engagement. Which channels are you using, who are you targetting, how to represent various profiles, etc.
            HervÈ highlights the fact that this project works because there is already a strong relationship with JP partners, which means that there is an internal network of people already working together that cannot be described properly
            Youki mentions that the objective of the workshop/follow-up meeting was not to gather a vast amount of people, but rather to gather key people.

            AL asks how much time it took to prepare this workshop.
            Youki: I was assisted by Dr. Kazuya Okada of the University of Tokyo for logistical aspects, and one of my secretaries for the e-mail campaign to Japanese cyber-security experts.
            I coordinated with key cybersecurity experts in Japan through e-mail. I was also assisted by my secretary to inform the 1st workshop to >60 experts through individual e-mail. 
            In total, the coordination and campaign e-mail resulted in more than 300 messages.

            It was pointed out that the document should explain why the 2nd day had less attendance

            --------------------------------------------

            D3.1

            1) Legal aspects

            AL raises the issue of a lack of conclusion in EU-JP comparison
            HervÈ says that it is mainly due to European law on cybersecurity being less mature (NIS directive bein transposed differently in countries), making it extremely complicated to cover
            NP mentions that IoT certification is being discussed currently and is too early to present. HervÈ mentions a similar feedback from ECSO where only the existence of the certification can be stated
            Youki adds that there is still a strong debate in Japan about IoT certification. A draft is available in Japanese.

            AF: The conclusion of this section needs some rewriting. The part that begins with "With respect to cybersecurity" needs a new paragraph and better phrasing about collaboration opportunities. 
            It needs to insist on the fact that the process is important since it is legislation in the making, in order to come up with a more common legislation between EU and JP and facilitate joint activities.

            2) Financing mechanisms

            AF: The JP section has to be improved with a better description of the mechanisms. The document should also include EUREKA clusters for industry.
            Concerns are raised about the strategic research agenda, that should not be a laundry list. Here, strategy is limited to the wishes of a group of people. 
            => What is the added value of this project?

            NP: The research agenda should be promoting industries
            How to facilitate the emergence of the cooperation in various research areas (e.g. medical, automotive market, etc.)?
            HervÈ sums up the remarks saying they come down to 2 aspects: prioritize areas, and push industry. That means that areas which aren't prioritized may be weak in the deliverable
            AF states that this is not an issue, it is better to insist on what is identified as areas we're good at. But the priorities have to be justified.
            Adam: All this is actually related to WP4 (agreed by reviewers)

            3) Industry aspects

            NP: The industrial challenges may vary in a given area (ex: privacy of big data) according to the industry (ex. automotive industry, energy, etc.). It is necessary to focus on industries that are common interest between EU and JP. The agenda should be industry-driven.
            AF: The chapter has a lack of methodology. Table 4.1 is not very relevant as it is since there is no visible hierarchy (e.g. ARTEMIS is part of ECSEL). The table should highlight a two-level hierarchy. JUs are operationalizing the R&D, cPPPs are at a lower level. The priorities are in the money. The JUs are verticals.
            Section 4.1.3.2 should mention Brittany region for its importance in cybersecurity (PEC).

            4) Strong and weak points

            It is highlighted that US is leader in many fields of cybersecurity and computer science.
            It is asked how much Japan spends for cybersecurity.
            Youki: D3.1 contains detailed numbers. It tells us that Japanese cybersecurity spending will exceed 1 trillion yen in 2018, which is roughly 7.8 billion euros.

            AF: Appendix A is very important and very good, but is still not complete

            -------------------------------------------

            Workshop (D2.3)

            CSIRT session

            Highlight of the interest of sector specific ISAC in Japan

            ECSO session

            NP: Is there a organization similar to ECSO in JP? If ECSO was to be created in JP, would the WG be different?

            Youki: Keidanren (Japan Business Federation) has a good number of activities going on in the area of cybersecurity.  
            Thus the landscape is different from Europe in that we have all-industry business federation with interest in cybersecurity, whereas in ECSO, cybersecurity is attracting membership from all industries.
            Keidanren also participates in policy dialogue with government by representing its industry voices in the government committees and subcommittees.
            METI has recently launched industry cybersecurity deliberation group which can be considered to be parallel to ECSO.
            They have 4 working groups:
            WG1 regulation, technology and standardization
            WG2 management, human resources, international relations
            WG3 cybersecurity business
            WG1 has sector-specific sub-working groups, such as power grid, building, etc.
            Materials can be found online (in Japanese):
            http://www.meti.go.jp/committee/kenkyukai/shoujo/sangyo_cyber/001_haifu.html
            http://www.meti.go.jp/committee/kenkyukai/mono_info_service.html#sangyo_cyber

            Privacy session

            What is the main difference between GDPR and Japanese regulation?
            => GDPR requires explicit consent from the user

            What are the articles of GDPR that are the most difficult to implement?

            Research session

            NP raises a contradiction with the industry session about Robotics, ML, AI not being considered by the industry.
            Pedro replies that the point of view expressed here is from research, not industry.

            AF raises concerns about the deliverable. The workshop was great, but the deliverable should be more than just the slides. There should be an added value. If the workshop organization is included, there should be extra content.
            => A report should be added, describing the process, the introduction of the organization, conclusion on the follow-up, etc. A presentation of the questionnaires might be added too.

            --------------------------------------------

            Dissemination

            ETSI interested in the standardization of SoC
            AF: Concerns with the document, missing the added value, and the relationship between the listed activities with the goals of the project. What is the added value of the participation in the networking events for the project? Which communities?
            Section 5.1: year not present (2017)
            Section 5 needs to be rewritten. Standards are in section 4.

            In what way the fact that JP EUNITY partners visited Greece (FORTH) for CIPSEC was dissemination?
            Same concern with ETSI: what's the value of EUNITY dissemination there?
            => The document should not only be a list of events
            HervÈ explains the link between ETSI and IETF. The implementation report on the MILE RFC is planned to be used in ETSI standards. This is not a community engagement activity, but it is about pushing common EU-JP activities.
            AF: Totally agree, but that needs to appear in the deliverable. It corresponds to what is missing in the document.
*D5.3*

            Youki says that communities are described in the DOA
            AF: It needs to be included in the deliverable too.
            AF remarks that there is no mention of JP research activities whereas it's in the contract. However, it does not make sense here. It could be amended with the PO.
            HervÈ: Without amendment, can we just refer to D3.1 in that section?
            => The reviewers and PO say that it seems acceptable
            NP: All events (organized or attended) need to be described with how many people, which kind of people, what is the scope, the outcomes, what were the goals and if they were met (and how to measure that, with reference to KPI)


            --------------------------------------------

            Future

            FIC2019: around 10000 participants
            AF: What's the purpose of going to FIC?  
            => Inform the FIC audience of the project
            AF suggests to use FIC to organize a very high level event: Bring a delegation from JP, strong keynote speakers, big industrials, and get a high level conversation with ministry to influence political dialog. It would involve officials from both JP and EU.
            Youki: What is the usefulness in including ministry officers? An agreement is already signed between JP and EC
            HervÈ: The usefulness is to meet ministry officers with ministry officers
            Youki: It is more useful to focus on business level, dialog has already been established. We can have an historical meeting between JP industry delegates with ECSO
            AF point out that the EC must be present at the ECSO meeting

            HervÈ highlights the ambition to reach a privacy event, since the main focus of the project has been cybersecurity until now. 
            The ENISA Privacy forum in June could be a good target, but it might need a 1 month extension
            => NP does not comment on the extension suggestion, and seems reluctant
            AF asks if there is a big conference oriented on Privacy, as it seems like every good conference on that topic is rather small (ESORICS, etc.)
            NP: How is ENISA Summer School related to EUNITY dissemination?
            AF: Why is Stefano attending a conference on Big Data? Is it related to EUNITY? 
            AF: What is the intention of Atos Scientific Community? 
            => Presentation of EUNITY as part of invovment of ATOS

            Currently no response for the Joint networking session between the 3 CSAs at ICT (Dec 4-6 in Vienna). If we obtain a positive response, we will be there.

            NP expects a final event at the end of the project and suggests to look at events around April 2019
            AF suggests a joint EU-JP event, starting in the morning in JP, then in the morning in EU while the events pursues during the afternoon in JP (with webcasting). It is suggested to contact ECSO. 

            AF: There are plenty of joint undertakings (e.g. ECSEC) with end user associations to target for dissemination and engagement with verticals. Get endorsement from verticals.
            HervÈ : We need to focus on the verticals that are focused on cooperation between EU and JP.
            NP & AF: There is a need to support the end user industries, not only the cybersecurity industry.

            --------------------------------------------

            Final remarks (by NP)

            Starting date of the project: June 1st 2017
            M12: May 31st 2018

            1) Deliverables due on M12: D2.3, D5.2, D5.3 (reviewed on M18, Dec 7th), due June 31st. 
            Deadline at mid/end of July. Not a major delay, aligned to obligations
            Deliverables accepted: D2.1, D5.1
            (Note: According to information from the EC subsequent to the Interim Review, none of the deliverables were actually accepted)

            2) SRIA: Needs to be defined by us, needs to support industries of mutual interest. We must decide which ones are important for EU and JP.
            Final outcome: SRIA that supports these common industries. Challenges may come from industry, and our expertise translates the challenges into an agenda. 

            3) Website: Should be secured, with a privacy policy visible in a flashy way. The content should represent and target the audience (EU and JP), identify the communities.

            4) Dissemination: Everything needs to be posted on the website, with an explanation on how it fits the goals, with measurable indicators, reasoning and motivations

            5) Social network (LinkedIn, Facebook, Twitter): Should be in Japanese too
*OK*           

            6) D4.1: Needs to be aligned with the project, describe a proper methodology and match objectives



            7) All Events should be measurable actions that fit the purpose of the project

            8) All the EU-JP channels need to match, driven by industry

            9) D2.1 has points that have to go to D5.3
            D5.3 should contain points raised today: Identify the communities, gaps, KPI for dissemination activities, measures 
            => It is advised to create a form to fill for every dissemination event
*OK*              
            D5.1: Website is the main dissemination channel (must be specified in D5.3).
             
            10) Enhanced version of website will be evaluated with D5.3 in December. Content and security policy should be in sync.
             
            11) Strong recommendation for a final dissemination activity, with a joint event to commuicate the outcomes.
            => Get concrete ideas in next review meetings

            AL requires more analysis in the deliverables

            AF adds that publications related to EUNITY should be on the website. No further comment.

            HervÈ: Mostly fair comments. Some challenging ideas, though we are unsure that everything can be reached. Everything we try will be documented.
            The final event seems interesting, we'll anticipate the technical difficulties.

            NP: 1st choice for review: December 7th in Vienna (NP might not be able to attend)
            2nd choice: January in Brussels (date to be defined)

            No further comment. The Interim Review ends.
                                                                                                                                                      


16/11/2018

For example, in order to request the timeline of a user, a client can perform 900 requests per alloted window

The seventh is the Random Node-Neighbor where a node is selected randomly along with its neighboring --> neighbouring nodes.
 are the nodes that are neighbors to a node

  prevention, sybil atttacks

  information or rumors.


 strong favoritism towards certain users. 

 content is a crucial precautious step. 

 Several methods are used for data collection and spam labeling of content in social networks.

 An influencial user can alter the spread patterns of information let that be a URL or a single tweet.

This is reflected in clickhtrough rate which is the percentage of spam links that users are tricked to follow over the sum of the total spam that they receive.

This belief is based on the signficantly different results returned on users with different search history on sensitive matters like the BP spill and Arab Spring. 

Interestingly although Social Networks have been criticized for apathy in external efforts to de-anonymize users, they have also been overly secretive in hiding controversial content published from certain  

15/11/2018 
added new dissemnation activities in eunity for FORTH
corrected d4.1 reviews for our part


*EUNITY tweets* 
    *Des ola ta link ato to d3.1 sta footnotes!* 
        https://www.computerweekly.com/news/4500260196/Cyber-attacks-an-increasing-concern-for-Asean-countries

        On Fri, Oct 12, 2018 at 6:56 AM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        kalhmera
        stelnw auto: 
        https://asia.nikkei.com/Spotlight/Bitcoin-evolution/Coinbase-calls-Japan-s-cryptocurrency-crackdown-good-for-us
         

        On Wed, Oct 10, 2018 at 11:20 AM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        exw kanei tweet gia ola ta items sto publication

        On Wed, Oct 10, 2018 at 10:55 AM Christos Papachristos <cpapachr@ics.forth.gr> wrote:
        Steile to. Giati oxi ? 

        Epishs exei anebei kai ayto sto website.
        GDPR and Japanese Privacy Act: Comparative Overview of GDPR and Japanese Privacy Act based on Deliverable D3.1.
        https://www.eunity-project.eu/m/filer_public/33/7b/337b40bf-0805-438b-a60f-49664f8f93bb/comparative_reporteu_gdpr_japanese_act_from31_formatted2.pdf

        Opote kane ki ayto ena tweet an den to exoyme kanei hdh.

        thanks,
        Christos.


        On 10-Oct-18 9:52 AM, Despoina Antonakaki wrote:
        Ayto ?? 
        https://economictimes.indiatimes.com/news/international/business/facebook-faces-1-63-billion-in-eu-fine-over-fresh-data-breach/articleshow/66023983.cms



        On Thu, Oct 4, 2018 at 2:46 PM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        Τελικα το εσβησα και εστειλα αυτο https://english.kyodonews.net/news/2018/09/1c2b20ba11a4-record-29-million-people-led-to-fake-websites-through-phishing.html

        On Thu, Oct 4, 2018 at 2:29 PM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        Για σήμερα έστειλα αυτό που εκκρεμούσε απο τα δικά σου 
        Japan - Cyber Security. This is a best prospect industry sector for this country.
        https://www.export.gov/article?id=Japan-Cyber-Security

        και τα υπόλοιπα τα βλέπουμε για την επόμενη εβδομάδα.

        On Thu, Oct 4, 2018 at 2:25 PM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        Isws kai auta 
        https://english.kyodonews.net/news/2017/08/da53d267d912-feature-lax-security-leaving-japanese-information-exposed-on-darknet.html?phrase=cybersecurity&words=Cybersecurity,cybersecurity

        https://english.kyodonews.net/news/2018/08/f6752ca5b061-abe-calls-for-better-cyber-space-defense-capabilities.html?phrase=cybersecurity&words=cybersecurity
        https://english.kyodonews.net/news/2018/09/1c2b20ba11a4-record-29-million-people-led-to-fake-websites-through-phishing.html
        http://www.eastasiaforum.org/2018/08/14/japans-cybersecurity-must-address-gaps-in-iot-and-cloud-security/

        On Fri, Sep 21, 2018 at 10:35 AM Christos Papachristos <cpapachr@ics.forth.gr> wrote:
        Isws gia tweets. Einai prosfata.

        A Cyber-security incident list since 2006.
        https://www.csis.org/programs/cybersecurity-and-governance/technology-policy-program/other-projects-cybersecurity

        Cisco Cyber-security report for Asia-Pacific. Threats are rising.
        https://www.cisco.com/c/m/en_au/products/security/offers/cybersecurity-reports.html

        Ayto einai mia meleth gia na boh8hsoyn US companies na kanoyn export products/services kai leei pws gia toys Olympiakoys h Iapwnia einai prosforo edafos
        sto kommati Cybersecurity.
        Japan - Cyber Security. This is a best prospect industry sector for this country.
        https://www.export.gov/article?id=Japan-Cyber-Security

        Ti lete? 
        thanks,
        Christos.



        On 30-Aug-18 2:38 PM, Despoina Antonakaki wrote:
        εκτος απο αυτά που ειναι λιγο παλιά 
        https://www.scmagazine.com/researchers-detect-fresh-activity-in-blackgear-cyber-espionage-campaign/article/781392/
        https://www.scmagazine.com/hackers-exploit-old-flaw-to-turn-linux-servers-into-cryptocurrency-miners/article/753144/
        https://www.scmagazine.com/report-coincheck-cyberthieves-attempting-to-move-sell-off-nem-cryptocurrency/article/740881/
        https://www.scmagazine.com/hackers-weaponised-secure-usb-drives-to-target-air-gapped-networks/article/776144/

        δεν εχω βρει κατι καλυτερο οποτε κανω tweet  αυτό που είχε στειλει ο Χρήστος:  https://thediplomat.com/2018/08/new-opportunities-for-eu-japan-defense-relations/

        On Tue, Aug 21, 2018 at 1:29 PM Despoina Antonakaki <despoina@ics.forth.gr> wrote:
        Οκ

        On Tuesday, August 21, 2018, Christos Papachristos <cpapachr@ics.forth.gr> wrote:
        8a proteina prwto to deytero (poy einai Ioylioy) kai telos Aygoysto to prwto poy einai Aygoystoy.

        thanks,

        Christos.

        On 21-Aug-18 12:48 PM, Despoina Antonakaki wrote:
        ok na steilw to prwto ?

        On Tue, Aug 21, 2018 at 12:37 PM, Christos Papachristos <cpapachr@ics.forth.gr> wrote:
        Pi8ana tweets.

        New Opportunities for EU-Japan Defense Relations
        https://thediplomat.com/2018/08/new-opportunities-for-eu-japan-defense-relations/

        Olympic games.
        https://www.japantimes.co.jp/news/2018/07/16/national/japan-strengthens-cybersecurity-cooperation-eu-ahead-olympics/#.W3vcK7glF9M

        thanks,
        Christos.





        https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment%20data/file/641155/Japan-UK%20Joint%20Declaration%20on%20Security%20Cooperation.pdf

TODO : 
setile paper ston polyvio kai alex gia ta dataset twn eklogwn ok 

EUNITY's Deliverable D5.3: Dissemination report year 1 now available in our website: ok

Deliverable D2.1: Community engagement report. ok

*TODO :* 

    Christos Papachristos <cpapachr@ics.forth.gr>
    6:56 PM (2 hours ago)
    to Despoina, Sotiris

    Synolo fainetai na einai 3 erga katw apo to call toy EUNITY
    https://cordis.europa.eu/search/result_en?q=contenttype=%27project%27%20AND%20/project/relations/associations/relatedCall/call/identifier=%27H2020-DS-SC7-2016%27
    me to koino Programme identifier H2020-EU.3.7.6

    EUNITY:
    https://www.eunity-project.eu
    https://twitter.com/eunity_project

    AEGIS:
    http://aegis-project.org/
    https://twitter.com/aegis_cyber
    https://www.linkedin.com/company/aegis-project/

    CYBERWATCHINGEU
    https://cyberwatching.eu/
    https://twitter.com/cyberwatchingeu
    https://www.linkedin.com/in/cyber-watching-3b1bb2139/

    Emeis sthn protash exoyme pei gia Linkedin alla meta sta WPs den 
    anaferoyme kati.
    Isws omws na prepei na kanoyme ena.

    Despoina,
    mporoyme na paroyme idees apo ta tweets/linkedin posts poy kanoyn kai ta 
    alla 2 projects kai na eimaste active toylaxiston to diasthma
    apomenei.


*todos EUNITY :*  

    - website (flags) (AK)
    - upload eunity deliverables (CP)
    - upload eunity flyer (CP)
    - News section: include PPTs, PDFs and a short description (CP)
    - Add the following entry from Anna (NASK) (CP)
      Presentation on the Kick off event of the European CyberSecurity Month “Case study: Opportunities for European-Japanese cooperation in the field of cybersecurity - strategic and technical perspective (presentation in Polish: Case study: Możliwości współpracy europejsko-japońskiej w dziedzinie cyberbezpieczeństwa - perspektywa strategiczna i techniczna) 
  *- Produce/upload/announce a one page comparison of GDPR (EU-JP) (information retrieved from respective slide of Workshop 1 and D3.1) (DA)
  *- Produce/upload/announce a D3.1 takeaway leaflet (DA)
  *- Announce via twitter D3.1 that is available on the website (DA)
  *- Announce via twitter any D3.1 highlights via twitter (DA)
    - check GA/contract whether we have promised a Linkedin account or not (CP)
    - Contact us: fix/replace captcha. (AK)
    - translate every page to JP (ping NAIST: Kazuya) 
    - fix the scroll in the tweets sections (AK)
    - ping Herve and start discussing about the Workshop 2 (EU) (AD+SI+CP)
    - check the dissemination (or other) activities of the other roadmapping projects (CP)

    linked in 
    herve Youki  mail gia diorganwsh gia to workshop 
    tweet to 3.1 einai online
    tweet takeaway gia to 3.1 

=================

EUNITY cybersecurity Japan Tweets

    https://english.kyodonews.net/news/2017/08/da53d267d912-feature-lax-security-leaving-japanese-information-exposed-on-darknet.html?phrase=cybersecurity&words=Cybersecurity,cybersecurity

    https://english.kyodonews.net/news/2018/08/f6752ca5b061-abe-calls-for-better-cyber-space-defense-capabilities.html?phrase=cybersecurity&words=cybersecurity
    https://english.kyodonews.net/news/2018/09/1c2b20ba11a4-record-29-million-people-led-to-fake-websites-through-phishing.html
    http://www.eastasiaforum.org/2018/08/14/japans-cybersecurity-must-address-gaps-in-iot-and-cloud-security/

    ----------------------
ELECTIONS dataset paper 
    https://arxiv.org/ftp/arxiv/papers/1707/1707.00086.pdf
    http://comprop.oii.ox.ac.uk/wp-content/uploads/sites/89/2017/06/Junk-News-and-Bots-during-the-2017-UK-General-Election.pdf
    https://link.springer.com/article/10.1007/s13278-018-0533-y
      
    According to this https://ig.ft.com/social-bots-of-brexit/  we need to search for these #Ukip, #UK, #Labour ITVDebate #GE2017  in our dataset. I guess any mention to a bot would be a goldmine.  
     1. We already lost French election MacronLeaks detection by Ferrarra https://arxiv.org/abs/1707.00086
    2. According to this https://ig.ft.com/social-bots-of-brexit/  we need to search for these #Ukip, #UK, #Labour ITVDebate #GE2017  in our dataset. I guess any mention to a bot would be a goldmine.  ..ok spoke too soon : http://comprop.oii.ox.ac.uk/wp-content/uploads/sites/89/2017/06/Junk-News-and-Bots-during-the-2017-UK-General-Election.pdf



         https://www.reuters.com/article/us-germany-election-fake/german-election-campaign-largely-unaffected-by-fake-news-or-bots-idUSKCN1BX258
        =================


        Macron https://wikileaks.org/macron-emails/emailid/2158
        https://globalepresse.net/2017/05/08/macronleaks-toxicomanie-homosexualite-rothschild/amp/?__twitter_impression=true

        Isws kati sxetiko me bot sto aggliko dataset ? https://www.independent.co.uk/news/long_reads/artificial-intelligence-democracy-elections-trump-brexit-clinton-a7883911.html

        https://www.bbc.com/news/election-2017-39886166

        Artificial intelligence can be used to manipulate individual voters. During the 2016 US presidential election, the data science firm Cambridge Analytica rolled out an extensive advertising campaign to target persuadable voters based on their individual psychology.



        *We used two independent datasets for our analysis. The  rst dataset consists of all the followers and friends of 92 million users. We used the random walk network sampling algorithm to obtain this dataset, which according to Lesko- vec and Faloutsos (2006) is the best method for capturing temporal graph patterns.*

        *The second dataset contains the followers and friends of all users that are present on the study of Kwak et al. (2010). This dataset contains the entire graph of Twitter as of July 2009 and contains 40.8 million users. In the period from November 2014 to January 2015, we downloaded all the fol- lowers and friends of these users. Each user on this dataset has on average 210 friends and 214 followers. We will refer to this dataset as the KWAK dataset.* 

*2/10/18* 
#thesis proposal : ask pilia poses selides. shoudl we add gme intro text ?\: 
  *PIlia says :ena kalo intro, objectives
  * liga pramata ap ta papers
  * kai ena sxetiko related 3-4 selides
  * kanto na fenetai san ena eniaio pragma
  *  dld to intro sou na sindeei ta 3 papers, vale to thesis statement, contributions klp
  * einai ousiastika oti:

  *  vrika afto to provlima, kai tha kanw afta kai afta gia na to liso










#SNRgroup - parousiaszw stis 2018-10-23 A survey of techniques for event detection in twitter kai 2018-11-27  Online human-bot interactions: Detection, estimation, and characterization  Despoina
# recitation hy345 stis 16/10 1400-1600
# fronthsthrio gia askisi 2 hy345   18/10   Φροντιστήριο 2  Deadline 2/11 des

*survey paper* 
#paper to include Epishs new papers to include in survey paper : https://link.springer.com/article/10.1007/s13278-018-0533-y
*thesis proposal* 

Πρόταση Διατριβής
εγκεκριμένη και υπογεγραμμένη από τη Συμβουλευτική Επιτροπή, μέσα σε προθεσμία τριών (3) εξαμήνων από την επιτυχία στις ΓΜΕ. Αν ο υποψήφιος δεν υποβάλλει την πρόταση εμπρόθεσμα, δεν μπορεί να εγγραφεί στο επόμενο εξάμηνο. 

Η πρόταση διατριβής πρέπει μέσα σε εύλογο αριθμό σελίδων και σε σημαντικό βαθμό λεπτομέρειας και βάθους να αναλύει τη συγκεκριμένη περιοχή που θα δουλέψει ο φοιτητής και το πρόβλημα που θα λύσει. H πρόταση αυτή μπορεί να αποτελέσει τον πυρήνα της βιβλιογραφικής αναδρομής της διδακτορικής διατριβής.


panpap leei oti 8elei introductions + contributions. ousiastika na peis tis 8a kaneis alla mhn valeis noumera. 


*ti-gyreve-to-rwsiko-trol-sto-dimopsifisma-tou-2015*
    Είναι γνωστό ότι τόσο κατά τη διάρκεια του δημοψηφίσματος όσο και μετά (και πριν..) επιχειρούσαν διάφορα κέντρα που προσπαθούν να κινήσουν το ενδιαφέρον της κοινής γνώμης προς τη μία πλευρά ή την άλλη.

    Η ιστορία π.χ. που λέει το protagon είναι "συμβατή" με τη πρόσφατη ιστορία της σύλληψης ρώσων πρακτόρων στην Ελλάδα που προσπαθούσαν να υποκινήσουν εθνικιστικά κινήματα ενάντια στη συφωνία των Πρεσπών:
    https://www.protothema.gr/politics/article/805035/financial-times-stin-alexandroupoli-egine-i-paremvasi-ton-roson-diplomaton-gia-to-skopiano/

    Αυτό μας λέει ότι στην Ελλάδα (αλλά και αλλού) γίνεται ένας σύγχρονος proxy war. Όχι με την έννοια της ένοπλης σύγκρουσης αλλά πόλεμος επιρροής. Οι αντίπαλες δυνάμεις τουλάχιστον στον Ελλαδικό χώρο είναι: (α) Ευρωπαϊκή Ένωση και (β) Ρωσσία. 

    π.χ. η έκβαση του μακεδονικού παίζει να ενδιαφέρει περισσότερο αυτές τις δυνάμεις παρά την Ελλάδα. 

    Οπότε το να περιμένουμε ξένα κέντρα να προσπαθούν να προωθήσουν το ΝΑΙ ή το ΟΧΙ είναι προφανές. Όσο αφορά το ΟΧΙ τα κέντρα αυτά είναι το ρώσσικο Internet Research Agency (που λέει και το άρθρο). Η ερώτηση είναι υπήρχαν κέντρα που προωθούσαν το ΝΑΙ; 

    O Juncker επίσημα τοποθετήθηκε υπερ του ΝΑΙ (https://www.euractiv.com/section/elections/news/juncker-asks-the-greeks-to-vote-yes-for-europe/) αλλά και όλα τα ιδιωτικά μέσα τηλεόρασης. Στο paper που βγάλαμε είδαμε ότι:
    in average, “YES” users posted approximately twice as many tweets (11.3) than “NO” users (6.1).
    Άρα τουλάχιστον στο επίπεδο tweet volume η ρωσσίδα πράκτορας δεν έκανε καλή δουλεία.

    Η ερώτησή μου είναι: Που είναι η "investigative journalism" το οποίο αποκλύπτει την οργανωμένη παραπληροφόρηση που έγινε υπέρ του ΝΑΙ; Και αν υπάρχει γιατί το protagon.gr δεν το έχει ξεμπροστιάσει; Μήπως επειδή ήταν από τους μεγαλύτερους υποστηρικτές του ΝΑΙ;

    Πέρα λοιπόν από τα πολιτικά, σε επίπεδο έρευνας έχει όντως νόημα να εφαρμόσουμε μεθόδους που κάνουν trace τέτοιες καμπάνιες και να τις κάνουμε assign με συγκεκριμμένα κέντρα.



    On Mon, Sep 3, 2018 at 10:28 AM Despoina Antonakaki <despoina@ics.forth.gr> wrote:


    ---------- Forwarded message ----------
    From: Sotiris Ioannidis <sotiris@ics.forth.gr>
    Date: Monday, September 3, 2018
    Subject: Fwd: Τι γύρευε το ρωσικό τρολ στο δημοψήφισμα του 2015; | Protagon.gr
    To: despoina@ics.forth.gr






    -------- Forwarded Message --------
    Subject: Τι γύρευε το ρωσικό τρολ στο δημοψήφισμα του 2015; | Protagon.gr
    Date: Sun, 2 Sep 2018 23:30:54 +0300
    From: Diomidis Spinellis <dds@aueb.gr>
    To: Sotiris Ioannidis <sotiris@ics.forth.gr>

    https://www.protagon.gr/themata/ti-gyreve-to-rwsiko-trol-sto-dimopsifisma-tou-2015-44341680049
    ===============================================
*HY345*
*Recitation*
-----------
    PROBLEM 3

    On all current computers, at least part of the interrupt handlers are written in assembly language. Why?

    All interrupts start by saving the registers, often in the process table entry for the current process. Then the information pushed onto the stack by the interrupt is removed and the stack pointer is set to point to a temporary stack used by the process handler. Actions such as saving the registers and setting the stack pointer cannot even be expressed in high-level languages such as C, so they are performed by a small assembly-language routine, usually the same one for all interrupts since the work of saving the registers is identical, no matter what the cause of the interrupt is. 


NIS sumer school enisa 

shadowserver
xcodeghost apple malware



 

Despoina:hy345 despoina$ gcc askisi2_2019.c 
working


21 September 
DCS projects meeting 


20/9/2017



*WP4. ATOS D4.1* 

    FORTH's deliverable part of the document 4.1 “Gaps and future challenges”.
     
    FORTH partners should prepare :
    3.1 Existing cybersecurity challenges in EU (research)
     
    REMINDER : This should be a list of some key topics from each domain (policy, research, business).
    No more than 20-30 in total deliverable document.
     
    By September 28: Each section leader produces first draft.  This will later be completed with input from all partners.
    By October 10:  All partners deliver contribution into to all sections.
     
    Please contact me with any questions you might have.


    a) List main cybersecurity challenges in Europe, and in Japan, separately.
      Covering policy, research and industrial aspects.
      
      These topics should not be only about cybersecurity products/services themselves.  We will include other topics around cybersecurity, that can benefit from cybersecurity.  I.e., cybersecurity in ML, data science, IoT, cloud, 5G, or cybersecurity in industry, transport, health, etc... (verticals).

*from initial resumes of strategic agendas: ENISA* :
  /Users/despoina/Documents/googleDrive/EUNITY/D3.1paradoteo/WOLD_From_Enisa_CYBERSECURITY_STRATEGIC RESEARCH AGENDA.docx: 
      
      Description of the issues and challenges 4.2.1 Technical challenges

      To achieve the goal of a society in which the institutions are trusted in their digital form, means first to achieve the basic resilience and security of their ICT systems:
      1. Security and Resilience of the Cloud: …having security metrics and a maturity model, employing security by design across the entire ecosystem, and for resilience, ensuring interoperability and adaptability of systems at all levels.
      ￼
      2. Cyber crime/Cyber terrorism prevention… numerous technical challenges here, for example how to balance surveillance and fundamental rights (surveillance in a privacy protecting, transparent, and responsible way), to prevent any data and information leakage to cyber-criminals, and the ability to detect and bring them to account.

      3. Trust Management in the Digital Society. Assurance and accountability will become competitive advantages for services in a future digital society. Is it possible to move beyond self-certifications towards metrics for trust and accountability, and ways to validate assurances and certifications automatically?

      4. Privacy in the Digital Society:   The PRIPARE project14 identified the following sub-challenges; 
      • generic integration in the many domain specific engineering design practice; 
      • multi- disciplinarity of the design practice; 
      • customisation techniques to take into account specific legal and socio-political parameters.  
      • 
      5. Digital identities remains a challenge for a heterogeneous and decentralized digital society, including the development of Global/interoperable ID systems, perhaps involving biometrics technologies that are at the same time privacy preserving and based on minimum disclosure principles, enabling and / empowering civilization to be based ‘globally’ and still empowered to carry out their local duties e.g. e- voting from abroad.

      6. Risk management for the digital world is still a challenge for digital societies. As we go to ever large scale interconnected systems, and the development of new risk management models and systems for cyber societies is necessary.

      7. Social networks security and privacy becomes challenging as social networks become embedded in the fabric of society and even become instruments of democracy. Cultural norms change more slowly than technology. How do we protect citizen’s security and privacy when the technology that exploits social networks is advancing so rapidly?

      8. Massive data collection and potential storage of data and information brought about by the advent and massive scaling up on uses and every day applications and services related to new types of devices e.g. IoT sensors.

      9. Big Data analytics. Lastly, in a world of IoT mass sensor data collection, the technical challenges related to security and privacy to manage and control what can be understood about us from the vast pools of data available when the whole world is profiled are immensely challenging. Is it possible to manage what can be inferred from data gathered in the course of our daily lives? What happens if this spreads into the political sphere?

   From 2017_WG6Strategic ResearchandInnovationAgenda(SRIA).pdf: 
   
   Cyber security challenges have been described in the cPPP European Cyber Security (ECS) industry
 proposal and initial cPPP Strategic Research Innovation Agenda (SRIA) v1.0: 
    • Market fragmentation;
    • Innovation led by imported ICT products;
    • Need to mitigate cyber security dependencies from external sources and achieve strategic
    supply chain in the field;
    • Less funding to research and innovation available and often dispersed due to a lack of
    transnational approach;
    • European industrial policies not yet properly addressing specific cybersecurity issues;
    • Weak entrepreneurial culture and lack of venture capital;
    • Human factor and skills shortage.   


eunity 
To ergo 3ekinhse 1/6/2017 M1
Twra dianyoyme to M6
Ara an ypologizw swsta: 
M14 - Aug. 2018
M24 - May 2019

01/06/17  M1
01/07/17  M2
01/08/17  M3
01/09/17  M4
01/10/17  M5
01/11/17  M6
01/12/17  M7
01/01/18  M8
01/02/18  M9
01/03/18  M10
01/04/18  M11
01/05/18  M12
01/06/18  M13
01/07/18  M14
01/08/18  M15

01/09/18  M16
01/10/18  M17
01/11/18  M18
01/12/18  M19
01/01/19  M20
01/02/19  M21
01/03/19  M22
01/04/19  M23
01/05/19  M24
 

  - FORTH 20M
Second workshop held,
conclusions elicited,
proceedings available,
preliminary research analysis
report available (D3.2),
existing collaborations and
gaps analysis available (D4.1)


MS3 Second project workshop inEurope 2 - FORTH 20M
Second workshop held,
conclusions elicited,
proceedings available,
preliminary research analysis
report available (D3.2),
existing collaborations and
gaps analysis available (D4.1)

twitter eunity account. 
eunity.project@gmail.com 
c2MHRwPMHaRbu789

#27 August 

7.6 Κατάθεση Πρότασης Διατριβής
Ο υποψήφιος διδάκτορας οφείλει να υποβάλει στην Γραμματεία Μεταπτυχιακών Σπουδών 
*Πρόταση Διατριβής*
εγκεκριμένη και υπογεγραμμένη από τη Συμβουλευτική Επιτροπή, μέσα σε προθεσμία τριών (3) εξαμήνων από την επιτυχία στις ΓΜΕ. Αν ο υποψήφιος δεν υποβάλλει την πρόταση εμπρόθεσμα, δεν μπορεί να εγγραφεί στο επόμενο εξάμηνο. 

Η πρόταση διατριβής πρέπει μέσα σε εύλογο αριθμό σελίδων και σε σημαντικό βαθμό λεπτομέρειας και βάθους να αναλύει τη συγκεκριμένη περιοχή που θα δουλέψει ο φοιτητής και το πρόβλημα που θα λύσει. H πρόταση αυτή μπορεί να αποτελέσει τον πυρήνα της βιβλιογραφικής αναδρομής της διδακτορικής διατριβής.


#21 August

*επταμελής επιτροπή*

Αθανασόπουλος, Πολακης , Φραγκοπούλου, Ιωανίδης, Πρακτικακης, Μαρκατος, Σπιλιωτοπουλος 
ερωτηση στην pgram για σπηλιοτοπ


*3.1 EUNITY* 


      Dear colleagues,

      After reviews, I have several questions that relate to information from partners:


      1) Section 3.1.1.2: Financing mechanism in the countries of the EUNITY project partners
      Paragraph: Greece and paragraph Spain

      Colleagues from FORTH an ATOS - could you elaborate this a little? An example is the French and Polish parts. 


      2) Section 3.2.2.2: This section should be completed with information about national calls other than Greece and Poland. If there is none, it should be mentioned. IMT will add information about calls in France. Also, it would be nice to have some extra details about the Greek initiative.


      If you have any information about calls in your countries, please write it or just give us the answer that it is not.

      Colleagues from FORTH  - could you give some more details about  the  "Hellenic Foundation for Research and Innovation" (which is market now on the tex file, due to lack of information).




      Please fill in the tex file in the right place or give me a reply in the return email as soon as possible.

          3.1.1.2. Financing mechanism in the countries of the EUNITY project partners
          France
          In France, the cybersecurity strategy is fixed by the Loi de Programmation Militaire
          (LPM) or “military planning law”. These programmes influence the amount
          of funding and the topics that are called by the three national funding entities that
          provide funding for cybersecurity research:
          Agence Nationale pour la Recherche (ANR) The French National Research
          Agency funds research projects under its yearly call for proposals. The projects
          funded by ANR are collaborative between academia and industry, with a strong
          focus on research. 

          ---> evalutaion --->>>>

          Projects are evaluated by committees of experts, usually
          from academia. In addition to the yearly global ANR research programme,
          there are several specific bilateral cooperation agreements that also include cybersecurity.
          ANR also funds projects under the CHIST-ERA European scheme.
           
          Direction G´en´erale des Entreprises (DGE) The French Ministry of Economy
          under the enterprises directorate has several schemes for funding collaborative
          research between academia and industry. It also contributes to funding at the
          European cluster level through contributions to ITEA and CELTIC. These calls
          are jointly managed and funded by the Banque Publique d’Investissement (BPI
          France). The projects are partially evaluated (labelled in fact) by the French
          regional competitiveness clusters. Amongst these clusters, several label cybersecurity
          projects. The most relevant competitiveness clusters are Systematic,
          SAFE and Aerospace Valley.
          Direction G´en´erale de l’Armement (DGA) The French Ministry of Defence
          hosts a procurement and research agency, that contributes to funding both
          academia and industry, with a specific focus on SMEs. These calls are generally
          jointly operated with DGE or ANR and have a dual-use objective. The projects
          are evaluated by ANR or DGE, following their specific rules for funding.
          In addition, a few French regions provide funding for research, in general to
          support PhD grants. The most active in the area is the Brittany region, which hosts
          the Pole d’Excellence Cyber (PEC). This cluster regroups the DGA research branch
          (located in the Brittany region) and industry to fund PhD research projects and
          chairs on cybersecurity.
          The following programmes fund cybersecurity research:
          ANR challenge 9 (ANR) The ANR Challenge number nine, entitled Libert´e et
          S´ecurit´e de l’Europe, de ses citoyens et de ses r´esidents, mimics the Digital Security
          calls of the H2020 programme. It funds projects related to fundamental
          research (such as cryptography), crisis management and resilience, defense
          against organized crime and terrorism, cybersecurity and protection of critical
          infrastructure.
          joint ANR-BMBF (ANR) ANR has created a partnership with the german ministry
          of research funding agency BMBF to create a joint bilateral call for French
          and German teams to collaborate on security projects, including cybersecurity.
          FUI and FSN (DGE) The Fond Unique Interminist´eriel (FUI) and Fond pour la
          Soci´et´e Num´erique (FSN) fund projects oriented towards industry, driven by
          industry but with academic collaboration. They aim at developping the digital
          society and are supported by excellence clusters. The yearly project call funds
          three to five cybersecurity projects each year.
          PIA, PIA2, PIAVE (BPI) The Programme d’Investissements d’Avenir (PIA) aims
          at funding the development of the French industry. Driven by industry and
          government needs, it funds three to four large cybersecurity projects that aim
          at a high TRL level, delivering working prototypes and close to market.
          RAPID (DGA/DGE) The R´egime d’Appui pour l’Innovation Duale (RAPID) programme
          fund dual-use projects aimed at industrial research and prototype
          development. It funds the development of cybersecurity prototypes at an intermediate
          TRL level. The projects may include industry and academia, but
          they must be coordinated by an SME.
           
          ASTRID (DGA/ANR) The Accompagnement Sp´ecifique des Travaux de Recherches
          et d’Innovation D´efense (ASTRID) programme funds specific disciplinary or interdisciplinary
          themes, at a low TRL level, again for dual-use research.
          In addition, many French institutions also participate in H2020 calls and are
          members of ECSO.

#16 July 2018 
telco : 

5.1 as is and we can update 5.3 
https in website 

community description in 5.3 as it will be inputed from 2.1 (ku leuven)

5.3 events --> in website


expolitation only mentioned in the review report 

forth + imt will review 3.1 

2.3 

discussion neo kefaleio 
ana session notes.

questionaires plots ?
ta pio shmantika 


2.3 : ola ta questionaires to appendix? mail se olous...

 


1)βαζουμε ta kpi για το leaven DEN ta evala ola giati den exei kpis connectetd to project - esteila mail 

2)Διορθώνω τα κόκκινα στο παραδοτέο - 

3) Βαζω questionnaires sto παραδοτέο 5.3 - Μαζί με τα figures apo tis pio shmenatikes erwthseis . ola ta questionaires to appendix? mail se olous...

4) Review number 3: Community description in abstract *is KUL going to de- fine community on D2.1 na to paroume kiemeis*

5) 5.3 Κάνω ένα νέο section me ta kpi s . sygkentrwmena ola ta kpi ana institute se pinaka prin tis formes .. ok apla leipoun tis elenas Lueven gia connected kpis to EUNIty project

6) Twitter for today? 

7) Review deliverable 3.1 next week 

8) 5.3 Do we keep the strucure of the dissemination form in the deliverable? 

9) merxi thn deutera gia to 5.3 

10 kpi for ICS-CoE mission visits to Europe? ok esteila mail - o xhrstos leei den xreizetai na valoume kpis . oi revierrs den mas eipan kati giaayto . 

11) date for the Motorola Motorola Solutions Innovation Showcase, date 

12) These kpis do not show very clearly how these accomplishes goals are connected with the EUNITY project,  ok eteila mail 



*My comments on deleiverables* d2.3 check contents 
"KPIs are to be defined in the introduction of D5.3"
 "...The deliverable must describe the connection between the events (workshop,
conferences etc.) where the partners participate and the common topics between the two regions selected as a
common background. The deliverable should answer questions such as: why such event were so interesting respect
the common cyber security area of the two regions? How the consortium partners disseminate the EUNITY project?..."

- Paragrafo me KPIs opws mas zhth8hke. Despoina to exoyme balei sth forma gia na mas ta dwsoyn? Sth synexeia mporoyme na ta symperilaboyme ola 
se mia paragrafo sthn arxh (superset of KPIs) 
- Despoina afora kai ayto thn forma poy exeis steilei stoys partners na symplhrwsoyn. Swsta ? 


Merged comments from review: 

*Website.*
1)Put a disclaimer on Twitter and the website that this is the opinion of the project and not the EU.
2)DG_Connect Twitter feed connection.
3)Minimal style.
4)Publication: *despoina:* include the two cybersecurity publications on the website. Probably remove the irrelevant one.
5)Build a JP website (or a subset?)
6)Change the place of the privacy policy (GDPR related. EU and JP rules).
7)Amend the 5.1 with security features of the website and the infrastructure. Be secure as much as possible (e.g use last version of joomla) 
8)Phd students not funded by the project visited Japan for further collaboration.One for 3 months and one for 1 month period. (ALSO report it on the website).
9)Youki: create a replica of the website in Japanese language. (inside the EU version).Provide account to Kazua so that he can update the 
10) Policy posted in a flashy way eye catchy way and provide link to define how you want to implement this.  
11) The content to CORRESPOND appropriately  to the audience. First identify the audience. mentioned in D2.1 ..a much more enhanced version. what is the community , what are the characteristics, whatever you say about the characteristics, the content of the website should target this community . the website should reflect the needs to your communities. 
12)All dissemination need to be posted. How many people participated, how this outcome fit the goal of the project that is as well defined in the research agenda. 


*Twitter*
1)More tweets, more content...probably the questionnaires results from the presentations.
*2.1*
1)should have a best practice section. What is the cybersecurity community there. Identify concretely your communities (in Japan and in Europe)
2)How did you come up with this community?
3)How can I reach this audience?
4)How did you chose those questions?
5)This is the Methodology and this is the lesson learned.
6)Mention difficulties and convey experience to others.
*3.1*
1)KUL section "With respect of cybersecurity service..." (create a new paragraph) (re-write it)
2)Include processes and legislation information.

3)Research: Enrich the Japanese part.
4)Include Eureka which is close to industry and to match the industry in the Japanese side.
5)NIS WG3 and ECSO are mostly wishes and not strategic .
6)We should act strategically and think about the topics.

7)Prioritize based on OUR knowledge and explain why. If you do this...this will happen.
8)e.g Check the CIs of the two regions. Include it in D3.1 probably ?

*despoina for 3.1*
  1)what do we mean by strategic research agenda, needs to be defined by you. Use YOUR expertise. 
  2)Support industries of mutual interest, include in Europe & Japan. 

#3.1 Section Industry
1)include CERTCOOP which is a CSIRT collaboration project (add it to the GCC table).
2)Information Sharing and Analysis Centres (ISACs)
*D2.3*
*1)Add missing information (Except the slides)
3)Include the discussions and the questionnaire analysis.*

*D5.3*
1)Thorough revision.
2)Relation between activities and the goals of the project.
3)*Community description in abstract*
4)*JP research activities landscape missing (add a paragraph and point to the D3.1 section x.x)*
5)Add the added value for the project from the events.
6)3.6 3.7.3.8 3.9.3.10 - These events are missing scope of visit. Was the goal accomplished? Provide Justification of the visit!
7)Section 5 the year is not there. 
8)5.1 France visit 2017 is missing. *OK* 
9)Section 5 revise (section 5.1) *OK by despoina. please revise*
10)*Justify ALL the events.*
11)link what is written and relate it to the project. *this is unclear Christo? is it the justification of the events?* 
12)e.g ETSI why EUNITY was there...? Did you propose...? 
13)The "intelligence" is missing from the deliverable. Is just a list of events. *this will be solved if we resolve 10*
14)About dissemination events:scope, how many participated outcomes and link the outcomes to the EUNITY project objectives.
15) *Slide 78 : remove CIPSEC . We responded that  it is part of the communication activities, building collaboration etc. *
*Dissemination*
1)FIC. Try to establish a high level meeting with Japanese partners and EU members and present the priorities that will be set by then.
2)Clarify the dissemination trip of Stefano on Feb 2019.
3)A conclusive event at the end probably of what is the outcome.
4)We can go for a event in Japan May2019 or check for an event on Apr2019.
5) We can have a video joint session morning in EU afternoon in JP. (max 90' common active time) Combine probably with the ECSO ? !
    *Review comments:*
    
    under this review D5.1 and D2.1 accepted
    2.3 and 5.2, 5.3 
    they are considered as drafts and will be reviewed on December.

    decide which industries are important for EU and JP and come with a Stretegic Agenda according to this.
    Translate the challenges to research agenda

    website and be secure: 
    versions of the website. security features to mention.
    eye catching way. 
    GDPR more visible
    Content appropriate to the audience we are trying to reach (identify our audience mentioned in D2.1) and also included in D5.3.
    What is the community and its characteristics. 
    and the content on the website should target this audience.

    All the dissemination activities should be posted. (website?)
    Social media: twitter in Japanese as well. 

    D4.1 state the methodology.

    All the events need to be measurable action. (include KPIs... e,g reach this audience)

    D2.1 communicty engagement report should go to D5.3
    Any revisions of the already submitted deliverables will be included in D5.3

    Define the KPIs for the dissemination activities and analyze them.
    Existing KPIs should be used across all dissemination activities.

    A form/report for each dissemination activity should 

    The website will be re-evaluated according to the comments.(content security policy) 
    Include slides for the website in the D5.3 
    Abstract: add that the website is the main dissemination channel and will be evaluated. 

    Publications should be on the website.

    All deliverables till end of July.





SARTE: an oxi emeis tote poio? an oxi twra tote pote?

Dear colleagues, 

I am still missing the scope-participants-KPI for the events of KU Leuven: 


\section{The Future of Security and Privacy, dcypher Symposium } KUL 
\section{The Future of Security and Privacy, Belgian Cybersecurity} KUL 
\section{Bitcoin: Publish or Perish, Workshop on Blockchain Technologies} KUL
\section{Cryptocurrencies and Blockchain} KUL
\section{Bitcoin and Blockchain, Cyber Security Coalition} KUL


kind regards, 
Despoina

13 July 2018 - 

#on the read in the car form groningen to schiplhol 
#EUNITY 

* D5.3 
* include questionaires ?
* keep this structure from teh dissemination forms with sections in chapter 3?
*MISSING FORMS*:
First Cyberwatching.eu Concentration Meeting
3.4 Fourth French-Japanese Cybersecurity Workshop *OK BY gregory*

\section{The Future of Security and Privacy, dcypher Symposium } KUL 
\section{The Future of Security and Privacy, Belgian Cybersecurity} KUL 
\section{Bitcoin: Publish or Perish, Workshop on Blockchain Technologies} KUL
\section{Cryptocurrencies and Blockchain} KUL
\section{Bitcoin and Blockchain, Cyber Security Coalition} KUL


8 July 2018 
on the reoad form nunster to groningen

writing the deliverable 2.3 

trying to find comments on th epresentations 

day 1
session 1
presenattion from Herve ?
send email to herve  + Youki : 


"
Dear colleagues, 

I have started editing the workshop proceedings, in order to add notes/comments (intelligence as noted by reviewers). 
I found notes form the workshop in svn. There are some unclear points though:

Was the first introductory presentation given by Herve or Youki?
There are two files in the svn for this session: kaskina.log
uchiyama.log" Is any of them related to your presentation? Can you provide any additional notes on this presentation?

There is a missing presentation from Takayuki Uchiyama from JPCERT/CC concerning the JPCERT capability building of session 1 day 1. Not in SVN. Should we include it?I have added the notes in SVN in the proceedings. 

I have inserted text taken from the notes of Gregory from the svn/eunity/eunity/workshops/201710_jpworkshop/session2/notes_group_gregory.txt

I have several comments (in red), that I would like to confirm.
Please let me know if some of the comments need to be left out. 

This documents has been edited with notes only till day 1. session 2. 
I will continue edit and sent more comment if needed. 


regards, 
Despoina 

6 July 2018 - 

#on the read in the car form utrecht to munster 
#EUNITY 

* D5.3 
* include questionaires ?
* keep this structure from teh dissemination forms with sections in chapter 3?
*MISSING FORMS*:
First Cyberwatching.eu Concentration Meeting
3.4 Fourth French-Japanese Cybersecurity Workshop OK BY gregory 
\section{The Future of Security and Privacy, dcypher Symposium } KUL 
\section{The Future of Security and Privacy, Belgian Cybersecurity} KUL 
\section{Bitcoin: Publish or Perish, Workshop on Blockchain Technologies} KUL
\section{Cryptocurrencies and Blockchain} KUL
\section{Bitcoin and Blockchain, Cyber Security Coalition} KUL


Dear colleagues, 

  I would like to remind you the dissemination form that has to be filled with KPIs
  for the deliverable D5.3. 
  The form is here: 

  and I would like your input till 7 July. 
  
  The missing events that lack scope-participants-KPI are:

  First Cyberwatching.eu Concentration Meeting
  Fourth French-Japanese Cybersecurity Workshop  
  The Future of Security and Privacy, dcypher Symposium - KUL 
  The Future of Security and Privacy, Belgian Cybersecurity - KUL 
  Bitcoin: Publish or Perish, Workshop on Blockchain Technologies - KUL
  Cryptocurrencies and Blockchainc KUL
  Bitcoin and Blockchain, Cyber Security Coalition - KUL

regards, 
Despoina

EUNITY project members from KUL 

    from review: 
        *D5.3*
    1)Thorough revision.
    2)Relation between activities and the goals of the project. *IN PROGRESS forms missing*
    3)Community description in abstract *is KUL going to define community on D2.1 na to paroume kiemeis?*
    4)JP research activities landscape missing (add a paragraph and point to the D3.1 section x.x) 
    5)Add the added value for the project from the events.
    6)3.6 3.7.3.8 3.9.3.10 - These events are missing scope of visit. Was the goal accomplished? Provide Justification of the visit!
    7)Section 5 the year is not there. 
    8)5.1 France visit 2017 is missing. *OK* 
    9)Section 5 revise (section 5.1) *OK by despoina. please revise*
    10)*Justify ALL the events.*
    11)link what is written and relate it to the project. *this is unclear Christo? is it the justification of the events?* 
    12)e.g ETSI why EUNITY was there...? Did you propose...? 
    13)The "intelligence" is missing from the deliverable. Is just a list of events. *this will be solved if we resolve 10*
    14)About dissemination events:scope, how many participated outcomes and link the outcomes to the EUNITY project objectives.
    15) *Slide 78 : remove CIPSEC . We responded that  it is part of the communication activities, building collaboration etc. *
    *Dissemination*
    1)FIC. Try to establish a high level meeting with Japanese partners and EU members and present the priorities that will be set by then.
    2)Clarify the dissemination trip of Stefano on Feb 2019.
    3)A conclusive event at the end probably of what is the outcome.
    4)We can go for a event in Japan May2019 or check for an event on Apr2019.
    5) We can have a video joint session morning in EU afternoon in JP. (max 90' common active time) Combine probably with the ECSO ? !
        *Review comments:*
      


2 rehershals -  monday tuesday 
aurio  - pi s 2 8a to 


ykiqsmX2rd5s
 presentation of EUNITY and panel session on certification at Cyberwatching.eu (CSA) concertation meeting in Brussels, April 2018
- presentation of EUNITY 1st year results at French-Japanese Cybersecurity Workshop in Annecy, May 2018
- presentation of EUNITY 1st year results at CNRS French working group on cybersecurity in Paris, May 2018

Herve : ETSI Information Security Indicators working group:

IETF is from Daisuke Myiamoto and ITU from Prof. Youki Kadobayashi. NAIST

Gregory Blanc IMT : 

I would add the following presentations:
- presentation of EUNITY and panel session on certification at Cyberwatching.eu (CSA) concertation meeting in Brussels, April 2018
- presentation of EUNITY 1st year results at French-Japanese Cybersecurity
Workshop in Annecy, May 2018
- presentation of EUNITY 1st year results at CNRS French working group on
cybersecurity in Paris, May 2018



pgpBmpmgd3ta
#29 June

Merged comments from review: 

*Website.*
1)Put a disclaimer on Twitter and the website that this is the opinion of the project and not the EU.
2)DG_Connect Twitter feed connection.
3)Minimal style.
4)Publication: *despoina:* include the two cybersecurity publications on the website. Probably remove the irrelevant one.
5)Build a JP website (or a subset?)
6)Change the place of the privacy policy (GDPR related. EU and JP rules).
7)Amend the 5.1 with security features of the website and the infrastructure. Be secure as much as possible (e.g use last version of joomla) 
8)Phd students not funded by the project visited Japan for further collaboration.One for 3 months and one for 1 month period. (ALSO report it on the website).
9)Youki: create a replica of the website in Japanese language. (inside the EU version).Provide account to Kazua so that he can update the 
10) Policy posted in a flashy way eye catchy way and provide link to define how you want to implement this.  
11) The content to CORRESPOND appropriately  to the audience. First identify the audience. mentioned in D2.1 ..a much more enhanced version. what is the community , what are the characteristics, whatever you say about the characteristics, the content of the website should target this community . the website should reflect the needs to your communities. 
12)All dissemination need to be posted. How many people participated, how this outcome fit the goal of the project that is as well defined in the research agenda. 


*Twitter*
1)More tweets, more content...probably the questionnaires results from the presentations.
*2.1*
1)should have a best practice section. What is the cybersecurity community there. Identify concretely your communities (in Japan and in Europe)
2)How did you come up with this community?
3)How can I reach this audience?
4)How did you chose those questions?
5)This is the Methodology and this is the lesson learned.
6)Mention difficulties and convey experience to others.
*3.1*
1)KUL section "With respect of cybersecurity service..." (create a new paragraph) (re-write it)
2)Include processes and legislation information.

3)Research: Enrich the Japanese part.
4)Include Eureka which is close to industry and to match the industry in the Japanese side.
5)NIS WG3 and ECSO are mostly wishes and not strategic .
6)We should act strategically and think about the topics.

7)Prioritize based on OUR knowledge and explain why. If you do this...this will happen.
8)e.g Check the CIs of the two regions. Include it in D3.1 probably ?

*despoina for 3.1*
  1)what do we mean by strategic research agenda, needs to be define by you. Use YOUR expertise. 
  2)Support industries of mutual interest, include in Europe & Japan. 

#3.1 Section Industry
1)include CERTCOOP which is a CSIRT collaboration project (add it to the GCC table).
2)Information Sharing and Analysis Centres (ISACs)
*D2.3*
*1)Add missing information (Except the slides)
3)Include the discussions and the questionnaire analysis.*

*D5.3*
1)Thorough revision.
2)Relation between activities and the goals of the project.
3)*Community description in abstract*
4)*JP research activities landscape missing (add a paragraph and point to the D3.1 section x.x)*
5)Add the added value for the project from the events.
6)3.6 3.7.3.8 3.9.3.10 - These events are missing scope of visit. Was the goal accomplished? Provide Justification of the visit!
7)Section 5 the year is not there. 
8)5.1 France visit 2017 is missing. *OK* 
9)Section 5 revise (section 5.1) *OK by despoina. please revise*
10)*Justify ALL the events.*
11)link what is written and relate it to the project. *this is unclear Christo? is it the justification of the events?* 
12)e.g ETSI why EUNITY was there...? Did you propose...? 
13)The "intelligence" is missing from the deliverable. Is just a list of events. *this will be solved if we resolve 10*
14)About dissemination events:scope, how many participated outcomes and link the outcomes to the EUNITY project objectives.
15) *Slide 78 : remove CIPSEC . We responded that  it is part of the communication activities, building collaboration etc. *
*Dissemination*
1)FIC. Try to establish a high level meeting with Japanese partners and EU members and present the priorities that will be set by then.
2)Clarify the dissemination trip of Stefano on Feb 2019.
3)A conclusive event at the end probably of what is the outcome.
4)We can go for a event in Japan May2019 or check for an event on Apr2019.
5) We can have a video joint session morning in EU afternoon in JP. (max 90' common active time) Combine probably with the ECSO ? !
    *Review comments:*
    
    under this review D5.1 and D2.1 accepted
    2.3 and 5.2, 5.3 
    they are considered as drafts and will be reviewed on December.

    decide which industries are important for EU and JP and come with a Stretegic Agenda according to this.
    Translate the challenges to research agenda

    website and be secure: 
    versions of the website. security features to mention.
    eye catching way. 
    GDPR more visible
    Content appropriate to the audience we are trying to reach (identify our audience mentioned in D2.1) and also included in D5.3.
    What is the community and its characteristics. 
    and the content on the website should target this audience.

    All the dissemination activities should be posted. (website?)
    Social media: twitter in Japanese as well. 

    D4.1 state the methodology.

    All the events need to be measurable action. (include KPIs... e,g reach this audience)

    D2.1 communicty engagement report should go to D5.3
    Any revisions of the already submitted deliverables will be included in D5.3

    Define the KPIs for the dissemination activities and analyze them.
    Existing KPIs should be used across all dissemination activities.

    A form/report for each dissemination activity should 

    The website will be re-evaluated according to the comments.(content security policy) 
    Include slides for the website in the D5.3 
    Abstract: add that the website is the main dissemination channel and will be evaluated. 

    Publications should be on the website.

    All deliverables till end of July.




#27 June 
1)vale enan foitith ka8e evdomada na stelnei ena tweet gia cybersceurity + japan, erwthsh  cyber attack+europe? ars technica klt
2)isws kapoia kommatia apo ta questionaires se tweetsn e.g. demographics

*REVIEW notes from Christos* 
*Website.*



*REVIEW on dissemination report :*
OUTCOME: 

starting june 1 2017 - month 12: May 31- 
D2.3 

the official deliverable d5.1 - d accepted

2.3 + 5.2 + 5.3 (12M) - have not seen them .. December 7 .

concrete comments: we mean by strategic research agenda - need to be define by you, support industries of mutual ineterest. which intrustry in  Europe, Japan, 

streategic research agenda taht support these industries, use aour experstise...to new cybersecurity researhc agenda
*---------*
website 1) be secure as much as possible  joomla ...which version.  
2)P&s policy posted in a flashy way eye cathcinh way link and define how you want.. 
3) the contect to CORRESPOND appropriateLY  to teh auduence. first identify the audience. mention in 2.1 ..a much more enhanced version. what is teh community , what are the characteristics, whatever you say about the characteristics, teh contect of the website should target this community . the website shoudl reflect the need to your communities. 

All dissemination need to be posted. how many people participated , how this outcome fite the goal of the project thai si the research agenda. 
Japanses as well. a subset at leas in japanese . 


d.1 methodolly 
everything needs to be aligned  in the project. why go to a conference if not aligned with the project? 
all the vents where organize or measurable actions. fitting your goal. mention : e.g go to events to provide impact-input in this topic .

*May 31 --> June 31 gai ta deliverable auta  end of July ...* end of July ... to accomodate the changes. 


*D2.1  --> D5.3* 
identify concretely your communities (europe +Europe)

5.3 final one (not the current) we would like to see gaps : comminuty explicitly characteristic. kpis for dissemination activities. start 

Add a tempate form 
with introduction

cope  # of particpante 
# venue 
how this cirtibuted to the goal 

we Will re-evaluate the website . teh main dissemination channel . we wiil revise it again, go throug hcontent- security policy    
*CREATE A FORM TAHT EVERYONE THAT GOES TO AN EVENT*
========== 

Generally the document needs a good revision! 

#Add added value of the dissemination what is the relationship of these activities wth the goal of the project 

  Description of teh community . 

  The JP landscape is missing either remove it or add it . 

a very good description of the event (at least)
3.6. 3.8 
KUL --> participated in these events , but what is the added value. 
2017 is missing from France, 26th-28th September, Telecom ParisTech slide 78) 

really rewriting. 


Slide 78 : remove CIPSEC ...si leei einai 
communication activities.  , building collaboration etc. 

slide 75 ) write more about what is the connection of these meetings with the EUNITY project . KUL visited 

why EUNITY was there in standards activites ? what is the connection ? add intelligence . what happened there?

the result is in D3.1 . maybe 

say in order not to publicate  link to D3.1 . 

why did you go?did you meet the goals of your visit? 
scope ,participation, outcome,  how the final results meet the goal of the project . 
quialitatitve measure . what did you gain ? in terms of the goal of the project 

-----------------
REVIEW
--------------------
H2 afonso ferreira

5.1 : website : minimalist , very poor things

twitter: No tweets since October  - 
the publication is irrelevant . I knew it!
Prepei na mpoun ta papers twn allwn. 
relationship with japanese partners, added value regarding the objectives of the projects? 
--------->would be rejected

whta are the qualitatitve and the quantitetive . which is audience.. website in english in japanese. intermidiade results 
show a demo of teh website. WHY to WHOM? 
GDPR. maybe in a popup that a user shoudl sign !maybe in the side we can write : this is the way we implemnt GDPR in this website . we should lead this !

security features. 
raise awereness


d3.1 : what is the added value of this project to the strategc agenda. 
the strategic agenda are just a list of wishes!??

give directives in cybersecurity 
digital single market and japanese iot nothing in europe.
SI: this is out of the scope of the project ??

=======

worshop 
*EUNITY* 
rehearsal interim review

Adam mentioned a confernece that he will esnt - maybe sent somthing (bot detection) 
how to continue with D3.2..the only potential changes are in H2020. 2021 

*dedousis* 
ldasave_%7Bht_FR_france17_parsed%7D_%7B%7D.html#topic=7&lambda=1&term=

1)look at 7 : we need stemming . remove all articles. (in, die, sie=you etc. ) vres ena dictionary etoimo gia γερμανικα-γαλλικα-stemming 
2) ht_DE_ht_FR__ ειναι μόνο στα γερμανικα 


*1218*
34287423 aithsh espa?

*old eunity notes* 
Till end of May proceedings. FoRTH D2.3 

he will ask this afternoon more docs for this deliverable. (presentations, full program etc) . 
about this report : questioneres in the report 

extend session 2 into some minutes that he is going to add .
--> if there are more minutes from ANYONE about the sessions from the workshop, please add them to the svn.

(auto anaferotan sto report tou questionaire: ) this report will be the basis. Christos will provide the latex template .
will be coordinated by FORTH , but can work together with him, he can help with. 

month 12 end of may 
okada will contribute/distribute staff about the questionaires
start drafting it . analysis will be dffrent if we add later numbers, but we can start drafting 


 gai na γαι να δουμε μπορει να κανει ελληνικα
*eunity d5.3* 
      na fugei olo to 7 

      na fugoun ola ta responsible partners

      na mpei to programma tou workshop 


      801 numbering check pantou 
      numbering check pantou 

      kena stis epikefalides twn kefalaiwn 


      vale kai auta : networking activities 

              Bart Preneel, *The Future of Security and Privacy,* Dcypher Event,
            >   Utrecht, October 4, 2017.
            400 people

            >   -
            >
            >   Bart Preneel, *The Future of Security and Privacy, Belgian Cybersecurity
            >   Convention,* Mechelen, October 25, 2017.
            200 people
            >   -
            >
            >   Bart Preneel, *Bitcoin: Publish or Perish,* Workshop on Blockchain
            >   Technologies, ISI, Kolkata, November 29 ÿÿ December 2, 2017.
            50 people
            >   -
            >
            >   Bart Preneel, *Cryptocurrencies and Blockchain,* Research Seminar at


            >   Kookmin University, Seoul, December 8, 2017.
            50 people
            >   -
            >
            >   Bart Preneel, *Bitcoin and Blockchain, *Cyber Security Coalition


            >   Belgium, Mons, December 14, 2017.


The small decrease over the last years is not a sign of decreasing interest but it's due to a batch effect: recent studies have not yet reached their full potential citations. 

*SYGMA :*  

  KUL: Participation to a Workshop this is number of participants not number of event 
  IMT : Participation to an Event other than a Conference or a Workshop (). Participation to a event: this is number of participants ?
NASK : 7 questionairaes do you think that this counts as 7 events or one

mail se olous mazi me to excel sxolia se osous ekana kanei la8os 

    Dear colleagues,

    I have gathered all your responses concerning the SygMa application about the funding amounts, the number of activities and the number of people attending Dissemination activities. 

    I attach the file, in which you should confirm your corresponding columns, for your institute. 
    The red cells probably should be corrected. 

    Specifically:
     For IMT: In line "Participation to an Event other than a Conference or a Workshop" on the second category "Specify the number of Dissemination and Communication ACTIVITIES linked to the project for each of the following categories", I am assuming 464 should be 1 (number of activities)
     For NASK : In line other, in the second category "Specify the number of Dissemination and Communication activities linked to the project for each of the following categories" the number of questionnaires (7), do you think that could count as 7 separate events or one?



    Also I see in D5.3 the following presentations, that we added, and I am not sure if they are counted in this excel: 

    * Adam Kozakiewicz, 25/10/2017, Motorola Solutions Innovation Showcase 2017,  Cracow, Poland"  ok 
    * January 2018, Hervé, presentation of EUNITY to ECSO WG6, with feedback from the Japan workshop  ok 
    * the "May 2018, Gregory, presentation of EUNITY to ECSO WG2 
    * Herve Debar, ETSI Information Security Indicators working group: 
      * June 2017 (physical meeting, Berlin)
      * September 2017 (physical, Paris)
      * December 2017 (Physical, Sophia Antipolis)
      * January 2018 (Physical at FIC, Lille)
      * February 2018 (Physical, Berlin)
      * April 2018 (Physical, Paris)

#11 July 2018 
*adeies ITE* ρωτησα την Μελτινι και επειδή ειμαι με μεταπτυχιακη υπορτοφια με λιγες ωρες δεν θα την δηωσουμε καθολου σαν αδεια απλα εκεινες τις μερες θα βαλω 0 ωρες και θα συμπληρωσω τισ ωρες αυτες τις ςπομενς μερες. 
*Μπουλος* follow up tetarth 9:30 prwi 
*pairaivw* πηρα την καρτα απο την Τραπεσα στο ΙΤε αλλα πιν αυριο μευαυριο μετα απο τηλεφωνο. στην τ
*Βιβι* να βαλω timeplAN για το review study + topic analysis / spam detection papers. 
*δεδουσις*  προσπαθησε να υλοποιησει την ιδεα του, αλλα δεν βγηκε κατι. του εστειλα τον κωδικα του δημοψιφισματος με lda να αρχισει να το δουλευει . 
 *eunity review meeting* ρωτησα τον σωτηρη αν μπορω  να μην παω λογω του ματιου , μου ειπε καλο θα ηταν να ειμαι αλλα αφου δεν γινεται αλλιως. 
 *eunity sygma* ειχαμε input απο Leuven. ειπαμε με τον cp να τα ανεβάσουμε . 
 *eunity d5.3*  koitaxa ta inputs apo ton Youki, ekana kapoies allages afairesa upokegaleio adeio anevasa se svn.  θα περιμενουμε απαντηση απο youki αν ειναι οκ με το subsection που αφιαρεσα και θα το στειλουμε τον Herve για review και submit. 
 *διαβατηριο* den apantane apo astynomia an xreiazonati rantevou
 *εσπα* θα ανακοινωθουν στις επομενες μερες. 
 *γραμματεια* πηγα την αξιολογηση
 *επιτηρηση* εστειλα mail για αλλαγη την Πεμπτη που εχουμε την γιορτουλα στο προνηπιο . 
 *eunity

13 
2014 1
15 2
16 3
17 4
18 5
#sunanthsh me vivi si 

*isws kapoio survey paper* panw se follower based systems and its misuses. (ousisastika 8a ienia to literature review gia to thesis)

*dataset:* 

BU = Bulgaria https://en.wikipedia.org/wiki/Bulgarian_parliamentary_election,_2017
DE = Germany https://en.wikipedia.org/wiki/German_federal_election,_2017
FR_ElectionPresidentielle201, FR_ElectionPresidentielle2017 = 
   France https://en.wikipedia.org/wiki/French_presidential_election,_2017 
FR_<ALL THE REST> = France https://en.wikipedia.org/wiki/French_legislative_election,_2017
GB = Great Britain https://en.m.wikipedia.org/wiki/United_Kingdom_general_election,_2017
NL = Netherlands https://en.wikipedia.org/wiki/Dutch_general_election,_2017
SE = Serbia https://en.wikipedia.org/wiki/Serbian_presidential_election,_2017
TR = Turkey https://en.wikipedia.org/wiki/Turkish_constitutional_referendum,_2017   

    Bot setection h pio elegant : fake news + misinformation in european election dataset ?

    Δέσποινα, έτρεξες κάποιον απλό learning αλγόριθμο (όχι deep learning) στα tweets από τις διαφορετικές γλώσσες? Έβγαλαν κάτι πιο coherent?

    Ίσως η καλύτερη κατεύθυνση είναι να κάνεις bot detection σε συνδιασμό με political campaign topic identification and targeted group identification. Με αυτό τον τρόπο μπορείς να βρείς campaing similarities and difference σε διαφορετικά election campaigns την ίδια περίπου περίοδο. Επίσης αν μπορείς να κάνεις identify kai fake news campaigns που σχετίζονται με τα election campaigns θα ήταν πολύ χρήσιμο.


# Paraskeuh 1 June
*EUNITY deliverable d5.3* 
 In Spain, there is already legislation that covers some security requirements
to be mapped to risk levels, namely the classification of information and the
handling of such information is covered by Law 9/1968, Law 11/2007 and
Royal Decree 3/2010. There is no legislation yet that requires mandatory reporting
of cybersecurity incidents, such as the one proposed in EU NIS directive,
but the National Cyber Security Strategy, adopted in 2013, states that enforced
incident reporting is a line of action that the Spanish government will pursue.



3.2.3.2 France
Brief description
In France, the law programming the defense strategy for 2014-2019 is the
main framework for the development of cybersecurity. It includes many of
the aspects that need to be covered in the strategic research and innovation
agenda of EUNITY. It creates obligations for operators of sensitive (critical)
infrastructure to investigate and report incidents, and to be equipped to resist
and/or detect attacks. It defines priority areas for the development of products
that are either innovative or that include sovereignity issues. It also outlines
a budget and describes several mechanisms (R&I funding, national platforms,
strategic projects, . . . ) to reach these goals. This law can be seen as a model
for the strategic development of cybersecurity in Europe.
The content of this section is focusing on more recent developments than
were included in the EUNITY Description of Action. The two fundamental
documents included here are the draft military planning law (published in
January 2018, for discussion by the french parliament) including the associated
report and the defense review of october 2017, and the cyberdefense review published in february 2018. These documents form a consistent set
and the core of the French cybersecurity doctrine for the 7 years to come.


This document describes the national strategy concerning cyber security in Greece setting the principles for the development of a safe online environment. The National Cyber Security Authority is implementing the National Cyber Security Strategy that is called to fill the gap between the public and private sector and is basically a tool for assuring integrity, availability and resilience of critical frameworks, confidentiality of the transmitted information and subsequently the advancement of online security


Previous strategies and related documents
Strategic vision
The main aim
Specific aims

Areas of interest - research and innovation context
Areas of interest - legal, policy and organizational perspective
Areas of interest - financial perspective

# bv0cr9cdf HY345
Despoina:_CSD_Phd_Thesis_Template despoina$ ssh  gate1.csd.uoc.gr -o HostKeyAlgorithms=+ssh-dss -o PubKeyAcceptedKeyTypes=+dsa -l antonakd


hy345 - exeteash askhsewn
 cp ~hy345/qemu-linux/hy345-linux.img


qemu-system-i386 -hda hy345-linux.img -append "root=/dev/hda" -kernel linux-2.6.38.1/arch/x86/boot/bzImage -curses
qemu-system-i386 -hda hy345-linux.img -append "root=/dev/hda" -kernel linux-2.6.38.1/arch/x86/boot/bzImage -curses

#18 Μαυ 

εχουμε ενα section για το παραδοτέο **D3.1 : The “3.2.4 National project calls"** subsection is to present a more substantive perspective, i.e. for example in the case of EUNITY this would be a description of the “Call for proposal: H2020-DS-SC7-2016”

Οπότε χρειαζόμαστε  calls και  description για αυτά. 
Βλεπω το NASΚ έχει βάλει 

EUNITY d3.1
3.2.4.4 In Poland [Responsible partner: NASK]

3.2.4.4.1 CyberSecIdent [Comment:todo]
So far there was two calls in the programme, namely: CyberSecIdent I

and CyberSecIdent II.


National programmes / Government programmes
– The Ministry of Education, Research and Religious affairs (MERRA)
– The Public Investment Programme (PIP)
– National Strategic Reference Framework 2007-2013 (NSRF)


auta einia calls?

Funding through NSRF 2007-2013
NSRF 2007-2013, through specific actions, (ARISTEIA/EXCELLENCE I
& II, ERC-GSRT) promotes excellence, and supports cooperation between
Greek research institutes (THALES, ARCHIMIDES). Additionally fellows can
gain experience and advance their skills through and doctoral programmes
and postdoctoral (HERAKLEITOS, SSF/IKY scholarships).
Mobility There is a legal framework that promotes mobi


The Hellenic Foundation for Research and Innovation
(ELIDEK) Scholarships for Doctoral Candidates in Computer Science and Engineering
**Μηπως σε αυτά θα βάλουμε τα calls που ειχα βρει ;Να βρω μονο τα ελληνικα  ; ** 


  with open('/storage2/deep_learning_elections/dataset/ht_GB_ElectionUK_1.json') as data_file_json:


Eleni birthday 

nikaines 2 paidia 2 megaloi
antwnhs 2 apidia 2 megaloi 
sofia 2 megaloi 
xrusou 1 paidi 2 megaloi 
viola 1 paidi 2 megaloi 
zaharis 2 paidia 2 megaloi --
kwsths 2 megaloi 1 paidi  
nikolas 1 apidi 2 megaloi 



#14 May 2018 
**evaluation csd** finished!

#13 May 
UMC BSN number
I would like to apply for the termination of my health insurance at umc.
My klantnummer is 3847495600 & burgerservicenummer 363460019

and the reason I want to terminate is that I will move to another country.

The date of termination should be 9 August 2013.

Recently I gave birth to a girl, name Eleni Kanteraki.
I received a letter from you that said that Eleni is now insured with umc so  I would like to apply for the termination of her insurance as well.
From your letter I see that her klantnummer is 4733431200 and the burgerservicenumber is 595158663


Aelxandros BSN: 524880207 30/7/78

DIGID 

Despoina.
Gebruikersnaam:
antonak


    Burgerservicenummer:
363460019
    A-Nummer:
4395183281

Vervaldatum:
09-07-2012

Activeringsdatum:
11-11-2010

Aanvraagdatum:
08-11-2010
aneiP3R00FG!

=========================


Vangelis Baby 
product highlights:
- tests show highest throughput available 
- sleek, modern look, after-market kits available for customization 
- highly portable w/ tons of functionality in a compact frame
- scalable, promises to “grow to match your enterprise’s needs” 
- compatible with previous models
- energy-efficient 
- one-of-a-kind prototype designed and produced by rarely-seen Japan - Greece collaboration

but:
- small input buffer requires frequent operator intervention
- advertised “self-cleaning” mode needs VERY long time to calibrate
- minimal diagnostics & troubleshooting facilities: a single audio alarm (with no volume control) 
- ZERO documentation included
- no output throttling
- requires extensive maintenance by a team of experts
- unscheduled downtime multiple times per day

overall: only for the enthusiast who will appreciate the killer features despite the high TCO. 5/5 stars

#10 May 2018 

febryary 2014   1o 
sept     2014       barca
ianouarios  2015 2o 
sept        2015       cypr
iano 2016       adeia
sept 2016       3o 
ian  2017       4o 
sept 2017       5o 
aerino 2018     6o 


dopafmai
antonakd
838939

**eunity** deliverable D2.1 made minor changes- in svn 
deliverable D3.1 fixed encoding issues : replaced ’ with '

# 9 May
**eunity D2.3** Added questionnaires

**minutes from Telco**

    # EUNITY May progress telco minutes
      by Gregory and Christophe
      May 9th, 2018 from 9am to 10am CEST.

      ## Agenda
      * Interim review
      * Progress on deliverables
      * Input to SyGMa portal
      * 2nd Workshop
      * Liaison with ECSO, Cyberwatching.eu (ICT2018, concertation), AEGIS, Japan

      ## Attendees
      NASK: Anna, Marek(?), Pawel
      IMT: Hervé, Gregory, Christophe
      FORTH: Despoina
      ATOS: Pedro
      KUL: Stefano
      NAIST: Youki

      ## Interim review
      In Brussels on June 28.
      Preparation meeting at IMT premises on June 27.

      Reviewers: Afonso Ferreira (IRIT), Andrea Lanzi (Milano)
      PO: Nineta Polemi

      Deliverables need to be sent by June 13. As well as the complete agenda.

      ### Agenda
      To be set. How long should the review last?
      Hervé's suggestion: 10am - 4pm (30mn set up, 3h presentation, 30mn private reviewers' discussion)
      incl. presentation of workshop, deliverables, future activities
      No objection from partners

      Seems no financial information is involved since period (of 18 months) is not over yet.

      Hervé proposes a slot to JP consortium. 
      Youki says he may if need arises.

      A visitor template will be sent to all to access EC premises.

      The review may take place in Beaulieu (DG CNECT).

      ## Dissemination
      In contact with Nick Ferguson (Cyberwatching.eu) for joint dissemination with AEGIS at ICT 2018 (Dec. 4 to 6)
      Joint networking session : towards EU and international harmonization of cybersecurity

      ## Deliverables progress
  ### D2.1: community engagement
      1st round of iteration done with Elena and Gregory. 
      Ready to be reviewed by a greater number of partners to ensure the document corresponds to expectations.

  Reviewers: Pedro, Despoina ok reviewed once . I will check it again if changes. 

  ### D2.3: workshop proceedings
      Added a feedback section.
  Lack of contents on industry session. Pedro notes that there are really few minutes, will contact Alicia to complete his.
  Pawel will provide additional minutes to complete his feedback slides presented during the workshop.
  Contributions on feedback section or other sections by May 16th.

      ### D3.1: preliminary analysis report
      More information is needed on R&I contents before May 21st.
      Sections 3.1 and 3.2 are lacking contributions from partners.

      Pedro indicates that these sections may cover the gap analysis.
      Hervé suggests that there may be an ECSO document on gap analysis.

      Pedro and Hervé discuss the availability of information in ECSO documents in particular with workforce shortage, certification, etc.
      Pedro suggests that it will make more sense since we are attempting to compare EU and JP, and not individual countries with Japan.

      ATOS is working on Sect.4. Looking for some contribution from JP side.
      Youki suggests people at JAXA may be of help on industry and standardization aspects.

      ### D5.1: Website and collaboration
      List of telcos by Gregory if needed.

  ### D5.3: Dissemination report
      A few sections are still missing (intro, networking events, etc.).
      Additional publications from all partners are requested.
      Contributions by May 16.

      ### Management report
      Need to confirm with the PO that management report is not needed since period of 18 months is not complete.
      A short draft can be prepared just in case.

      ## Input to SyGMa portal
  still missing info from KUL.

      ## 2nd workshop
      A date after ICT 2018 and before May 2019.

      Pawel reminds that 2nd workshop milestone was originally to be completed by January 2019 (M20).

      Candidate conferences for collocation:
      - ICT 2018: another networking session in addition to the joint one
      - CONEXT 2018 (Dec. 4 to 7), colliding dates with ICT 2018
      - FIC 2019 (end of Jan. 2019 in Paris) could be interesting but more expensive and more industry oriented
      - French-German cybersecurity research forum

      Hervé will investigate the FIC option in order to get a EUNITY booth in the research village jointly coordinated by IMT.

      ## liaison 
      Gregory attended Cyberwatching.eu and ECSO WG2.
      Will attend FR-JP cybersecurity symposium in Annecy on May 16 to 18.
      One important point raised during ECSO WG2 meeting is the lack of domestic cybersecurity products and services in both EU and JP, and in particular as being used in the administration/gov/institutions.


#8 May 
**eunity** deliverable D3.1 
3.2.3.9 Common areas of strategies in the field of research and inno-
vation[Comment: a brief summary to be done here.] However strategies, as a very high-level documents, do not provide specific information regarding to planned research and innovation actions, they outline main directions of such actions. It is very important that all analysed countries have prepared documents of the strategies but their granularity is varied]
In Poland
[Responsible partner: IMT] [Responsible partner: ATOS]
[Responsible partner: FORTH]
CyberPolicy Portal
Scientific and Academic Computer Network - National Research Institute (NASK-PIB) has published a web portal - CyberPolicy which can be found on www. cyberpolicy. nask. pl . CyberPolicy portal aims at providing knowledge about cybersecurity from the strategic, regulatory, organizational and practical perspective. The main mission of the portal is to gather and disseminate infor- mation regarding new regulations, programmes, strategies, good practices and initiatives directly connected with cybersecurity’s ecostystem However the por- tal is not currently very comprehensive and only available in Polish, but very promising is the dynamic growth of the portal.

opote in greece 8a mporopusame n a valoume : 
http://mindigital.gr/index.php/69-ggpsp/kyvernoasfaleia/2055-ethniki-stratigiki-kyvernoasfaleias
http://mindigital.gr/index.php/kyvernoasfaleia

evala sto paradoteo :

transavia: 
her-gro : 1July-12 July : 888
her - ams : 849

her - ams - ath 882


aegean her ams her 1200+ asto kai me endiamesous sta8mous!
her ams ath 1300+

airbnb 6 beds https://www.airbnb.com/rooms/961242?location=Groningen%2C%20Netherlands&s=O4C7rOGy 119 /night! teleio
https://www.airbnb.com/rooms/17551138?location=Groningen%2C%20Netherlands&adults=4&children=1&home_collection=1&s=1e8DG7HR
https://www.airbnb.com/rooms/17729866?location=Groningen%2C%20Netherlands&adults=4&children=1&home_collection=1&s=1e8DG7HR 205
#7 May 

**anaconda at aneipero** https://www.digitalocean.com/community/tutorials/how-to-install-the-anaconda-python-distribution-on-ubuntu-16-04
eixa kanei su san root !
xana install san despoina uparxei hdh 

/home/despoina/anaconda3/bin/jupyter  notebook --ip 0.0.0.0 

insert token

# 3 May 

**UNITY** changes from input in deliverables D5.3, D2.3 
revise D3.1  TILL page 68:  - 3.8 National preparedness exercises

#2 May 
**tweet deep learning**
Explanation:
Every file contains tweets regarding electoral events.
The format of the filename is ht_<COUNTRY>_<HASHTAG>_<BATCH>.json.gz 
Country codes and wikipedia links to events are:
BU = Bulgaria https://en.wikipedia.org/wiki/Bulgarian_parliamentary_election,_2017
DE = Germany https://en.wikipedia.org/wiki/German_federal_election,_2017
FR_ElectionPresidentielle201, FR_ElectionPresidentielle2017 = 
   France https://en.wikipedia.org/wiki/French_presidential_election,_2017 
FR_<ALL THE REST> = France https://en.wikipedia.org/wiki/French_legislative_election,_2017
GB = Great Britain https://en.m.wikipedia.org/wiki/United_Kingdom_general_election,_2017
NL = Netherlands https://en.wikipedia.org/wiki/Dutch_general_election,_2017
SE = Serbia https://en.wikipedia.org/wiki/Serbian_presidential_election,_2017
TR = Turkey https://en.wikipedia.org/wiki/Turkish_constitutional_referendum,_2017   



ti mphke pou: 

**Strategic vision** : h intro paragrafo apo to Resume from Greek National Cyber Security Strategy ENISA:   Summary, Introduction
**The main aim** 2h paragrafo General Principles and Objectives apo to Resume from Greek National Cyber Security Strategy ENISA
**Specific aims** Resume From Greek ERA Strategy - Priorities in the Greek Strategic Plan:
**Areas of interest - research and innovation context** apo to Resume from Greek National Cyber Security Strategy ENISA:   Action Framework – Strategic Objectives

**Areas of interest - financial perspective**Resume From Greek ERA Strategy



        **Policies kai regulation profanws den pianoume emeis **

        Oson afora to ellhniko kemeno apo "Greek Strategy for the European research area" 8a poume oti den vrikame kati gia security alla 8a dwsoume mia eikona tou ti anaferei mesa. 
         
        Sto sunolo 8eloume na vgei ena keimeno 50--60 selides. 

    Opote sto doc: /Users/antonakd/Google Drive/EUNITY/D3.1paradoteo/ : 

    *Resume From Greek ERA Strategy*

    Auto mallon fainetai na tairiazei sto 
    \subparagraph{Areas of interest - financial perspective} 
    mas leipei to \subparagraph{Areas of interest - legal, policy and organizational perspective}
    mhpw sienia kai auto edw? Alla apo shmeiwseis xrhstou vlepw oti mallon den piazoume emeis. 


    *Resume from Greek National Cyber Security Strategy ENISA* 
    AUTO MALLON fainetai na tairiazei sto D3.1 \subparagraph{Areas of interest - research and innovation context}



#30 April

**EUNITY dissemination report** 

Sharks : Deliverable D6.2: Dissemination report, year 1(despoina:~ antonakd$ /Users/antonakd/Google\ Drive/EUNITY/D5.3Dissemination\ reportYear1/sharcs-d6.2\ -\ Copy\ \(1\).pdf 
)

**Kiran dataset requested:**

the dataset is ordered according to the heuristic that produces an estimation of the following time.
The heuristic is described in the paper:

https://link.springer.com/article/10.1007/s13278-018-0490-5 
or http://sci-hub.hk/https://link.springer.com/article/10.1007/s13278-018-0490-5 ;)


And is originally appeared here: https://www.microsoft.com/en-us/research/uploads/prod/2016/11/We-Know-Who-You-Followed-Last-Summer.pdf

To get the dates you will also use the json file attached.
I also show some code

import bisect
import json

with open('creation_times_s.json') as f:
    creation_time = json.load(f)

creation_times_ids = [x[1] for x in creation_times]

def get_creation_time_from_id(twitter_id, return_index=False):
        creation_index = bisect.bisect_left(creation_times_ids, twitter_id)

        if return_index:
                return creation_index

        if creation_index == len(creation_times):
                return creation_times[-1][0]
        return creation_times[creation_index][0]


Now suppose that we have this line of the file:
5220 4674 5151 f


This means: 4674 WAS FOLLOWED BY 5151 at estimated time of : get_creation_time_from_id(5220).



#29 April

ASONAM alex bot paper 
Αυτό που έκανα είναι:
1. Πήρα τους 1304 χρήστες από τον γράφο του Πολ. και τους 400 χρήστες που είναι semantically characterized από τον γράφο στο fig. 9.
2. Έψαξα για ακμές στο αρχείο με τα list memberships που να έχουν ως node1 έναν από τους 1304 και ως node2 έναν από τους 400
3. Βρήκα 60.853 τέτοιες ακμές
4. Βρήκα όμως ότι μόνο 273 από τους 1304 σημετείχαν σε αυτές. 
5. Για κάθε έναν από τους 273 κοίταξα το semanic cluster των χρηστών (από τους 400) που είναι list co-membership.
6. Δλδ για τον χρήστη 100 πήρα ότι έχει list member με 10 politicians, 20 news/media, 30 celebrities κτλ.
7. 

#28 April
Apo galini 
ssh galini -l despoina ICS  account 

Access via ssh, in two steps:
[1] connect to the 'ssh gateway':
ssh despoina@shark.ics.forth.gr
password: P9jyTg4gov

This gateway is accessible from the lab's subnets (139.91.70.x, 139.91.92.x), and from FORTH-ICS's VPNs (subnets: 139.91.203.x, 139.91.204.x). It is also accessible from a general-use ssh gateway that FORTH-ICS operates: galini.ics.forth.gr

[2] From 'shark.ics.forth.gr', connect via ssh to your test machines (e.g. hydra0, hydra1).



pare to gephi kai kane label tta clusters an vreis estw kai mia lista pou exeis kanei esu annotate mes sto diko sou grafhma 

#27 April 
EUNITY D3.1 

Apo palies seimeiwseis 

    Meeting 1/3/2018 EUNITY 

    pernoume to keimeno ths enisa trends in threats  (epigrammatika, profanws autoi exoun kanei mia extended analysi – isws apla na einai arketo na paroume tous titlous twn dikwn tous kefalaiwn kai na poume ata einia ta thredns in threats) kai 8a htan to idaniko na ta sundiasmoume me ta calls pou uparxoun mesa sto keieno tou H2020 . Apo auta ta calls an exoun dhmosieusei hdh kati sta antistoixa projercs mporoume na anaferoume mia pi8anh *sunergasia?* 
    Oson afora ta measurements, den einai aparaothto na dwsoume luseis se auta ta trends( eidika an einai nea threats den einai kai eukolo na dwsoume emeis lush) , alla ena roadmapping oson afora sto funding alla kai stis kateuthuntiries grammes pou dinei h episthmonikh koinothta. 

    **Policies kai regulation profanws den pianoume emeis **

    Oson afora to ellhniko kemeno apo "Greek Strategy for the European research area" 8a poume oti den vrikame kati gia security alla 8a dwsoume mia eikona tou ti anaferei mesa. 
     
    Sto sunolo 8eloume na vgei ena keimeno 50--60 selides. 

Opote sto doc: /Users/antonakd/Google Drive/EUNITY/D3.1paradoteo/ : 

*Resume From Greek ERA Strategy*

Auto mallon fainetai na tairiazei sto 
\subparagraph{Areas of interest - financial perspective} 
mas leipei to \subparagraph{Areas of interest - legal, policy and organizational perspective}
mhpw sienia kai auto edw? Alla apo shmeiwseis xrhstou vlepw oti mallon den piazoume emeis. 


*Resume from Greek National Cyber Security Strategy ENISA* 
AUTO MALLON fainetai na tairiazei sto D3.1 \subparagraph{Areas of interest - research and innovation context}


#26 April 2018
**D3.2** add attachment at section of workshop : session 6 **at svn**
**D3.1** greek chars? mail to Anna **at svn latest changes**


#For national strategies links provided: 
17https://www.enisa.europa.eu/topics/national-cyber-security-strategies/ncss-map
18https://www.enisa.europa.eu/topics/national-cyber-security-strategies/ncss-map
19https://www.enisa.europa.eu/publications/national-cyber-security-strategies-animplementation-
guide/at download/fullReport
20https://www.enisa.europa.eu/publications/ncss-good-practiceguide/
at download/fullReport

#Analysis will be based on these questions:
What research and innovation actions or objectives were defined in a
national strategy?
2. What areas of research and innovation are defined in a strategy as especially
important? [Comment: to be decided whether question 1. and 2
should be merged]
3. Whether an approach to define a strategy and research and innovation
actions in various countries is similar to other countries? [Comment: to
be decided whether it is truly important for us]
4. What are the goals beyond the strategy objectives defined by the ENISA
(and briefly described below)?



#25 April

**EUNITY** filled in the mechanism to finance cybersecurity and in D3.1 chapter ResAndInnov.tex  chapter 3.1.2**SVN**

**dedousis**  vale se ena doc ola ta results : implementation A, input files for A , results 

na doume ti exoume so far  


#24 April
Gathered SyGma app and responded to emails
*EUNITY update tasks from cp*
 

  1) to keimeno apo to RESUME FROM GREEK ERA STRATEGY - 8a mpei sto kefalaio 3 in Greece alla pepei na ginei reshape. katarxhn na parei to structure pou exei to In poland isws , h mporoume na rwthsoume an 8a allaxei ?
  Apo thn uparxousa domh pou exei grayeo to In poland , exoume diaforetika ta national funding sources, ta international kai mixed ienia koina. 

  2) Ta threats (RESUME FROM ENISA THREAT LANDSCAPE REPORT 2017) 8a mpoun sto 4.1 4.2 pou anamigniomaste kai emeis, alla 8a ta steloume sthn Anna

  3) To RESUME FROM GREEK NATIONAL CYBER SECURITY STRATEGY ENISA - 8a eprepe na phgainei sto chapter 3 : research and innovation aspect - apla ekei exei ta projects - 8a rwthsoume 


  7) Ta calls 8a krathsw mono oso einai gia cyber security (oxi physical) kai me seira : arxika cybersecurity kai meta security . Mia mikrh perigrafh tou ka8e project kai ta setlnoume sthn Anna .  
  ta calls 8a moiun apo thn anna 2 (selida 16): 2. European research strategy
**maybe sent an email to Anna about this??**

#23 April
**paper asonam**
**uploaded data from Kiran** 


#20 April

**[EUNITY]**
==D2.3==
Corrected D2.3 with new chapter for interactions and sections 2,3,5,6,7,8 
added to svn
*added program *
*moved interaction to the end*  
=== and the of them ==
*EUNITY update tasks from cp*

  8) Sto collaboration tools mporeis na baleis 2 protaseis gia to SVN ... to structure toy... ti periexei mesa...
  ta notifications poy pairnoyme emeis (FORTH) otan kapoios kanei commit... kai o,ti boh8aei sto overall management 
  and smooth progress of the project.  OK apla exw valei mono svn (mail + doodle? ) 
    ** OK @svn27/3/2018 **

  4) steile to mail gia to dissemination report me cc cp + si 
      DONE

  6) gia to dissemination reposrt sto website : 1 screen shot kai 1 paragrafo DONE OK
       @svn27/3/201

    * gia to deliverable 3.1Deliverable D3.1: Preliminary version of the Cyber-security Research Analysis Report for the two regions 
  5) gia ta projects (sto kefalaio 3.2) 8a paw sto website tou ka8e project, kai apo to abstract 8a kanw rephrase : 
  skopos tou project 
  target, 
  ti pragamateuete 
  kai poio htan to outcome (p.x. red book) + eikona apo to website opws p.x. http://www.syssec-project.eu/ thn eikona tou vivliou
    OK @svn27/3/201


  1) to keimeno apo to RESUME FROM GREEK ERA STRATEGY - 8a mpei sto kefalaio 3 in greece alla pepei na ginei reshape. katarxhn na parei to structure pou exei to In poland isws , h mporoume na rwthsoume an 8a allaxei ?
  Apo thn uparxousa domh pou exei grayeo to In poland , exoume diaforetika ta national funding sources, ta international kai mixed ienia koina. 

  2) Ta threats (RESUME FROM ENISA THREAT LANDSCAPE REPORT 2017) 8a mpoun sto 4.1 4.2 pou anamigniomaste kai emeis, alla 8a ta steloume sthn Anna

  3) To RESUME FROM GREEK NATIONAL CYBER SECURITY STRATEGY ENISA - 8a eprepe na phgainei sto chapetr 3 : reserach and innnovation aspect - apla ekei exei ta projects - 8a rwthsoume 




  7) Ta calls 8a krathsw mono oso einai gia cyber security (oxi physical) kai me seira : arxika cybersecurity kai meta security . Mia mikrh perigrafh tou ka8e project kai ta setlnoume sthn Anna .  
  ta calls 8a moiun apo thn anna 2 (selida 16): 2. European research strategy

#19 April 

Sunanthsh me poluvio gia to asonam paper. 
Set next steps highlited in red in latex. Regarding Twitter lists: 

{\color{red}STORYLINE: This section describes a classifier of the
above detected bots into categories based on lists. Describes
methodology:
  1. get list similarity graph, find sub-graph projection on bot nodes only.
  2a. filter resulting graph by a threshold to remove noise (few random lists?)
  2. run clustering on resulting graph
  3. say manual classification of resulting communities, based on
  "source/victim nodes that got copied" in the graph
  4. present quantitative results: number of clusters, average
  size/density/etc-graph-features. Figure with degree distributions
  maybe?
  5. if time, correlate with referendum dataset (how many bots did we
  find that existed and tweeted back then).
}


#18 APril  


**[sudo python -m SimpleHTTPServer ]**

ok copy ta data se storage2 pou exei xwro . /stroage2/share

#share twitter data
111G /storage3/marienbad/SNAP/output_graph.heuristic.final.uniq.gz
43G /storage3/marienbad/compact_graph.output_graph.heuristic.final2.gz

Pou/pws na anebasw/steilw auta ta arxeia?

====TO: Indos====
Steile to parakatw afou broume tropo na anebasoume ta arxeia 

================
KWAK dataset:
Contains all friends and followers of all users present in http://an.kaist.ac.kr/traces/WWW2010.html

Specifically from this link: http://an.kaist.ac.kr/~haewoon/release/twitter_social_graph/twitter_rv.tar.gz

In the period from November 2014 to January 2015, we downloaded all the followers and friends of these users.
This dataset also includes users that we did not sample. 
This results in some edges being twice:

For example let's say that on KWAK's dataset we have the edge:
A --> B
then we take all friends and followers of A and B
If we assume that A follows B, C and is followed by D and E
and if we assume that B follows K, L and is followed by A and M
Then our dataset contains:
A --> B
A --> C
D --> A
E --> A
B --> K
B --> L
A --> B (twice!)
M --> B

Note that from all these edges we have sampled (meaning downloaded the friends and followers from only A and B).

Location:
XXXX
Size: 111GB

BIG dataset
Contains our dataset described in the paper: https://link.springer.com/article/10.1007/s13278-018-0490-5 
Location: XXXX
Size: 43GB

This is different from KWAK on the following:
If it contains the edge A -->B, then we have sampled both A and B.
Yet, we DO NOT include (in the gunzip) the friends and followers of A and B that we have not sampled.
This is because of file size limitations. 
All friends and followers from this dataset comprise many terabytes of data that we have saved in millions of files. 
We cannot provide a comprehensive (like a gunzip) file to download it..
This is why it has the "compact" part on its name. 

Semantics:
 id_1 id_2 f|F

F: id_1 FOLLOWS id_2
f: id_1 IS FOLLOWED BY id_2

Also if you cannot access https://link.springer.com/article/10.1007/s13278-018-0490-5 
You can use http://sci-hub.hk/https://link.springer.com/article/10.1007/s13278-018-0490-5 ;)

##EUNITY################################


### D5.1
Good progress on this deliverable. --- **[more typos corrected]**

### D5.3 
---> Sect. 8 to be contributed by FORTH OK added twitter to svn as well. **[ok]**  

###input for SyGma app : **[mail from ATOS]**
 Quesada, Inmaculada <inmaculada.quesada@atos.net>
Attachments6:11 PM (17 hours ago)
to Pedro, despoina 
Dear Despoina,
Please, find attached Atos information about dissemination activities
Best regards
Inmaculada
=============================
17 APril  EUNITY

###D2.3 : avala preface pou eixe o Xrhstso kai attach ola ta presentations apo to workshop . 
periemnw kati mikra suntactika apo ton Xrhtso, hdh sto svn



###D5.3 : 
Deliverable D5.3: Dissemination report year 1

apo forth : 

to introduction giati exei pinpoint to IMT ?
Estile o Youki mail gia 


On Tue, Apr 17, 2018 at 9:49 AM, Youki Kadobayashi <youki-k@is.naist.jp> wrote:
Dear Despoina,

Judging from activities at SVN, D5.3 needs more work before the
target date of Apr 23.  If there is something we can do within
the Japanese partners, please let me know.

Many thanks,
        Youki Kadobayashi, NAIST

=====apanthsa: + estiela gentle reminder gia to deadline / 
Dear Youki, 

if you have any relevant information concerning the sections below, please provide: 

Chapter 4: Participation in networking events
Chapter 5 : Publications in conferences and journals 
Chapter 6: Dissemination through standards activities

thank you,


with kind regards, 
Despoina Antonakaki

############################################
 ## Progress on Deliverables

### D5.1
Good progress on this deliverable.


--------->[TODO] FORTH: add a section on collaborative tools: SVN and GoToMeeting. DOne in word and sent to cp: 

      Despoina Antonakaki <despoina@ics.forth.gr>
      Attachments6:09 AM (10 minutes ago)
      to Christos 
      καλημέρα Χρήστο, 

      έκανα ένα local copy το D5.1: Website and collaboration tools και πρόσθεσα δύο κεφάλαια πριν το conclusions για το SVN και το GoToMeeting. Για το GoToMeeting δεν έχω βάλει πολλά και επισης δεν έχω βάλει logo, μόνο URL (δεν ξέρω αν παίζει κάτι με Copyright). 

      Έχω βάλει track changes, αν νομίζεις είναι οκ να τα ανεβασω και sto svn. 


### D2.3

[TODO] ALL: Please contribute the minutes to the SVN.
[TODO] Session chairs: collect minutes from their session's interactions and contribute a small summary to the deliverable.

--------->[TODO] FORTH: Deliverable to be committed to the SVN. ΟΚ το + Mail cp 
    
        Despoina Antonakaki <despoina@ics.forth.gr>
        Attachments6:19 AM (1 minute ago)
        to Christos 
        Επίσης για το Deliverable D2.3: Workshop 1 proceedings, όπως μου είχε ζητησει και στο telco εφτιαξα ενα latex αρχειο και το ειχα ανεβάσει στο svn  ώστε να αρχισουν να βάζουν υλικό οι Partners. Εκεί νομιζω ειχαμε πει εμεις θα βάλουμε υλικό που εχουμε ήδη και ειναι στο svn (programma kai presentations), δεν τα εβαλα αυτα ακόμη. 

        Βέβαια δεν είμαι σίγουρη για το structure του, θα το δούμε μαζι. 
        https://dcs-svn.ics.forth.gr/svn/eunity/deliverables/eunity-d2.3/




################################
*BOt paper*
  #Γεια, έχω ετοιμάσει μία πρώτη ανάλυση για bot + lists. Τα βήματα που έκανα είναι:

  Πήρα το αρχείο botsim.txt.gz και εφάρμοσα ένα filtering στο weight ώστε να μπορεί να γίνει plot ο γράφος. Συνολικά έχει 866 εκατ. edges.. .
  Το filtering ήταν:
  weight > 500 . Πέρασαν 8952 edges
  Remove Duplicate edges, έκοψε 2949 edges
  Remove self-referenced edges (edges με ίδιο source,target). έκοψε 989 edges
  plot με cytoscape.
  Το αποτέλεσμα είναι εδώ: https://s3.eu-central-1.amazonaws.com/28745de72970/botsim_over_500.html
  Φαίνονται πάλι 3 πολύ διακριτολί clusters. Θα συνεχίσω με:

  Ποια είναι τα semantics των clusters?
  Να βάλω πληροφορία από τα αρχεία bottweets*.txt.gz ώστε να έχουμε και numbers of copy events



# to kouki kai to revu8i 

  lhxiarxikh praxh genishs 
  vevauwsh paidiatro meta 15 iouliou gia na einai prosfata 
  emvolia  fwtotupia

  telos uouliou kleinoun gia kalokairi gia treis evdomades 

#easychair antonakd 0Jd5VenzH6


#aneipero
* OLD: ssh -p 2222  despoina@139.91.70.42
    * OLD: ssh -p 2222  despoina@139.91.70.146
    * OLD: ssh -p 2222  despoina@139.91.70.38
    * OLD: ssh -p 2222  despoina@139.91.70.66
    * OLD: ssh -p 2222  despoina@139.91.70.69
    * OLD: ssh -p 2222  despoina@139.91.70.73
    * OLD: ssh -p 2222 despoina@139.91.70.24
    * ssh -p 2222 despoina@139.91.70.82
    139.91.70.29
    139.91.71.13

# April 5th, 2018 EUNITY telco
    from 9:00 to 10:15 am CEST

    Minutes by Gregory and Christophe
    ## ## ################################################################## ## 
    ## ## ################################################################## ## 
    ## ## ################################################################## ## 

    ## ## ################################################################## ## 
    ## Attendees
    IMT: Hervé, Christophe, Gregory
    NASK: Anna, Pawel
    KUL: Elena, Stefano
    ATOS: 
    FORTH: Despoina
    NAIST: Youki, Daisuke
    UT: Kazuya

    ## Agenda
    * Progress on D5.1 - Website and collaboration tools (M3)
    * Progress on D2.1 - Community Engagement Report (M6)
    * Progress on D2.3 - Workshop 1 Proceedings (M12)
    * Progress on D5.2 - Management Report Y1 (M12)
    * Progress on D5.3 - Dissemination Report Y1 (M12)
    * Progress on D3.1 - Cybersecurity Research Analysis v1 (M14)
    * SyGMa reporting
    * CyberWatching.eu Concertation Meeting in Brussels (Apr 26)
    * Workshop 2

    ## Progress on Deliverables


    ### D5.1
    Good progress on this deliverable.


    --------->[TODO] FORTH: add a section on collaborative tools: **[SVN and GoToMeeting. OK]** 

    Twitter is not really active (last tweet in January).

    ### D2.1
    Progress ongoing by Elena and Stefano.

    3 questionnaires (Meiji, JAIST, JPCERT) missing but NAIST provided most information.
    Their responses may not be relevant, since JP partners are not funded.
    JP partners are consulted as experts e.g., JPCERT is invited for their CERT expertise, JAIST for cyberranges and testbeds, Meiji for privacy.

    Some inputs on questions 1 and 2 are not very relevant.

    Partners may be pinged again to clarify their contributions.

    [TODO] KUL: Deliverable to be committed to SVN for all to contribute.

    # [DES]I just went through the document saw [FORTH]
    _[DES]I just went through the document saw [sublime-markdown-extended](FORTH))_
     **[selida 8 , section 3.2.3]**

    [TODO] ALL: Missing EU contributions to be committed by April 13th EOB.

    ### D2.3

    [TODO] ALL: Please contribute the minutes to the SVN.
    [TODO] Session chairs: collect minutes from their session's interactions and contribute a small summary to the deliverable.

    --------->[TODO] FORTH: Deliverable to be committed to the SVN. **[OK]** 

    ### D5.3 
    ---> Sect. 8 to be contributed by FORTH OK **[OK]** **[SVN ok ]**
    Sect. 9 -- collaborative activities:
    - visit from IMT in Tokyo (April), to be mentioned as a link between NECOMA and EUNITY, helped preparing the workshop
    - visit from JP partners in Paris, Athens, funded by MIC

    --------->[TODO] FORTH: Deadline to be set by email. **[OK]**

    ### D5.2
    Review on June 28th. 
    Sharp deadline on June 13th to provide everything (deliverables, efforts).

    [TODO] IMT: need to contact the PO to understand what is expected in this Y1 report, since the period is 18 months and fix an agenda for the review meeting.

    ### D3.1
    Description of how the national strategy should be contributed, to be committed today.

    Some project descriptions from FORTH.
    KUL sections are being finalized before being circulated.

    ToC is ready.

    First draft expected before review meeting (end of June).
    To be submitted by the end of July.

    ## Continuous Reporting

    --------->[TODO] FORTH: Table to be inputted to SyGMa on Participant Portal about dissemination activities in link with D5.3 : Despoina I vahe sent around an email and wait for input!**[One input for ATOS, waiting for the rest to complete]**

    ## Concertation Meeting
    Stefano available to speak from April 16th.
    Pedro to be contacted.

    Youki to be contacted for JP perspectives.

    3 CSAs funded by EC, incl. Cyberwatching (general, 4 years) and AEGIS (EU-US, 2yr).

    [TODO] IMT: contact Stefano, Pedro and Youki to prepare slides for the Concertation meeting

    ## Workshop 2
    [TODO] IMT: consult the PO on whether the workshop could be held after M24.
    --------->TODO] ALL: set a date for Workshop 2
    [TODO] ALL: set a date for Workshop 2

    ## Next telco
    [TODO] IMT: Doodle to be circulated.

============================
#5 April ENITY Meeting 
  1)The sygma agenda application - https://ec.europa.eu/research/participants/portal/desktop/en/funding/guide.html - summary of publcation missing 
   write the delivery date (TODO )
  input publication (TODO )
  participal portal account available?
  Despoina can FORTH fill in missing details? (Ekana register gia account)

  D5.1
  Maybe add more collaboration tools like svn and goto meeting.Asked about if we agree to add svn + go to meeting - I said its ok to add. 

  D2.3
  meeting minutes in svn (workshop). not only questionnaires because they are part of another deliverable.
  But moments interaction with keynotes etc.
  FORTH leads this. I will create a file in svn (latex) so partners can add their input 

  Fill in publication in dissemination report 
  D3.1 Anna will put in svn new version of deliverable so all can fill in with common ToC. 

  D5.3 section 8 - corrected already in svn( social media by FORTH )

  we will set deadline by email . tous eipa meta thn deutera wste na sunenoh8oume gia to pote.  

  3.2 before review meeting a draft

  For second workshop - 20 month is late need to set a date. RAID is early . Maybe set a doodle ? Christo na ftiaxoume ena doodle? ti hmeromhnies na valoume omws? 
========================
#EUNITY tasks
  Dear EUNITY colleagues,

  I understand you all have been really busy in this new year period,
  However, we have some works ahead of us regarding EUNITY, and notably a few deliverables.

  In this regard, I would like to set up monthly telcos starting now. Please find below a Doodle to cast your votes for the next telco date:
  https://doodle.com/poll/7eewdp9z64gvbenz

  I would like to discuss the following since we are already in M9
  (URGENT) - D1.1 Communit engagement report led by KUL (2,5 months late): all partners please answer to Stefano's questions

  (HIGH) - M14 deliverable due July 31st, 2018: D2.1 Preliminary version of the Cybersecurity Research Analysis Report. All leading partners need to analyze literature and questionaire results from the workshop.
  We should start drafting the ToC at least.

  (MEDIUM) - EUNITY Y1 review: dates are either 27-28/6 or 28-29/6

  (MEDIUM) - EUNITY European Workshop organization: should take place during the last 6 months of the project, ie. M19-M24, from December, 1st 2018 at the earliest

  (MEDIUM) - M12 deliverables due May 31st, 2018:
  -- D1.2 (website) Workshop 1 proceedings led by FORTH
  -- D4.2 management report for Y1 led by IMT
  -- D5.3 dissemination report for Y1 led by FORTH


============================

*bot paper*
  ka8e node einai xrhsths - connectionectio between two = they both belong to N listes . N=Gephi ==> Filters (dexia) attributes==> Range common

  1) coloring me vash to common ranking common - color ta edges analoga se poses liste anoikoun 
  arxika to coloring ieni grammiko , mporeis na to allaxeis apo edw : spline - ALLA DEN EXEI DIAFORA

  2) NODES poio megalous analoga me to posa tweets exoune 
  edw vazoume spline

  mege8os tou node 

  3)community detection : statistics modularity run 
     meta les xrwmatise t o me vash to modularity  

  nodes--> partition --> modularity class
     listes pros copied tweets 

=============
*EUNITY update tasks from cp*

  8) Sto collaboration tools mporeis na baleis 2 protaseis gia to SVN ... to structure toy... ti periexei mesa...
  ta notifications poy pairnoyme emeis (FORTH) otan kapoios kanei commit... kai o,ti boh8aei sto overall management 
  and smooth progress of the project.  OK apla exw valei mono svn (mail + doodle? ) 
    ** OK @svn27/3/2018 **

  4) steile to mail gia to dissemination report me cc cp + si 
      DONE

  6) gia to dissemination reposrt sto website : 1 screen shot kai 1 paragrafo DONE OK
       @svn27/3/201

    * gia to deliverable 3.1Deliverable D3.1: Preliminary version of the Cyber-security Research Analysis Report for the two regions 
  5) gia ta projects (sto kefalaio 3.2) 8a paw sto website tou ka8e project, kai apo to abstract 8a kanw rephrase : 
  skopos tou project 
  target, 
  ti pragamateuete 
  kai poio htan to outcome (p.x. red book) + eikona apo to website opws p.x. http://www.syssec-project.eu/ thn eikona tou vivliou
    OK @svn27/3/201


  1) to keimeno apo to RESUME FROM GREEK ERA STRATEGY - 8a mpei sto kefalaio 3 in greece alla pepei na ginei reshape. katarxhn na parei to structure pou exei to In poland isws , h mporoume na rwthsoume an 8a allaxei ?
  Apo thn uparxousa domh pou exei grayeo to In poland , exoume diaforetika ta national funding sources, ta international kai mixed ienia koina. 

  2) Ta threats (RESUME FROM ENISA THREAT LANDSCAPE REPORT 2017) 8a mpoun sto 4.1 4.2 pou anamigniomaste kai emeis, alla 8a ta steloume sthn Anna

  3) To RESUME FROM GREEK NATIONAL CYBER SECURITY STRATEGY ENISA - 8a eprepe na phgainei sto chapetr 3 : reserach and innnovation aspect - apla ekei exei ta projects - 8a rwthsoume 




  7) Ta calls 8a krathsw mono oso einai gia cyber security (oxi physical) kai me seira : arxika cybersecurity kai meta security . Mia mikrh perigrafh tou ka8e project kai ta setlnoume sthn Anna .  
  ta calls 8a moiun apo thn anna 2 (selida 16): 2. European research strategy



=====================================================================================


1 screen shot kai 1 paragrafo 


nai setilw to mail gia to 5.3 



elidek
gsrt (kai links) 
mixasmo mesw calls


gia projects  - perigrafh apo to site tu ti pragmateuotan 

poio to main oicome p.x red book - ti exei to  ABSTRACT skopos target paradotea - 1 paragfrafo per projects + eikones opws to proposal 


---------------


national allazoun mono 

apo edw 8a gvoun ta subsections

ta calls 8a moiun apo thn anna 2 (selida 16)

4.1. -  4.2  - ta threatrs  







==========================================

==========================================
============

Symfwna me ta minutes kai ayta poy eipame sto telco χ8εσ exoyme na etoimasoyme 
1. FORTH M3 31/8/2017 : D5.1 Website and collaboration tools ( o Adam anafere sto telco pws sto SyGMA kati 8a prepei na anebei an exoyme yposx8esei kapoio paradoteo (DX.X) ane3arthta an to exoyme xarakthrisei Other h' Report  (8a to ftia3w 
*  Sotiri, Exeis akoysei kati paromoio gia to (1) ? * 

2. FORTH M12 30/4/2018 : D2.3 Workshops proceedings 1 (8a mazepsoyme ta public PDF se ena deliverable)

3. FORTH M12 30/4/2018 : D5.3 Dissemination report year 1 (8a etoimasoyme ToC kai 8a to kanoyme circulate kapoia stigmh syntoma) 

4. NASK M14 31/7/2018 : D3.1 Preliminary version of the Cyber-security Research Analysis Report for the two regions (exei hdh etoimasei content kai input h Despoina to opoio 8a 3ekinhsoyme siga siga na bazoyme sto deliverable)

8a ftia3w egw syntoma ta (1) kai (2).
Despoina an 8es 3ekina to ToC gia to D5.3 (mporeis na basisteis se ayta poy soy exw steilei) wste na to kanoyme circulate
kai meta blepoume ti apo to content poy etoimases 8a perasoyme sto D3.1.

thanks,
Christos.
======================

Meeting me poluvio Paraskeuh 2/3/2018: 

* please read - review paper (syntactically) 
* continue on lists (add semantics etc) 
** as doume mphws o grafos me tis liste mpoirei na vgei apo gephi: na mpoun xrwmata kai semantics. exei polu kalo export ..
* mexri Paraskuh na to xanadoume 

Meeting 1/3/2018 EUNITY 

https://cyberwiser.eu/greece-gr

1) D5.1 - report  - to website - 8a paroume apla screenshots apo to website kai 8a to feroume sthn morfh apo antistoixou paliou aradoteou 
2) D2.2 Workshop Proceedings - surrafh twn pdfs pou einai sto svn 
3) D5.3 Dissemination report  - 8a ftiaxoume to TOC kai 8a to prow8hsoume stous partners gai na sullexoume uliko ?
(edw eixame pei oti 8a mpoun peirgrafes apo ta dissmination activities : workshop, questionareis h oti allo exei ginei pros auth thn kate8unsh? kala 8umame?)
==============
pernoume to keimeno ths enisa trends in threats  (epigrammatika, profanws autoi exoun kanei mia extended analysi – isws apla na einai arketo na paroume tous titlous twn dikwn tous kefalaiwn kai na poume ata einia ta thredns in threats) kai 8a htan to idaniko na ta sundiasmoume me ta calls pou uparxoun mesa sto keieno tou H2020 . Apo auta ta calls an exoun dhmosieusei hdh kati sta antistoixa projercs mporoume na anaferoume mia pi8anh *sunergasia?* 
Oson afora ta measurements, den einai aparaothto na dwsoume luseis se auta ta trends( eidika an einai nea threats den einai kai eukolo na dwsoume emeis lush) , alla ena roadmapping oson afora sto funding alla kai stis kateuthuntiries grammes pou dinei h episthmonikh koinothta. 

**Policies kai regulation profanws den pianoume emeis **

Oson afora to ellhniko kemeno apo "Greek Strategy for the European research area" 8a poume oti den vrikame kati gia security alla 8a dwsoume mia eikona tou ti anaferei mesa. 
 
Sto sunolo 8eloume na vgei ena keimeno 50--60 selides. 

===================

X array of traiing data 
Y array of target label data 

EUNITY dissemination report  : 
oi egine worshop, questionairies
gia to workshop proceesings: yparxoun pdfs apo to workshop, apla 8a ftiaxoume ta arxeio kai 8a ta valoume mesa ayta ta pdf vlepw twra ienia sto svn ston katalogo workshops

20/2/2018

Gia to paradoteo D1.2 sto svn exei anevasei h Anna Felkner apo to NASK ena tex me toc kai introduction. Sthn selida 11 exei gia to FORTH 3.1 Mechanisms to finance cybersecurity research. Emeis prepei na grayoume gia Greece

eunity 
To ergo 3ekinhse 1/6/2017 M1
Twra dianyoyme to M6
Ara an ypologizw swsta: 
M14 - Aug. 2018
M24 - May 2019

Ta paradotea poy prepei na kanoyme contribute  opws fainetai kai apo to contract poy soy eixa steilei einai:
D3.1: Preliminary version of the Cyber-security Research Analysis Report for the two regions - M14 
D3.2: Revised version ‘Cyber-security Research Analysis Report’ for the two regions. - M24


--------------

I would like to discuss the following since we are already in M9
(URGENT) - D1.1 Communit engagement report led by KUL (2,5 months late): all partners please answer to Stefano's questions

(HIGH) - M14 deliverable due July 31st, 2018: D2.1 Preliminary version of the Cybersecurity Research Analysis Report. All leading partners need to analyze literature and questionaire results from the workshop.
We should start drafting the ToC at least.

(MEDIUM) - EUNITY Y1 review: dates are either 27-28/6 or 28-29/6

(MEDIUM) - EUNITY European Workshop organization: should take place during the last 6 months of the project, ie. M19-M24, from December, 1st 2018 at the earliest

(MEDIUM) - M12 deliverables due May 31st, 2018: 
**-- D1.2 (website) Workshop 1 proceedings led by FORTH**
-- D4.2 management report for Y1 led by IMT
**-- D4.3 dissemination report for Y1 led by FORTH**
-----------------


Now uploading photoslibrary 2017-> 08 done
now uploadinh 12 
2018--> 01 uploading now οκ 02 ΟΚ 


26/1/2018

sunanthsh me cp. 

pernoume to keimeno ths enisa trends in threats  (epigrammatika, profanws autoi exoun kanei mia extended analysi) kai 8a htan to idaniko na ta sundiasmoume me ta calls pou uparxoun mesa sto keieno tou H2020 . Apo auta ta calls an exoun dhmosieusei hdh kati sta antistoixa projercs mporoume na anaferoume mia pi8anh *sunergasia?* 
Oson afora ta measurements, den einai aparaothto na dwsoume luseis se auta ta trends( eidika an einai nea trhets den einai kai eukolo na dwsoume emeis lush) , alla ena roadmapping oson afora sto funding alla kai stis kateuthuntiries grammes pou dinei h episthmonikh koinothta. 

Policies kai regulation profanws den pianoume emeis 

Oson afora to ellhniko kemeno apo "Greek Strategy for the European research area" 8a poume oti den vrikame kati gia security alla 8a dwsoume mia eikona tou ti anaferei mesa. 
 
Sto sunolo 8eloume na vgei ena keimeno 50--60 selides. 



25/1/2018

regarding paradoteo eunity. Eixa arxisei na diavazw to Greek ERA strategy , alla mou fianteai polu feniko sxetika me kteuthintiries grammes kai porous pou kaluvoun thn ereuna sthn Elleada. Den uparxei kamia nuxe se security opote xekinhsa na diavazw to SEA paradoteo gia na dw xana ti eidous plhrofria 8a xreisteina sullexoume. 

meta prepei na xanadw ola ta svn slides kai docs gia peretero phges. 
Isws to setcion 1.2 structure of this dcument na einia arketo :

yaxnoume gai TRENDS in cyber security, approaches in EU and JAPAN
priorities and recocmendation and actions 


    TRENDS in cyber security: we need to point out first the security thread trends(in SEA tehy found them from SOFOS 2015 ) 
    A simple google search for keyword: cybersecurity threats 2017 gives us blogs magazines etc. We need Strategic agendas!
  A)  So google search for cybersecurity threats 2017 + strategic agenda: 

    1 )https://cybersecuritysummit.co.uk/summit-agenda/ they need money ...

    2) https://ec.europa.eu/digital-single-market/en/policies/cybersecurity --> oN More information
    Mid-term review of the 2015 Digital Single Market strategy: Press release - Q&A press release http://europa.eu/rapid/press-release_IP-17-1232_en.htm
    Sto more info: For more Information: Communication A Connected Digital Single Market for All http://ec.europa.eu/newsroom/document.cfm?doc_id=44527


    edw periexei ... means extending the Digital Single Market Strategy to keep up to date with EMERGIG TRENDS and CHALLENGES  such as those related to online platforms, the data economy and CYBERSECURITY

    At 3.3 3.3 Fostering a trustworthy cyber ecosystem: Tackling cybersecurity challenges together

    Society is shifting its focus from specific connected devices (computers, smartphones or wearables) to omnipresent connectivity (household items, industrial goods, etc.). By 2020 an estimated 6 billion household devices (televisions, refrigerators, washing machines etc.) will be connected to the internet in the EU alone.54 A connected economy and society is more vulnerable to cyber threats and attacks and requires stronger defences. ...More than 4,000 ransomware attacks have occurred every day since the beginning of 2016, a 300% increase over 201555....


found in foonotes :
    1) STAFF FOUND 2016 for later : : How to protect your networks from ransomware, CCIPS, 2016 https://www.justice.gov/criminal-ccips/file/872771/download. technical-document-ransomware-prevention-and-response.pdf
    2)  - f 6 July 2016  - 57 Such as the Computer Security Incidents Response Teams set up by the Directive 2016/1148 of the European Parliament and of the Council of 6 July 2016 concerning measures for a high common level of security of network and information systems across the Union, CERT-EU or the solidarity clause (Article 222 of the Treaty on the Functioning of the European Union)--> google : http://eur-lex.europa.eu/legal-content/EN/TXT/?uri=uriserv:OJ.L_.2016.194.01.0001.01.ENG&toc=OJ:L:2016:194:TOC exei kai ELLHNIKA ! 

    auto exei measures ...The Directive on security of network and information systems (NIS Directive).pdf  MALLON DEN EXEI TOIPOTA 
  58 2013 PALIO !!!Cybersecurity Strategy of the European Union: An Open, Safe and Secure Cyberspace; JOIN (2013)1.

  edw akouw prwth fora to "hybrid threats: The United States Joint Forces Command defines a hybrid threat as, “any adversary that simultaneously and adaptively employs a tailored mix of conventional, irregular, terrorism and criminal means or activities in the operational battle space.
" + fuzion cell: http://europa.eu/rapid/press-release_IP-17-2064_en.htm  alla ta pianei polu epifaniaka 



B)  gogle search "cybersecurity threats 2017 strategic agenda enisa" https://www.enisa.europa.eu/publications/enisa-threat-landscape-report-2017
ENISA Threat Landscape Report 2017 BINGO! 
mesa sto arxeio uparxei  kai taxonomy 53 https://www.enisa.europa.eu/topics/threat-risk-management/threats-and-trends/enisa-threat-landscape/threat-taxonomy, accessed November 2017.
54 https://etl.enisa.europa 


0) Intro?
1) trend threats
2) Measurements oxi roadmaping funding eite 8ewroun oi episthmones  

policies, priorities  OXI 
cybersecurity in EU /JAPAN? differences? 

Apo tis phges tou workshop:

  1) FORWARD Whitebook 2009 - palio ... 
  2) Horizon 2020 Work Programme 2018-2020 DRAFT 5.i. Information and Communication Technologies
  3) WG6 – Strategic Research and Innovation Agenda (SRIA) - june 2017
  4) Strategic Research Agenda Final v0.96 - 2015 palio 
  5) NIS Platform - Cybersecurity Strategy - 2013 

TI LEEI TO GRANT AGREMENT
-----------------------------------
The two deliverables in this WP describe the research landscape of the two regions. The first version is preliminary
and will be updated by the end of the project.
D3.1 : Preliminary version of the -->Cyber-security Research Analysis Report<-- for the two regions [14]
Based on D2.1, this report identifies and describes the mechanisms to finance research in both regions, reviews the
main research directions in the field, identify the strong and weak points and highlights common interests between the
EU and Japan which may create opportunities, explored in WP4.
D3.2 : Revised version ‘Cyber-security Research Analysis Report’ for the two regions. [24]
Cybersecurity roadmaps and work programmes get updated and this deliverable will reflect the latest advances
described in the Cyber-security roadmaps and other sources identified by D2.1.  








15/1/2018 
===============

Tweetluenza: Predicting Flu Trends from Twitter Data
review tsiknaki: My suggestion to the editor is accept with major revisions.
--------
snam review: allagh ta figures sthn selida pou anaferonati : 
https://tex.stackexchange.com/questions/8625/force-figure-placement-in-text


-----------
eunity meeting : 

Till end of May proceedings. FoRTH D2.3 

he will ask this afternoon more docs for this deliverable. (presentations, full program etc) . 
about this report : questioneres in the report 

extend session 2 into some minutes that he is going to add .
--> if there are more minutes from ANYONE about the sessions from the workshop, please add them to the svn.

this report will be the basis. Christos will provide the latex template .
will be coordinated by FORTH , but can work together with him, he can help with. 

month 12 end of may 
okada will contribute/distribute staff about the questionaires
start drafting it . analysis will be dffrent if we add later numbers, but we can start drafting 


 
======================

Mίλησα και με τον Alex που εχει κάνει bot detection  σε dataset του Πολύβιου και εφαρμόζει jacquard distances στα tweets. 
Στην περίπτωση των russian bots/trolls θα ήταν καλό, είτε να μπορούμε να δούμε ip, αν είναι βέβαια όχι τόσο sophisticated και δεν περνάνε από κάποιο(ους) proxy,είτε να δούμε κάποιο paper που να αναφέρει συγκεκριμένα κάποια features που θα βοηθούσαν στον εντοπισμό των συγκεκριμένων users.  

Με βάση το άρθρο: 
http://www.economist.com/news/britain/21731669-evidence-so-far-suggests-only-small-campaign-new-findings-are-emerging-all?frsc=dg%7Ce
υπάρχουν 2700 accounts του IRA 
"...When it was summoned before Congress last month, Twitter published a list of 2,700 accounts run by the Internet Research Agency (IRA), a well-known troll farm with ties to the Kremlin. Two groups of British researchers who had collected Brexit-related tweets cross-referenced this list and found that some IRA accounts had pushed out content on the referendum..."
Βρήκα την λίστα εδώ: 
https://www.recode.net/2017/11/2/16598312/russia-twitter-trump-twitter-deactivated-handle-list

Φαντάζομαι μπορουμε απλα να ψαξουμε αυτα τα usernames στο dataset απο τις ελληνικές εκλογές και το δημοψίφισμα, για να δούμε αν ειχαν οποιαδήποτε αναμείξη.  

Επιπλέον ο Alex αρχισε προσφατα ενα tool το οποίο χρησιμοποιώντας jacquard distances ανισχνευει bots tweets. Θα μπορούσαμε διερευνητικά να τρεξουμε και αυτό το εργαλείο στο ίδιο dataset. 

Fantazomai ayth einai h lista


Ανάλυση ελληνικών tweets πανω στο δημοψίφισμα του 2015 και στις μετέπειτα εκλογές.

8/11/2017


paper gia reading group me poluvio: Group formation in large social networks: membership, growth, and evolution
to diavasa.

...back to eunity : 
===================
7/11/2017 
* paper gia dcs presentation : Temporal Effects on Hashtag Reuse in Twitter:
A Cognitive-Inspired Hashtag Recommendation Approach . Uparxei etoimh parousiash !

* Milhsa me tsamardino : Μιλησαμε πριν απο λίγο στο τηλέφωνο με τον κ. Τσαμαρδίνο,

του εξήγησα ποιο είναι το dataset και ότι θέλουμε να κάνουμε topic analysis (NLP) αλλα language agnostic χωρίς να βάλουμε λεξικά μιας και μιλάμε για 8 διαφορετικές γλώσσες και ότι έχουμε βρει την tweet2vec(word & character embedding) τεχνική που θέλουμε να κάνουμε utilize. 

Μου πρότεινε να δούμε αρχικά το LDA κατά ποσο δουλεύει σε αυτό που θέλουμε να κάνουμε. Του είπα ότι το έχουμε χρησιμοποιήσει ήδη στην προηγουμενη δουλειά του Plos. Ποιο είναι το added value για deep learning? ας αποδείξουμε πρώτα ότι με απλές τεχνικές όπως LDA δεν μπορούμε να προχωρήσουμε, και αν δούμε ότι όντως το χρειαζόμαστε ας πάμε με deep learning .

Είπαμε ότι αργότερα μόλις τελειώσουμε με το Twitter corpus, θα δούμε το gpu acceleration σε deep learning. 

* mail ston dedousi:
LDA Twitter


 * PAPER : Language-Independent Twitter Sentiment Analysis. Sascha Narr, Michael Hulfenhaus and Sahin Albayrak . http://www.dai-labor.de/fileadmin/files/publications/narr-twittersentiment-KDML-LWA-2012.pdf http://www.slideshare.net/saschanarr/languageindependent-twitter-sentiment-analysis-14331264
 * Announcing SyntaxNet: The World’s Most Accurate Parser Goes Open Source https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html 
*  http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0155036 Multilingual Twitter Sentiment Classification: The Role of Human Annotators  Igor Mozetič , Miha Grčar, Jasmina Smailović
* Cross-Lingual Sentiment Analysis Without (Good) Translation. Mohamed Abdalla, Graeme Hirst https://arxiv.org/abs/1707.01626
* https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5
Essential Cheat Sheets for Machine Learning and Deep Learning Engineers Kailash Ahirwar
* A character-based convolutional neural network for language-agnostic Twitter sentiment analysis . Joonatas Wehrmann ; Willian Becker ; Henry E. L. Cagnini ; Rodrigo C. Barros . http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7966145 
* https://www.jair.org/media/4992/live-4992-9623-jair.pdf A Primer on Neural Network Models for Natural Language Processing 

kapoia lectures pou mporoun na voh8hsoun: 
* https://github.com/oxford-cs-deepnlp-2017/lectures Oxford Deep NLP 2017 course 
Sxetika me ta lexika pou me eixes rwthsei: 

* The dictionary I use in my code https://medium.com/broken-window/the-power-of-wordnet-with-nltk-7c45b20f52cf 
* https://github.com/fluhus/wordnet-to-json WordNet in JSON format.  
* http://parrotprediction.com/dive-into-wordnet-with-nltk/ Dive into WordNet with NLTK 
* https://medium.com/ai-society/jkljlj-7d6e699895c4 A Comprehensive Introduction to Word Vector Representations Esteban Vargas


============
   * 2 February 2017 . http://www.nlpolitics.com/en/twitter-graphs.html An Analysis of French Primaries Candidates Twitter Usage Remi Bois 

* 2 February 2017 . PAPER : Language-Independent Twitter Sentiment Analysis. Sascha Narr, Michael Hulfenhaus and Sahin Albayrak . http://www.dai-labor.de/fileadmin/files/publications/narr-twittersentiment-KDML-LWA-2012.pdf http://www.slideshare.net/saschanarr/languageindependent-twitter-sentiment-analysis-14331264 

    * 6 February 2017 . Election polling is in trouble. Can internet data save it? By John Bohannon http://www.sciencemag.org/news/2017/02/election-polling-trouble-can-internet-data-save-it 
    * 3 April 2017 . https://dumps.wikimedia.org/enwiktionary/ 
    * 30 July 2017 Sequence Classification with LSTM Recurrent Neural Networks in Python with Keras http://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/ 
    * 30 July 2017 . Understanding Convolutional Neural Networks for NLP Denny Britz 
    * 30 July 2017 . Exploring the Limits of Language Modeling Rafal Jozefowicz Oriol Vinyals Mike Schuster Noam Shazeer Yonghui Wu . Google Brain . https://arxiv.org/pdf/1602.02410.pdf 
    * 4 August 2017 . Tilting Towards the Cosmopolitan Axis? Political Change in England and the 2017 General Election     Will Jennings,
    Gerry Stoker http://onlinelibrary.wiley.com/doi/10.1111/1467-923X.12403/abstract 
    * 29 August 2017 . https://www.recode.net/2017/5/6/15568582/twitter-bots-macron-french-presidential-candidates-hacked-emails Twitter bots are being weaponized to spread information on the French presidential campaign hack by April Glaser 
    * ### Wordnet 
* 29 August 2017 . https://github.com/fluhus/wordnet-to-json WordNet in JSON format.  
* 29 August 2017 . The dictionary I use in my code https://medium.com/broken-window/the-power-of-wordnet-with-nltk-7c45b20f52cf* 29 August 2017 . http://parrotprediction.com/dive-into-wordnet-with-nltk/ Dive into WordNet with NLTK 
* 29 August 2017 . https://medium.com/ai-society/jkljlj-7d6e699895c4 A Comprehensive Introduction to Word Vector Representations Esteban Vargas 
* 29 August 2017 . https://github.com/oxford-cs-deepnlp-2017/lectures Oxford Deep NLP 2017 course  
    * 29 August 2017 . Beautiful visualizations of how language differs among document types  https://github.com/JasonKessler/scattertext 
    * 29 August 2017 . Generalisation in Named Entity Recognition: A Quantitative Analysis https://arxiv.org/abs/1701.02877 Isabelle Augenstein, Leon Derczynski, Kalina Bontcheva 
    * 29 August 2017 . https://blog.booking.com/named-entity-classification.html Named Entity Classification 
    * 29 August 2017 . TheanoLM is a recurrent neural network language modeling tool implemented using Theano  https://github.com/senarvi/theanolm 
    * 29 August 2017 . tweet2vec https://github.com/bdhingra/tweet2vec 
* 29 August 2017 . Announcing SyntaxNet: The World’s Most Accurate Parser Goes Open Source https://research.googleblog.com/2016/05/announcing-syntaxnet-worlds-most.html 
    * 29 August 2017 . http://www.europeanfutures.ed.ac.uk/article-2583 Twitter Sentiment Analysis on the UK’s EU Membership , Clare Llewellyn and Laura Cram 
    * 29 August 2017 . Twitter Refugee Sentiment Analysis (x-post /r/MachineLearning) https://www.reddit.com/r/LanguageTechnology/comments/4yvosd/twitter_refugee_sentiment_analysis_xpost/ 
    * 8 September 2017 . The rise of political apathy in two charts https://www.nature.com/articles/n-12342912?WT.mc_id=TWT_NatureNews&sf85790605=1 
    * 8 September 2017 . Knowledge-Powered Deep Learning for Word Embedding https://pdfs.semanticscholar.org/553a/6530b0802da9bec354d0a70fde254f6a5e36.pdf Jiang Bian, Bin Gao, and Tie-Yan Liu 
    * 8 September 2017 . Offline bilingual word vectors, orthogonal transformations and the inverted softmax http://www.gitxiv.com/posts/CTjSJFDmuirj7iB2L/offline-bilingual-word-vectors-orthogonal-transformations 
    * 8 September 2017 . Teaching Machines to Read and Comprehend Karl Moritz Hermann Hermann, Karl Moritz, Tomas Kocisky, Edward Grefenstette, Lasse Espeholt, Will Kay, Mustafa Suleyman, and Phil Blunsom. https://arxiv.org/pdf/1506.03340.pdf 
    * 8 September 2017 . Semantic prosody https://en.wikipedia.org/wiki/Semantic_prosody 
    * 8 September 2017 . https://github.com/zhangxiangxiao/Crepe Character-level Convolutional Networks for Text Classification  
    * 8 September 2017 . Text Understanding from Scratch https://arxiv.org/pdf/1502.01710.pdf Xiang Zhang Yann LeCun
    * 8 September 2017 . Deep Learning for Natural Language Processing – ICLR 2017 Discoveries  https://amundtveit.com/2016/11/12/deep-learning-for-natural-language-processing-iclr-2017-discoveries/
    * 8 September 2017 . Deep Learning for Natural Language Processing – ICLR 2017 Discoveries  https://amundtveit.com/2016/11/12/deep-learning-for-natural-language-processing-iclr-2017-discoveries/ Amund Tveit 
* 11 September 2017 . http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0155036 Multilingual Twitter Sentiment Classification: The Role of Human Annotators  Igor Mozetič , Miha Grčar, Jasmina Smailović
* 11 September 2017 . https://startupsventurecapital.com/essential-cheat-sheets-for-machine-learning-and-deep-learning-researchers-efb6a8ebd2e5 Essential Cheat Sheets for Machine Learning and Deep Learning Engineers Kailash Ahirwar
    * 17 October 2017 . Βachelor thesis I eνας φοιτητής θέλει λέει να ασχοληθεί με deep neural networks.  https://mail.google.com/mail/u/0/#inbox/15f29efbb1d31868 
* 1 November 2017 . Cross-Lingual Sentiment Analysis Without (Good) Translation. Mohamed Abdalla, Graeme Hirst https://arxiv.org/abs/1707.01626 
* 1 November 2017 . A character-based convolutional neural network for language-agnostic Twitter sentiment analysis . Joonatas Wehrmann ; Willian Becker ; Henry E. L. Cagnini ; Rodrigo C. Barros . http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7966145 
* 6 November 2017 . https://www.jair.org/media/4992/live-4992-9623-jair.pdf A Primer on Neural Network Models for Natural Language Processing . Yoav Goldberg https://twitter.com/newsycombinator/status/897775107728449536?refsrc=email&s=11

===============

telco me tsamardino

του εξήγησα ποιο είναι το dataset και ότι θέλουμε να κάνουμε topic analysis (NLP) αλλα language agnostic χωρίς να βάλουμε λεξικά μιας και μιλάμε για 8 διαφορετικές γλώσσες και ότι έχουμε βρει την tweet2vec(word & character embedding) τεχνική που θέλουμε να κάνουμε utilize. 

Μου πρότεινε να δούμε αρχικά το LDA κατά ποσο δουλεύει σε αυτό που θέλουμε να κάνουμε. Του είπα ότι το έχουμε χρησιμοποιήσει ήδη στην προηγουμενη δουλειά του Plos. Ποιο είναι το added value για deep learning? ας αποδείξουμε πρώτα ότι με απλές τεχνικές όπως LDA δεν μπορούμε να προχωρήσουμε, και αν δούμε ότι όντως το χρειαζόμαστε ας πάμε με deep learning .

Είπαμε ότι αργότερα μόλις τελειώσουμε με το Twitter corpus, θα δούμε το gpu acceleration σε deep learning. 

EUNITY 
1. Pairnw ta slides apo to workshop
2. Briskw megala consortia pou anaferontai sta slides (prepei na einai 3-4).  Ena apo auta einai to H2020 pou mou exeis steilei to link: https://ec.europa.eu/programmes/horizon2020/sites/horizon2020/files/h2020-leit-ict-2018-2020_pre_publication.pdf
3. Stis perigrafes kai sta documentations pou uparxoun online gia auta ta consortia/projects vriskw uliko gia na balw sto deliverable.
4. Kanw focus kuriws se “Cybersecurity, IT security, kai privacy."
5. Prospa8w na ta balw sto idio format / katigoriopoihsh pou exei kai to CONNECT2SEA deliverable

thanx!
=========================      
reading group 2/11/

Gia to study me twitter lists :

*8a 8elame idanika na 
** Apo user id xrhstwn --> feature ana context 
na kanoume epivevaiwsh apo clusters

* content based vectors : 
** 2o suxniteres lexeis 
** wres tweeting 
** features 
** ...

==> correlate kai me content based features?

ieee ianouario ?

to persino user id lists tou poluviou? mporei na ginei kapoia statistc analysis ?

===========
nickard: 

bot detection : xekiname me to botornot. cannot find code. pame gia feature extraction?
leaterature review : report poluviou & paper 

Qiang Cao, Michael Sirivianos, Xiaowei Yang, and Tiago Pregueiro. Aid-
ing the detection of fake accounts in large scale social online services. In
Proceedings of the 9th USENIX conference on Networked Systems Design
and Implementation, pages 15–15. USENIX Association, 2012.

attached a draft report of my notes.

============
dedousis: 


1.) dataset apo GB: ht_GB_SnapGeneralElection_1_num.txt Open with Google Docs
2) etrexe: Γεια σας σας στελνω ακριβως τα αρχεια μου οπως τα εχω στον φακελο.Εκει θα βρειτε τον φακελο tweet2vec-master και μεσα στον φακελο misc
1 script parse.py το οποιο αναλυει το dataset και κραταμε μονο το text.Επειτα στο tweet2vec-master παλι υπαρχει ο φακελος tweet2vec, εκει το μονο που πρεπει να κανετε ειναι να τρεξετε την εντολη sh tweet2vec_encoder.sh το οποιο θα ξεκινησει την διαδικασια για την προβλεψη των hashtags.Τελος τα αποτελεσματα θα τα βρειτε μετα την ολοκληρωση στον φακελο results.

https://www.dropbox.com/s/72qmauixbxahns5/dataset_parse.tar.gz?dl=0

3) Parhgage ena txt me precicted hts 

============

dedousis : dictionaries 
=========
gia to eunity

Τα taska βασικα εινια 2 να 

1) Να βρουμε Resources τα οποια δινουν ουσιαστικα τις ερευνητικες κατευθυντηριες γραμες για το cyber security(ισως και privacy) σε Ευρωπη kai Ιαπωνια. Αυτες οι πηγες ειναι ειτε μεγαλα projects τα οποια παροεχουν τα λεγομενα strategic research agents (hypec? carv),  το horizon2020, o ENISA και για Ιαπωνια θα μας στειλουν αυτοί.  
2) Το επόμενο task ειναι να γ΄ίνει μια αναλυση πανω σε αυτες τις δυο κατευθυνσεις (Ευρωπαικη - Ιαπωνικη) και να βρεθούν τα κοινα σημεια  αλλα και οι διαφορές.  

-----------------------
skype with dspiliot
   csv 

   mesa sto csv 8a exei link gia ta images

   pws xeroume pooi apo tous  tweeters einia voters?apo pou einia ?

   gia ka8e xwra an to tweet einai grammeno se authn thn xwra?

   sarcasm

   topic ; wiki , lexicon  
   tweet2vec na provleyei entities 
==============================================
Bachelor Thesis 

FILES: (/storage2/european_election)
ht_BU_neborn_1.json.gz
ht_BU_neborn_2.json.gz
ht_BU_newborn2017_1.json.gz
ht_BU_newborn2017_2.json.gz
ht_DE_BTW17_10.json.gz
ht_DE_BTW17_11.json.gz
ht_DE_BTW17_1.json.gz
ht_DE_BTW17_2.json.gz
ht_DE_BTW17_3.json.gz
ht_DE_BTW17_4.json.gz
ht_DE_BTW17_5.json.gz
ht_DE_BTW17_6.json.gz
ht_DE_BTW17_7.json.gz
ht_DE_BTW17_8.json.gz
ht_DE_BTW17_9.json.gz
ht_FR_ElectionPresidentielle2017_1.json.gz
ht_FR_ElectionPresidentielle2017_2.json.gz
ht_FR_ElectionPresidentielle2017_3.json.gz
ht_FR_ElectionPresidentielle2017_4.json.gz
ht_FR_ElectionPresidentielle2017_5.json.gz
ht_FR_ElectionPresidentielle2017_6.json.gz
ht_FR_ElectionPresidentielle2017_7.json.gz
ht_FR_ElectionPresidentielle2017_8.json.gz
ht_FR_ElectionPresidentielle2017_9.json.gz
ht_FR_france17_10.json.gz
ht_FR_france17_11.json.gz
ht_FR_france17_1.json.gz
ht_FR_france17_2.json.gz
ht_FR_france17_3.json.gz
ht_FR_france17_4.json.gz
ht_FR_france17_5.json.gz
ht_FR_france17_6.json.gz
ht_FR_france17_7.json.gz
ht_FR_france17_8.json.gz
ht_FR_france17_9.json.gz
ht_FR_france2017_10.json.gz
ht_FR_france2017_11.json.gz
ht_FR_france2017_12.json.gz
ht_FR_france2017_13.json.gz
ht_FR_france2017_1.json.gz
ht_FR_france2017_2.json.gz
ht_FR_france2017_3.json.gz
ht_FR_france2017_4.json.gz
ht_FR_france2017_5.json.gz
ht_FR_france2017_6.json.gz
ht_FR_france2017_7.json.gz
ht_FR_france2017_8.json.gz
ht_FR_france2017_9.json.gz
ht_FR_legislatives2017_1.json.gz
ht_FR_legislatives2017_2.json.gz
ht_FR_legislatives2017_3.json.gz
ht_FR_legislatives2017_4.json.gz
ht_FR_Presidentielle2017_1.json.gz
ht_FR_Presidentielle2017_2.json.gz
ht_FR_Presidentielle2017_3.json.gz
ht_FR_Presidentielle2017_4.json.gz
ht_FR_Presidentielle2017_5.json.gz
ht_FR_Presidentielle2017_6.json.gz
ht_FR_Presidentielle2017_7.json.gz
ht_FR_Presidentielle2017_8.json.gz
ht_FR_Presidentielle2017_9.json.gz
ht_FR_Presidentielle2017TONOS_1.json.gz
ht_GB_ElectionUK_1.json.gz
ht_GB_ElectionUK_2.json.gz
ht_GB_ElectionUK_3.json.gz
ht_GB_ElectionUK_4.json.gz
ht_GB_ElectionUK_5.json.gz
ht_GB_ElectionUK_6.json.gz
ht_GB_ElectionUK_7.json.gz
ht_GB_GE2017_10.json.gz
ht_GB_GE2017_11.json.gz
ht_GB_GE2017_1.json.gz
ht_GB_GE2017_2.json.gz
ht_GB_GE2017_3.json.gz
ht_GB_GE2017_4.json.gz
ht_GB_GE2017_5.json.gz
ht_GB_GE2017_6.json.gz
ht_GB_GE2017_7.json.gz
ht_GB_GE2017_8.json.gz
ht_GB_GE2017_9.json.gz
ht_GB_GeneralElection_1.json.gz
ht_GB_GeneralElection2017_1.json.gz
ht_GB_GeneralElection2017_2.json.gz
ht_GB_GeneralElection2017_3.json.gz
ht_GB_GeneralElection2017_4.json.gz
ht_GB_GeneralElection2017_5.json.gz
ht_GB_GeneralElection2017_6.json.gz
ht_GB_GeneralElection2017_7.json.gz
ht_GB_GeneralElection_2.json.gz
ht_GB_GeneralElection_3.json.gz
ht_GB_GeneralElection_4.json.gz
ht_GB_GeneralElection_5.json.gz
ht_GB_GeneralElection_6.json.gz
ht_GB_GeneralElection_7.json.gz
ht_GB_GeneralElection_8.json.gz
ht_GB_GeneralElection_9.json.gz
ht_GB_SnapGeneralElection_1.json.gz
ht_GB_SnapGeneralElection_2.json.gz
ht_GB_SnapGeneralElection_3.json.gz
ht_GB_SnapGeneralElection_4.json.gz
ht_GB_SnapGeneralElection_5.json.gz
ht_GB_SnapGeneralElection_6.json.gz
ht_GB_SnapGeneralElection_7.json.gz
ht_NL_15maart_1.json.gz
ht_NL_15maart_2.json.gz
ht_NL_15maart_3.json.gz
ht_NL_15maart_4.json.gz
ht_NL_15maart_5.json.gz
ht_NL_15maart_6.json.gz
ht_NL_15maart_7.json.gz
ht_NL_tk17_1.json.gz
ht_NL_tk2017_1.json.gz
ht_NL_tk2017_2.json.gz
ht_NL_tk2017_3.json.gz
ht_NL_tk2017_4.json.gz
ht_NL_tk2017_5.json.gz
ht_NL_tk2017_6.json.gz
ht_NL_tk2017_7.json.gz
ht_NL_verkiezingen_1.json.gz
ht_NL_verkiezingen_2.json.gz
ht_NL_verkiezingen_3.json.gz
ht_NL_verkiezingen_4.json.gz
ht_NL_verkiezingen_5.json.gz
ht_NL_verkiezingen_6.json.gz
ht_SE_izbori_1.json.gz
ht_SE_izbori2017_1.json.gz
ht_SE_izbori2017_2.json.gz
ht_SE_izbori2017_3.json.gz
ht_SE_izbori2017_4.json.gz
ht_SE_izbori_2.json.gz
ht_SE_izbori_3.json.gz
ht_SE_izbori_4.json.gz
ht_TR_evet_1.json.gz
ht_TR_evet_2.json.gz
ht_TR_hayir_1.json.gz
ht_TR_hayir_2.json.gz

How to access:
https://s3.eu-central-1.amazonaws.com/482ffd6274d94effb6b0e95d9c5c4495/<FILENAME>

For example:
https://s3.eu-central-1.amazonaws.com/482ffd6274d94effb6b0e95d9c5c4495/ht_BU_neborn_1.json.gz

Total: 9.7GB

!!!Important!!!!!
Twitter explicitly forbids the distribution of large data dumps that contain (among other) tweets. So be careful and DO NOT share these links!

Explanation:
Every file contains tweets regarding electoral events.
The format of the filename is ht_<COUNTRY>_<HASHTAG>_<BATCH>.json.gz 
Country codes and wikipedia links to events are:
BU = Bulgaria https://en.wikipedia.org/wiki/Bulgarian_parliamentary_election,_2017
DE = Germany https://en.wikipedia.org/wiki/German_federal_election,_2017
FR_ElectionPresidentielle201, FR_ElectionPresidentielle2017 = 
   France https://en.wikipedia.org/wiki/French_presidential_election,_2017 
FR_<ALL THE REST> = France https://en.wikipedia.org/wiki/French_legislative_election,_2017
GB = Great Britain https://en.m.wikipedia.org/wiki/United_Kingdom_general_election,_2017
NL = Netherlands https://en.wikipedia.org/wiki/Dutch_general_election,_2017
SE = Serbia https://en.wikipedia.org/wiki/Serbian_presidential_election,_2017
TR = Turkey https://en.wikipedia.org/wiki/Turkish_constitutional_referendum,_2017   

For every country we used various hashtags to download tweets.
For example for Dutch Elections we used #15maart, #tk17, #tk2017 hashtags 
For every hashtag we downloaded tweets in various batches
For example:
ht_NL_tk2017_1.json.gz
ht_NL_tk2017_2.json.gz
ht_NL_tk2017_3.json.gz
ht_NL_tk2017_4.json.gz
ht_NL_tk2017_5.json.gz
ht_NL_tk2017_6.json.gz
ht_NL_tk2017_7.json.gz

We downloaded all #tk2017 tweets in 7 batches.
These batches are ordered according to time.
So all tweets in _1 precede all tweets in _2 which precede all tweets in _3 etc.

The files are zipped with gzip
If you unzip the files, each line is a tweet.
Each tweet is represented by a JSON object
The format of this JSON is explained here: https://developer.twitter.com/en/docs/tweets/data-dictionary/overview/tweet-object 

The order of tweets in each file is chronologically reversed. 

For example let's say that in total there are 10 tweets regarding a certain hashtag (for example #elections). 
Let's also say that we downloaded all these tweets in 3 batches. 
The files: 

ht_XX_elections_1.json
ht_XX_elections_2.json
ht_XX_elections_3.json

Then the first file: ht_XX_elections_1.json
contains the tweets: 3,2,1  IN THAT ORDER

the second file: ht_XX_elections_2.json
contains the tweets: 8,7,6,5,4 IN THAT ORDER

and the third file: _election_3.json
contains the tweets: 10,9 IN THAT ORDER

we assume that tweet 1 was first sent and tweet 10 was the last sent. 

so in order to get all tweets in chronological order you should:
Reverse all files 
For example:
tac ht_XX_elections_1.json > ht_XX_elections_1_reversed.json
tac ht_XX_elections_2.json > ht_XX_elections_2_reversed.json
tac ht_XX_elections_3.json > ht_XX_elections_3_reversed.json

and then concatenate them:
cat \
   ht_XX_elections_1_reversed.json \
   ht_XX_elections_2_reversed.json \
   ht_XX_elections_3_reversed.json \
   > ht_XX_elections_all.json 


I can figure out the following studies:

1. Bot detection
2. Study the mention graph, reply graph
3. Discourse analysis: https://en.wikipedia.org/wiki/Discourse_analysis 
4. Hashtag prediction: https://arxiv.org/abs/1605.03481 
5. Sentiment analysis and Sarcasm Detection. 
6. Topic Analysis with LDA (https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) and Deep Neural Networks
7. Compare average users favoritism towards specific party with final election results. Can Twitter predict election results?
8. <VERY HOT>: Language agnostic techniques. 

You can add anything to this list that you think it is relevant and you would like to work on.

Are you interested in a bachelor thesis regarding these?






===================================================================================================
PLOS One  Last fInal review

Change 1:
We changed the affiliation information of author named: Dimitris Spiliotopoulos
His affiliation was corrected to: University of Houston, Department of Computer Science, Houston, TX, United States

Change 2:
We removed the "Availability" section. Data and code availability is described in the "data availability" part of this letter below. 

Change 3:
As per recommendation from PLOS ONE guidelines, we removed funding information from the Acknowledgments section.
Funding information is described in the Funding part of this letter below.

Also please make note of the following changes:
There are some changes in Author Contribution.

The changes are that we added the following contributions to author: Sotiris Ioannidis:
Investigation
Project administration

Below we list the UPDATED contributions list for each author:

Author Contribution:
=============
AUTHOR: Despoina Antonakaki:
Conceptualization
Data curation
Formal analysis
Investigation
Methodology
Resources
Software
Validation
Visualization
Writing – original draft
Writing – review & editing

AUTHOR: Dimitris Spiliotopoulos:
Data curation
Investigation
Methodology
Visualization
Writing – original draft
Writing – review & editing

AUTHOR: Christos V. Samaras:
Data curation
Methodology
Software
Writing – original draft
Writing – review & editing

AUTHOR: Polyvios Pratikakis:
Writing – review & editing

AUTHOR: Sotiris Ioannidis:
Conceptualization
Funding acquisition
Supervision
Investigation
Project administration

AUTHOR: Paraskevi Fragopoulou:
Conceptualization
Funding acquisition
Investigation
Project administration
Supervision

Funding
=====
The research was supported and financed by the following two research projects: 
(1) FP7 Marie-Curie ITN iSocial funded by the European Comission under grant agreement no 316808.
(2) UNICORN, Funded by the European Commission (H2020-ICT-2016-1/ICT-06-2016) under grant agreement no 731846.

Competing interests
=============
The authors have declared that no competing interests exist.

Data Availability
==========
The source code and instructions on how to obtain part of the data for the reproduction of the presented analysis are available at the following Zenodo repository: https://zenodo.org/record/820555 with DOI: 10.5281/zenodo.820554.
The source code is available under the Apache License 2.0.
The code and analysis are available in the form of a single Jupyter notebook (http://jupyter.org/).

Data are available in the figshare repository with DOI: 10.6084/m9.figshare.5492443.v1 under the Apache License 2.0

Twitter raw data cannot be shared due to Twitter's Developer Agreement and Policy: https://developer.twitter.com/en/developer-terms/agreement-and-policy

===


The first file contains the lists. This includes the id, the full name, the number of the members, the owner_id, the subscriber's count, and info about the user (id, followers_count, statuses_count, description, friends_count, zone

The number os all lists are 2530 and 408 that were duplicates

The second file has all the lists'members. This includes the id,date,user_id and list_id. The total entries are 144296 with 40563 dublicates. The  lists that correspond to this memberships are 1899. So there are 2530-1899 = 631 lists in teh lists file that do not have any members. 


=================
1. Explore Facebook filter bubbles for political polarization or for certain extreme situations, such as refugee crises, disasters, etc. (could also be for Twitter, maybe)

2. Classify communal posts according get to informativeness, helpfulness, for the greater good

3. User involvement and exposure to new movements or ideas, informativeness, diversity and how that can be implemented 

4. Sustainability as outreach for followers in business and politics, speed, dispersion, diversity of users, etc. study of Twitter and Facebook 

Datasets here: https://dataverse.harvard.edu/dataverse/facebook
(need to check if aggregate data are useful)

Also, parent directory has 10000s of datasets 


Datasets also here: 

https://snap.stanford.edu/data/
http://socialcomputing.asu.edu/pages/datasets
https://www.yelp.com/dataset_challenge

Dataset links:
http://www.kdnuggets.com/datasets/government-local-public.html
http://www.kdnuggets.com/datasets/api-hub-marketplace-platform.html

---------------------
Try to predict who will be the next user that a user follows in twitter. We can extract network properties per user. Then we can train a ML algorithm with these properties and build a model that can predict the next follower. This can help to (1) model the evolution of the network (2) build a recommendation system. 

Plot the social network graph of twitter with a new layout that will take into account the time creation of the links. If we plot this we may be able to picture the "evolution arrow" of twitter. Or else to show the general tendency of new following relationships. The hypothesis is: Does twitter has a constant rate of new edges? If not how can we model it?

Find users that always "follow back" according to the social network evolution data that we have collected. Then make an account and follow these users. Do they follow us back? Post fake spam links to a fake spam url that we will create. Measure the clickthrough rate. Maybe add fake products and allow users to make fake purchases. How much did we earn?

Can we predict location / language from network properties? (Probably already done but as with @spam paper, we can do it easier with simples metrics / data)

==============

instagram acces token 6101890146.1677ed0.3621d9a468254656bfbb6e3ad18876ea
================

cgale ta users_id apo to TwitterLists dataste kai apo to dataset twn eklogwn . Ta 8elei o poluvios gai na katevasei ta followers/ RT graphs 

isws an vgaloume ta followers retweets graphs ??clusters kai mporoume na sugkrinoume ta graphs me ta graphs pou exoume vgalei hdh   

============

More Efficient Secure Outsourcing Methods for
Bilinear Maps ?

especially Tian et al.’s [20]:. Compared to the state of the art algorithms (especially Tian
et al.’s [20] - Tian, H., Zhang, F., Ren, K.: Secure bilinear pairing outsourcing made mo)
, our algorithms need less offline computations, less memory, and less queries to the servers

How do yo manage ? . In order to manage that, different from the previous
studies, we use negation of an input value (it is almost for free since it is located
over the elliptic curve), and we also send the same checking computation to both
servers.


----------
Revisiting Two-hop Distance-Bounding Protocols: Are you really close enough?
Nektaria Kaloudi and Aikaterini Mitrokotsa




====================================


in the of health related devices - data is increadibly sensitive and hard to be provided to researhc . how is the scientific commiunity plannig t build a bridgefor providing these dat 

it more crycial i guess more tahn any wehre else. Are there any initaitives for allowing the usage of these adta ?How easy is it?


do you condider any kind of side channel atatcks?

performace of block eneration process


=================

how are the data sharedin thes two part of executions?

how many cors have you tried this? how does it scale ?
supervid

template attack VERYFY  PIN superviseed classigfication , which method?

how doe you measure the correleation in CPA AES
 ============================
poluvios: an efarmozame auto pou kaname twra stis listes se politikous kai vlepame an uparxei clustering antistoixo kai stous folowers\twitter users ?
======8a to suzjhthsoume perissotero 

https://github.com/LevPasha/Instagram-API-python: 

git clone https://github.com/LevPasha/Instagram-API-python.git

cd Instagram-API-python

ANTI gia 
pip install -r requirements.txt 
python3 -m pip install -r  requirements.txt 

python3 test.py

      python3 test.py 
      Imageio: 'ffmpeg-osx-v3.2.4' was not found on your computer; downloading it now.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Traceback (most recent call last):
        File "test.py", line 7, in <module>
          imageio.plugins.ffmpeg.download()
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/plugins/ffmpeg.py", line 55, in download
          get_remote_file('ffmpeg/' + FNAME_PER_PLATFORM[plat])
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/core/fetching.py", line 121, in get_remote_file
          _fetch_file(url, filename)
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/core/fetching.py", line 177, in _fetch_file
          os.path.basename(file_name))
      OSError: Unable to download 'ffmpeg-osx-v3.2.4'. Perhaps there is a no internet connection? If there is, please report this problem.
      despoina:Instagram-API-python antonakd$ python3 test.py 
      Imageio: 'ffmpeg-osx-v3.2.4' was not found on your computer; downloading it now.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Error while fetching file: <urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:748)>.
      Traceback (most recent call last):
        File "test.py", line 7, in <module>
          imageio.plugins.ffmpeg.download()
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/plugins/ffmpeg.py", line 55, in download
          get_remote_file('ffmpeg/' + FNAME_PER_PLATFORM[plat])
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/core/fetching.py", line 121, in get_remote_file
          _fetch_file(url, filename)
        File "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/imageio/core/fetching.py", line 177, in _fetch_file
          os.path.basename(file_name))
      OSError: Unable to download 'ffmpeg-osx-v3.2.4'. Perhaps there is a no internet connection? If there is, please report this problem.
      despoina:Instagram-API-python antonakd$ vim test1.py 

FROM https://stackoverflow.com/questions/27835619/urllib-and-ssl-certificate-verify-failed-error
just browse to Directly run /Applications/Python\ 3.6/Install\ Certificates.command solve my problem on OSX. 

and run Install Certificates.command

KAI TAN TAN ftanoume sto idio problham me to aplo diko mas script : AttributeError: 'InstagramAPI' object has no attribute 'login'!!!





==< conda install anaconda=4.1.1
conda install python=3.6
python3.6
pip install python-instagram
python3.6 -m  pip install python-instagram

    File "<stdin>", line 1, in <module>
  AttributeError: 'InstagramAPI' object has no attribute 'login'

  ==> python3.6 -m pip install scrapy --upgrade

python3.6 -m pip install pystan
python3.6 setup.py install

python3.6 -m pip install --upgrade setuptools
python3.6 -m pip install ez_setup
python3.6 -m pip install unroll
python3.6 -m 
python3.6 -m 
python3.6 -m pip install mysqlclient
=====================================
21/9 

σχετικα με το Instagram που ανέφερε χτες ο Σωτηρης, 

εριξα μια ματία αν υπαρχει API και τι studies εχουν γίνει. 
Λοιπον 

 Υπάρχει API
      CLIENT STATUS RATE LIMIT
      Sandbox 500 / hour
      Live  5000 / hour

      Still pending my request...
Σχετικά studies
google scholar: 
    1)Cited by 190:    What We Instagram:  A First Analysis of Instagram Photo Content and User Types
      Yuheng Hu Lydia Manikonda Subbarao Kambhampati - qualitative and quantitative analysis on
      Instagram -  identify the different types of
      active users on Instagram using clustering
    2) Cited by 143: Zooming into an Instagram City: Reading the local through social media
  ".. Next, we compare the visual signatures of 13 different global cities using 2.3 million Instagram photos from these cities. Finally, we use spatio–temporal visualizations of over 200,000 Instagram photos uploaded in Tel Aviv, Israel over three months to show how they can offer social, cultural and political insights about people’s activities in particular locations and time periods...."
    3)Cited by 116: Faces engage us: photos with faces attract more likes and comments on Instagram
      We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors,
      likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to
      receive comments, even after controlling for social network reach and activity.

    SPAM/followers campaigns ?    
    Same techniques as Twitter? Hijacking hashtags ?
        https://blog.markgrowth.com/top-instagram-bots-for-gaining-followers-79a1ccd081b3  
        https://www.instagram.com/instagress_follower18/
 Using third-party apps ?
    https://instalex.pro/article/instagram-followers             
    
    Βεβαια υπαρχουν ηδη studies και για αυτο: http://ieeexplore.ieee.org/abstract/document/7920623/
    https://scholar.google.gr/scholar?q=instagram+spam+hashtags&btnG=&hl=en&as_sdt=0%2C5
Network analysis :  epishs vrika mia douleia a large-scale quantitative analysis opou μετρανε homophily, reciprocity,  Clustering Coefficient
Analyzing User Activities, Demographics, Social Network Structure and User-Generated Content on Instagram

20 September
=============
aristero cluster 
2194605741 ==> Τσαντίλας @vasilis_tag
147159572 => @eLeNa_KiiiΚοκορόμυαλη @eLeNa_Kiii
2330406834 => @MosaicPiece

mikro dexi cluster https://twitter.com/@cstaikouras 84853888 => @cstaikouras
540179903 => @MakisVoridis
22310233 => @EVenizelos
334602996 => @atsipras
https://twitter.com/@nikospappas16

katw mikro cluster 
258729654 => @iefimerida
186060772 => @Kathimerini_gr
250058740 => @amna_news
231807647 => @tovimagr
18934391 => @naftemporikigr


akomh pio mikro cluster 
256655573 = https://twitter.com/mignatiou
289527193 => @KostasVaxevanis
https://twitter.com/@SiaKossioni
26315349 => @tsapanidou
327267369 => @NChatzinikolaou

kai o ywriarhs katw
1652541 => @Reuters
51241574 => @AP
5402612 => @BBCBreaking


19 September

http://observer.com/2017/01/spear-phishing-twitter-machine-learning/ spearphishing on twitter ?
---------

0) ena plot me to plh8os twn listwn ? Plot sta member ..einai power ?
 ποια η πιθανοτητα να βρεις λιστα με 10^2 Members ==> 10^-3 cdf (slide )

 ccdf poia h pi8anothta na vreis mia lista me megelos 10^-2 kai MEGALUTERH (eforson einai CCDF )

 an einai power law tote to a einai 2.5 

 ma8hmatika den mporej na sou pei an einia power law h oxi . apla kanei kapoio comparison me kapoiew sunarthseis 

 Compare power_law , exponential: (12.36423519664454, 0.15895533321530197)
Compare power_law , lognormal (-3.478126149463928, 0.097083800625743927)
Compare exponential , lognormal (-15.842361346108447, 0.020856431099269036)



1)sto slide 8 to Edge: user_a has list_a, user_b has list_b. JD(list_a, list_b) < 0.9
to has ti nhmainei ? einai membership ? Nai einai ownership  an einai membership den xeroume an exei nohma (?) auto to plot. 
isws na prepei na doume edge metaxu duo komvwn an anhkoume kai oi duo xrhstes sthn idia lista . 
==========
O xrhsths A exei th lista B kai th lista C
o xrhsths D exei th lista E
oi listes B,E exoun JD 0.8
oi listes E,D exoun JD 0.3

opote exoume duo links meta3u A kai D



2)To biderectionality ti deixnei sta plots?  giati den eiani to idio xrwma kai stis duo katu8unseis? 

--> edge and anhkoume kai oi duo sthn idia lista membership 
===============
O grafos den einai directed
kata la8os mpikan belakia


3) posoi tritoi mas akolou8oun ??

4) bot discovery . Posoi mas exoun xarakthrisei san bot. 
Posoi yhfizoun oti o xrhsths A einai bot . 

@Perfect_Niomode does not exist

5) oi listes gia mikra JD oi titloi tous na einai  to idio accross language 8a mas dwsei "metafrash". Na 
gia jd < 0.5 na doume ta onomata twn listwn an semantic correlation 
extract automata keywords. 

6) na steilw ston poluvio mia lista apo id xrhstwn (apo to dataset twn eklogwn) gai na doume na katevasoume tis listes tous 

7) instagram api ?

 Uparxei API : rates 500/hour? :

      CLIENT STATUS RATE LIMIT
      Sandbox 500 / hour
      Live  5000 / hour

      Still pending my request...

google scholar: 
    1)Cited by 190:    What We Instagram:  A First Analysis of Instagram Photo Content and User Types
      Yuheng Hu Lydia Manikonda Subbarao Kambhampati - qualitative and quantitative analysis on
      Instagram -  identify the different types of
      active users on Instagram using clustering
    2) Cited by 143: Zooming into an Instagram City: Reading the local through social media
      terface and the ways this interface and the application’s tools structure users’ understanding and use of the “Instagram medium.” Next, we compare the visual signatures of 13 different global cities using 2.3 million Instagram photos from these cities. Finally, we use spatio–temporal visualizations of over 200,000 Instagram photos uploaded in Tel Aviv, Israel over three months to show how they can offer social, cultural and political insights about people’s activities in particular locations and time periods.
    3)Cited by 116: Faces engage us: photos with faces attract more likes and comments on Instagram
      We use a corpus of 1 million Instagram images and organize our study around two social engagement feedback factors,
      likes and comments. Our results show that photos with faces are 38% more likely to receive likes and 32% more likely to
      receive comments, even after controlling for social network reach and activity.


    SPAM/followers campaigns ?
    
    Same techniques as Twitter? Hijacking hashtags ?

        https://blog.markgrowth.com/top-instagram-bots-for-gaining-followers-79a1ccd081b3  
        https://www.instagram.com/instagress_follower18/

        /Users/antonakd/Desktop/instagram_followers.png
    Using third-party apps ?
      https://www.blackhatworld.com/seo/instagram-disallowing-copy-followers-on-3rd-party-apps.847777/
              /Users/antonakd/Desktop/third_party.png

    https://instalex.pro/article/instagram-followers     
    
    alla uparxoun hdh studies : http://ieeexplore.ieee.org/abstract/document/7920623/
    https://scholar.google.gr/scholar?q=instagram+spam+hashtags&btnG=&hl=en&as_sdt=0%2C5     


-----------------
Parsing Twitter Lists

H clique tou bhmatos
32949753 --> @tovimagr/blogs
:"@tovimagr/tovimagr","id":44021424,
"@tovimagr/society","id":32950702
@tovimagr/culture","id":32951637
"@tovimagr/tovima","id":44021854
@tovimagr/tovimagr","id":44021424
"full_name":"@tovimagr/sports","id":32951653
"@tovimagr/world","id":32950644
@tovimagr/blogs","id":32949753,
"@tovimagr/finance","id":32949218
@tovimagr/science","id":32947968,
@tovimagr/politics","id":32947749,

Mi allh clika 

"@Pandaguru/artists","id":41859306,
@Pandaguru/kind-souls","id":41859267,
@Pandaguru/pandafavs","id":41859249
@Pandaguru/cat-lovers","id":41859291,
"@Pandaguru/warriorpoets","id":41859263
kok

allh klika 
@pirenecess/rdyhrth","id":46383689
"@pirenecess/beliebers","id":46383425
"@pirenecess/teambiebs","id":46383414,
kok



to dexi lcc : 
"@apostolosa62/vip","id":215203378 (aytos exei alles 6 listes)
@CharmingAssh0le/list","id":227032667 (alles 3)

14 September 
======================
  polyvios:# 8α ειχε νοημα να κανουμε Jaccard μεταξυ των user id ana λιστα γαι να δουμε κατα ποσο οι λιστες εχουν κοινους χρηστες -->apply_jaccard_distance_to_lists()


--> despoina: exoume ena dict me ana duo sunduasmous olwn twn listwn, kai ena set me tous KOINOUS metaxu twn listwn autwn, xthstes.

p.x (865107383881781248, 199719286): set([2737841607, 
, 482265939, 593999061, 282105495, 329051647]) 

Oi listes 865107383881781248 kai 199719286 exoun koinous xrhtes tous 2737841607, 174205897, 482265939, 593999061, 282105495, 329051647]


H 865107383881781248 einai h  @MarMcGyver/list  name":"Προφιτερόλ"," kai exei members thn nyxta_stasoy(2737841607) thn chrysamyra 174205897 ktl



kai h 199719286 einai h  {" description":"Συντομα κοντα σας...", name":"@hellmaker77/list1",  name":"ΣΑΗΜΠΕΡ ΜΠΟΥΛΙΝΓΚ"," exei members epishs nyxta_stasoy(2737841607) thn chrysamyra 174205897 ktl





  gia na doume an duo listew exei koinous xrhstes , 
  depsoina:οποτε τα sets μας να ειναι user_ids, ana duo listes -tries - tesseris listes???

  https://github.com/polyvios/el-wiktionary-parser



September 2013 
January 2014 1o 
September 2014 barca
January 2015 2o 
September 2015 cuprus
January 2016 pregnancy
September 2016 3o 
January 2017 4o 

September 2017 5o 
January 2018  6o
September 2018 7o 
January 8o 


HPC=============
WeC44SS42gArxT3dg

R4774372

In parallel computing, Amdahl's law is mainly used to predict the theoretical maximum speedup for program processing using multiple processors. It is named after Gene Amdahl, a computer architect from IBM and the Amdahl Corporation. This term is also known as Amdahl's argument.
What is Amdahl's Law? - Definition from Techopedia
https://www.techopedia.com/definition/17035/amdahls-law

https://en.wikipedia.org/wiki/Julia_(programming_language)


======
Pairnoume ta tweets
Gia ka8e language kai ka8e event efarmouzoume:

STEP 1: LDA

Briskoume thematic clusters (or else topics)
Apo to LDA pairnoume tis le3eis pou anoikoun sto idio topic me to issue. p.x. pairnoume to issue "Economy", se poio topic anoikei? Poies alles le3eis uparxoun se auto to topic?


STEP 2: Word Embeddings through Deep Learning

Me ta word embeddings gia ka8e le3h bgazoume ena vector (p.x. Merkel --> <0, 0.5, 0.45, 0.9, 0.1>)
Auto to vector (<0, 0.5 , 0.45 , 0.9 , 0.1>) deixnei poso "konta" einai h le3h (Merkel) me alles le3eis. Ka8e 8esh ston vector einai kai mia le3h.
Le3hs oi opoies einai conceptual close, ta vectors tous, exoun mikres apostaseis.
Opote mporoume na metrhsoume to "semantic distance" meta3y le3ewn.
Apo ta Word Embeddings pairnoume tis le3eis twn opoion ta vectors einai pio konta stis le3eis pou brikame apo to STEP 1. ('h to anti8eto paitame le3eis pou anoikoun men sto idio topic alla exoun megales apostaseis).
Gia ka8e issue (Economy, Education, Corruption, ...):
Apo ta STEP 1 kai 2 gia auto to issue (p.x. economy) exoume mia sullogh apo le3eis pou sxetizontai me auto to issue (Language agnostic!)
STEP 3. Bres ola ta tweets pou exoun tis le3eis pou sxetizontai me auto to issue.
STEP 4. Xwrise ta tweets pou sxetizontai me auto to issue se duo set: TRAIN, TEST
Twra exeis ena dataset to opoio exei ola ta tweets kai me poia issues sxetizontai Dld kati san
Tweet 1: <Issue 1, Issue 2>
Tweet 2: <Issue 1, Issue 3> 
AUTO EINAI TO TRAIN
Exeis epipleon kai TEST data, opote mporoume na efarmosoume classification. O classification algori8mos mas 8a einai "tweet2vec" o opoios briskei Character Embeddings (des parakatw) 
STEP 5: Efarmose Character Embedding through Deep Learning
Enw me ta word Embeddings exoume mapping apo le3eis se vectors (p.x. Merkel --> <0, 0.5, 0.45, 0.9, 0.1>) me to character Embedding exoume mapping meta3u TWEET kai vectors. 
Dld exoume kati se stul: "I voted XYZ" --> <0.3 , 0.75 , 0.2 , 0.6>
Ta classes mas omws einai issues. Opote to vector space apoteleitai apo issues. Opote to <0.5, 0.45, 0.9, 0.1> sumainei: Economy: 0.5, Education: 0.45, Corruption" 0.9, ...
Dhladh gia ka8e tweet 3eroume "poso" exei na kaneis me oikonomia, corruption ktl.
To pio shmantiko einai oti den kaname KANENA assumption gia th glwssa! (aplws tou dwsame mia lista apo issues se diafores glwsses)
STEP 6. Perform post-analysis:
Sugkrine apotelesmata meta3u xwrwn, electoral events ktl.
P.x. Poso shmantikh einai h anergeia sthn Ellada se sxesh me thn Agglia? ktl..

------------


AnEIPRO aneipero internet problem : 

home/despoina/e1000

make clean
make 
make install

restrt
=====================
/ete/inti.d/networing strat 
ifconfig eth0 up

3 items failed to upload
Failed to upload
IMG_3315.JPG
Failed to upload
IMG_6193.JPG
Failed to upload
IMG_6159.JPG

2 items failed to upload
Failed to upload
IMG_0833.JPG
Failed to upload
IMG_0657.JPG

0031 68 58 01 852
8/81 item failed to upload
Failed to upload
IMG_2739.JPG

IMG_0240.JPG
Failed to upload
IMG_0384.JPG

12 items uploaded
1 item failed to upload
Failed to upload
IMG_0713.JPG

https://www.youtube.com/watch?v=IgSuFYamZas&list=PLkkuNyzb8LmxFutYuPA7B4oiMn6cjD6Rs
gpu train on deep learning 
7/8/17

amazon: ___photos from camera to amazon 2: 2013 - 4582 items - uploading now

IMG_2433.MOVFailed to upload

 103 28 18 46  81846
=================
1) keras.io 

  download from https://pypi.python.org/pypi/Keras
   python setup.py build
   python setup.py install

   ImportError: No module named tensorflow
   pip install tensorflow
   ImportError: cannot import name np_utils
   pip install np_utils

  epimenei 
   ImportError: No module named tensorflow

  https://github.com/tensorflow/tensorflow/issues/647
   pip install virtualenv
   conda create --name=tensorflow_env python=2.7
   source activate tensorenv
  $ pip install --upgrade https://storage.googleapis.com/tensorflow/mac/cpu/tensorflow-1.2.1-py2-none-any.whl (apo edw https://www.tensorflow.org/install/install_mac#the_url_of_the_tensorflow_python_package kai edw https://www.tensorflow.org/install/install_mac)

  --->By default, Keras will use TensorFlow as its tensor manipulation library. Follow these instructions to configure the Keras backend.


2)http://deeplearning.net/tutorial/deeplearning.pdf
=================


Poster womEncourage
The preferred poster size is AO: 32.7 x 45.4 inches 83.0 x 115.4 cm

1. LDA. Mporoume na baloume REAL-TIME topic analysis sto dashboard pou exei ftia3ei? Emeis exoume empeiria apo LDA
2. Mporoume na to “poulisoume” ws language agnostic method for Twitter analysis?dld na to efarmosoume se alles glwsses?
Kai kuriws gia ta elections tou 2017? Exoume hdh katebasei ta tweets gia tis ollandikes ekloges (~50.000)
3. Kwdika wste na kanoume contribute. 
4. Genikotera na kanoume draft ena paper apo twra
5. Sarcasm detection. Prepei na ginei train ena model gia sarcasm detection: Na paroume p.x. 2000 tweets kai na ta kanoume flag ws sarcasm/non-sarcam. meta na paroume ooooola auta ta features pou perigrafei autos sto pdf kai na ta peta3oume se enan classifier. kai meta na tou petame tweet kia na ms pei an einai sarcastic h’ oxi. genikotera sentiment analysis xwris sarcasm detection den exei nohma
########

Foundation for Research and Technology - Hellas (FORTH)
Institute of Computer Science
N. Plastira 100
Vassilika Vouton, GR-700 13 Heraklion, Crete, Greece

EL 090101655
##############
trimelhs τριμελης τριμελής επιτροπή διδακτορικού
  3/11/15
kyria  Antonakaki,
 
Apo thn Epitroph Metaptyxiakwn Spoydwn (GSES 10/3/2015) egkrithke h aithsh sas gia thn  sygkrothsh ths Trimeloys Symboyleytikhs  Epitrophs gia thn epiblepsh ths didaktorikhs sas diatrivhs (attached sxetiko eggrafo).
 
Sth diathesi sas gia otidhpote symplhrwmatiko.
 
apo th grammateia
e.kosma


https://mail.google.com/mail/u/0/#search/%CF%84%CF%81%CE%B9%CE%BC%CE%B5%CE%BB%CE%B7%CF%82/14c07d25397bd1b6?compose=15d5587215846dc2

Προς: κα.  Αντωνακάκη Δέσποινα
            Διδακτορική Φοιτήτρια
           Τμήμα Επιστήμης Υπολογιστών




Με απόφαση της Γενικής Συνέλευσης με Ειδική Μεταπτυχιακή Σύνθεση του Τμήματος Επιστήμης Υπολογιστών του Πανεπιστημίου Κρήτης, στις 10/3/2015, μετά από εισήγηση της Συντονιστικής Επιτροπής Μεταπτυχιακών Σπουδών, ορίσθηκε η παρακάτω τριμελής συμβουλευτική επιτροπή για την εκπόνηση της Διδακτορική σας Διατριβής:


1.  Ε. Μαρκάτος,  Καθηγητής,  Τμήμα Επιστήμης Υπολογιστών, Επιβλέπων
2.  Π. Φραγκοπούλου, Καθηγήτρια,Τμήμα Μηχανικών Πληροφορικής, ΤΕΙ Κρήτης, Μέλος
3.  Σ. Ιωαννίδης, Ερευνητής , Ινστιτούτο Πληροφορικής, ITE, Μέλος






            Αντώνης Αργυρός
            Διευθυντής Μεταπτυχιακών Σπουδών 
Τμήμα  Επιστήμης Υπολογιστών

  ------------------

  polyvios:# 8α ειχε νοημα να κανουμε Jaccardμεταξυ των user id ana λιστα γαι να δουμε κατα ποσο οι λιστες εχουν κοινους χρηστες 

  gia na doume an duo listew exei koinous xrhstes , 
  depsoina:οποτε τα sets μας να ειναι user_ids, ana duo listes -tries - tesseris listes???

  https://github.com/polyvios/el-wiktionary-parser

---------------------------
https://www.hatebase.org/request_api/antonakd: 

Request an API key
API key Queries Daily limit
8faacf4fa87b7e6b50a275b7e4e64ed4  0 100

------------------
Hate speech lexicon: 
https://arxiv.org/pdf/1703.04009.pdf  "...We begin with a hate speech lexicon containing words and
phrases identified by internet users as hate speech, compiled by Hatebase.org."
-------
TwitterLists data

lists.json: 
listmembers.json: pollales anafores(mia ana grammh) enos user_id shmainei h summetoxh tou xrhsth sthn sugkekrimenh lista. Oxi aparaithta ownership. To ownership fainetai sto lists.json. 

Enas xrhsths mporei profanws na einai melos se polles listes. 
Mia lista mporei na exei melh pollous xrhstes .: N-N

opote to parse pernei arxika oles tis listes enos xrhsth kai gia autes tis listes 
#Pare mono tous xrhstes pou anoikoun (pou kapoioi alloi xrhstes tous exoun valei se) panw apo mia lista
  #olous tous sunduasmous ana duo twn xrhstwn 
------------------------


forologikh
2015 32155,62
2014 31482,32
2013 26887

συναντηση Βιβή ΠΟλύβιος Πεμπτη 29 Ιουνιου 

--------
ΠΟλυβιος εχει dataset on user lists Twitter: 
tasks: take a look at the data .
exoume ta keywords apo duo phges . 
na efarmosoume javaquard distance metaxu twn listwn  . (gia na petaxoume ton 8oruvo, na valoume ena hyhlo threshold)

----------------
similarity metaxu listwn -->> isuxei? einai similarity metaxu keywords?

an ta keywords na einai ta entities kai na doume to entity graph


na knaoume isws gai sugkekrimena topics

p.x commercial "great product"  


?na yaxoume aposkleistika gia hate speech : wictionary ==> prosvlhtikes lexeis?

fake news?clickbait. clickfunnel. 
ti einia fake news?





--------------------



na kanoume mia ereuna gia Disseminate rumors and conspiracy theories (Bessi et al. 2015). 
fake news detection  

twitter lists ? gia kathgoripoihsh twn tweets ..isws na pareis mia gia language agnostic . poio einai to language tou term ths listaa?
mine tis listes gia user clustering (einai agnostic?)  

Dutch, 
UK,
French Presidential, 
French legislative, 
Turkey referendum,
kai mas menoun oi germanikes pou einai to septembrio

exoume framework gia Language agnostic!

to opoio den exei efarmostei pote (AFAIK) se tweets

https://arxiv.org/pdf/1502.01710.pdf

https://github.com/dennybritz/deeplearning-papernotes/blob/master/notes/text-understanding-from-scratch.md

Since 2015 there is a revolution in NLP

The reason for this is that researchers foudn ways to apply deep learning methods in NLP so war there are two approaches:\

The first and more.. traditional is the word2vec : this method treats words as features Or else each data point is a word

so if our corpus contains sentences that are made from only 10 words:

then each data point is a vector that contains all zeros except 1 at the position of the word
For example:
0,0,0,1,0,0,0,0,0
0,1,0,0,0,0,,0,0

h 8esh tou 1 einai monadikh gia ka8e le3h

uparxei mia prosarmogh ths word2vec gia tweets, h tweet2vec

h opoia einai se python thn exoume egkatasthsei kai douleuei

to original publication einai gia hashtag prediction, alla mporoume na to xrhshmopoihsoume kai gia entity prdeiction
metnasteush, oikonomia ktl..


This is the original publication: https://arxiv.org/pdf/1502.01710.pdf

to kako einai oti den exoume ulopoihsh so fat se python alla kati 8a broume

To fantastiko me ta character vectors einai oti:xrhsimopoioun “convolution deep learning methods”
to convnet xrhsimopoiounbtan klassika se image analysis

CONVolution NETworkds  https://en.wikipedia.org/wiki/Convolutional_neural_network

opote anoigetai enas dromos gia naxrhsimopoihsoume to know how apo convnets se NLP

kaneis den exei kanei tpt akoma se tweets, social networks ktl kai einai poliu kalo  gia language agnostic afou sto network den to kaneis feed me le3eis alla me characters



Inline image 1







PONE-D-17-06366
Social media analysis during political turbulence
PLOS ONE

Dear Mrs Antonakaki,

Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we feel that it has merit but does not fully meet PLOS ONE’s publication criteria as it currently stands. Therefore, we invite you to submit a revised version of the manuscript that addresses the points raised during the review process.



We would appreciate receiving your revised manuscript by Jun 30 2017 11:59PM. When you are ready to submit your revision, log on to http://pone.edmgr.com/ and select the 'Submissions Needing Revision' folder to locate your manuscript file.

If you would like to make changes to your financial disclosure, please include your updated statement in your cover letter.

To enhance the reproducibility of your results, we recommend that if applicable you deposit your laboratory protocols in protocols.io, where a protocol can be assigned its own identifier (DOI) such that it can be cited independently in the future. For instructions see: http://journals.plos.org/plosone/s/submission-guidelines#loc-laboratory-protocols

Please include the following items when submitting your revised manuscript:
A rebuttal letter that responds to each point raised by the academic editor and reviewer(s). This letter should be uploaded as separate file and labeled 'Response to Reviewers'.
A marked-up copy of your manuscript that highlights changes made to the original version. This file should be uploaded as separate file and labeled 'Revised Manuscript with Track Changes'.
An unmarked version of your revised paper without tracked changes. This file should be uploaded as separate file and labeled 'Manuscript'.
We look forward to receiving your revised manuscript.

Kind regards,

Boris Podobnik
Academic Editor
PLOS ONE

Journal Requirements:

1) When submitting your revision, we need you to address these additional requirements.

Please ensure that your manuscript meets PLOS ONE's style requirements, including those for file naming. The PLOS ONE style templates can be found at
http://www.journals.plos.org/plosone/s/file?id=wjVg/PLOSOne_formatting_sample_main_body.pdf and http://www.journals.plos.org/plosone/s/file?id=ba62/PLOSOne_formatting_sample_title_authors_affiliations.pdf


[Note: HTML markup is below. Please do not edit.]

Reviewers' comments:

Reviewer's Responses to Questions

Comments to the Author

1. Is the manuscript technically sound, and do the data support the conclusions?

The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented. 

Reviewer #1: Yes

Reviewer #2: Yes
 

2. Has the statistical analysis been performed appropriately and rigorously? 

Reviewer #1: I Don't Know

Reviewer #2: Yes
 

3. Have the authors made all data underlying the findings in their manuscript fully available?

The PLOS Data policy requires authors to make all data underlying the findings described in their manuscript fully available without restriction, with rare exception (please refer to the Data Availability Statement in the manuscript PDF file). The data should be provided as part of the manuscript or its supporting information, or deposited to a public repository. For example, in addition to summary statistics, the data points behind means, medians and variance measures should be available. If there are restrictions on publicly sharing data—e.g. participant privacy or use of data from a third party—those must be specified.

Reviewer #1: Yes

Reviewer #2: Yes
 

4. Is the manuscript presented in an intelligible fashion and written in standard English?

PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.

Reviewer #1: Yes

Reviewer #2: Yes
 

5. Review Comments to the Author

Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)

Reviewer #1: Authors propose an social media analysis focusing on sentiment analysis that is regarded as crucial for valuing twitter (OSN) as data source to measure/predict public opinions. Inspired by two distinctive political events, the Green referendum and legislative election in 2015, they analysed tweets produced in certain time windows of two evens, first clarified distinct entities against referendum (or austerity), and implemented detailed sentiment and sarcasm detection based on the entity identification.

I have enjoyed reading this manuscript and understand that authors implemented comprehensive methods to enhance reliability of sentiment detection that is still in immature stage but should be improved considering the importance of social medias' impact on societal phenomena or decisions.

As for the evaluation of technical solidity (as one not involved in this filed directly), I would like to rely on editor's choice. Instead, I have few comments from wider perspective.

1) In figure 7, what is unit of sarcasm level in y axis?

2) In figure 8, what is unit of sentiment in y axis?
How can we conclude that Positive sentiment and Negative sentiment are polarised? Any examples of positive or negative words or can you show readers how you classified those words?

3) Although authors argued topic analysis is useful for deeper understanding, it is still unclear how it deepens the findings they found in this work. Can you please clarify why it complements the analysis?

4) The percentage of tweets related to sarcasm is surprisingly high. Can authors support the evaluation is robust? The results are not influenced by using other methods?

5) In figure 9, again the unit of positive and negative and can it be explained intuitively?

6) Not an expert involved in this field, it is difficult to evaluate the propriety of each method used in sections.
Can authors briefly explain the context to choose the methods rather than simply describing weakness and improved points made?

minors
words used in figure 11 and 12
-- Debt and Freedom are entities or words people used a lot?

Reviewer #2: The analyzes are correct and the conclusions are consistent. But perhaps the type of analysis is too poor. I come from a tradition of more qualitative analysis, so that this kind of quantitative discourse analysis, recognizing its interest and rigor, seems to me insufficient. Perhaps the quantitative analysis presented could be combined with a somewhat more qualitative approach , offering "real" examples of the categories resulting from the analysis. Thus, when you say "we measured the average tweets posted by \ YES" users and \ NO "users. We define as \ YES ", a user that has at least one \ YES" entity and no \ NO "entity. Similarly, we define \ NO" users accordingly ", some tweets of each type could be offered by way of example. Or similarly, when it says: "Using the trained SVM classifier, we generated \ sarcasm values" for all 130,000 original texts in our dataset. We have mapped each \ sarcasm value "to one of the following categories: \ no sarcasm" for negative values, \ sarcasm 1 "for values ​​from 0% to 20% of positive sarcasm values, \ sarcasm 2" for values ​​from 20% to 40% of positive sarcasm values, and \ sarcasm 3 "for values ​​greater than 40% of the \ sarcasm value," providing an example of each type can be illustrative of the logic and effectiveness of this method of detecting sarcasm.

Congratulations on the paper and greetings from Spain
 

6. If you would like your identity to be revealed to the authors, please include your name here (optional).

Your name and review will not be published with the manuscript. 

Reviewer #1: (No Response)

Reviewer #2: Jorge Ruiz. IESA-CSIC



[NOTE: If reviewer comments were submitted as an attachment file, they will be attached to this email and accessible via the submission site. Please log into your account, locate the manuscript record, and check for the action link "View Attachments". If this link does not appear, there are no attachment files to be viewed.]

Need assistance with your figure files?

While revising your submission, we encourage you to use PACE (the Preflight* Analysis and Conversion Engine, http://pace.apexcovantage.com/), a digital diagnostic and conversion tool for figure files. PACE helps users ensure that their figures meet PLOS requirements and that the quality of published figures will be as high as possible. To use PACE, you must first register as a user. Then, login and navigate to the UPLOAD tab, where you will find detailed instructions on how to use the tool. If you encounter any issues or have any questions when using PACE, please email us at figures@plos.org.

=============================

kri8inaki: data - mia mikrh perigafh link sta post processed dat gia na ienai poi eukola prosvasima kai tous apantame oti ienia eikei publicly available 
cc ton si kai me vash ta review tou plos 

PLOS ONE 
reviews by Jun 30 2017 11:59PM. 

Woman encourage  
Participation Scholarships applications due June 12, 2017
Notification of Participation Scholarships acceptance July 14, 2017
Notification of accepted posters  June 5, 2017
Final poster abstracts due  July 3, 2017
Poster pdf due  July 31, 2017

DELTIO AKSIOLOGHSHS gia toys DIDAKTORIKOYS FOITHTES at CSD_ PhD student evaluation form
 --> 15n  Iouniou 2017.

Facebook Grace Hopper Scholarship
Completed applications are due by Πέμπτη, 15 Ιουνίου 2017 στις 11:59 μ.μ. PST.
https://www.facebook.com/careers/program/gracehopper2017/?attachment_canonical_url=https%3A%2F%2Fwww.facebook.com%2Fcareers%2Fprogram%2Fgracehopper2017%2F
--------------------------
18 May Grace Hopper FB scholarship
How did you become interested in Computer Science? (1-2 paragraphs)
I became interested in Computer Science when I had started exploring the theory of computation and the various computational models. I got really intrigued when read the Rice΄s Theorem and Church΄s thesis, the Turing machines and the fact that there are theoretically unsolvable computational problems.

Why would Grace Hopper be an impactful experience for you? (1-2 paragraphs)
Throughout my PhD studies I had the opportunities to collaborate with a numerous and very competent groups of young researchers. From the fruitful synergy of these collaborations, I had the opportunity to learn new technologies, reshape my research hypothesis, receive tangible help on testing them and get access to additional computational resources and tools. The overall lesson from this experience is: whenever possible, seek for collaborators, discuss openly your research interests, share your current results and build reciprocal relations. The quality and impact of my research has been tremendously boosted by adhering to this philosophy. Yet, although my PhD’s organizing consortium (ITN) invested an extreme amount of effort on being extrovert and bringing scholar and established researchers together, I feel that I need to move beyond and to reach out to more enthusiasts  of my field.

Grace Hopper is a prestigious scientific event covering networking and exploring possibilities to the attendees. For these reasons I believe that it will be a beneficial and impactful experience for me.

What has been your biggest obstacle to pursuing Computer Science? How has it motivated you to pursue your future goals? (2-3 paragraphs)
Computer science lies in the edge of technological, social and scientific realms of modern world. Pursuing a career in computer science, requires the deep understanding of a multitude of technical, mathematical and practical skills. 
It is indicative that a small computer code glitch, a small underestimation of theoretical complexities of an applied algorithms, or a minor neglection of modern hardware abilities can render useless a huge and costly computer science project. 
On top of that, the norm of today may be an obscure and outdated technology of tomorrow. We often notice very promising and modern technologies to have a lifespan of less than one year.
Keeping in pace with computer science’s advancements today, it is like riding a technological roller coaster. Thrilling but challenging and sometime overwhelming. I consider this to be the hardest obstacle for a modern CS researcher. Nevertheless, being in a scientific field that is so keen to innovation with momentous effects in the society has motivated me to become adaptable, fast learner and methodologically flexible which in turn has helped me to become a better researcher.


is a prestigious scientific event covering networking and exploring possibilities to the attendees. For these reasons I believe that it will be a beneficial and impactful experience for me.

-------------------
1941 sustegazomena - piran8ou 40 2810257486

185 +  40  = 225 335 

2016?
2015 32155,62
2014 31482,32
2013 26887

* 2 May 17
fltk on mac : 

guidance from https://elearn.uoc.gr/pluginfile.php/72690/mod_resource/content/2/Assignment_3/README.OSX.txt:

1. autoconf 
2. ./configure
- autoconf

- ./configure

- make

- sudo make install



-------------csd3666  csd3772 BUFFER DUMMY
  

csd3764 csd3292
---------------
Pixeltan - Yamerarena-i



-------
σεπτ 2013
ιανουαριοσ 14 1ο 
σετπ 14 βαρκα
  ιανουα 15 2ο ---
  σεπτ 15 κυπρος
ιανουαρ 16 αδεια 
σεπτ 16 3ο 
ιανουαρ 17 4ο 
------
Stop Clickbait: Detecting and Preventing Clickbaits in Online News Media

cosn asonam
  
Security and Privacy, Usenix Security, CCS, NDSS, ACSAC, RAID


s&P '16: SoK: Towards Grounding Censorship Circumvention in Empiricism .. 
usenix : You are Who You Know and How You Behave: Attribute Inference Attacks
via Users’ Social Friends and Behaviors


1) na steiloume se kapoio kalo sunedrio itriple e ieee, igcom ? kdd mallon 
giati apla den 8a mporw na kanw defence to thesis mou xwris ena polu kalo 

Na doume pou allou (se kalo sunedrio-journal) steloun oi poloi kaloi p.x tou asonam . 
to asonam einai kalo apla mikrhs emveleis kai mono se social networks
-- > 
-- > https://scholar.google.gr/citations?view_op=top_venues&hl=en&vq=eng_datamininganalysis
Lescovec: ACM International Conference on World Wide Web (WWW), ACM International Conference on Web Search and Data Mining (WSDM (https://cs.stanford.edu/people/jure/pubs/)

isws an kaname authn thn douelia me ekloges + langiage agnostic na to stelname sto kdd?




2) epishs eipame gia thn epitroph , na doume poios mporie einai mesa. na yaxw poio ka8hghtes einai sxetikoi me auta pou kanw (ka8hghthes kai na mporoeun an peis8oun) dikaioakos? hlias? polakis? allos? poluvios?

επταμελής εξεταστική επιτροπή σύμφωνα με τον Ν3685/08, άρθρο 9.

3)epishs gia na parousiasw kai na grayw to thesis , prepei na exw ousiastika mia protash kai na thn kanw defence . Exw to x kai to apodeiknuw. 


--------

200.000 tweets dutch eelections
exoume epishs tis Gallikes (2 proedrikes + vouleutikes) exoume episs Germania kapou telos kalokairiouGerman federal election, 2017 24 September 2017 , Norwegian parliamentary election, 2017 11 September 2017

me NLP 8a prospa8hsoume na kanoume entity detection wste na doume poia topics exairontai sta tweets (p.x metanasteutiko, oikonomiko , diaplokh, eikona elladas stis xwres autes - na ginoume san thn ellada-)

Epishs 8eloumena doume ti allo paizei sta hashtags , kanontas telika mai parmoia analysi opws sthn ellada, LDA, topics, sentiment analysis , sarcasm detection ka. 

language agnostic analysis kinoumaste kuries stis megales xwres Gallia Germania kai meta xrihsimipoume tis mikres xwres gia control 

-------

an dw hashtag (deleting entries while working) merged elections and referendum an nomizoume oti prepi na vgoun exw 
mellontika 8a kanei update ta hastags oso allazoun (px sta8akis )
tsipras referendum - diduma hashtags - mporei na xa8oun kapoia hashtags . na parei na grouped hashtags akomh kian den anaferontai etsi mesa sto keimeno . p.x tsipras tsipras Tsipras τσιπρας  


estw ena entity p.x. tsipra ..kai uparxei kai sto keimeno ... o prwtos ors o perigrafikos kai o deuteros . alexis tsipra 
 ---------

astuomiko tmhma: 274 128 , 
astuomiko tmhma: 274 194 

---------
valane kai to thisisacoup  edw : https://www.dropbox.com/sh/zzdh2ooht12bf5a/AABWn2PDkB9GNcbZgC6Mf5XEa?dl=0

Gia to this is a coup opws ti eidan autoi : 
ta perisotera ienia agglika 
to perasane 2 fores ..mia gia agglika mia agglika
opote se ka8e gramh exoume : ta tria  prwta ienai gia ta ellhnika kai ta upoloipa ta agglika . otan einai ellhniko to sentiment ekfrazetai sta tria prwta kai ta agglika einia 1 -1  kai 0 ara neutral .


apo deiytera na arxisoume na grafoume  sto ggogle doc. protimoun google docs gia na mhn exoume conflicts metaxu mas .   

twra ousiastika h analush einai pio down to the point ,oxi toso quick and dity opote elpizouem oti 8a vgei kati .  


egw xrhsimoppoie ta data gia na kanw ta plot . apla apla na kanoume outputa se ena txt authn thn plhroforia pou eixame pei . 

auto pou 8eloun apo emasn einai : oxia apla plots 
tweet id  - timestamp  - entities - hashtags + sentiment . 

auto me atuo 8elei na kanei statistikh analush sumfwna me ta expected apotelemsata ths analushs. Kata poso ena hastag xrhsimopoieitai me arnhtiko sunais8hma gia ena proswpo ...kai me ti timestamp  na doume pws auta allaxane (me vash kapoia gegonota?), qai square anova kai tetaoia .... staistical analysis gia to pws to semantic kanei carryover ta hashtag kai ta proswpa . 


gia to  this is a coup den xeroume ti mporei na vgei alla estw ...


apo ta hastah tou tsipra 8a mporousame na pame pisw apo ti referendum na doume taseis ....? 

8a steile xana me ena email ....me ti akrivws zhtaei ??





 ---------------

 ti perimenei apo emena o dhmhtrhs : ekloges 

 auto pou estilame 8a exei exei alles lexeis kai alla tags . . exoune ena story sto mualo

 2 Τ περίπου - 90Μ nodes - όσο το δυνατόν περισσότερο mnhmh ..//////////////

 http://arxiv.org/pdf/1111.4570.pdf: The computations were performed on a 24-core machine with
72 GiB of memory and 1 TiB of disk space

to pio shmantiko mas problha einia h Mhnhmh ,. 

κανει το average degree
gia na metrhseis to av. degree prepei na exeis enan counter gia ka8e kombo gai ka78e mera
ara 8es: 90.000.000 users nodes (ta dika mas data) * 3000 meres (ta 9 xronia pou einai live to twitter)
sunolika exoume friends/followers apo 90.000.000 users  einai oloi oi users pou exoume kanei collect tous friends/followers


eimaste sto 10% (4 meres) peripou alla an eixame mnhmh kai den xreiazotan na to kanei ston disko 8a phgainame poluy pio grhgora
            100
meta apo polles dikes mou prospa8eies kateluxa oti o kaluteros trops einai xrhsimopoioume th snap library pou kanei polu kalo memory optimization alla den ftanei!
 sunexeia to koitame mpas kai to beltiwsoume, alla paizoume me ton xrono, den mporoume na kanoume problepsh apo oti exei ginei mexri twra
 isws na einia kai 8ema engineering kai na to teliewsw se 2-3 meres... den einaia oti to exw balei na trexei kai apla to koitaw... kanoume improvements sunexeia


eixame to 8ema me ton disko (ola ta data apo cuprus htan mesa) eutxws ta swsame alla twra epeidh ta metafera ston neo , den exe xwro ston neo disko  , opote xasame ki ekei xrono ,

---> na kanw resubmit to idio opws htan . 

ο sentiment analyser den exei 8ema me ta metadedomena . 
to json den mporoyn na to perasoyn ..
alla 8eloyme keimeno ... 

0.65  0.59 

8a vrei mexri aurio : 

poies lexeis kai me ti sentiment susxetizomntai kai poia alla terms sxetizontai me ti sunais8hma sxetizontai . auta 8a ta vrei o samaras mexri thn Trith kai egw mexri thn paraskeu 8a ulopoihsw thn idea pou exei steilei sto skaip.  

opote mexri aurio 8a dw thn analush se ekloges kai this is a coup. 

----------
exoume me to id pleon ta tweets . eipane mexri thn paraskeuh na einai etoimo to processing  kai apo thn paraskeuh kai meta na arxisoume to keimeno .  na vroume ta links metaxu twn hashtags . sentiment ana entities (proswpa ktl ) . 

---------------


sentiment analysis 

      Στο linked file θα βρεις το sentence level sentiment για το κείμενο από το πρώτο dataset που μας έδωσες: elections_round2

      https://www.dropbox.com/s/4or7okgescfv2tq/tweeterText_v1.1.txt.zip?dl=0

      Κάθε γραμμή έχει το κειμενο ενός tweet και το sentiment που έχει 2 τιμές:
      1 (not positive) to 5 (extremely positive)
      -1 (not negative) to -5 (extremely negative)

      "Why does it use two scores? Because research from psychology has revealed that we process positive and negative sentiment in parallel - hence mixed emotions.”

      Τη Δευτέρα θα είναι έτοιμο και το ίδιο αλλά ακόμα καλύτερο accuracy.
      Σημείωση: υπάρχουν γραμμές γεμάτες ορθογραφικά λάθη και κολλημένες λέξεις κλπ. Αυτές προτείνω να μην ληφθουν υπόψη γιατί δεν είναι neutral το sentiment, απλά δεν βρέθηκε καμιά σωστα γραμμένη λέξη για να αποδοθει sentiment, οπότε δινονται τιμες "1 -1" 

      Πότε μπορείς να κανoυμε ενα skype για να δουμε τα επόμενα βήματα?

------------
gia thn annarrwtikh:
§
xarti
bibliario trapezas 
tautothta
bibliario ugeuas ika

-------------
skype sentiment analysis: 


Εμείς κάνουμε assign τα tweets σε κόμματα με βάση τα hashtags. Θα ήταν καλuτερα να είχαμε και τα hastags. 
CDF sentiments per koma. 

Ο δικαιολογείται ως μεγάλη Ελληνική ομάδα δούλεψα σκληρά έπαιξα καλά αλλά φταίει η διαιτησία  3 -3
neutral/?

na trexoume thn analush gia ola ta dataset .
Apo auyto pou exei trexei 8eloume na doume overall sentiment gia ola ta tweets pou periexoun nd h onomata melwn ths nd ???
me to xeri eyaxa nd ND ΝΔ ή -5 -4 κτλ 

to 8ema ienia polla apo ta tweets einai irrelevant h eirwnika . auta sigoura den 8a eprepe na sunisferoun sto apotelesma 
------
sentiment analysis sunanthsh samaras- spiliotopoulos - 21 march 

      σημερα 8α εχοuμε το τελικο version tou sentiment
      erwthsh: mporoume na sumperilavoume to hashtag . ? mporoume na krathsoume to hashtag. . exoume valei mono elhnikes lexeis... 
      an vrei emoticon?  
      an mporoume na exagoume komma apo to keimeno ... (px kapoio  gia ton suriza na milaei eirwnika gia thn nd)

      Na xanatrexoume to keimeno kai na afhsoume ta hashtag. 
      kanoume to idio kai gia to referendum.


      NAI kai OXI ...metrame ari8m0hashats ....prpeei na exagoume kapoia plhroforia apo to keimeno . an anefere hashtag gia komma vazei kaluero context .

      election me sentiment + hashtasgs mesa ...

      kai apo aurio gia refrendum.


      o algori8mos mporei na  vgazei 8etiko arnhtiko kai neutral . mhpws na mas dinei mia timh . 
      exontas thn lexh h to hashtag  

      new exicpn 3 lexika : prosarmosmeno + wildcard 
      + merged 
      to deutero lexico eiani pio plousio .

      http://sentistrength.wlv.ac.uk/results.php?text=I+love+you+but+hate+the+current+political+climate.&submit=Detect+Sentiment&result=dual

      oi sthles pou ekfrazoun to suais8hma se ka8e tweet 

      POS1  POS2  POS3  POS4  Subjectivity1 Subjectivity2 Subjectivity3 Subjectivity4 Polarity1 Polarity2 Polarity3 Polarity4 Anger1  Anger2  Anger3  Anger4  Disgust1  Disgust2  Disgust3  Disgust4  Fear1 Fear2 Fear3 Fear4 Happiness1  Happiness2  Happiness3  Happiness4  Sadness1  Sadness2  Sadness3  Sadness4

      tetarth 12 1o oro 1o kthrio me bibiliario . 

      nerr  negative recogntion 

      tetarth xana gia skype . 10. keimeno hastgas kai posotive + negative . referendum . 

TI 8eloume 
      na doume sentiment analysis ana komma
      na doume sentiment analysis se NAI KAI OXI   

8a mporosame na vgaloume ta eirwnika kai na afhnei mono ta supportive gia ena sugkekrimeno komma ?
auto pou prepei na ginei einai na broume enan tropo na bgaloume ta troll-tweets
bazoun apisteuto 8orubo
den exei nohma na bgazeis sumperasmata apo to keimeno otan to 90% einai trolls
      8a mporousame na kanoume kapoia NLP analusi? kamia idea?

---------------------

na doume sentiment analysis ana komma
na doume sentiment analysis se NAI KAI OXI   

8a mporosame na vgaloume ta eirwnika kai na afhnei mono ta supportive gia ena sugkekrimeno komma ?
auto pou prepei na ginei einai na broume enan tropo na bgaloume ta troll-tweets, bazoun apisteuto 8orubo
den exei nohma na bgazeis sumperasmata apo to keimeno otan to 90% einai trolls
8a mporousame na kanoume kapoia NLP analusi? kamia idea? (den to eipame , htan mia skeyh pou eixa offline)

polla tweets exoun treis teleies ...einai anaktisima ? (kovei lexeis , protaseis ktl) mporoume na ta paroume apo API ...  einai polla?? 
h eirwnia kai ta troll ...einai kai gai tis 2 meries opote  As kanoume assume oti kanoun cancel out .

susxetismos sentiment me hashtags (anagwgh)

a mporousame na pros8esoume kai sentiment analysi sto lda ? .(despoina) Kane share auta ta noumera .  

Kathgoriopoihsh twn username ana topic?

(Tendencies) Fine grained analysis (slide 10) auxanontas to polarity. Epiplon qualitative analysis me sugkekrimena legomena tou politikou  . (isws sunergasia me omada voulis twn ellhnwn)
An p.x. ena tweet exei mesa ton tsipra kai ton samara ... mporei na exei positive kai megative (sumplhrwmatika  mporoume na krinoume apo ta hashtag) 

Htan xronika ta tweets ? (despoina). 
Exoume xasei ta metadedomena . Na ftiaxoume ena object ana tweet (isws kai to username na exei nohma na valoume) Poia metadedomena 8a h8ela na kratame? 
----------
koritsia skype : censorship twitter:
      Apo pilia: 
      Comparison of withheld and non-withheld tweets
      • Investigate how tweets are being chosen for being withheld
      • Graph properties, similarities and differences, clusters
      • Investigate if there are patterns in user behaviour
      • Influence of these users and propagation of tweets
      Estimate how long tweets live before being withheld
      • Investigate connections between users that have withheld tweets
      • Identify Influence of these users and propagation of tweets

      Σύγκριση των παρακρατούμενων και μη παρακράτηση tweets
      • Υπεύθυνος για το πώς tweets που επιλέγεται για να παρακρατηθεί
      • ιδιότητες Graph, ομοιότητες και διαφορές, συστάδες
      • Ερευνητής στο αν υπάρχουν μοτίβα στη συμπεριφορά των χρηστών είναι
      • Επίδραση της θες για τους χρήστες και διάδοσης των tweets

epishs auto pou xehasa  na anaferw einai oti 8a mporousa na steilw mia hdh dhmosieumenh douelia gia spam sto twitter 
Asxoloume me evolution analusis of metrics on the social graph of twitter alla auto 8a to steilw twra ton aprilio sto Asonam, den xerw kata poso erxesai se conflict me to na graftei kai poster


twra gia background work se sensorship sto twitter: 

 trends censorship 
      protest movement gains traction and media coverage, and participants, observers and critics turn to Twitter to discuss it, why are these widely-known hashtags not Trending? Why are they not Trending in the very cities where protests have occurred, including New York?
                          

political censorship
        se politikes epanastasteis diegerseis: (complete list at wiki ) se trends http://socialmediacollective.org/2011/10/19/can-an-algorithm-be-wrong/ "Can an algorithm be wrong? Twitter Trends, the specter of censorship, and our faith in the algorithms around us" 

The Twitter Revolution in the Gulf Countries:  
        Αραβική Άνοιξη (αραβικά: الربيع العربي) ονομάστηκε ένα κύμα διαδηλώσεων και διαμαρτυριών στη Μέση Ανατολή και τη Βόρεια Αφρική [1], που εκδηλώθηκε από τις 18 Δεκεμβρίου του 2010.Πριν τη συγκεκριμένη χρονική περίοδο, το Σουδάν ήταν η μόνη Αραβική χώρα που ανέτρεψε επιτυχώς δικτατορικά καθεστώτα το 1964 και το 1985. Εκδηλώθηκαν εξεγέρσεις στην Τυνησία και την Αίγυπτο, εμφύλια σύρραξη στη Λιβύη, εξεγέρσεις στο Μπαχρέιν, τη Συρία και την Υεμένη. Μεγάλες διαδηλώσεις έγιναν επίσης στην Αλγερία, το Ιράν, το Ιράκ, την Ιορδανία, το Μαρόκο και το Ομάν. Μικρότερες οργανωμένες διαμαρτυρίες έγιναν στο Τζιμπουτί, το Κουβέιτ, τον Λίβανο, τη Μαυριτανία, τη Σαουδική Αραβία, και το Σουδάν.

        Equally important has been the role of social media and digital technologies in allowing citizens within areas affected by 'the Arab Uprisings' as a means for collective activism to circumvent state-operated media channels.[342]

        Revolutions that were previously started on Facebook alone were rapidly quashed by secret police in those countries, so much so that in Egypt a prominent activist group always had "Do not use Facebook or Twitter" on the front and backs of their revolutionary material.[352]
        ------
    The main purpose of this article is to discover the new media phenomenon in the Arab world and how it has changed the nature of public discourse. Other purposes are to explore the role of Twitter in presenting Arab discourse and to explore the new censorship roles.

        According to Amin (2001), in the early 1990s, Arab regimes resisted new technologies because they saw them as a threat to the ability to control media. 

Adapting Social Spam Infrastructure for Political Censorship
        A striking example of such manipulation recently occurred on Twitter when an un- known attacker leveraged 25,860 fraudulent accounts to send 440,793 tweets in an attempt to disrupt political conversations following the announcement of Russia’s parliamentary election results.

        In this paper, we undertake an in-depth analysis of the infras- tructure and accounts that facilitated the attack

=========================
IKA :  tetarth 12 1o oro 1o kthrio me bibiliario . 

======================================
seires:
better call soul 
tv show time
lab
master of none

==========
1. Prepei na ginei to sorting. Dld na efarmosoume to heuristic kai na sortaroume ta edges analoga me to estimation tou pote dhmiourgh8hkan

2. Eixame ena disk failure. Ekei pou egrafe emfanise ena bad sector kai eprepe na antigrapsoume ta dedomena se kainourgio disko. Dedomenou oti ta dedomena einai 1T (mporei kai parapanw) auto phre ligo xrono.

3. Exoume faei kapoio xrono gia data normalization. Diladi na briskontai ola ta dedomena se ena dir me to idio format. Dedomenou to ogkou twn dedomenwn auto phre ligo xrono (basika auto akoma trexei)


4. Exw thn entupwsh oti oi xrhstes pou exoume katebasei einai panw apo to 10% twn ENERGWN xristwn. Ti ennow:
Ka8e fora pou tou lew na 3anakatebasei tou lew: "diale3e enan random xrhsth pou ekane to pio prosfato tweet se mia apo tis 15 megaluteres poleis tous kosmou"
Exw parathrhsei oti peripou sto 50% twn periptwsewn o xrhsths pou bgazei ton exoume katebasei hdh.

8a mporousame stis epanalhyeis na katevazoume ligotero dhmofileis xrhstes . h na allaxoume polh: nai.. ex8es ebala to Riant! (prwtevousa ths Saoudikhs Arabias) gia auto to logo!epishs exw balei mesa kai Rome, Paris pou den 9ewrounte twitterikes poleis!

5. Sxetika me th diametro uparxoun duo kateu8hnseis. Kai oi duo ekmetaleuontai tous celebrities.
H mia einai:
3ekina apo tous celebrities kai prospa8hse na kaneis restruct (periorizw) ton grafo anadromika, mexri na baleis oso to duynaton perissoterous xrhstes mesa. Ka8ws kaneis restruct metra to diameter
Mhn kaneis load OLO ton grafo sthn mnhmh giati auto einai adunato
apla pare mono ton grafo bazontas mesa ta celebrities
p.x. 10 celebrities ta kanoun follow 100M users


Υπάρχει και μία ιδέα η οποία βασίζεται στο γεγονός ότι γνωρίζουμε ότι ο γράφος περιέχει μερικά πολυ σημαντικά hubs, τα οποία είναι τα celebrities. Για παράδειγμα ο Justin Bieber έχει 70Μ followers όσους περίπου και ο Obama. Αν σκεφοτύμε ότι όλο το twitter έχει 650Μ χρήστες, αυτό σημαινει ότι ένα πολύ σημαντικό ποσοστό των χρηστών του twitter υπάρχει σε απόσταση 1 από celebrities. Το hypothesis είναι ότι μπορούμε να κάνουμε reconstruct όλο τον social graph ξεκινώντας από αυτούς που έχουν απόσταση 1 από celebrities, μετά αυτούς που έχουν απόσταση 2 κτλ. Ανάλογα με την κατανομή αυτών των τιμών θα μπορέσουμε να κάνουμε ένα καλό estimation του diameter σε σχετικά σύντομο χρόνο, Υπάρχουν και πολλές δημοσιευμένες εργασίες σχετικά οι οποίες θεωρούν έναν random γράφο (όχι social).

xekina apo tous celebriteis kai prospa8hse na kaneis restruct ton grafo anadromika , mexri na valeis osous perissoterous xrhtses mporeis. ka8ws kaneis resrtuct katagrafeis to diameter. Mhn kaneis load olo to grafo, auto einai adunatpn. apla pare moni ton grafo vazontas mesa olous tous celebrteis. 

Gia tous xrhstes pou den akolou8oun amesa tous celebrities (auto mono sthn periptwsh tou undirected grafou) prepei na vroume thn apostash apo tous celebrities. 1 , 2 hops?Pws ? 

H 2h einai:
Exoume to hypothesis oti to longest shortest distance DEN pairna apo celebrities
Epeidh an pernage den 8a htan longest!
Dld se ola ta koufa monopatia pou uparxoun apo ta ekatomuria edges. Kapou uparxei ena terastio monopati pou sundeei duo nodes, opou auto to monopati einai h shortest distance mneta3u autwn twn nodes. Auto to monopati einai akribws terastio epeidh DEN pairnaei apo megala hubs tous diktuoy.
Opote h idea einai:
Bgale ola ta celeberities kai olous tous followers tous. Ftia3e enan poly sparse grafo kai metra th diameter kanonika ekei mesa

Kai oi duo me8odoi lene: "to diameter mporei na ginei approximate an pareis upopsin sou ta celebrities"
H mia leei: "OLOI oi xristes exoun mikres apostaseis apo ta celebrities, opote an metrihseis autes tis apostaseis kai pareis th megaluterh tote exeis upologisei (approximated..) to diamater"
H 2h leei: "To diameter einai to longest shortest path tou grafou kai dedomenou oti ta celebrities einai hubs kai "mikrainoun tis apostaseis" tote bgalta teleiws apo tous upologismous sou, kati pou 8a kanei ton grafo polu-polu pio elafru"

Mporoume na parousiasoume ta apotelesmata apo ta duo auta approximations kai na ta sugkrinoume



6. 
Ola auta 8eloun experimentation, alla to "measurement of Twitter's diameter" is HUGE
Mhn trelenomaste me ta deadlines. To 8ema einai na prolaboume to deadline h' na bgei h uperdhmosieush kai na exoume polla citations?
Exoume kai san backup solution to average degree. (Ta review ginontai olo kai kalutero kai to ASONAM den 8a dextei mono 6(!) papers…)


o si proteinei : ka8e evdomada vgainoun poll gia diafora politika 8ema , ta mporoume na kanoume track . 
triple AI 
asonam ..satellite workshop 


Gia to referendum: ti 8eloume na kanoume ...den exei 

------------
background work: 

How Social Network is Evolving?
- A Preliminary Study on Billion-scale Twitter Network  (short paper 4 selidakia) www13
Twitter user data with
469.9 million users and 28.7 billion relationships. 
4. NETWORK ANALYSIS

4.1 Degree Distribution
4.2 Reciprocity
4.3 Degree of Separation and Diameter



δεδομένου οτι έχουμε 10 εκατομμύρια κατεβάσει απο εδω (Κύπρο) + 16 εκ. στην Κρήτη 



O(N^2). Computation of the exact diameter in main memory is very expensive 3600 M 
O Deepak Ajwani to meiwnei se The I/O complexity of external-memory BFS is Ω(N/√B) I/Os.


60Μ nodes  60 sundiasmos ana duo = 60!/2!(60-2)!  swsta? = 8.3209871e+81  /2(2.3505613e+78  = 8.3209871e+81 /4.7011227e+78  = 1769.9999832 M 


About network evolution
--------------------------------

Although we have many rejections we are approaching our goal. We are getting there!
The purpose is to write a high profile paper!

The comments are getting better and better every time.

The last comment was that average degree is not enough to describe the evolution of Twitter we need other metrics as well.
Towards this we have to incorporate the diameter.
All rejection comments (from all 3 papers) are commenting about the lack of celebriteis on our dataset and they don't like our sampling technique. For this reason we have to throw this dataset out!

The dataset that wew are collecting now does not have this problem: The sampling technique is correct (random walk) and is sufficient large (~90M nodes).

Right now we habve collected 70M nodes. It is difficult to estimate the number of edges but I guess is many billions.
For this reasons I suggest to repeat the analysis we the average node degree, fit the leskovec model (we already have code/methods to do that, plus it does not require large computational resources).

Plus we have to do the diameter. Towards this we have to apply various heuristics since it is computatinally impossible to perform exact measurements. the heuristic that we apply now has to do with the fact that celebrities are a major hub of the network. Hence we can measure the distance from a user to another user be meaasuring their distance from a celebrity. 



About dimopsifisma
------------------------------
I think we can build a technique to predict election results based on the techniques of Exit poles. That is fidn a subset of twitter users that are predictive of the election results. The same as exit poles. https://en.wikipedia.org/wiki/Exit_poll-------------------

---------------------------



MIlan isocial issues 
----------

2nd secondment reports (by 1st of september)

progress reports by february 29

newsletter march 31

after project  career development plan . by sept 1

online courses kth & UB 


* Synanthsh Marios Dikaiakos Giorgos Palis xarhs 


Hfomertia 
antidrash enterpreneurs se sugkekrimenes eidhseis. 8etika h arnhtika (exei sxesh me to hate tweet - alla oxi akrivws)

kai peripou afora sentiment anaylisi h alliws sta ellhnika υφομετρια (οπως του το ορισε μια γλωσολογοα που μιλησαν)
μια παραλληλη ιδεα που ισως να κολλαει ειναι  βλεπουμε προσφατα νεα- eidhseis και πως ανιδραει ο χρηστης (enterprenuers) σε αυτο;θετικα αρνητικα με σαρκασμο;το ηφος εχει. και ισωσ και απο το ηφος να μπορουμε να κανουμε κατηγπριοποιηση των  enterprenures?

αντγραφουν σε διαφορετικο ηφος stis  eidhseis?antidroun me sarkasmo?arnitika ? 8etika


 references by me : Το ερευνητικό του έργο εντοπίζεται στους χώρους της υπολογιστικής γλωσσολογίας και της ποσοτικής επεξεργασίας γλωσσικών δεδομένων με έμφαση στην υφομετρία και την αυτόματη αναγνώριση συγγραφέα http://www.ill.uoa.gr/an8ropino-dynamiko/melh-dep-kai-biografika/biografiko-g-mikroy.html (xmm :In 1992 he joined Institute for Language and Speech Processing (ILSP) and in 1996-1998 he was head of the Institute's Liaison Office.)

======================

abstract. (for presentation at ucy)

Analysis of evolution, dynamics and vulnernabilities of OSNs


Twitter is a popular microblogging social platform, established on 2006 and as of today has reached 645 million registered users where half of them are monthly active. Except from ordinary individual users, Twitter is utilized from news agents, public figures, and organizations to disseminate their activity and engage in discussion with other users. One of the factors contributing to this success is the inherent property of the platform for spreading news --encapsulated in short messages that are tweeted from one user to another -- across the globe. 

The research community has focused several studies on Twitter, covering a wide spectrum of experiments. The first study we conducted was focused on the exploitation of trending topics towards spam dissemination. We analyzed a large collection of tweets and explore the dynamics of popular trends and other Twitter features in regards to deliberate misuse. A specific class of trend-exploiting campaigns was identified that exhibits a stealthy behavior and hides spam URLs within Google search-result links. We build a spam classifier for both users and tweets, and demonstrate its simplicity and efficiency. Finally, we visualize these spam campaigns and reveal their inner structure. [Antonakaki et al, SocInfo 2014]

Our second study was focused on the analysis of the social graph of Twitter. The online activity and the dynamics of the social graph of Twitter are considered to be indicative of the tendencies of the off-line social life and reflect the preferences of the public in general [Java A. et al, WebKDD/SNA-KDD '07]. We propose a sampling framework that allows the estimation of graph properties on large social networks. We apply this framework to a subset of Twitter’s social network that has 13.2 million users, 8.3 billion edges and covers the complete Twitter timeline (from April 2006
to January 2015). We derive estimation on the time evolution of 24 graph properties many of which have never been measured on large social networks. We further discuss how these estimations shed more light on the inner structure and growth dynamics of Twitter’s social network.


For these reasons the structure and properties of the social graph of Twitter has been the subject of numerous studies that seek to model and sometimes predict the behaviour of users as well as how this behaviour affects the growth dynamics of the graph.


On a smaller study we used the usage of Twitter by Greek users in order to measured the occurrence of certain hashtags affiliated with specific political parties. Based on these measurements we took the chance to attempt some predictions!



 Today, it is sufficient to just inspect the trending topics
in Twitter for figuring out what is happening around the world.  Unfortunately,
the capabilities of the platform can be also abused and exploited for
distributing illicit content or boosting false information, and
the consequences of such actions can be \emph{really} severe: one false tweet was enough for
making the stock-market crash for a short period of time in 2013.
%One contributing factor to this success are hashtags that allow the conceptual indexing of tweets.

In this paper, we analyze a large collection of tweets and explore the dynamics of
popular trends and other Twitter features in regards to deliberate misuse.  We
identify a specific class of trend-exploiting campaigns that exhibits a
stealthy behavior and hides spam URLs within Google search-result links.  We
build a spam classifier for both users and tweets, and demonstrate its
simplicity and efficiency. Finally, we visualize these spam campaigns and
reveal their inner structure.


short bio : 

 I finished my Bachelor at the Computer Science Department of the University of Crete. I obtained my MSc in Biomedical Computing & Technology at the University of Crete & BMI of ICS -FORTH at Heraklion, Greece on April 2006, with title «Text Mining in the BioMedical Domain: Biomedical literature categorisation, Document Clustering and Genes Networks». On September 2006 till December 2009 I worked on Software Design and Development at the Centre of Communications & Networking of the University of Crete. Specifically my main focus included design, development and support of video streaming services (video on demand and webcast applications) as well as installation, development and support of the e-learning platform. I also worked on the development, support and administration of networking application related with LDAP, helpdesk, directory, telephone accounting. On February 2010 till September 2013 I worked as a software engineer in the Genomics Coordination Centre of the Genetics department of University of Groningen, UMCG in the Netherlands. Mainly I focused on Java software development for MOLGENIS framework for life science research, data indexing, search engine optimization and Semantic Integration. I was also the leader software developer for the Catalogue of Dutch Biobanks for BBMRI-NL & Biobank variable catalogue for Lifelines. I focused also on web services development for OntoCAT, which was highly accessed, published on BMC Bioinformatics 2011. 

 Currently I am at the second year of PhD fellow for ISocial ITN program and my main focus is on analysis, dynamics and vulnerabilities of OSNs.



Current research interests include:

privacy and security concerns over social networks, data placement and distribution, trust issues - trust computation and community detection in social networks. Collaborative tagging, NLP, complex networks, crowd sourcing systems and adaptation on a distributed network, crowd assisted search, crawling of data from SN and investigating vulnerabilities



---------------------------
ucy- day 1: 

printers: [9/21/15, 11:08:38 AM] Thanasis Foudoulis: https://hp1-217.in.cs.ucy.ac.cy/
[9/21/15, 11:08:54 AM] Thanasis Foudoulis: http://lex-217.in.cs.ucy.ac.cy/
[9/21/15, 11:08:55 AM] Thanasis Foudoulis: http://lex-217.in.cs.ucy.ac.cy/

Eipame na kanw ki egw mia parousiash thn allh evdomada (thn epomenh Tetarth ) kapou 45 lepta gia to ti kanw. Na grayw ena mikro abstract kai ena short bio na tous to steilw prin thn parousiash. 

epishs gia to amaxi mou eipan oti o Kolja eixe parei apo Hertz gia enamish mhna me 200 eurw. tespa 8a rwthsoume . mou proteiname pantws na paroume prosfora apo leukwsia, oxi apo aerodromio , lene einai pio akriva. 8es na to koitaxeis shmera h aurio prin epistreyoume to allo? 

Gia to ti 8a kanw edw, eipame na  milhsoume me ton Xarh kapoia stigmh, alla to afhsame ligo xalaro. mou eipe pali oti sto tmhma edw exei alla duo paidia . panw katw auta pou eipame kai sto skype : 

 Nikos louloudis
Graph analysis temporal evaluation graphs 

Ego networks 
Entrepreneurs Merika ekatomuria nodes networks Twitter 
Εντοπισμός χαρακτηριστικά επιχειρηματιών και κατηγοριοποίηση αν τς ego networks πως διαφοροποιείται ο απλός χρήστης απο τον entrepreneur


Andreas papadopoulos clustering se networks 


Takis metaxas συνεργάζεται με Mario 
https://blogs.wellesley.edu/twittertrails/


-----------------
sunanthsh me ucy 

 Nikos louloudis
Graph analysis temporal evaluation graphs 

Ego networks 
Entrepreneurs Merika ekatomuria nodes networks Twitter 
Εντοπισμός χαρακτηριστικά επιχειρηματιών και κατηγοριοποίηση αν τς ego networks πως διαφοροποιείται ο απλός χρήστης απο τον entrepreneur


Andreas papadopoulos clustering se networks 


Takis metaxas συνεργάζεται με Mario 
https://blogs.wellesley.edu/twittertrails/


--------------

100.000  total downloaded for all cities 

https://www.ucl.ac.uk/~uctpcab/research/PRL.pdf: J. Travers and S. Milgram, Sociometry 32, 425 (1969).
[11] J. Kleinberg, Nature (London) 406, 845 (2000).
[12] D. J. Watts, P. S. Dodds, and M. E. J. Newman, Science
296, 1302 (2002).


[11] J. Kleinberg, Nature (London) 406, 845 (2000).:  A characteristic feature of small-world networks is that their diameter is exponentially
smaller than their size, being bounded by a polynomial in logN, where N is the number of nodes.In other words, there is
always a very short path between any two
nodes.


============
3 September

meeting referendum 

den kanoume poluplokh analush. apla pragmata. enas counter pou metrame posa oix, posa nai . kai mia provleyh gia tis ekloges den 8a eixe nohma?
gia periodika 8eloume kati aplo opws http://www.computer.org/web/computingnow/internetcomputing, https://www.usenix.org/publications/login , http://spectrum.ieee.org/, As doume pws grafoun se auta ta periodika kai kalo 8a htan na to exoume p.x. etoimo thn epomenh twn eklogwn ...(leme twra)

Apo to usenix login uparxei mono auto anoikto : https://www.usenix.org/system/files/login/articles/login_aug15_02_bratus.pdf
free sample http://www.qmags.com/magazines/PubHomePage.asp?publication=207&sessionID=8B5B3D8ABEFC8C1B64678B209
http://delivery.qmags.com/d/?pub=IC&upid=16328SP&fl=others%2fIC%2fIC_20110101_Jan_2011.pdf


gia to IMC, pame gai 3w http://www.www2015.it/ http://www2016.ca/calls.html - Research track abstract registration:  
Saturday, October 10, 2015 (23:59 Hawaii Standard Time)
Research track full paper submission:
 Saturday, October 17, 2015 (23:59 Hawaii Standard Time)  

?? h asonam? , gai merika mikra parallhla dataset opws auto pou exoume (apo tuxaia shmeia mesa stongrafo) kai prospa8oume na apodeixoume oti einai homogenius & isotropic (paper fusikhs??)
Giati xreiazomaste toso polu epexergastkh isxu??
Xreiazomaste mia istoria...einai to inflation deflation arketo ?


================
8August
https://github.com/apache/storm/blob/master/examples/storm-starter/src/jvm/storm/starter/WordCountTopology.java
https://github.com/gyfora/summer-school
https://dato.com/products/create/open_source.html

Apache camel https://camel.apache.org/

class 01 .cloud. databricks notebook 138078

========================
7 August


Using Social Media for health studies
http://edge.org/conversation/social-networks-and-happiness
geoloation of tweets 
https://www.aaai.org/ocs/index.php/WS/AAAIW13/paper/download/7085/6497

https://cloud.google.com/dataflow/

----------

https://en.wikipedia.org/wiki/Smartvote

dimensionality reduction : eigeinvectors
five leverls in teh question -> YES or NO 
PCA
plot of all ideological spaces with different colors

slide 16=
autre = others 
red & light green left 
riht side green deep = right parties
top right = neoliberal right parties

----------------
6 August 
spark https://spark.apache.org/ - https://databricks.com/ - pearson https://databricks.com/blog/2014/12/08/pearson-uses-spark-streaming-for-next-generation-adaptive-learning-platform.html


link spam : Ullman 

spam farms http://www2007.org/workshops/paper_102.pdf
----------------------------------
5 August
Apache pflink http://ictlabs-summer-school.sics.se/slides/flink-intro.pdf 

ML: 

4 August summer school Stockholm 
______________________________
workshop stockholm 






Ullman-------------

quadratic process
locality sensitive hashing LSH

set similarity:

/Users/despoina/Dropbox/__icosial/isocial_meetings summerSchoolAugust15Stockholm

https://www.janelia.org/
https://www.elastic.co/community
https://www.found.no/foundation/writing-a-plugin/

AAA  http://lightning-viz.org/

http://notebooks.codeneuro.org/
http://www.nature.com/news/interactive-notebooks-sharing-the-code-1.16261

------------------------------------------
analysi ston xrono - hstogram ana mera ana xrono ana mhna
graph RTs 

ml algorithmo me trofodothsh manually  . 



------------------------------------------

sunanthsh me thn vivi : 
Gia to plot me ta The histogram of d is:

Na doume to distribution tou d. An mporoume na to plottaroume. Ena cdf? Isws to grey zone einai polu megalo . An to d enai konta sto 0.5 tote isws auto to grafhma na 8elei ligo refinement . 


sto idio plot kai ta yes kai ta no ...kai na einai cummulative : na mhn ta xanametrame
blogspot 

Note that the point that seem to be standing "alone" are actually connected (this is a co-occurrence of hashtags) but the line is very light. 


* mail : 
 * 
   As I have said I am currently investigating the general use of the redirect exploit in Twitter. This is because I feel that the Get More Followers campaigns and the "Google obfuscating technique" that we published is just the tip of the iceberg. Searching for spam links through lookups in RBLs is not a good technique. The reason is that spammers are using many techniques to hide spam links in legit URLs. I was investigating a bit more and I found out the following: The user: https://twitter.com/jasoniwuqubib in twitter is obvious a fake account. All his followers (450) as obvious fake as well and are twitting exactly the same content. All links that they tweet have the following format: http://<SOMETHING1>.<LEGIT_DOMAIN>/<SOMETHING2> In total they have twitted more than 6000 links. 

   According to the dig tool, all LEGIT_DOMAINS use the freedns.afraid.org DNS. This DNS allows the free use of any subdomain for 91.600 free domains. One of them is podium.ru That means that if www.podium.ru (real example) is a legit site that uses this DNS, then anyone can register XYZ.podium.ru and redirect it to an IP of his choice.For example this:

      http://news-24-06-2015-pslxj.shosun.podium.ru/xhosa-56/poker-treker-rus.html 
      redirects to an obvious spam site. Since podium.ru is not spam and has not been flagged as such, anyone can posts links of this kind in Twitter.As a proof of concept I registered to freedns.afraid.org and I registered the domain: 
      despoina.podium.ru to redirect to ICS/FORTH (139.91.152.92)

      Now if you visit: http://despoina.podium.ru redirects to ICS...

      I think that the range of this abuse is huge and it is worth to investigate it a bit further. I discovered this by chance so I think that other techniques should be also used.




Spam Filtering in Twitter Using Sender-Receiver Relationship
"
Nonetheless, URL obfuscation tech- niques (e.g. , using “nevasubevu\t. blogs pot\t.\tco\tm (take out spaces)” instead of “nevasubevu.blogspot.com”) make it difficult for any automated tool to recognize the em- bedded URLs in the first place.""

titlos gai to research brainstrorming : show me the money ...Show Me the Money: Characterizing Spam-advertised Revenue
Measuring Pay-per-Install: The Commoditization of Malware Distribution
sotiris:
POio einai to % spam sto internet ? 3/4 Roughly three quarters of the world's email traffic was spam during December 2013, according to Russian security firm Kaspersky Lab. spam emails averaged around 74% of all emails sent out during the Q3 period.(http://blog.marginmedia.com.au/Our-Blog/bid/91275/7-Sobering-Statistics-about-Spam
)
 http://www.v3.co.uk/v3-uk/news/2324684/three-quarters-of-worlds-email-traffic-is-spam
Poso sto Twitter ? 10%  2. Overall, looking at social media as a whole over the years, about 8% of posts that occur on social media are spam posts. That's actually quite a lot, when you think about it.

poio einai to pio shmantiko paper/ @spam (Paxson) : ccs 10 Proc. ACM CCS, October 2010.
POioi ton kanoun cite? 
+ K. Thomas, C. Grier, V. Paxson and D. Song, Suspended Accounts in Retrospect: An Analysis of Twitter Spam, Proc. ACM IMC, November 2011.

real time : Design and Evaluation of a Real-Time URL Spam Filtering Service

* 15 Iouniou 
 * Gia thn askhsh 459 
  * 1) 1) Routers: 
        step 1 ) take all days and for each day parses all planet lab nodes. For each planet lab node takes all lines that do not contain the string ‘destination’. These lines contain only the routing nodes. For each line containing a routing node we take only the ip address. Then it sends (pipes) these ip addresses to the ask1.py file:

        Erwthseis: 
        assignment 1)
        question 1)opote exoun xehwrisei ta routing nodes swsta (exoun vgalei exw ta destinations?) pws? pws diavazeis ka8e arxeio? pws xehwrizeis thn ip ? 8elome unique ips..

        question 2) Question 2) Is the Internet power law? Plot the number of edges of each router as a function of the router rank. Fit it with a function. Is it power law? According to wikipedia: the straight-line on the log-log plot is often calledthe signature of a power law.Fainetai power law gia tous routers?

        Sxolia ulopoihshs: create links between different IPs and save them separate? IP(i) IP(j) occurrences” again those lines had to be unique so another hash table was used.The tricky part is that a link with IP(i) IP(j) is the same with IP(j) IP(i).

        Plotting) According to wikipedia: the straight-line on the log-log plot is often called the signature of a power law. fainetai auto sto plot?
        Question 3(a): "Question 3 - Is the Internet getting larger? a. Report the number of routers as a function of time

        I was able to counter all the routers but because the files were inconsistent I had to pick the dates in order to plot them number of routers as a function of time.
        I did not use the data after 2010 because the number of routers is a magnitude smaller and also I excluded the report from  03/2009 because only 8k routers were found.


        b. Report the average path length as a function of times the Internet getting larger? 3-b) path seems to be getting smaller"

Question 4: For this question I used all the pairs from 2011 to 2014 for the file trace.out.planetlab1.cs.umass.edu. Every Ip destination has for every year in 2011 2012 2013 and 2014 the RTT from planetlab1.cs.umass.edu and they are sorted according to the IP. The files used for this is the question4.cpp and a script to get readout the file planetlab1.cs.umass.edu. The reported RTTs are containted in the rtt.txt.



* 12 June
kai 
    du -shcl  *.uobs.gz : clustre 154G  total
    aneipero: 152G    total

...............

  apo to copy : sto aneipero leipoun ta antikeimena pou arxizoun apo user_objects_0 ARI*MO 
  copy sto vpn: 

  session 6543
  scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_[0-9]*.gz ./
 and copying to aneipero :sudo scp antonakd@161.116.80.211:/home/antonakd/snap_user_objects/to_move2/* .
 session 13390


  epishs leipoun : 

  user_objects_aaaadddwse.uobs.gz user_objects_aaadfbsend.uobs.gz user_objects_aaasssvlaadoumpa.uobs.gz user_objects_abdfndfnxfn.uobs.gz user_objects_adddddvrghjawgddddwse22 user_objects_adddddvrghjawgddddwse22  user_objects_adddddvrghjawgssssddddwse.uobs.gz user_objects_addwse.uobs.gz  user_objects_aerbaeraerbqe.uobs.gz user_objects_aerbaeraerbqewfdddwe.uobs.gz user_objects_aerbaeraerbqewfwe.uobs.gz user_objects_aerbaeraerbqewfwe.uobs.gz user_objects_aerbaeraerbqsssewfdddwe.uobs.gz  user_objects_aerbaeraerbqsssewsssfdddwe.uobs.gz 

and copyng to aneipero : sudo scp antonakd@161.116.80.211:/home/antonakd/snap_user_objects/move3/* ./ session 16992

* COPY snap user objects : 
 
    From https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository

    create the directory in  /Users/despoina/GitHub/
    then git init 
    then macbook-pro:GitHub despoina$ git clone https://github.com/antonak/phd.git
    PROSOXH sthn prohgoumenh entolh evala ton antonak OXI to https://github.com/kantale/phd.git


    -----

     (albeniz- username: antonakd)


    vpn @ barca: 161.116.80.211
    scp antonakd@161.116.80.211:/home/antonakd/*.uobs.gz ./

    aneipero: ssh -p 2222  despoina@139.91.70.146


    ssh <usern
    ame>@albeniz2.ffn.ub.es   

    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/*.uobs.gz ./

    session 27274
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_UNKNOWN* ./


    session 27140
     scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_s*.gz ./

    session 27140 
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_t*.gz ./

    session  DEN UPARXOUN APO U
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_u*.gz ./

    session  27437 V
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_v*.gz ./

    session  W 27503
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_w*.gz ./

    session  27582 X
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_x*.gz ./

    session  27627 y
    scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/user_objects_y*.gz ./

    -rw-r--r-- 1 antonakd antonakd    0 Jun  9 16:54 user_objects_VNbncsGbjS2.uobs.gz
    -rw-r--r-- 1 antonakd antonakd    0 Jun  9 16:55 user_objects_Ybf9OWn1Drllxlkxy.uobs.gz
      

       sudo scp antonakd@161.116.80.211:/home/antonakd/snap_user_objects/to_move/* .    session id 13390


    du -shcl  *.uobs.gz : clustre 154G  total
    vpn : to move : 16G     total + DEn exei nohma exw svhsei polla apo edw giati den eixame xwro 
    aneipero:  /storage3/snap_user_objects : 133G total 



* New macbook: 
From https://git-scm.com/book/en/v2/Git-Basics-Getting-a-Git-Repository

create the directory in  /Users/despoina/GitHub/
then git init 
then macbook-pro:GitHub despoina$ git clone https://github.com/antonak/phd.git
PROSOXH sthn prohgoumenh entolh evala ton antonak OXI to https://github.com/kantale/phd.git


-----

New vpn @barca : !..vpn (albeniz- username: antonakd)


ssh <usern
ame>@albeniz2.ffn.ub.es

scp antonakd@albeniz.ffn.ub.es:/users/antonakd/marienbad/save/ids_modulo/*.uobs.gz ./

vpn @ barca: 161.116.80.211
scp antonakd@161.116.80.211:/home/antonakd/*.uobs.gz ./

aneipero: ssh -p 2222  despoina@139.91.70.146


ssh 139.91.90.28 -l amira amira_12

* gia backup sto aneipero : cp file to  /freenas/users_backup/despoina/

 1) Analysis of SNAP dataset:
    1)  Apply the same analysis as with our "own" dataset. Just measure the graph metrics. The code is ready. I just have to change the input!
    2) In collaboration with  Marian, proceed the 'percolation graph analysis'. Investigate when/how the twitter becomes a connected graph
  2) Investigate some more the "inflation/deflation" events that we discovered in our IMC paper. It is clear from some graph properties that twitter went through some phases. Investigate some more and associate with other events (example: block from China)
  3)We have in our disposal the user objects of 250 million users. Still haven't figure how to utilize this dataset!
  4) A follow up of the "Get More Followers" papers: the Google Obfuscation is just one of the link obfuscation techniques. Spammers use more exploits to hide spam links as legitimate. There is a very good review of this phenomenon: http://vxhex.blogspot.gr/2012/11/weaponizing-jsfiddle-codepen-and-jsapp.html . What is the scale of this exploit in Twitter?
  5) I am very keen on doing a "social study" in Twitter. If the SI paper (GMF campaigns) is more about security, IMC paper is more about social network analysis then a "social study" would integrate my PhD. I think something closer to what Ferrari is doing. Nothing concrete yet, just a thought.



 *Ratio of followers / followings in our dataset (NOT SNAP) 
     for efficiency we didn't download the followers list for users that have more that 5000 followers (we call them celebrities). The reason is that some of them have extremely large number of followrs (ie 1.000.000) and given the limitations of Twitter API we would have wasted all of our time and resoucres to download these lists. 
     The question is now what did we miss?

     We plot the ratio of followers/followings + folowers for each user for the first 350.000 users in our dataset . 

     From the plot that should have 0.5 (50 %) which is the value that users should have reached, we miss roughly ~12% of following relationships and this is the percentage of following relationships that are targeting celebrities. 



  Twitter id progression 
      Since we want to do studies in the Twitter dataset, we need to know approximately the time range when an account was created.

      We don;t donwload the actual time of creation. We map the id to a short time period of one month. We donwload the user objects some of the users and we request the time creation of the users for the firts of each month. To do that we parse our dataset and take the ids of random users tha created their account on the 1st of each month form 2006 to 2015. So for the users that we dont have the time of account creatio, we map to the month that he was created. We see where his is fall and approximate (witinh one month) the time creation.

      By sorting this dataset, we have an idea of the users growth ovwer time (although this might not be indicative: it is known that twitter ids do not have a one to one correspondence with users). nevertheless thi sis extremely useful because now we know the month when an id was created.    

      The data is here: http://pastebin.com/Tu2hZWER 
      So for example:
      5_2009 --> 36843096
      6_2009 --> 43908407
      7_2009 --> 52584160
      If a user has an id: 40000000 we know that we created her account sometime between 5/2009 and 6/2009.

      We observe a huge increase between 2012 - mid 2013 . There are also indications of a decrease in the rate of growth of twitter's users at the end of 2014. This might be an early sign of saturation on twitter?

      The small corners may be an indication of the change of the algorithm that produces the Twitter IDs. 


  Preparation of the graph
      We have sorted the complete dataset from earlier to sooner link creation according to the known heuristic. 
      We have altered a bit the heuristic in order to include friendship relationships. 
      So we can say that we utilized all our downloaded data. 

      The result is a single file 240GB, with ~10 billion followers/followings relationships. 
      The first thing that we did was to make a graph for the initial relationships that happened in 2006. 
      This graph is directed. An edge from A to B means that A follows B. 
      For each edge that we added we computed some metrics. For the sake of novelty we applied some metrics that are not available in igraph. Of course we plan to also include the well-known graph metrics of igraph in the next step.

      apo thn arxh tou dataset ws to telos metrame posous followers eixe o xrhsths gia ton opoio parathrh8hke followback . Oi followers htan 2, 420 fores. 

      Sto panw shmeio tou kitrinou sumperenoume oi 300 (400 - 100 roz peak) followback eginan ston 1st follower enw 100 (peak tou roz) eginan ston 2nd follower. 

      Sto shmeio 21,90 sto telos tou metrhmatos: poses fores sunanthsame followback opou o A eixe 21 follower? htan 90 . kai apo tous 90 - 40 = 50 egine folowback stn 1st follower 

 
        plot

      Here we plot every followback that happened. The followbacks are divided on the numbers of followers that a user had when the followback happened. For example 90 followbacks happened where the user who did the followback had 20 followers.
 
      The color that we use in the bar represents how old was the following relationship that we followbacked. Yellow colors indicate that the followback happened to the most recent followers, purple to the 2nd more recent, etc.
       
      The main incentive for this plot was:
         (1) to check the validity of the heuristic and 
         (2) to make a meaningful plot about the nature of the followbacks.
       
      We notice that the majority of the followbacks happened to the very last user that followed us. A note on the color range: the color that we used is 1/(reverse_order) on the shown bar. So the first follower is on the top of the bar, the second on the middle and so on.
        


Is there a path in the directed graph from B (target) to A (source) for every following?

      The question here is when a following A->B happens, is there a path from B to A on the directed graph? Or else can I go from B to A by visiting following relationships. To investigate this we plotted the distribution of the shortest path on directed graph for each following:


      vlepoume mia ek8etikh ptwsh tou sortest path , ara o grafos mas ginetai more dense - connected 

      * "no_path" means that there is no DIRECTED path between target and source
      * "in_subgraph" means that this following did not happened in the main graph but in a "subgraph". 

      We noticed while we were building the graph, that the graph was not strongly connected even if we ignore edge directions. We noticed that a main big graph was forming along with many small sub-graphs with 2 to 10 nodes. 

      We decided to ignore following relationships that happened in the sub-graphs for this metric. This does not mean that we remove the subgraph. Many subgraphs get connected to the main graph eventually in the future. See also next graph.
      
      In this graph we see that even in the early phases (because the data is from 2006) of twitter although there was a big percentage of "no_path" relationships, there was a short (1-3 edges) path from B to A on the directed graph for the majority of the following relationships. 


What is the percentage of following relationships that happened on the big cluster elefantas ?
      Plot of the percentage of following relationships that happen on the main graph: NOT CDF

      25.000, 89: apo tous 10 M follower relationship shorted by creation ctime gia ka8e ena po auta to ta relationships ta vazoume sto nework. Meta metrame posa nodes exei to network. (X axonas) 

      poio einai to plh8os twn nodes pou vriskontai sto cluster (  o axonas y)

      25.000, 89: otan valame ton 25000th user sto network tote to 89% twn xrhstwn htan ston elefanta  

      This plot covers all following relationships that happened between 21 March 2006 and 13 November 2008. This is a period of 2 years 8 months. We notice that this ratio approaches 100% (all followings belong to a single strongly connected graph)



Distribution of the shortest path between B (target) and A (source) on the UNDIRECTED graph
      Instead of looking on the directed graph, we did the same as before on the undirected graph. The question here is what is the distance from A to B right  BEFORE before A followed B. We measured this distance for all followings that happened in 2006.  We did that for all followings and for all followings that are not followbacks. 


      metrame thn apostash tou a, b undirected prin ginei to follow metaxu tous. (meta h apostash gineteai 1) 

      to kokkino peak : den sumainei apolutos tipota giati :  efoson den exeis followback, h apostash den 8a einia 1 opote to distribution einai 0 
      (h grammh h kokkinh apo to 0-2 prepei na fugei) 
      enw gia ta all followings 1, 5000,prin kanei o a --> B uparxei path path metaxu tous me 1 hop ara auto enia followback kai auto to parathroume 5000 fores. 
      to plh8os twn followings pou exei mikro shortert path prin ginei to folowing einai megalo . 
      enw ton plh8os twn followings pou exei megalo  shortert path prin ginei to folowing einai mikro

      h kathfora: 
      oso megalwnei to shortest path se ena following, (prin ginei auto to following) toso pio spanio einai na vries auto to following. 




 ==============================

filezilla sto csd: 
kaneis ssh gate1.csd.uoc.gr -l hy459  954yh_2014! apo command line
kai meta patas enable rodi

oti ru8miseis sou vgazei ths vazeis sto filezilla: 

Username: hy459
Hostname: gate1.csd.uoc.gr
Port: 17518
Meta sto pedio host tiu filezilla : sftp://gate1.csd.uoc.gr
============== 

suanathsh 30 march : 
  number of node/edge : anapoda tous axones..

  Prepei na ginoun se histographs... ta graphs me ths mple grames kai ta trigwna kai to epomeno plot..


Sunanthsh 30 March

snap : 37M

Pairnoume ola ta following relationships ordered by creaiton tim
kai ta bazoume ena-ena
kai gia ka8e ena (Sth pragmatikothta gia ka8e 100) metrame posous clusters exeis o grafos

dld posa unconnected components
kai metrame posoi einai oloi oi clusters (maurh grammh)
posoi einai oi clusters pou exoun toulaxisotn 3 nodes
dld to grafima deixnei oti:
parolo pou fainetai na au3anontai oi clusters oso bazoume edges
h pleiopsififa twn clusters exoun 2 nodes

eno h pleiospifia twn nodes paei se clusters me polla melh

---> h grammh pou leiepi kai sumplhrwnei einia cluster = 2]

============

(apo 18 March) 
σας στελνω ενα pdf με 3 plots. 
Οσον αφορα το download στο snap εχει φτασει στο 24M(/40Μ nodes)

 Τα plots ειναι απο το ιδιο dataset που ειχαμε δει και την προηγουμενη φορα: 
From the SNAP dataset take all users than have id < 1.000.000
  * Take only the users that we have downloaded their followers: 1153 
  * Remove nodes (users) that all their followers are users that we have not downloaded: Keeping 384 
  * Find all edges of this graph: 783 
  * Sort these edges according to creation time according to the heuristic
    
Ηθελα να βγαλω καποια plots apo το δικο μας dataset αλλα ειχα διαφορα θεματα με τον cluster συγκεκριμενα ειχαν  power cut in the UB and we had to shutdown the albeniz.!!

btw δεν έχω κάνει ακόμη backup τα data apo UB και είναι περίπου 1T . 
=======12 March 


There is a cluster in Barcelona that runs several clients for an experiment. 
Each client tries to connect to aneipero.ics.forth.gr, receives a task_id from a queue that is served in aneipero, then tries to complete the task with this task_id.

I noticed that after some point, the rate at which the cluster completes tasks is not improved by adding more clients. Moreover I noticed that some clients fail to connect to aneipero with EOFError on the connection socket. A third indication is that when I run:
netstat -an | grep "139.91.70.146:50000" | grep "ESTABLISHED" | wc -l

Then this number is not getting higher than 1017 no matter how many clients I submit to the cluster. So I am thinking that there should be a throttle on the number of ingoing connections of aneipero.ics.forth.gr .

Solution: Increase open files limit: 
http://unix.stackexchange.com/questions/108603/do-changes-in-etc-security-limits-conf-require-a-reboot
==========9March 

Καποιες αλλες ιδεες για το paper : 
* Try to predict who will be the next user that a user follows in twitter. We can extract network properties per user. Then we can train a ML algorithm with these properties and build a model that can predict the next follower. This can help to (1) model the evolution of the network (2) build a recommendation system. 
* Plot the social network graph of twitter with a new layout that will take into account the time creation of the links. If we plot this we may be able to picture the "evolution arrow" of twitter. Or else to show the general tendency of new following relationships. The hypothesis is: Does twitter has a constant rate of new edges? If not how can we model it?
* Find users that always "follow back" according to the social network evolution data that we have collected. Then make an account and follow these users. Do they follow us back? Post fake spam links to a fake spam url that we will create. Measure the clickthrough rate. Maybe add fake products and allow users to make fake purchases. How much did we earn?
* Can we predict location / language from network properties? (Probably already done but as with @spam paper, we can do it easier with simples metrics / data)

=========27 februariou : layout : 

gia to layout tou graph pou rwthse o Swthrhs ontws auto htan to defaut poy evaze to igraph, to opoio einia to http://en.wikipedia.org/wiki/Force-directed_graph_drawing(Kamada-Kawai force-directed algorithm). Evala explicilty ta parakatw kai phra to apotelesma pou exoune sta plots sto attachment. To prwto meros tou onomatos einai to onoma tou layout (uparxei perigrafh edw https://github.com/igraph/python-igraph/blob/master/doc/source/tutorial.rst) kai to deutero meros tou onomatos posa links exei pros8esei sto grafo . 
---
regards,

=========
python /Users/antonakd/GitHub/phd/code/marienbad.py --action build_graph 
python /Users/antonakd/GitHub/phd/code/marienbad.py --action plot --plot 3

24 Febraruiou 

I did the following analysis:
* From the SNAP dataset take all users than have id < 1.000.000
* Take only the users that we have downloaded their followers: 1153 
* Remove nodes (users) that all their followers are users that we have not downloaded: Keeping 384 
* Find all edges of this graph: 783 
* Sort these edges according to creation time according to the heuristic
* Make 783 plots. Each one for each new edge. Create 783 PNG files. Merge them in a gif 
    * This gif is available here:https://www.dropbox.com/s/4cgnvdxv861yxwg/result_1.gif?dl=0
    * You can see how a big cluster is developing and how small islands are forming as well.

*For each one of the 783 stages. I took the subgraph with the highest number of nodes.
*For this subgraph I calculated the average degree of nodes.
*Then I plotted it. The plot is the following:

PLOTS: 
figure_assortativity_degree

     1) assortativity: This coefficient is basically the correlation between the actual connectivity patterns of the vertices and the pattern expected from the disribution of the vertex types.http://arxiv.org/abs/cond-mat/0209450

     ==================>In our plot. In order to see this properly we have to include characteristics like language,country, cultural characteristics to see whether similar nodes aka users in Twitter connect together if they are similar. Is this information taken into account already ?

2)==================figure_average_closeness:================== 
    The closeness centerality of a vertex measures how easily other vertices can be reached from it (or the other way: how easily it can be reached from the other vertices). 
      It is defined as the number of of vertices minus one divided by the sum of the lengths of all geodesics from/to the given vertex.
    The closeness centerality of a vertex measures how easily other vertices can be reached from it (or the other way: how easily it can be reached from the other vertices). It is defined as the number of the number of vertices minus one divided by the sum of the lengths of all geodesics from/to the given vertex.


    In the mathematical field of graph theory, the distance between two vertices in a graph is the number of edges in a shortest path (also called a graph geodesic) connecting them. 

      ==================>In out plot initially it have larger values close to but as more nodes & vertices are added the value of closenness falls since the graph becomes more dense and more well connected, so it is easier for some vertices to be reached from other . After 200 edge addition it seems to be constatn like the possible "neighbors" are already shaped. 

3) ==================figure_average_degree==================
    Calculates the average degree of the neighbors for each vertex, and the same quantity as the function of vertex degree.


    In the study of graphs and networks, the degree of a node in a network is the number of connections it has to other nodes and the degree distribution is the probability distribution of these degrees over the whole network.


      ==================>In out plot the average degree of each node increases as nodes are connected between each other and teh graph is becoming more dense. The abnormal values at the beginning is because some "islands" were picked as the largest at the beginning but they were not "evolving" (they were surpassed by other islands).


===============================

snap : 24M sto snap
Percolation plot. the first plot shows the number of subgraphs or components as they are shaped as we add more edges. In the beginnig we see that the subgraphs are increasing in number and after the insertion of 100 edges it remains almost constant for a bit and then starts decreasing. This can be explained in the sense that as new edges are introduced, users are getiing more and more connected and forming less sugraphs. We expect to have percolation when there are no subgraphs but one big component. You could not see more edges because tehre are not included in this subdataset .  
    the dataset is this  I did the following analysis:
  * From the SNAP dataset take all users than have id < 1.000.000
  * Take only the users that we have downloaded their followers: 1153 
  * Remove nodes (users) that all their followers are users that we have not downloaded: Keeping 384 
  * Find all edges of this graph: 783 
  * Sort these edges according to creation time according to the heuristic
  
this plot show as new edges are insterted how are new users introduced. When we have like a line then users are connected to already existed edges. e.g. 160-162 # nodes are the same , so no new users where introduced but some users were connected to some others.

 
 the second plot (blue lines) show the following: 

 each red triangle is the index/order of the user that user X follows back. Instead of a triangle we sometimes see a blue line which means: the length of the line shows the number of followers of user X. where it starts on -y axis -shows which follower he followed back first(that is the triangle there). This plots shows that most users tend to follow back the latest users that followed him. (each blue line or triangle shows a follow relation. Not all the current followers of a users are represented in this line, only one follow relation.)
the blanks are there because the distance between X and Y users (X,Y is the new edge intorduced in this point) was not 1. So this new edge that was introduced connected two users via other users , there is no direct (follow - followe connection YET between X,Y)   
(this plot some how gowe to the direction of : Try to predict who will be the next user that a user follows in twitter.)
 
 The third plot shows the distance between 2 users that were just connected but were not connected till now with direct connection. 

 So a point with x=300,y=5, means that when the 300th edge was introduced, (x-->Y and x,y  were not connected till now with direct connection) had till now distance 5 users. Now they have 1. 

 =========================  

Try to predict who will be the next user that a user follows in twitter. We can extract network properties per user. Then we can train a ML algorithm with these properties and build a model that can predict the next follower. This can help to (1) model the evolution of the network (2) build a recommendation system. 
Plot the social network graph of twitter with a new layout that will take into account the time creation of the links. If we plot this we may be able to picture the "evolution arrow" of twitter. Or else to show the general tendency of new following relationships. The hypothesis is: Does twitter has a constant rate of new edges? If not how can we model it?
Find users that always "follow back" according to the social network evolution data that we have collected. Then make an account and follow these users. Do they follow us back? Post fake spam links to a fake spam url that we will create. Measure the clickthrough rate. Maybe add fake products and allow users to make fake purchases. How much did we earn?
Can we predict location / language from network properties? (Probably already done but as with @spam paper, we can do it easier with simples metrics / data)

6.7 M sto SNAP


Ta plots : 

1)==================figure_assortativity_degree: ==================

      See assortativity() for the details. assortativity_degree() simply calls assortativity() with the vertex degrees as types.

      assortativity: This coefficient is basically the correlation between the actual connectivity patterns of the vertices and the pattern expected from the disribution of the vertex types.http://arxiv.org/abs/cond-mat/0209450

        We study assortative mixing in networks, the tendency for vertices in networks to be connected to other vertices that are like (or unlike) them in some way. We consider mixing according to discrete characteristics such as language or race in social networks and scalar characteristics such as age. As a special example of the latter we consider mixing according to vertex degree, i.e., according to the number of connections vertices have to other vertices: do gregarious people tend to associate with other gregarious people? We propose a number of measures of assortative mixing appropriate to the various mixing types, and apply them to a variety of real-world networks, showing that assortative mixing is a pervasive phenomenon found in many networks. We also propose several models of assortatively mixed networks, both analytic ones based on generating function methods, and numerical ones based on Monte Carlo graph generation techniques. We use these models to probe the properties of networks as their level of assortativity is varied. In the particular case of mixing by degree, we find strong variation with assortativity in the connectivity of the network and in the resilience of the network to the removal of vertices.


      (wikipedia) Assortativity, or assortative mixing is a preference for a network's nodes to attach to others that are similar in some way. Though the specific measure of similarity may vary, network theorists often examine assortativity in terms of a node's degree.[1] The addition of this characteristic to network models more closely approximates the behaviors of many real world networks.
      ----------
        ==================>In our plot. In order to see this properly we have to include characteristics like language,country, cultural characteristics to see whether similar nodes aka users in Twitter connect together if they are similar. Is this information taken into account already ?



 2)==================figure_average_closeness:================== 
    The closeness centerality of a vertex measures how easily other vertices can be reached from it (or the other way: how easily it can be reached from the other vertices). It is defined as the number of the number of vertices minus one divided by the sum of the lengths of all geodesics from/to the given vertex.
    The closeness centerality of a vertex measures how easily other vertices can be reached from it (or the other way: how easily it can be reached from the other vertices). It is defined as the number of the number of vertices minus one divided by the sum of the lengths of all geodesics from/to the given vertex.


    In the mathematical field of graph theory, the distance between two vertices in a graph is the number of edges in a shortest path (also called a graph geodesic) connecting them. 

      ==================>In out plot initially it have larger values close to but as more nodes & vertices are added the value of closenness falls since the graph becomes more dense and more well connected, so it is easier for some vertices to be reached from other . After 200 edge addition it seems to be constatn like the possible "neighbors" are already shaped. 

3) ==================figure_average_degree==================
    Calculates the average degree of the neighbors for each vertex, and the same quantity as the function of vertex degree.


    In the study of graphs and networks, the degree of a node in a network is the number of connections it has to other nodes and the degree distribution is the probability distribution of these degrees over the whole network.


      ==================>In out plot the average degree of each node increases as nodes are connected between each other and teh graph is becoming more dense. The abnormal values at the beginning is because some "islands" were picked as the largest at the beginning but they were not "evolving" (they were surpassed by other islands).

4 ==================figure_average_neighborhood_size==================
  For each vertex specified by vertices, returns the number of vertices reachable from that vertex in at most order steps.

      ==================>Similarly like in figure_average_degree the neighbors vertices reachable from other ones are zero and incrwasing as the connectivity of the nodes increases. As bigger components are formed, the average_neighborhood_size increases. 

5 ==================figure_average_neighborhood_size==================
  For each vertex specified by vertices, returns the number of vertices reachable from that vertex in at most order steps.

  ==================>Similarly like in figure_average_degree the neighbors vertices reachable from other ones are zero and incrwasing as the connectivity of the nodes increases. As bigger components are formed, the average_neighborhood_size increases. 

6 ==================figure_average_path_length==================

Average path length is a concept in network topology that is defined as the average number of steps along the shortest paths for all possible pairs of network nodes. It is a measure of the efficiency of information or mass transport on a network.


  this is very interesting as it seems to increase till around 200 edges and then falling as the components start to form and slightly decreasing since the graph is more interconnected now so it take lesser and lesser steps(edges) to form the paths. 

7 ==================figure_average_shortest_path_of_100_random_pairs==============
  see 6!

8) =================figure_average_shortest_path=========================
  see 6 

9) ==========figure_betweenness_average_notzero(=means with non zero values) ==============   
  Calculates or estimates the AVERAGE betweenness of vertices in a graph.


        Betweenness centrality is an indicator of a node's centrality in a network. It is equal to the number of shortest paths from all vertices to all others that pass through that node. 

        A node with high betweenness centrality has a large influence on the transfer of items through the network, under the assumption that item transfer follows the shortest paths. The concept finds wide application, including computer and social networks,[1][2] biology,[3][4] transport [5] [6] and scientific cooperation.[7] Development of betweenness centrality is generally attributed to sociologist Linton Freeman.[8] The idea was earlier proposed by mathematician J. Anthonisse, but his work was never published.[9]
        
        Betweenness centrality is related to a network's connectivity, though in what way it is not fully understood[9]

      ==================>in our plot initially nodes are not connected so it is at zero values, since there are no nodes that seems "come in between other nodes". The number of shortest paths from all vertices to all others that pass through a specific node, increases as connectivity(interconnectivity) increases and density of teh graph . As bigger and bigger components form, more and more nodes have higher betweeness average . It make sense to see this plot increasing . The small spikes may seem as an indication of components with npdes that are traversed by more paths, (tehy are more interconnectd as aother components)

  10) figure_betweenness_average_
  
  the difference with the previsou: we have more spikes...the zero alues are out so ? the average number of shortest paths from all vertices to all other that pass to a node increases, since the UNCONNECTED nodes are removed form our graph ?   ??

  11) ==================Evolution of clique number ==================
      Returns the clique number of the graph.

        The clique number of the graph is the size of the largest clique.

        The size of the largest clique when we have 300 edges is 3...why the gap??? and on 800 edges is 5 nodes 
12) 


=============

virality on Twitter : Good Friends, Bad News Affect and Virality in Twitter http://arxiv.org/pdf/1101.0510v1.pdf an kai o kolja metraei kati diaforetiko 
----------
sunanthsh 26/2/ Vivi si
    * Moproume na ftiaxoume to gif me thn xronologikh seira dhmiourgias twn NODES
    1) mporoume na valoume sto gif kai ta nodes me thn xronologikh seira pou dhmiougountai ? 
    Giati exei auto to layout? panw ena kuklo xekomemno apo ta alla? 
    Nomizw to layout tou igraph exei na kanei me auto : https://github.com/igraph/python-igraph/blob/master/doc/source/tutorial.rst
    so define explicitly layout : marienbad: line 3655:   layout = g.layout_reingold_tilford()
    Ta dokimasa sxedon ola apo edw: https://github.com/igraph/python-igraph/blob/master/doc/source/tutorial.rst
    alla ola -ektos apo auta pou den trexoun kan- einai sto idio pattern . kuklos me periferia kapoia nodes pou den enonontai me to kentriko main component.  den katalavainw giati to kanei auto . 

    * story 2) xreiaszomaste ena story gia to paper. px. otan eisa to average path lentgth ti auaxanotan kai mesa meionotan epeidh o grafos egine pio dense ...einai mia kalh arxh. as vroume kialla tteoia kala plota na vgaloume paromoies istoiesoules. (rwthsan an to average path lenge story exei hdh djmosieutei)

    * metrikes kolja sto diko mas dataset . As grayoume to idio paper tou kolja alla sto twitter
    * 8elei to oloklhwrmeno grafhma tou evolution ..leei kai eixame pei ti einai to oloklhrwmeno grafhma tou evolution 
    ===========
* to hadoop einai software pou ka8etai panw se enan cluster- cluster exoume kai einai kalosthmenos, me ena kalo subsampling twn dedomenwn eimaste ok

we need a story : 
understanding Twitter from a network analysis perspective

h mesh apostash twn friend se km 
http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.180.8485&rep=rep1&type=pdf
=================================
=================================
downloaded so far 4.2 M apo ta 40M
=================================
=================================
=================================



        neighborhood_size(vertices=None, order=1, mode=ALL)
        source code 
        For each vertex specified by vertices, returns the number of vertices reachable from that vertex in at most order steps.




        Correlations between nodes of similar degree are often found in the mixing patterns of many observable networks. For instance, in social networks, highly connected nodes tend to be connected with other high degree nodes. This tendency is referred to as assortative mixing, or assortativity. On the other hand, technological and biological networks typically show disassortative mixing, or dissortativity, as high degree nodes tend to attach to low degree nodes.[2]

        http://signsat40.signsjournal.org/cocitation/


        http://en.wikipedia.org/wiki/Centrality


        Closeness centrality[edit]
        In connected graphs there is a natural distance metric between all pairs of nodes, defined by the length of their shortest paths. The farness of a node s is defined as the sum of its distances to all other nodes, and its closeness is defined as the reciprocal of the farness.[7][8] Thus, the more central a node is the lower its total distance to all other nodes. Closeness can be regarded as a measure of how long it will take to spread information from s to all other nodes sequentially.[9]
        In the classic definition of the closeness centrality, the spread of information is modeled by the use of shortest paths. This model might not be the most realistic for all types of communication scenarios. Thus, related definitions have been discussed to measure closeness, like the random walk closeness centrality introduced by Noh and Rieger (2004). It measures the speed with which randomly walking messages reach a vertex from elsewhere in the network—a sort of random-walk version of closeness centrality.[10] Hierarchical closeness of Tran and Kwon (2014)[11] is an extended closeness centrality to deal with the limitation of closeness in directed networks.The hierarchical closeness explicitly includes information about the range of other nodes that can be affected by the given node.


         eigenvector centralities.eignvalue centrality - maybe connected tp if a user is infliencial?? brilliant ! but already done !: http://arxiv.org/pdf/1209.4616.pdf




* plots : 
to ka8e shmeio sto plot einai enas grafos
me thn enoia oti otan  to 63edge p.x. mpei sto graph , sto plot anaparistate h h timh ths idiothtas (pou deixnei to plot) sto x=63
dhladh oso 
otan to 400 edge proste8ei sto grafo h timh(antistoixo png arxeio) p.x. tou shortest path 8a exei allaxei apo ekenh pou htan sto 399 h ka8e diafoertikh auth timh fainetai san teleia panw sto plot 

Average shortest path : 
1) pernoume 100 tuxaio edges 
---------------
  I did the following analysis:
  * From the SNAP dataset take all users than have id < 1.000.000
  * Take only the users that we have downloaded their followers: 1153 
  * Remove nodes (users) that all their followers are users that we have not d ownloaded: Keeping 384 
  * Find all edges of this graph: 783 
  * Sort these edges according to creation time according to the heuristic
  * Make 783 plots. Each one for each new edge. Create 783 PNG files. Merge them in a gif 
      * This gif is available here: https://www.dropbox.com/s/4cgnvdxv861yxwg/result_1.gif?dl=0  Macintosh HD ▸ Users ▸ antonakd ▸ Documents ▸ Dropbox ▸ __icosial ▸ ___twitterevolution
      * You can see how a big cluster is developing and how small islands are forming as well.

  *For each one of the 783 stages. I took the subgraph with the highest number of nodes.
  *For this subgraph I calculated the average degree of nodes.
  *Then I plotted it. The plot is the following:

  The abnormal values at the beginning is because some "islands" were picked as the largest at the beginning but they were not "evolving" (they were surpassed by other islands).
  Similarly I can very easily do the same for a huge collection of graph metrics.  

* 
mexri ti id exei katevasei kai posa exei katevasei gai to snap kai mia ektimhsh gai to pote 8a to exoume 
1.000.000 / 40.000.000, ektimhsh: 30 meres
Gia to id  den mporw na to pws epeidh sthn ousia einai random order
* 18/2/1015

  Αυτή τη στιγμή έχω φτιαξει γύρω στα 400 application keys
  τα οποία μας επιτρέπουν να κατεβάζω με ρυθμό 500.000 την ημέρα
  το SNAP dataset έχει 40Μ users
  περιμένω στις επόμενες μέρες να επαναφέρω τον ρυθμό download εκεί που ήταν πριν μου κόψουν τους (προηγούμενους) λογαριασμούς

  Δλδ περίπου 1Μ την ημέρα
  επίσης παράλληλα προσπαθώ να δω με πιο τρόπο θα μπορέσω να επεξαργαστώ αυτή τη πληροφορία η οποία είναι μέχρι στιγμή σε txt αρχεία
  Η όλη ιδέα να βάλω τα data σε μία απλή file based database όπως η sqlLite δεν φαίνεται να προχωράει.

  Μετά από τα 10Μ entries αρχίζει να γίνεται πολύ αργή.
  Υπάρχει η ιδέα να χρησημοποιείσω άλλα back ends όπως η MySQL . To ψάχνω τώρα
  Αυτό είναι απαραίτητο γιατί ο όγκος των δεδομένων είναι τέτοιος που απλά "δεν παίζει" να τα κάνω load στη μνήμη.
  Ένα τελευταίο:

  Το cluster στη Βαρκελώνη μπορεί να τρέχει μέχρι 40 processes ταυτόχρονα
  Αν κάνεις commit και άλλα jobs τότε γίνονται queue (περιμένουν δλδ να τελειώσουν αυτά που τρέχουν)
  Μου πήρε κάποιο χρόνο να το "ρυθμίσω" ώστε κάθε process να σηκώνει ακριβώς ACCOUNTS / 40 processes. Ώστε να "τρέχουν" όλα τα accounts που έχω φτιάξει.

* 10/2/2015 
  * install igraph in mac : 
    * according to this : http://igraph.org/python/#pyinstallosx it is preferable to isnatll it with brew
     * so ...: http://igraph.wikidot.com/installing-python-igraph-on-mac-os-x
       * run in mac : brew install cairo
          Warning: cairo-1.12.16_1 already installed
          * despoina:code antonakd$ brew install py2cairo
            * ...Warning: Could not fix libpython2.7.dylib in /usr/local/Cellar/py2cairo/1.10.0/lib/python2.7/site-packages/cairo/_cairo.so
              * gpoogle : https://github.com/Homebrew/homebrew/issues/12893
              ok ...this is getting too hard : 

              http://igraph.org/nightly/get/python-osx/python_igraph-0.7.0-py2.7-macosx10.8.dmg

              trexei !!
              alla se console ths python : >>> import igraph
            Traceback (most recent call last):
              File "<stdin>", line 1, in <module>
            ImportError: No module named igraph


  another try : http://stackoverflow.com/questions/25728531/cant-import-igraph-python2-7-after-installing-on-osx
     brew install homebrew/science/igraph like posed here and linked the formula with brew link igraph and it brewed with no problems.


      I realize I have pipi and python through anaconda so I googles igraph anaconda nad find this : http://lists.nongnu.org/archive/html/igraph-help/2013-08/msg00056.html

      with among aother says that the probem is:

      "Well, the happiness was short-lived.  The re-install of libtool solved"

      So I have to resintall libtool which used to cpme with Xcode ...: install libtool macos : 

      http://www.jattcode.com/installing-autoconf-automake-libtool-on-mac-osx-mountain-lion/

      so : 

      curl -OL http://ftpmirror.gnu.org/autoconf/autoconf-2.69.tar.gz
          curl -OL http://ftpmirror.gnu.org/autoconf/autoconf-2.69.tar.gz
          tar -xzf autoconf-2.69.tar.gz 
          cd autoconf-2.69
          ./configure && make && sudo make install
           
          curl -OL http://ftpmirror.gnu.org/automake/automake-1.14.tar.gz
          tar -xzf automake-1.14.tar.gz
          cd automake-1.14
          ./configure && make && sudo make install
           
          curl -OL http://ftpmirror.gnu.org/libtool/libtool-2.4.2.tar.gz
          tar -xzf libtool-2.4.2.tar.gz
          cd libtool-2.4.2
          ./configure && make && sudo make install

          everyhting seems ok !!

brew install homebrew/science/igraph
Warning: igraph-0.7.1 already installed, it's just not linked


from https://github.com/igraph/igraph/issues/538: seems to need igraph C library...

http://igraph.org/c/ 

You can use the regular Unix way (as above), or Homebrew, the homebrew/science/igraph formula.

 

=========================
pare to 1/10 ..subset gia 
scp backup to dataset 


datasset me tous 1ous n users ? 

partial ordering ... graph ? opws mporoume na 
2) eforson exoume link creation ru8mo auxhshs tou twitter + connections 
sto cdf me to 2000 users total : toi sunevei akrives sto shmeio tou s ths gwnias . an einai na ftasei enas xrhsths mexri to 1800 leei as ftasei kai 2000 meta prepei na katavalei mai metaluterh prospa8ei na prosperasei to threshold . (celebrities ? )
xreiazomase mia erwthsh ...

analush ana xwra ? uparxei antistoixo paper pou na kanei to idio ?



poso xrono na kanoume ta dedomena diaxeirisima ? 

imc & sigmentrics 2 deadlinies 
diavase apo ta procedding --related papers ...glwssa ...

----------------
Peirama: 

ekana to peirama pou legame(sorry gia thn ka8usterhsh) 

xreiazomai enan tuxaio xrhsth. Apo tous xrhstes pou exoume hdh katevasei pernw ton 2356958402. Autos exei ws followers tous:

2256400662, 2478801998, 2881274440, 18526909, 1284999673, 2841776049, 22763701, 245520753, 16484374, 390233709, 2181161588, 2315376242, 852039852, 2840753357, 864383419, 2449790401, 224225955, 54852355, 281031538, 1948207765, 69485846, 33360722, 2481255127, 544481207, 630558314, 289272520, 86180752, 28623880, 2213855610, 2360882965, 83987145, 2795391715, 2774095489, 485945367, 17797388, 97398563, 2735202001, 253152325, 190564949, 47553668, 2458231830, 1691841104, 1448924196, 2452872000, 2452874257, 39707999, 1077824294, 712774064, 121131407, 381708550, 2436605492, 2199672295, 2396516720, 774175080, 70105587, 14324284, 1703856740, 30597144, 72464809, 81846137, 62839179, 158539834, 23547345, 112386661, 713851982, 1540566667, 74799761, 41914619, 1887838634, 545483963, 2582456827, 2426899684, 19898016, 1392826357, 39787453, 14267832, 171131696, 2212393613, 313054802, 20444825, 351364190, 133239513, 104211492, 295132630, 29600755, 59587471, 68070319, 1859190696, 2272564039, 2469732464, 17093617, 170024549, 32160273, 37732219, 398890032, 1279964905, 879161563, 294028987, 2363300970, 14503769, 152889033, 2340484741, 17561781, 57030951, 27522668, 2371129262, 9626672, 731244888, 428373620


Sthn synexeia pernw twra to creation_time olwn olwn twn followers tou 2356958402.
Einai sorted me bash to pote egine to link creation kai OXI me bash to user_creation_time
Opote as upo8esoume oti 8eloume na efarmosoume to heuristic gia ton 90sto friend tou 2356958402
pairnoume loipon to creation time olwn twn followers pou kanan follow ton 2356958402 apo ton prwto mexri kai ton 90sto
kai pairnoume to pio prosfato:

'Mon Nov 17 16:06:50 +0000 2014'
Opote ena upper bound gia to link creation time meta3y 2356958402 kai tou 90stou tou follower einai to 'Mon Nov 17 16:06:50 +0000 2014'

An efarmoseis to heuristic gia tous  10 prwtous followers to estimation einai:
['Sat Dec 21 12:19:06 +0000 2013', 'Mon May 05 20:12:56 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014', 'Mon Nov 17 16:06:50 +0000 2014']



Twra exoume ena upper bound gia to link creation time meta3y 2356958402 kai twn followers.

Mporw na efarmosw thn idia texnikh kai gia tous friends. 

To heuristic auth thn stigmh to trexw ston cluster (UB).   

-------------------------
----------
Exoume katevasei 277.908.000 user objects. Dld exoume ta meta-data (creation_time, location,…) gia olous autous tous xrhstes.

Alla mporoume na trexoume to heuristic gia tous ~12.000.000 ekatomuria xrhstes pou exoume tous following / followers.

Dhladh: Katebasame gia 12M users tous friends/followers. Oi friends/followers autwn twn 12M xrhstwn periexoun 350M diaforetika user ids kai emeis mporesame na katebasoume ta user_objects twn 278M apo autous (prin mas kopsei to twitter)  

Opote twra 8a efarmosoume to heuristic gia tous 12.000.000 xrhstes . An omws enas apo autous exei enan follower pou den anoikei  tous 278M (dld den prolabame na katebasoume to user object tou) tote to heuristic an kai mporei na efarmostei apla den 8a einai toso akribes.   

Twra koitanw na dw pws 8a proxwrisoume me auta ta data  .

Oson afora to dataset apo to snap, telika eixe Connections: 1.468.365.182 , Nodes: 40.103.281 (xrhstes). 
(To arxeio exei duo ari8mous se ka8e grammh, dld duo sthles, Metrhsa posous diaferika noumera uparxoun sth prwth sthlh
 kai einai 40.103.281, upo8etw einai xrhstes)  

 pare to 1/10 ..subset gia 
scp backup to dataset 
-----------------

* snap dataset : 

 * To arxeio exei duo ari8mous se ka8e grammh, dld duo sthles, Metrhsa posous diaferika noumera uparxoun sth prwth sthlh
 kai einai 40.103.281

* isocial meeting 
* secondment report by june 1 
* progress report --> newsletter --> by February 15 
* newsletter by march 1 
* online courses 

summer school workshop in Crete 21st poster + presenattion
summer school on Big Data in Stockholm 3-14 Aug 2015 : Mining Mssive Datsets 

* Let's fetch for the specific dataset 40.000.000 nodes (snap stanford) the ids and try to infer the date of these links . 
 * dataset available here: http://an.kaist.ac.kr/traces/WWW2010.html
  * let's run teh heuristic for this dataset . 

* heuristic :
    >
    > Και τα δύο μπορούν να χρησιμοποιηθούν με τον ίδιο τρόπο για να
    > βρείς δύο bounds για το creation time ενός link και να παρεις το καλύτερο
    > (πιο
    > πρόσφατο) από τα δύο. Αυτό θα σου δώσει καλύτερο approximation του link
    > creation time.
___________________________________________________________________________________________________
          Το twitter σου δίνει τη λιστα με του followers ενός χρήστη ταξινομημένη σύμφωνα με την χρονική στιγμή που δημιουργήθηκε το link (Δλδ δεν σου δίνει το link creation time, αλλά σου δίνει το χρονικό ordering των links).
      Επίσης το twitter σου δίνει το creation time  κάθε λογαριασμού.


      Ας υποθέσουμε ότι ο Α κάνει follow τον Β
      Ας υποθέσουμε ότι Φ είναι το σύνολο των λογαριασμών που κάνουν follow τον Β.
      Ας υποθέσουμε οτι Φ1,Φ2,Φ3..  ανοίκουν στο Φ και είναι ταξινομημένα ανάλογα με την ημερομηνία που έκαναν follow τον Β.

      Δηλαδή ιχύει: Φ1 < Φ2 < Φ3 < Α < Φ4 ...

      (Δηλαδή: ο Φ1 έκανε follow τον Β, μετά ο Φ2 έκανε follow τον Β, μετά ο Φ3 κτλ)

      Οπότε ισχύει ότι τα παρακάτω events γίναν με χρονολογική σειρά:
      event 1 : Ο πιο πρόσφατος (creation time) από τους Φ1, Φ2, Φ3 (έστω Φπ) έφτιαξε τον λογιαριασμό του.
      event 2 : Ο Φπ έκανε follow τον Β
      event 3 : O A έκανε follow τον Β 

      Άρα ένα κάτω όριο του λink date είναι το event 1:
      Δηλαδή το πιο πρόσφατο creation time των λογαριασμών που κάναν follow τον Β πριν τον Α.

      Δυστυχώς δεν μπορούμε να χρησημοποιήσουμε το αντίστοιχο heuristic για να υπολογίζουμε το πάνω όριο.

      Το καλό είναι ότι έχουμε ένα δημοσιευμένο heuristic για τον υπολογισμό του link creation time.

___________________________________________________________________________________________________

iSocial Crete 
* semi annual report -> newsletter 
* second round of secondments 
* 21-22 May summer school 

 * cd marienbad/save
   * wc -l user_objects_*       3.352.330  total

   * 1.083.702 Auto 8a sou dwsei to plh8os twn xrhstwn gia tous opoious 3eroume to account_creation_time
 * count users downloaded so far:
      cd mariembad/save
    wc -l *.txt  : 9831820 total

* 
-------peirama ---
* Estw 10 nodes Twitter xrhstwn pou exoune katevasei kai ena endexomeno follower f (pou xeroume apo prin) pou na anhkei se olous tous tous followers/folowings twn 10 nodes. 
      * 8a dokimasw na kanw provleyh to creation time tou f .
      * me vash tis gnwstes stimes tou xronou ..ana doume me to mati ti mporw na xerw ...to link pote mporei na dhmiourgh8hke?vazontas lower bounds (me vash to heuristic tou paper : We Know Who You Followed Last Summer: Inferring Social Link Creation Times in Twitter)
-------------

-----------------
                https://twitter.com/jackschofield Joined December 2008  A
                following : Mark Hachman - Joined April 2009    B
                            Cyrus Farivar Joined January 2007   C
                             Natasha Singer - Joined July 2011  D


                             to heuristic :

                             Cyrus Farivar Joined January 2007   C
----------------

    Xreiazesai kai th lista me olous tous friends tou jackschofield

    kai pare tuxaia ena arxeio: save_*

    estw save_lalakislalo1.txt kane less sto arxeio
    kai pare mia grammh (pou na mhn einai polu megalh)

    ["Mon, 01 Dec 2014 12:36:54 +0000", 105867, 2356958402, [245520753, 2878784774, 33360722, 17093617, 480582261, 544481207, 778427430, 938080704, 43208100, 61632434, 630558314, 97398563, 485945367, 47553668, 2735202001, 2436605492, 121131407, 381708550, 2396516720, 2199672295, 70105587, 14324284, 96102210, 9308212, 324176286, 89276951, 388345704, 230944453, 925039052, 41561657, 45373841, 258847118, 15163166, 96294925, 300803303, 543700209, 155230346, 494073170, 52133120, 22023030, 17280969, 10352892, 34617752, 444852917, 1097934120, 969703848, 390959011, 1130798947, 1605867390, 1145952974, 1599066644, 11050032, 1705189098, 19898016, 106580083, 85527065, 1168003974, 317216139, 1509195565, 3795281, 74799761, 1605916658, 1281705354, 20133108, 25819761, 481578520, 935756275, 28654709, 1933604712, 2263467936, 407725357, 856471832, 1244087220, 492248801, 1061929410, 23547345, 88973414, 2209547786, 209983922, 41914619, 859728296, 431560137, 1887838634, 2427702890, 1393678560, 1579125037, 2582456827, 1540566667, 393250237, 2426899684, 487833518, 426909329, 175150751, 285165232, 74171204, 298029693, 25140707, 324896218, 78653568, 32372834, 46371428, 132698610, 112386661, 57463391, 206128869, 324978824, 27116474, 452225824, 54966684, 135528262, 39924174, 377412052, 223916070, 337284096, 28881634, 212299083, 183548902, 96253785, 39787453, 25084400, 40514127, 40517222, 839048401, 277660111, 38148704, 297719472, 191181692, 104211492, 2302136934, 190564949, 44932663, 397764090, 86180752, 852039852, 185910976, 129248147, 1286859991, 243592010, 192347055, 213586183, 1435577916, 343987100, 104597802, 63448334, 231916274, 634325483, 177805965, 606760856, 116867280, 1128132072, 376559783, 36814136, 36504063, 2253786841, 81846137, 313054802, 493170186, 1413359930, 19662097, 2162994943, 75379918, 107682912, 191517678, 17051344, 346740364, 16484374, 253184910, 17042078, 8842302, 514806103, 93244606, 169633285, 1140028267, 10180222, 208572474, 835653272, 562100356, 262887338, 232318831, 213012200, 34710591, 21928178, 18499709, 211261440, 125680195, 38892114, 180273692, 16960160, 423556756, 17251787, 33279328, 22763701, 15060148, 293116923, 48966898, 199737585, 18058609, 83987145, 29600755, 47983577, 133239513, 16174754, 543876839, 466062053, 575655913, 237409428, 6794502, 216793572, 19704268, 107174526, 19843630, 129842864, 115132543, 33998183, 208988759, 20971256, 14267832, 44438256, 19416598, 203470497, 41592143, 50753411, 20444825, 123582098, 17248121, 29812651, 20746400, 58788614, 37334808, 20750406, 492806249, 16245822, 18198832, 31461371, 38489678, 8963722, 32624460, 86626845, 25950355, 56050543, 879161563, 1279964905, 1499192467, 274132854, 562335280, 2363300970, 32427234, 82336717, 56564230, 275690183, 62862144, 124237063, 56685979, 44418062, 29726578, 200634860, 146569971, 130241862, 17561781, 731244888, 9626672, 2371129262, 228586748, 17047208, 15862891, 16629477, 21237486, 56384845, 34675456, 32615991, 33838201, 31484145, 15755223, 19658826, 17089636, 18247542, 16150688, 22019881, 22497950, 20278673, 57030951, 26832834, 16274109, 14738561, 9780512, 37732219, 18168650, 56593116, 63368894, 71210524, 50318478, 15154811, 14085070, 23962312, 12819112, 71323069, 34222024, 67003972, 28173220, 65713027, 60633599, 20410279, 85906238, 65712206, 67432574, 108185297, 127910801, 259277766, 56378468, 25550217, 152889033, 51198116, 46478786, 117064656, 90699238, 141242032, 50014224, 428373620, 171566372, 937570435, 46145761, 39694489, 185374895, 46034070, 282180852, 266223488, 171411817, 95610582, 177502839, 257482404, 115039678, 223560830, 32160273, 63837338, 74690215, 318053222, 35306978], [2256400662, 2478801998, 2881274440, 18526909, 1284999673, 2841776049, 22763701, 245520753, 16484374, 390233709, 2181161588, 2315376242, 852039852, 2840753357, 864383419, 2449790401, 224225955, 54852355, 281031538, 1948207765, 69485846, 33360722, 2481255127, 544481207, 630558314, 289272520, 86180752, 28623880, 2213855610, 2360882965, 83987145, 2795391715, 2774095489, 485945367, 17797388, 97398563, 2735202001, 253152325, 190564949, 47553668, 2458231830, 1691841104, 1448924196, 2452872000, 2452874257, 39707999, 1077824294, 712774064, 121131407, 381708550, 2436605492, 2199672295, 2396516720, 774175080, 70105587, 14324284, 1703856740, 30597144, 72464809, 81846137, 62839179, 158539834, 23547345, 112386661, 713851982, 1540566667, 74799761, 41914619, 1887838634, 545483963, 2582456827, 2426899684, 19898016, 1392826357, 39787453, 14267832, 171131696, 2212393613, 313054802, 20444825, 351364190, 133239513, 104211492, 295132630, 29600755, 59587471, 68070319, 1859190696, 2272564039, 2469732464, 17093617, 170024549, 32160273, 37732219, 398890032, 1279964905, 879161563, 294028987, 2363300970, 14503769, 152889033, 2340484741, 17561781, 57030951, 27522668, 2371129262, 9626672, 731244888, 428373620]]


Loipon o xrhsths: 2356958402 Exei ws followers tous:

2256400662, 2478801998, 2881274440, 18526909, 1284999673, 2841776049, 22763701, 245520753, 16484374, 390233709, 2181161588, 2315376242, 852039852, 2840753357, 864383419, 2449790401, 224225955, 54852355, 281031538, 1948207765, 69485846, 33360722, 2481255127, 544481207, 630558314, 289272520, 86180752, 28623880, 2213855610, 2360882965, 83987145, 2795391715, 2774095489, 485945367, 17797388, 97398563, 2735202001, 253152325, 190564949, 47553668, 2458231830, 1691841104, 1448924196, 2452872000, 2452874257, 39707999, 1077824294, 712774064, 121131407, 381708550, 2436605492, 2199672295, 2396516720, 774175080, 70105587, 14324284, 1703856740, 30597144, 72464809, 81846137, 62839179, 158539834, 23547345, 112386661, 713851982, 1540566667, 74799761, 41914619, 1887838634, 545483963, 2582456827, 2426899684, 19898016, 1392826357, 39787453, 14267832, 171131696, 2212393613, 313054802, 20444825, 351364190, 133239513, 104211492, 295132630, 29600755, 59587471, 68070319, 1859190696, 2272564039, 2469732464, 17093617, 170024549, 32160273, 37732219, 398890032, 1279964905, 879161563, 294028987, 2363300970, 14503769, 152889033, 2340484741, 17561781, 57030951, 27522668, 2371129262, 9626672, 731244888, 428373620


pare twra to creation_time olwn autwn
cd phd codde
python 

user_lists = [2256400662, 2478801998, 2881274440, 18526909, 1284999673, 2841776049, 22763701, 245520753, 16484374, 390233709, 2181161588, 2315376242, 852039852, 2840753357, 864383419, 2449790401, 224225955, 54852355, 281031538, 1948207765, 69485846, 33360722, 2481255127, 544481207, 630558314, 289272520, 86180752, 28623880, 2213855610, 2360882965, 83987145, 2795391715, 2774095489, 485945367, 17797388, 97398563, 2735202001, 253152325, 190564949, 47553668, 2458231830, 1691841104, 1448924196, 2452872000, 2452874257, 39707999, 1077824294, 712774064, 121131407, 381708550, 2436605492, 2199672295, 2396516720, 774175080, 70105587, 14324284, 1703856740, 30597144, 72464809, 81846137, 62839179, 158539834, 23547345, 112386661, 713851982, 1540566667, 74799761, 41914619, 1887838634, 545483963, 2582456827, 2426899684, 19898016, 1392826357, 39787453, 14267832, 171131696, 2212393613, 313054802, 20444825, 351364190, 133239513, 104211492, 295132630, 29600755, 59587471, 68070319, 1859190696, 2272564039, 2469732464, 17093617, 170024549, 32160273, 37732219, 398890032, 1279964905, 879161563, 294028987, 2363300970, 14503769, 152889033, 2340484741, 17561781, 57030951, 27522668, 2371129262, 9626672, 731244888, 428373620]
>>> len(user_lists)
109
>>> len(user_lists)
109
user_lists_1 = user_lists[0:100]
>>> len(user_lists_1)
100
user_lists_2 = user_lists[ 100 : ]
>>> len(user_lists_2)
9
>>> 
from marienbad import get_users_objects
pip install ntplib (se terminal)

/Users/antonakd/anaconda/bin/pip install ntplib

user_object_1 = get_users_objects(user_lists_1, account_name='despantonak@gmail.com_11012015_9')
user_object_2 = get_users_objects(user_lists_2, account_name='despantonak@gmail.com_11012015_9')
auta einai ta user_objects dld olh h metaplhroforia twn users
Twra pairnoume ta creation times:


Katarxhn as ta enwsoume:
user_objects = user_object_1 + user_object_2


len(user_object_1)
100
len(user_object_2)
9


Sth sunexeia as paroume ta creation times:

creation_times = [x['created_at'] for x in user_objects]
creation_times[:10] 


 mporoume na ta metatrepsoume twra apo string se unix_epochs
etsi wste na mporoume na kanoume sugkriseis:


from marienbad import get_tweet_date

creation_times_epochs = [get_tweet_date(x) for x in creation_times]

 twra exoume to creation time olws twn followers tou 2356958402
O 2356958402 einai o arxikos user

einai sorted me bash to pote egine to link creation kai OXI me bash to user_creation_time
Opote
As upo8esoume oti 8eloume na efarmosoume to heuristic gia ton 90sto friend tou 2356958402
pairnoume loipon to creation time olwn twn followers pou kanan follow ton 2356958402 apo ton prwto mexri kai ton 90sto:

creation_times_epochs[:90]

kai pairnoume to pio prosfato:

max(creation_times_epochs[:90])

1416233210.0 gia na to metatrepsoume: 

import time
>>> time.strftime('%a %b %d %H:%M:%S +0000 %Y', time.localtime(1416233210.0))
'Mon Nov 17 16:06:50 +0000 2014'
>>> 

Opote ena upper bound gia to link creation time meta3y 2356958402 kai tou 90stou tou follower einai to 'Mon Nov 17 16:06:50 +0000 2014'

Pame na to efarmosoume twra gia olous tous followers tou 2356958402
kai oxi mono gia ton 90sto

heuristic_all = [max(creation_times_epochs[:i+1]) for i in xrange(len(creation_times_epochs))]
kai twra metatrepoume olon ton pinaka apo epochs se strings:

from_epochs_to_string = lambda x :  time.strftime('%a %b %d %H:%M:%S +0000 %Y', time.localtime(x))
auto einai to idio me:
def from_epochs_to_string(x):    return time.strftime('%a %b %d %H:%M:%S +0000 %Y', time.localtime(x))

twra mporw na kanw:

heuristic_all_string = [from_epochs_to_string(x) for x in heuristic_all]

Gia des ta prwta 10..

heuristic_all_string[0:10]

apla mporeis na to efarmoseis auto kai stous friends oxi mono stous followers. Dld:



---------------------------
http://silo.bennington.edu/the-topology-of-human-networks-online/


  * pws vlepeis gia posous xrhstes exei trexei to heuristic?
   * cd marienbad/save
   * wc -l user_objects_*    1827427 total

   * 1.083.702 Auto 8a sou dwsei to plh8os twn xrhstwn gia tous opoious 3eroume to account_creation_time
 * count users downloaded so far:
      cd mariembad/save
    wc -l *.txt  : 9831820 total

  * Metrics for new paper?:

      Task 1: 
        * kane mia lista me ola ta measurements pou mporoume na trexoume gia to 1% tou grafou pou exoume katevasei  
        *cdf : followers/ following  small world problems 
        * connected components cliques ?
        * six degrees of separation ?
        * apostaseis se ola ta zeugh komvwn 
        * modularity 
        * cdf apostaswns se ola ta zeugh komvwn 
        Look at:
        * sigcomm imc <-- social networking papers 
        * http://www.francescobonchi.com/
        * http://www.cs.cmu.edu/~christos/PUBLICATIONS/sigcomm99.pdf
        * International World Wide Web Conference
        * kdd
        Confirm that the network follows the classic rules: 
          * a)“six degrees of separation”  by Milgram [S. Milgram, The Small World Problem, Psychol. Today 1, 61 (1967). [16] J. Travers, S. Milgram, J. Travers, and S. Milgram, An Experimental Study of the Small World Problem, Sociometry 32, 425 (1969). [17] M. Newman, A.-L. Barabási, and D. J. Watts, The Structure and Dynamics of Networks (Princeton University Press, Princeton, 2006). [18] R. Albert, H. Jeong, and A. L. Barabasi, The Diameter of the World Wide Web, Nature (London) 401, 130 (1999).] 
       
          b) the “strength of weak ties” by Granovetter [M. S. Granovetter, The Strength of Weak Ties, Am. J. Sociology 78, 1360 (1973). [21] N. Friedkin, A Test of Structural Features of Granovetter’s Strength of Weak Ties Theory, Soc. Networks 2, 411 (1980). [22] L. Lü and T. Zhou, in Proceedings of the 1st ACM International Workshop on Complex Networks Meet In- formation, CNIKM’09 (ACM, New York, 2009), pp. 55–58. [23] J.-P. Onnela, J. Saramäki, J. Hyvönen, G. Szabó, D. Lazer, K. Kaski, J. Kertész, and A.-L. Barabási, Structure and Tie Strengths in Mobile Communication Networks, Proc. Natl. Acad. Sci. U.S.A. 104, 7332 (2007). [24] M. Szell, R. Lambiotte, and S. Thurner, Multirelational Organization of Large-Scale Social Networks in an Online World, Proc. Natl. Acad. Sci. U.S.A. 107, 13 636 (2010).]

          Detailed experiments [Leskovec, Kleinberg, and Faloutsos in Refs: [J. Leskovec, J. Kleinberg, and C. Faloutsos, Graph Evolu- tion: Densification and Shrinking Diameters, ACM Trans. Knowl. Discov. Data 1, 2 (2007). [34] J. Leskovec, J. Kleinberg, and C. Faloutsos, in Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD’05 (ACM, New York, 2005), pp. 177–187.] prove that the evolution of an OSN follows the steps: 


          Kolja's paaper refers to  two parameters expressed by λ, μ the virality and the mass medi influence.these 2 params play a complementary role on the tpologicaal growth of the graph. Each user of the OSN can either be susceptible (not members of sn), active and passive. Worth exprloring?



  * Notes from paper : "...such temporal evolution follows an intricate path: an initial phase where the social graph is made of small clusters with increasing diameter and average degree, followed by a dynamical percolation transition and, finally, an epoch of increasing average degree and shrinking diameter, akin to the observations by Leskovec, Kleinberg, and Faloutsos in Refs.


  * count users downloaded so far:
      cd mariembad/save
    wc -l *.txt

  * Heuristic implementation 
    San argument tou dinoume to plh8os apo clients pou 8eloume na trexei (posa dld accounts apo to domain = heuristic)

    MAIN THREAD:
    To programma parsarei ta arxeia pou exoume katebasei kai einai sto format:

    [user_id, user_order, timestamp, [user_friends],[user_followers]]

    Ka8e grammh (dld ka8e use_id) pou diabazei th bazei se ena queue A
    sth synexeia parnei ola ta ids (dld: user_id + user_friends + user_followers) kai ta bazei se ena allo queue B.
    Yparxei kai ena HashTable C ulopoihmeno se sqlite (https://pypi.python.org/pypi/sqlitedict) .  Auto to hashtable 8a krataei ta creation_times twn ids. 

    GIA KA8E CLIENT SIKWNOUME ENA THREAD TO OPOIO:
    diabazei ids apo to B. Sth synexeia gia ka8e id koitazei na dei an uparxei sto C. An den yparxei tote to apo8ikeuei se enan pinaka. Otan autos o pinakas ftasei ta 100 ids (maximum ids gia to twitter API: https://dev.twitter.com/rest/reference/get/users/lookup) tote rwtaei to twitter API gia ta user objects autwn twn 100 ids (user objects einai mia domh pou periexei meta-info opws creation_time, locations, ...). Sth synexeia apo8ikeuei ta creation_times autwn twn 100 ston C. Epishs apo8ikeuei ta user objects se ena arxeio. 

    EPISHS SIKWNOUME ENA EPIPLEON THREAD TO OPOIO:
    Diabazei tis grammes apo to queue A. Gia ka8e grammh pairnei ta user_id, user_friends, user_followers. Sth synexeia gia olous autous tous users psaxnei na brei to creation_time sto C. An den to brei tote perimenei 5 seconds kai 3anaprospa8ei. Molis brei to creation time, upologizei ta heuristics. dld upologizei ena lower bound gia to link creation time gia ka8e follower kai gia ka8e friend tou user_id. Sth shnexeia apo8ikeuei to bounds se ena arxeio creation_time_heuristic.cth 

    Notes:
    Giati tosh poluplokothta?? 

    (1) Auth einai h optimum lush h opoia egkuatai oti 8a kanoume minimize ta queries pros to twitter.  Ola ta queriese periexoun ton maximum ari8mo apo ids (100). An dld enas user exei 2 follower kai 2 friends (4 sunolo) tote den 8a kanoume query to twitter an den gemhsoume kai allous user mexri to 100.

    (2) me th xrhsh tou C egkuomaste oti den 8a rwtisoume duo fores to twitter gia ton idio xrhsth. O C parolo pou ton xrhsimopoioume ws hashtable, apo8ikeuetai ston disko. Opote mporei na einai oso gematos 8eloume (apo prohgoumenh empeiria 3eroume oti den mporoume na exoume hashtable megalitero apo 100.000.000 keys)

    (3) Epishs efarmozoume to heuristic thn wra pou katebazoume ta data. Ara den xreiazetai na 3anaparsaroume ta data.

* 15/1/2015
 * sunanthsh me Vivi sotiri : 
  * heuristic
  * algorithm of Kolja? read paper or ask him ..is it a specific algorihm that can be found in another library like igraph or is it custom ?

Measurement metrics:
    *  http://www.francescobonchi.com/

    
    * Aggregate Characterization of User Behavior in Twitter and Analysis of the Retweet Graph:
         * autos edw exei polla datasets ...worth exploring ?
         * epishs ola ayta ta peiramata ta trexei se tweets dataset. mhpws na ta trexoume sto allo dataset pou exoume ? an kai einai se trendng topics ...
         * lifetime tweet distribution is a type-II discrete Weibull stemming from a power law hazard function,
         *  the tweet rate distribution, although asymptotically power law, exhibits a lognormal cutoff over finite sample intervals, 
         * and the intertweet interval distribution is power law with exponential cutoff.
         * The retweet graph is small-world and scale-free, like the social graph, but is less disassortative and has much stronger clustering.
         * The retweet graph is small-world and (roughly) scalefree, like the social followers graph, but less disassortative and more highly clustered. It is more similar than the followers graph to real-world social networks, consistent with better reflection of real-world relationships and trust.(Section VI)
         * Critique of Previously-Reported Power Law Behavior
         * TABLE II: Power-Law Exponents for Lifetime Contributions in Various Online Communities, Computed Incorrectly Using Equal-Count Binning
         * Fig. 3: The probability that a user who has sent x tweets quits without sending another, i.e., the hazard rate. The decreasing trend suggests a sort of momentum; the more times a user has tweeted, the more likely he is to tweet again. The power law parameters are calculated from Table III, not fit to the data.
         * Fig. 4: Distribution of tweets per user for the four month period from June through September 2012.
         * Fig. 5: Distribution of tweet counts over various sample periods, showing the time-dependent cutoff. The asymptotic distribution is Pareto. Traces for the urn model describing this effect were obtained by simulation.
         * Fig. 6: Distributions for tweets sent, retweets sent, and times retweeted for the 1 week and 4 month samples. All categories show similar time-dependent phase changes, suggesting the same underlying mechanism. Retweets differ from tweets only in a lower average rate (parameter c in the urn model).
         * Fig. 7: The interevent distributions with users grouped by number of tweets for the three month period covering June through August 2009. The line is a best-fit power law with exponential cutoff.
         * Fig. 8: The interevent distributions of Figure 7 collapse when scaled by the group’s average interevent duration, ∆Ta. The line is a best-fit power law with exponential cutoff.
         * Fig. 9: Distribution of number of edge weights in the retweet graph, corrected using the EM method. A directed edge indicates that one user retweeted another and the weight is the number of such retweets.
         * Fig. 10: In and out degree distributions for the retweet graph. Both exhibit the double-Pareto behavior common to evolving networks [38], [41]. In the upper tail, the in-degree power-law exponent is 2.2 and 3.75 for the out-degree.
         * Fig. 11: Distribution of average path length (degree of sepa- ration) in edge-sampled retweet graph. The gray line is the estimated distribution for the full graph.
         * Fig. 12: Directed assortativities r as a function of edge sampling rate. Edge sampling does not affect assortativity because all node degrees are sampled independently and identically.
         * Fig. 13: Directed assortativity r of the retweet graph and the social following graph. The retweet graph has higher assortative, more consistent with real world social networks than most online social networks
         * Fig. 14: The four types of open (solid edges) and closed (solid and dashed edges) directed triplets used for cluster analysis. A vertex can form up to eight such triplets with each pair of neighbors, two of each type. The clustering coefficient Cβ∈{cycle, middleman, in, out} is the fraction of β-triplets (open and closed) that are closed
         * Fig. 15: The clustering coefficient estimator C􏰑 􏰒 1 C as a α function of edge sampling rate on the social “following” graph. Although potentially biased, the estimator is quite accurate for such graphs.
         * Fig. 16: Clustering coefficients for the social “following” graph and the retweet graph. Clustering is significantly more prominent in the retweet graph and more consistent with real- world social networks.
         * Fig. 17: Portion of a retweet graph showing how spammers are less connected. Non-spammer B is connected to non-spammer A by three independent paths, the shortest of which has length two. Spammer S is connected by only a single length-three path.
         * Fig. 18: Percentage of removed and extant Twitter users as a function of distance from benign users in the retweet graph. Most removed users are spammers, so this graph shows that distance is highly correlated with spammer behavior.
         * Fig. 19: Illustration of the modified R-MAT algorithm for generating synthetic retweet graphs and a resulting adjacency matrix. Fewer edges are placed in the benign–spam quadrant to model the lower likelihood of such retweets. Within each quadrant, edges are cascaded in proportion to probabilities a, b, c, and d to generate a scale-free, small-world structure.
         * Fig. 20: Connectivity of benign pairs as a function of the benign edge density. Above 5%, almost all pairs are connected. We expect that density does not grow with network size, so this limits the network size for which the false positive rate is acceptable. For large networks, the technique will only work within clusters.
         * Fig. 21: Performance of J48 classifier over distance and connectivity attributes in the synthetic graphs. The benign edge density (marker symbol and color) range from 0.00002 to 0.003 and the number of B–S edges per spammer node (marker size) ranges from 0.01 to 1. Each marker is a single point on the resulting ROC curve.


    * We Know Who You Followed Last Summer: Inferring Social Link Creation Times in Twitter
        *  propose a method for Twitter’s social network that takes a single static snapshot of network edges and user account creation times to accurately infer when these edges were formed.
        * study the celebrity subgraph formed by the 1508 accurate celebrities found in Section 4.2: 
         * We focus largely on temporal analyses of this subgraph as this is the novel information provided by our method.
         * Broad analysis of celebrity subgraph
           * The left window of Figure 3 displays the fraction of celebrities with greater than k followers as a function of k.
           * The right window of Figure 3 displays the fraction of users following k celebrities as a function of k on a loglog scale.
           * The complementary cumulative distribution function for the number of followers of a celebrity.
           * The total celebrity follow rate (follow events per hour) and Twitter account creation rate (accounts created per day) over time.
           * Impact of the Suggested Users List :Given that the overall celebrity follow rate halved when Twitter switched to the categorical suggested users list, it is clear that being on the suggested users list increases the acquisition of new followers substantially.
           * The fraction of follow events for each celebrity per day as a function of time. The three labeled grey lines are the times of the interface changes described in Sec. 5.1.
           * following latency: In our theoretical analysis, users’ following behavior is determined by a latency distribution
           * We examine the actual latency of users, the differences between their account creation time and following time.
           So instead we measure the conditional probability that a user waits t seconds to follow the celebrity given that they follow the celebrity within a month of account creation. 
           Figure 6: The number of follow events binned by hour as a function of latency for the follow events of users created before September 1, 2010.
           * Figure 7: A heatmap of the creation time versus follow time over all celebrities with latencies greater than one day on a log-scale. The hours represent the GMT timezone.
           * The relative popularity as a function of time for five celebrities. The random attachment prediction is shown in bold. Labeled arrows corre- spond to events discussed in the text.
        -------

maiil to Marian: 

hello Marian!
happy new year! 

I have some notes about the current progress:
We are currently downloading with 1.000.000 users/day
We have already obtained aproximatelly 6.000.000 users. This makes the 1% of our target (645,750,000)
We can increase this rate if we add more account (I have added so far:~1200)(it would help if you could provide me some accounts in Twitter :) 

I want to run a simple experiment on this dataset, so could you provide me, if it is possible the algorithms that you run on Pokec http://complex.ffn.ub.es/~mbogunya/archivos_cms/files/PhysRevX.4.031046.pdf. I could also give you instruction on how to access the data on the cluster, and run it yourself. 

-----------------------
mail :
 * Parathrhseis :
    * Den 3erw an to ka8e node exei monadika ips logika exoun  mporeis na deis omws posa nodes einai apo ta node ids
     * xerw oti ka8e job exei 30 clients pou katebazoun opote afou exw 40 jobs kata meso oro to 24wro p.x. 40 * 30 = 1200
     * Ka8e client katevazei 15 query ka8e 15 lepta , 1 query gia OLOUS tous followers kai 1 query gia followes - 1 query gia OLOUS tous followers kai 1 query gia OLOUS tou followings
     * ara ka8e client katebazei 8 users / 15 lepta (8 = 15/ 2)
     * ara an poume oti exoume kata meso oro 1200 jobs kanw 15 * 1200 ka8e 15 lepta  = 18000 ana 15 lepta 
      * h mera exei 24 wres=24*60 = 1440 lepta = 96.. 15lepta, ara to 24wro kanw 18000* 96= 1.728.000 queries  to 24wro 
     * an to query katebasei panw apo 5000 tote 8ewroume oti einai celebrity kai ton petame
     * To ka8e query mporei na katebasei mexri to polu 5000 . An exei parapanw tote emeis den kanoume allo query alla t markaroume ws celebrity 

     *  Otan enas xrhsths xasei ena follower followee, pws diaxeirizomaste ta updates sto grafo:
        *  prepei na tous katebaseis olous, emeis exoume parei ena aplo instance tou grafou, den uparxei tropos na kanoume update tis listes me tous followers/followings xwris na 3anakatebasoume ooolo ton grafo

Task 1: 
    * kane mia lista me ola ta measurements pou mporoume na trexoume gia to 1% tou grafou pou exoume katevasei  
    *cdf : followers/ following  small world problems 
    * connected components cliques ?
    * six degrees of separation ?
    * apostaseis se ola ta zeugh komvwn 
    * modularity 
    * cdf apostaswns se ola ta zeugh komvwn 
    Look at:
    * sigcomm imc <-- social networking papers 
    * http://www.francescobonchi.com/
    * http://www.cs.cmu.edu/~christos/PUBLICATIONS/sigcomm99.pdf
    * International World Wide Web Conference
    * kdd
    Confirm that the network follows the classic rules: 
      * a)“six degrees of separation”  by Milgram [S. Milgram, The Small World Problem, Psychol. Today 1, 61 (1967). [16] J. Travers, S. Milgram, J. Travers, and S. Milgram, An Experimental Study of the Small World Problem, Sociometry 32, 425 (1969). [17] M. Newman, A.-L. Barabási, and D. J. Watts, The Structure and Dynamics of Networks (Princeton University Press, Princeton, 2006). [18] R. Albert, H. Jeong, and A. L. Barabasi, The Diameter of the World Wide Web, Nature (London) 401, 130 (1999).] 
   
      b) the “strength of weak ties” by Granovetter [M. S. Granovetter, The Strength of Weak Ties, Am. J. Sociology 78, 1360 (1973). [21] N. Friedkin, A Test of Structural Features of Granovetter’s Strength of Weak Ties Theory, Soc. Networks 2, 411 (1980). [22] L. Lü and T. Zhou, in Proceedings of the 1st ACM International Workshop on Complex Networks Meet In- formation, CNIKM’09 (ACM, New York, 2009), pp. 55–58. [23] J.-P. Onnela, J. Saramäki, J. Hyvönen, G. Szabó, D. Lazer, K. Kaski, J. Kertész, and A.-L. Barabási, Structure and Tie Strengths in Mobile Communication Networks, Proc. Natl. Acad. Sci. U.S.A. 104, 7332 (2007). [24] M. Szell, R. Lambiotte, and S. Thurner, Multirelational Organization of Large-Scale Social Networks in an Online World, Proc. Natl. Acad. Sci. U.S.A. 107, 13 636 (2010).]

      Detailed experiments [Leskovec, Kleinberg, and Faloutsos in Refs: [J. Leskovec, J. Kleinberg, and C. Faloutsos, Graph Evolu- tion: Densification and Shrinking Diameters, ACM Trans. Knowl. Discov. Data 1, 2 (2007). [34] J. Leskovec, J. Kleinberg, and C. Faloutsos, in Proceedings of the Eleventh ACM SIGKDD International Conference on Knowledge Discovery in Data Mining, KDD’05 (ACM, New York, 2005), pp. 177–187.] prove that the evolution of an OSN follows the steps: 


      Kolja's paaper refers to  two parameters expressed by λ, μ the virality and the mass medi influence.these 2 params play a complementary role on the tpologicaal growth of the graph. Each user of the OSN can either be susceptible (not members of sn), active and passive. Worth exprloring?

1)Initially a small number of nodes consist the network. This cluster has increasing diameter and average degree,. 
2)The next phase inclludes a dynamic percolation 
3)the final epoch includes the shrinking diameter

 
Task 2 :
    * Tha paroume  ena tuxaio  xrhsth kai 8a  xekinhsoume apo edw na katevazw apo to aneipero gia na valw allh mia skopia tou grafous 

Task 3 - Peirama:
      * Katarxhn 8a rwthsw ton Marian an exei tous algori8mous pou etrexe gia to Pokec() sloveniko facebook): http://complex.ffn.ub.es/~mbogunya/archivos_cms/files/PhysRevX.4.031046.pdf:
      * Estw 10 nodes Twitter xrhstwn pou exoune katevasei kai ena endexomeno follower f (pou xeroume apo prin) pou na anhkei se olous tous tous followers/folowings twn 10 nodes. 
      * 8a dokimasw na kanw provleyh to creation time tou f .
      * me vash tis gnwstes stimes tou xronou ..ana doume me to mati ti mporw na xerw ...to link pote mporei na dhmiourgh8hke?vazontas lower bounds (me vash to heuristic tou paper : We Know Who You Followed Last Summer: Inferring Social Link Creation Times in Twitter)
       * pare ton algori8mo tou Marian kai trexe to
       * vale meta to pragmatiko xrono dhmiourgias kai xana trexe tous algori8mous tou

-----------------
Apanthsh 
 * den 3erw an to ka8e node exei monadika ips logika exoun  mporeis na deis omws posa nodes einai apo ta node ids
 * me qstat mou leei ka8e grammh ena job - ka8e job exei 30 clients pou katebazoun opote p.x. 40 * 30 = 1200
 * Ka8e client katevazei 15 query ka8e 15 lepta , 1 query gia OLOUS tous followers kai 1 query gia followes - 1 query gia OLOUS tous followers kai 1 query gia OLOUS tou followings
 * ara ka8e client katebazei 8 users / 15 lepta (8 = 15/ 2)
 * ara an poume oti exoume kata meso oro 1200 jobs kanw 15 * 1200 ka8e 15 lepta  = 18000 ana 15 lepta 
  * h mera exei 24 wres=24*60 = 1440 lepta = 96.. 15lepta, ara to 24wro kanw 18000* 96= 1.728.000 queries  to 24wro 
 * an to query katebasei panw apo 5000 tote 8ewroume oti einai celebrity kai ton petame
 * To ka8e query mporei na katebasei mexri to polu 5000 . An exei parapanw tote emeis den kanoume allo query alla t markaroume ws celebrity 
 * mporoume na paroume  ena tuxaio kinezo xrhsth kai na  xekinhsoume apo edw na katevazw apo to aneipero gia na valw allh mia clique tou grafou mia kai exw arxisei na katevaze gai mena ston cluster?
   * mporoume na auzxhsouem to ru8mo epi 10 ? OXI 
* otan enas xrhsths xasei ena follower followe, pws diaxeirizomaste ta updates sto grafo
ta update twn link ()? an xasw ena follower ? Prepei na katevasw olo to x, followers svhsontai, neous followes prosti8enati...
 *  prepei na tous katebaseis olous, emeis exoume parei ena aplo instance tou grafou, den uparxei tropos na kanoume update tis listes me tous followers/followings xwris na 3anakatebasoume ooolo ton grafo
 * trexe to exhs peirama: 
  * Katarxhn 8a rwthsw ton Marian an exei tous algori8mous pou etrexe gia to Pokec() sloveniko facebook): http://complex.ffn.ub.es/~mbogunya/archivos_cms/files/PhysRevX.4.031046.pdf:
  * Estw 10 nodes Twitter xrhstwn pou exoune katevasei kai ena endexomeno follower f (pou xeroume apo prin) pou na anhkei se olous tous tous followers/folowings twn 10 nodes. 
  * 8a dokimasw na kanw provleyh to creation time tou f .
  * me vash tis gnwstes stimes tou xronou ..ana doume me to mati ti mporw na xerw ...to link pote mporei na dhmiourgh8hke?vazontas lower bounds (me vash to heuristic tou paper : We Know Who You Followed Last Summer: Inferring Social Link Creation Times in Twitter)
   * pare ton algori8mo tou Marian kai trexe to
   * vale meta to pragmatiko xrono dhmiourgias kai xana trexe tous algori8mous tou



 * mail sotiri  vhttp://www-kdd.isti.cnr.it/~berlingerio/papers/is20102.pdf
-----------------------
sunanthsh ViVi Sotiris 12/1
----------------
cdf : followers folowing  small world problems (oi dikes mas)

mporoume na xanaxekinhsoume apo allo xrhsth?

connected components cliques ?

six degrees of seperation ?

apostaseis se ola ta zeugh komvwn 

modularity 

cdf apostaswns se ola ta zeugh komvwn 

IMC social networking papers 

lista me ola ta measurements mexri Paraskeuh gia to 1% 

http://www.francescobonchi.com/
http://www.cs.cmu.edu/~christos/PUBLICATIONS/sigcomm99.pdf

sigcomm imc <--

International World Wide Web Conference
kdd

--------

Katevazoume peripou me 1000 thn wra ? swsta?

1 query to sec  (overall)

moroume na paroume  ena tuxaio kinezo xrhsth kai xekina apo edw na katevazw apo to aneipero gia na valw allh mia clique tou grafou mia kai exw arxisei na katevaze gai mena ston cluster?
epi 10 ..mporoume na auxhsoume ton ru8mo?




----------
peirama me algori8mous tou Marian
------------------
8a ton rwthsw an exei tous algori8mous pou etrexe gia to Pokep() sloveniko facebook)
Estw 10 kuklakia kai ena asteraki(sike pou xeroume hdh) pou na peftei se followers/folowings twn 10
Kuklakia einai oi xrhstes nodes tou twitter pou exoume katevasei tous followers/followes
kai asterakia einai oi followers followes
na kanw provleyh to creation time  tou .
me vash tis gnwstes stimes tou xronou ..ana doum eme to mati ti mporw na xerw ...to link pote mporei na dhmiourgh8hke 
vazonats lower bounds 
pare ton algori8mo tou marian kai trexe to 
vale meta to pragmatiko xrono dhmiourgias (afou einai sike to peirama xeris :)) kai xana trexe tous algori8mous tou 

den xeroume creation times twn *. Prepei 
ta update twn link ()? an xasw ena follower ? Prepei na katevasw olo to x 

tous algori8mous gia to sloveniko mporouem na tosu trexoume ...? 


node 1---> node 2 

creation time node 1 me node x ?

x1 ---> x2 ---> x3 --->x4 --->x5 --->x5 --->
-----------------------> 

estw oti vriskw oti o x1 sundeete me x4, mporw na vrw to creation time (estimate) tou link?

xerw to creation (account) time tou xn followers/followies h 8a prpei ena to katwvasw otan 8a katevasw ton komvo xn

Einai ordered list oi komvoi opwn tous katevazw twra ? Einai oi followers/ followes 
ordered list ta nodes (me vash to cretaion time accunt )
-------------
exume 1262 apps
5,8 ekatomuria exei katevasei -- to 1%
----------------------- 
mail 11/1/2015--------------------------
-----------------------
-----------------------
Kapoia notes sxetika me to current progress:

To downloading phgainei twra me ru8mo 1.000.000 users/day

Exoume katebasei gurw stous 6.000.000 xrhstes. Dld to 1% tou stoxou. (645,750,000 telikos stoxos)
Oso pernaei o xronos omws dhmiourgoume perissotera accounts (so far:~1200) opote perimenoume na anebei kai o ru8mos download. 

Epishs etreja to ejhs peirama: 


Gia olous tous xrhstes pou exoume katebasei pare tous followers/followings tous. Pare omws MONO ta monadika ids. O skopos einai na ftia3oume mia lista me ta ids me olous tous xrhstes tou twitter.

To skriptaki apla ekane parse ta arxeia pou exoume katebasei kai opote eblepe ena id enos follower.following to ebaze se mia domh dedemenwn (hastable).  To scriptaki mporese na apo8ikeusei 100.000.000 ids prin krasarei apo mnhmh, To endiaferon omws htan oti eixe parei tous followers/followings apo mono 450.000 xrhstes otan sunaibei auto. 

Ekana plot to plh8os twn ids pou pairnei kapoios otan kanei query X xrhstes. O grafos autos einai o akolou8os:

Inline image 2

Ta dedomena mporoume na kanoume fit ena power low. 

Sumfwna me auton gia na ftasoume ta 600.000.000 ids xreiazetai na kanoume query 7.200.000 xrhstes.

Dedomenou oti exoume hdh 6.000.000 xrhstes (kai an to fit einai swsto) eimaste konta sto na paroume ta ids apo olous tous users tou twitter.

---------------------- 

Computer Communications is part of the Elsevier publishing company. Elsevier has a big history of policies that are in contrast with academic principles. For a list of these someone could take a look at the wikipedia page: http://en.wikipedia.org/wiki/Elsevier#Criticism_and_controversies 
Having articles paywalled to the public while publicly funded scholars are assigned to do the review (which is the "heavy work" of publishing) is unethical. There is even an open call from academics to boycott Elsevier's titles: http://thecostofknowledge.com/ . 


* 15/12/14


* des latest conferences on social networks big data analysis pou koinountai
* ulopoihse to hueristics kai trexe to se ena mikrotero dataset
* mail ston kolja remonder 
* des xana tis isees pou eixes steilei kai ti mporoume na kanoume 

count users downloaded so far:
    cd mariembad/save
    wc -l *.txt
1033936

start script:

an uparxei tpt periergo sto error:
cat *sh.e*


pame sto marienbad/

cat README.txt 


9 December 

uber security issues

http://www.nytimes.com/2014/12/08/opinion/we-cant-trust-uber.html?smid=tw-share&_r=1

http://venturebeat.com/2013/03/15/uber-rape-charge-highlights-safety-concerns-for-car-hire-startups/

Hello,

On 2/12/13 5:06 PM, Despoina Antonakaki wrote:
Γεια, και ευχαριστώ για το υλικό.

Από την πρώτη ματιά που τους έριξα φαίνονται πολύ ενδιαφέρον! Νομίζω ότι είναι μια καλή ιδέα να ετοιμάζω μία παρουσίαση (σε στυλ journal club) με τις εντυπώσεις μου από την ανάγνωσή τους και να τη παρουσιάσω σε επόμενο telcos. Αυτό το θεωρώ σημαντικό ώστε να πάρω feedback σχετικά με αυτά που έχω κατανοήσει.

Οι ώρες που εμένα με βολεύουν για το εβδομαδιαίο telcos είναι:
Κάποια μεσημεριανή ώρα (αν βολεύει όλους βέβαια) , ίσως κατά τις 12:30 (ώρα Ελλάδος) 
Απογευματινή μετά τις 4 (ώρα Ελλάδος ) 

Θα ήθελα να ζητήσω κάτι ακόμα:

1. Λίστα με τα 2-3 κυριότερα συνέδρια / περιοδικά του τομέα
Ta kuriotera sunedria tou xwrou einai ta ekshs:
Security and Privacy, Usenix Security, CCS, NDSS, ACSAC, RAID
Oson afora periodika,  uparxoun ta Security and Privacy Magazine,  Usenix login ktlp alla genika kalutera na diavazeis
ta paper pou vgainoun se sunedria.


 
2. Αν υπάρχουν κάποια feeds από ενημερωτικά sites / blogs / ... από άτομα / οργανισμούς που δραστηριοποιούνται στον χώρο.
Mia kalh diodos plhroforias einai to Twitter. Mporeis na vreis diaforous pou drasthriopoiountai sto xwro,
ka8ws kai ereunhtikes omades, kai na kaneis subscribe sto feed tous.

Xairetw,
Iasonas


-------------
Δέσποινα στο twitter μπορούμε να ξέρουμε από πια χώρα είναι ένας χρήστης?
Επίσης πόσο fine grain είναι το location information.

Πχ Μπορούμε να ξέρουμε ότι κάποιος είναι από USΑ ή μπορούμε να ξέρουμε και
από ποια πολιτεία της USA είναι?

      Γενικότερα ναι, μπορούμε να ξέρουμε.

    σύμφωνα με το API: https://dev.twitter.com/rest/reference/get/users/lookup
      "created_at": "Mon Feb 26 18:05:55 +0000 2007",
      "location": "San Francisco, CA",

    To location mallon exei na kanei me to ti exei dhlwsei o xrhsths otan ekane sign up 

    Parola auta to API mas epistrefei kai meta-info apo to teleutaio tweet tou xrhsth.
    Opote an exei energopoihsei to :
     "geo_enabled": true,

    Tote mas epistrefei kai ta coordinates tou teleutaiou tweet (mono an to exei steilei apo GPS-enabled device)
    "coordinates":
    {
        "coordinates":
        [
            -75.14310264,
            40.05701649
        ],
        "type":"Point"
    }


--------------------
  me december 1 : 

    Hello,

      I have submitted a number of jobs on the Albeniz cluster in the all.q queue.

    These jobs do not require significant cpu but require a lot of runtime. 

    The task that this job performs is downloading the graph structure of Twitter.
    This task needs to be running as long as possible.
    In the documentation I could not find what is the walltime of all.q so I set my scripts to terminate after 6 hours. 
    Since the expected running time of this task is 1-2 months, this setting holds back a lot my analysis since I will have to resubmit continuously.

    Is there a way to have a longer walltime?
    I have split the task in numerous workers / jobs, so changing the walltime is relatively easy for me.
    The ideal walltime for me would be 7 days.
    This setting would not add significant load to the cluster since my jobs do not do anything cpu demanding.

   Kolja : 
      since some things in the cluster changed recently I am not 100% sure, but jobs usually have no walltime limitation if they are put in the normal queue, called "Exe" (at least on the old cluster). I think that if you do not specify an explicit queue, there should be no limitation. 



1 December : me 

      Γεια,

    Λοιπόν έχω βάλει 100 client στον albeniz cluster.
    Οι clients αυτοί κατεβάζουν μόνο τον social graph του twitter όπως συμφωνήσαμε με τον Μαριάν. 

    Ο ρυθμός που κατεβάζουμε τώρα είναι 600 users / hour 
    Δεδομένου ότι θέλουμε να κατεβάσουμε για εκατοντάδες εκατομύρια χρήστες, θα χρειαστούμε τουλάχιστον 1000 clients ώστε να γίνει αυτό σε διάστημα ~2 μήνες. 

    Σκέφτομαι να στείλω ένα μέιλ σε συνεργάτες / φίλους κτλ ώστε να τους εξηγήσω την διαδικασία για να φτιάξουν keys στο twitter ώστε να μου τα στείλουν και να τα προσθέσω ως clients. 

    Το πλάνο μέχρις στιγμής είναι:
     - Κατεβάζουμε τον social γράφο (δλδ όλους τους χρήστες + friends)
     - Εφαρμόζουμε το heuristic για να βρούμε το link creation time
     - Το στέλνουμε στον Μαριάν για ανάλυση 

    Είπα του Μαριάν να του δώσω τα intermediate data που ήδη έχω ώστε να ξεκινήσει την ανάλυση αλλά είπε ότι προτιμάει να περιμένει τα final 

    Ο Kolja δεν έχει κάνει κάτι μέχρι στιγμής με τα data που του είχα στείλει (= 6 million users)

    Προτείνω να κάνουμε ένα δικό μας πλάνο το οποίο θα το "τρέχουμε" παράλληλα με τον Μαριάν. 

    Βασικές αρχές αυτού του πλάνου μπορεί να είναι:
    - Να βρούμε social stats του twitter (number of followers, followings, celebrities)
    - Πως μπορούμε να κάνουμε visualize (very) big network social graphs?
    - Υπάρχει τρόπος να βρούμε fake accounts απλά από τους friends / followers τους? 
        - Υπόθεση: fake accounts απλά κάνουν follow τυχαίους χρήστες με την ελπίδα ότι και οι χρήστες θα τους κάνουν "follow back"  και έτσι θα λαμβάνουν τα "μηνύματά τους". Μπορούμε να βρούμε χρήστες που δεν ανοίκουν στον social circle των χρηστών που κάνουν follow και να τους κάνουμε flag. 
        - Ένα άλλο είναι χρήστες που όλοι οι followers τους είναι fake accounts  
    - ...
  



-------------------
1500 * 2 + 1100  4100  
300

500 + 300 + 70 * 2= 940

1240 + 4100 = 5340

--screen -r 4163

R:26979969
Adding new user:2869361864      ORDER:26979970
Adding new user:419937679      ORDER:26979971
Adding new user:1279283256      ORDER:26979972
Adding new user:849693271      ORDER:26979973
Adding new user:245237504      ORDER:26979974
Adding new user:168411464      ORDER:26979975
Adding new user:254812379      ORDER:26979976
Adding new user:215147261      ORDER:26979977
Adding new user:211498903      ORDER:26979978
Adding new user:135156582      ORDER:26979979
Adding new user:1360698032      ORDER:26979980
Adding new user:1360574107      ORDER:26979981
Adding new user:1622180688      ORDER:26979982
Adding new user:418568245      ORDER:26979983
Adding new user:115754952      ORDER:26979984
Adding new user:250352185      ORDER:26979985
Adding new user:2841008570      ORDER:26979986
Adding new user:591761728      ORDER:26979987
Adding new user:1726040910      ORDER:26979988
Adding new user:1423688718      ORDER:26979989
Adding new user:2838407857      


25943 - server : [antonakd@nodo00 ~]$ python /users/antonakd/phd/code/marienbad.py --action http_user_server --port 8088 --max_followers 4000



25176 - 
[antonakd@nodo00 code]$ python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name mariolasoumpa1 --max_friends 4000 --max_followers 4000

25230 - 
[antonakd@nodo00 ~]$ python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name lalakislalo  --max_friends 4000 --max_followers 4000

25088 - 
[antonakd@nodo00 ~]$ python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name lalakislalo1 --max_friends 4000 --max_followers 4000

25350 - 
[antonakd@nodo00 ~]$ python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name lalakislalo2 --max_friends 4000 --max_followers 4000

25667 - 
[antonakd@nodo00 ~]$ python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name lalakislalo3 --max_friends 4000 --max_followers 4000

------------

20 000 000  /a week 

645,750,000 / 20  = 32 weeks . 

setting script running on cluster : 

* /users/antonakd/phd/code/marienbad.py --action http_user_server --port 8088 --max_followers 4000

  python /users/antonakd/phd/code/marienbad.py --action http_user_server --port 8088 --max_followers 4000
  Connection established 
  Max order: 18294382
  Max followers (celebrity limit): 4000
  Serving on port: 8088
  serving at port 8088

* python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name despoinalikaki1 --max_friends 4000 --max_followers 4000


python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name despoinalikaki1 --max_friends 4000 --max_followers 4000

python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name papadakdespoina1 --max_friends 4000 --max_followers 4000


python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name mariolasoumpa4 --max_friends 4000 --max_followers 4000

python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name mariolasoumpa1 --max_friends 4000 --max_followers 4000


python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name vlaadoumpa3 --max_friends 4000 --max_followers 4000

vlaadoumpa2
python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name vlaadoumpa2 --max_friends 4000 --max_followers 4000
-----------------------------------------
NOT YET : APO TO telos ta accounts 

-----------------------------------------
    


    python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name papadakdespoina1 --max_friends 4000 --max_followers 4000


    python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name papadakdespoina1 --max_friends 4000 --max_followers 4000


    python /users/antonakd/phd/code/marienbad.py --action get_friends_client --server http://127.0.0.1:8088 --account_name papadakdespoina1 --max_friends 4000 --max_followers 4000


----------------------------------------------------------------------------------

meeting : 
* Is this user a celebrity? (True/False). Has this user more than 4.000 followers? . If a user has more than 4.000 followers is 

--> maybe 1M as threshold 
                -->all username + #of followers
      -->first plot : disrtibution of#folloers 

**
----------------------------------------------------------------------------------
Adding new edge: 16428372 --> 14069302   ORDER: 5000
friends user: 770512 already

set script running on cluster :

    #!/bin/bash
    # The name of the job, can be anything, simply used when displaying the list of running jobs
    ##$ -N program name
    # Giving the name of the output log file
    ##$ -o $JOB_NAME-$JOB_ID.log
    # Combining output/error messages into one file
    ##$ -j y
    # One needs to tell the queue system to use the current directory as the working directory
    # Or else the script may fail as it will execute in your top level home directory /home/username
    #$ -cwd
    # Uncomment the following line if you want to know in which host your job was executed
    echo "Running on " `hostname`
    # Now comes the commands to be executed
    # Copy exe and required input files to the local disk on the node
    cp your_exe $TMPDIR
    cp your_input_file $TMPDIR
    # Change to the execution directory
    #cd $TMPDIR/
    # And run the exe
    #./your_exe
    python /users/antonakd/phd/code/marienbad.py --action http_user_server --port 8088 --max_followers 4000
    # Finally, we copy back all important output to the working directory
    #scp your_output_files.dat  nodo00:$SGE_O_WORKDIR


python /users/antonakd/phd/code/marienbad.py --action http_user_server --port 8088 --max_followers 4000
*********

http://stackoverflow.com/questions/5207013/bash-check-if-pid-exists
    wait $pid
    which will return when $pid finishes.

    Otherwise you can use

    ps -p $pid
    to check if the process is still alive (this is more effective than kill -0 $pid because it will work even if you don't own the pid).


--------------
        Hello everyone,

        I would like to update you on the progress that I have so far on the task of collecting a sub-sample of twitter network.

        Chapter 1 (Really)

        Before we start a bit of terminology (according to the API):
        * if A follows B then:
             A belongs to the followers of B 
             B belong to the friends of A

        The algorithm that I have implemented so far is the following:

        1. Initiate the network with only one user (me!)

        2. For each node of the network I collect:
            - The list of followers (chronologically ordered list according to date of link creation). Lets call this set FOLLOWERS
            - The list of friends (chronologically ordered list according to date link creation). Lets call this set FRIENDS
            All nodes on the network are directed. The edge: A --> B . Means that A follows B
            So after I download the list of followers and the list of friends of a user (let's say me). The network becomes:
            FOLLOWERS --> Me --> FRIENDS 

            For each node we store:
                * user_id (a unique integer provided by twitter)
                * username (twitter's username)
                * account creation time (when this user created his/her account)
                * The data that this user was added to the graph (or else when he was picked by the algorithm)
                * order of addition. The order (Starting from 1) that this user was added to the network. I am #1

                --> maybe 1M as threshold 
                -->all username + #of followers


                * Is this user a celebrity? (True/False). Has this user more than 4.000 followers? . If a user has more than 4.000 followers is marked as celebrity. That means that this node will remain on the network but the algorithm will no look for his/her followers/followings. Since almost all twitter users are following some celebrities, it is very often for our algorithm to choose to update the network with the friends / followers of a celebrity. The problem here is that the followers of a celebrity can be so many (10ths of million for some) that can: (1)  Introduce huge biases on the network and (2) make computationally / storage things very difficult. By excluding these users we focus on studying the behavior of "real-user" while we keep the structure of the network balanced. Many "celebrity" nodes are not even human. For example @twitter has 35.5M followers.   
                * Is this user crawled? (True/False) Have we collected the friends/followers of this user? If not that means that this node was added as a friends/follower of another user. 

            For each edge we collect:
                * The ids of the friend/follower relationship that this edge represents.
                * The friend_order and the follower_order. Suppose that we have the edge A-->B and friend_order is 5 whereas follower_order is 10. That means: B is the 5th friend of A and A is the 10th follower of B. This is very crucial information in order to apply a heuristic to approximate the link creation time. 
                * A list that contains the timestamps when this edge was found by the algorithm. While the algorithm runs it may find the same edge twice. For example in the future we may freeze the number of nodes and we may look for friendship changes on a given set of nodes. Then it is important to note when a friendship was found and when it didn't. So I have four lists:
                    * friend_found, friend_not_found, follower_found, follower_not_found . For example let's say than in day X we find the relationship: A --> B while looking for friends of A. Then on that nodes we add the timestamp of X on the list: friend_found. In another day (Y) we find the same edge (A-->B) while looking on the followers of B. Then we add the timestamp of Y on the list followers_found. Then A decides to unfollow B. Then in day Z while looking for friends of A we do not find B. Then we add the timestamp of Z to the list: friends_not_found. 
                         This is an effort to keep a time-record of the events that happened in our network given the limitations that are imposed by the twitter API.

        3. After updating the friends/followers of all nodes on the network, then GOTO STEP 2. 

        I am running this algorithm since last  week with some interruptions (AKA: bugs..). I have set up 20 twitter client accounts for this purpose. 
        So far the network contains:
         
        nodes: 6.520.263
        Edges: 20.079.014
        Number of nodes that have been crawled: 515.640 . That means that from 6.5M nodes we have follower / following information of 0.5M nodes. 
        Storage taken on HD (mongodb): 24G 
        Time needed to traverse the network: (or else the time that it took to measure the crawled nodes: 3hr, 45minutes)

        Chapter 2
        How do we continue?

        We can continue expanding the networks forever (or as far as we have disk space). But at some time we need to go back and check for the changes that happen on the friendship relationships as time goes by. I guess this is important if we want to study the evolution of the network right?

        I am thinking to froze the network at 10.000.000 nodes. Then the clients, instead of looking for new friends/followers, they will look for changes on the existing network structure. These changes can be: new followings (in and out of the frozen network), unfollowings, account deletions and accounts going private. The code for doing this is ready.

        Of course we can combine both tasks with some tradeoffs / heuristics.

        That's all. Sorry for the long email!

        I am looking forward for your additions / corrections / ideas

        Cheers,
        Despoina


* starting mongo db at UB cluster albeniz: 
  /users/antonakd/mongodb/mongodb-linux-x86_64-2.6.4/bin/mongod --port 27089 --dbpath  /users/antonakd/mongo_data


      ************I send you your username and password for the new albeniz
      The address is albeniz.ffn.ub.es

      User: antonakd
      Password: an1929
      (Change your password using passwd)

      There is a example script in your direftory, model_script.sh

      It has the same type of queues that albeniz2:

      To submit a job in the default queue:
      qsub <script>

      To submit a job in the fast queue (jobs that finish in 12 hours):
      qsub -l fastq=1 <script>

      To submit jobs in parallel( if you are using mpi):
      qsub -pe mpi <numero_procs> <script>

      To see the queue: qstat
      To see the hosts: qhost
      (There is no showq, because is another queue system)

      For now you only can submit 20 jobs for user in each queue

      Luis Expósito.


*********************************

traloma8 eleni kanteraki

 $l#k)%ml1Q

 cluster ub : ssh <username>@albeniz.ffn.ub.es
 User: antonakd
Password: an1929 --> !..albeniz

export PATH=/home/antonakd/mongodb/mongodb-linux-x86_64-2.6.4/bin/:$PATH

********Trying to install anaconda on pandora : 

**getting reeror : -2.1.0-np19py27_0 ...
      installing: _cache-0.0-x0 ...
      Anaconda-2.1.0-Linux-x86.sh: line 396: /Users/despoina/anaconda/pkgs/python-2.7.8-1/bin/python: cannot execute binary file
      ERROR:
      cannot execute native linux-32 binary, output from 'uname -a' is:
      Darwin pandora.ffn.ub.e
after google : https://groups.google.com/a/continuum.io/forum/#!msg/anaconda/o6VeA7Fg2eU/AHxG_WZW0qgJ
installed http://repo.continuum.io/miniconda/.osx-32/ MINIconda
i need sudo !

      4225
      000
      Next cursor: 1403322497756330915
      Total followers: 5000
      Maximum possible followers of 4000 reached.
      Got all followers. Size: 5000
      Traceback (most recent call last):
        File "/home/despoina/Github/phd/code/marienbad.py", line 1331, in <module>
          elif args.action == 'user_iterator':
        File "/home/despoina/Github/phd/code/marienbad.py", line 492, in get_friends_client
          received_data = do_POST_request(server, {u'get': u'3', 'user_id':user_id, 'friends' : all_friends, 'followers' : all_followers})
        File "/home/despoina/Github/phd/code/marienbad.py", line 420, in do_POST_request
          print 'Could not connect to server: %s' % (str(e))
      TypeError: not all arguments converted during string formatting
      You have new mail in /var/mail/despoina

      4620

      Traceback (most recent call last):
        File "/home/despoina/Github/phd/code/marienbad.py", line 1331, in <module>
          elif args.action == 'user_iterator':
        File "/home/despoina/Github/phd/code/marienbad.py", line 492, in get_friends_client
          received_data = do_POST_request(server, {u'get': u'3', 'user_id':user_id, 'friends' : all_friends, 'followers' : all_followers})
        File "/home/despoina/Github/phd/code/marienbad.py", line 420, in do_POST_request
          print 'Could not connect to server: %s' % (str(e))
      TypeError: not all arguments converted during string formatting
      You have new mail in /var/mail/despoina
      despoina@aneipero:/storage2/marienbad$ 46204620
      Sorry, command-not-found has crashed! Please file a bug report at:
      https://bugs.launchpad.net/command-not-found/+filebug
      Please include the following information with the report:

      command-not-found version: 0.2.44
      despoina@aneipero:/storage2/marienbad$ 4620
      Sorry, command-not-found has crashed! Please file a bug report at:
      https://bugs.launchpad.net/command-not-found/+filebug
      Please include the following information with the report:


* 10/10
6146: crashare : 
Fetching followers for user: 53022408
Fetch followers URL: https://api.twitter.com/1.1/followers/ids.json?cursor=-1&user_id=53022408&count=5000
Maximum followers: 4000 Maximum friends: 4000
 Oops!  Something went wrong when opening url https://api.twitter.com/1.1/followers/ids.json?cursor=-1&user_id=53022408&count=5000&oauth_body_hash=2jmj7l5rSw0yVb%2FvlWAYkK%2FYBwk%3D&oauth_nonce=75772845&oauth_timestamp=1415294122&oauth_consumer_key=0U03JsZz0TsNjPrGReXW4voui&oauth_signature_method=HMAC-SHA1&oauth_version=1.0&oauth_token=133651369-LRjdkvCShiSptFFas4mDQV0ZLlTbFc0n5MfgKDR4&oauth_signature=AnAKXRQU%2BMzxaq5Ic5vRZh5ntFY%3D. Try again...
Could not decode the JSON error message: No JSON object could be decoded
Traceback (most recent call last):
  File "/home/despoina/Github/phd/code/marienbad.py", line 1334, in <module>
    get_friends_client(server=args.server, account_name=args.account_name, max_friends=args.max_friends, max_followers=args.max_followers)
  File "/home/despoina/Github/phd/code/marienbad.py", line 476, in get_friends_client
    all_followers = get_all_Friends_Followers(user_id, account_name, 'followers', max_friends=max_friends, max_followers=max_followers)
  File "/home/despoina/Github/phd/code/marienbad.py", line 920, in get_all_Friends_Followers
    raise Exception('Unknown error code: %i' % (content))
Exception: Unknown error code: 5555
You have new mail in /var/mail/despoina
4494crashare


Fetching followers for user: 21647948
Fetch followers URL: https://api.twitter.com/1.1/followers/ids.json?cursor=-1&user_id=21647948&count=5000
Maximum followers: 4000 Maximum friends: 4000
Current followers: 5000
Next cursor: 1421229822572749911
Total followers: 5000
Maximum possible followers of 4000 reached.
Got all followers. Size: 5000
Traceback (most recent call last):
  File "/home/despoina/Github/phd/code/marienbad.py", line 1331, in <module>
    elif args.action == 'user_iterator':
  File "/home/despoina/Github/phd/code/marienbad.py", line 492, in get_friends_client
    received_data = do_POST_request(server, {u'get': u'3', 'user_id':user_id, 'friends' : all_friends, 'followers' : all_followers})
  File "/home/despoina/Github/phd/code/marienbad.py", line 420, in do_POST_request
    print 'Could not connect to server: %s' % str(e)
TypeError: not all arguments converted during string formatting
You have new mail in /var/mail/despoina

------------4431------
l friends. Size: 279
Fetching followers for user: 85013354
Fetch followers URL: https://api.twitter.com/1.1/followers/ids.json?cursor=-1&user_id=85013354&count=5000
Maximum followers: 4000 Maximum friends: 4000
Current followers: 222
Next cursor: 0
Total followers: 222
Got all followers. Size: 222
Traceback (most recent call last):
  File "/home/despoina/Github/phd/code/marienbad.py", line 1331, in <module>
    elif args.action == 'user_iterator':
  File "/home/despoina/Github/phd/code/marienbad.py", line 492, in get_friends_client
    received_data = do_POST_request(server, {u'get': u'3', 'user_id':user_id, 'friends' : all_friends, 'followers' : all_followers})
  File "/home/despoina/Github/phd/code/marienbad.py", line 420, in do_POST_request
    print 'Could not connect to server: %s' % str(e)
TypeError: not all arguments converted during string formatting
You have new mail in /var/mail/despoina




---------------------------4367----------
Got all friends. Size: 929
Fetching followers for user: 237320454
Fetch followers URL: https://api.twitter.com/1.1/followers/ids.json?cursor=-1&user_id=237320454&count=5000
Maximum followers: 4000 Maximum friends: 4000
Current followers: 1818
Next cursor: 0
Total followers: 1818
Got all followers. Size: 1818
Traceback (most recent call last):
  File "/home/despoina/Github/phd/code/marienbad.py", line 1331, in <module>
    elif args.action == 'user_iterator':
  File "/home/despoina/Github/phd/code/marienbad.py", line 492, in get_friends_client
    received_data = do_POST_request(server, {u'get': u'3', 'user_id':user_id, 'friends' : all_friends, 'followers' : all_followers})
  File "/home/despoina/Github/phd/code/marienbad.py", line 420, in do_POST_request
    print 'Could not connect to server: %s' % str(e)
TypeError: not all arguments converted during string formatting
You have new mail in /var/mail/despoina



SI :social influence workshop : 
  present 1: Garlaschelli
  INVITED TALK - DR. DIEGO GARLASCHELLI, UNIVERSITY OF LEIDEN, THE NETHERLANDS
RECONCILING LONG-TERM CULTURAL DIVERSITY AND SHORT-TERM COLLECTIVE SOCIAL BEHAVIOUR
  asimulation theory in phycology
  he claims bounded confidence : information difuses on the overlpa of social networks  
  data 1992!!! no social network data - survey data 

  ultrametric data in dentrogram

  valori et al  PNAS vol109 no4 pp 1068-1073
  http://www.pnas.org/content/109/4/1068.full.pdf

**present2Michae Mas 
  MICHAEL MAES AND LUKAS BISCHOFBERGER
  WEB PERSONALIZATION AND OPINION POLARIZATION




** Naming game


* 4 november : 
 * egaktashash 
 ssh pandora.ffn.ub.es -l despoina 

marian ssh cluster entry 

 git - mongo - anaconda 

* 21 October :===========================================================================================================================================
=============================================================================
telefonica: 

>  mydata = read.csv("/Users/antonakd/Documents/__icosial/_telefonica/churn_personality_QOexperience/data/Churn/all period measurements/psychographicsEVENING.csv")

ok you can create veryyy easy plots of networks baye ets if you have data like this: 

try in R : 
          # load the data and build the correct network from the model string.
          data(insurance)
          res = empty.graph(names(insurance))
          modelstring(res) = paste("[Age][Mileage][SocioEcon|Age][GoodStudent|Age:SocioEcon]",
            "[RiskAversion|Age:SocioEcon][OtherCar|SocioEcon][VehicleYear|SocioEcon:RiskAversion]",
            "[MakeModel|SocioEcon:RiskAversion][SeniorTrain|Age:RiskAversion]",
            "[HomeBase|SocioEcon:RiskAversion][AntiTheft|SocioEcon:RiskAversion]",
            "[RuggedAuto|VehicleYear:MakeModel][Antilock|VehicleYear:MakeModel]",
            "[DrivingSkill|Age:SeniorTrain][CarValue|VehicleYear:MakeModel:Mileage]",
            "[Airbag|VehicleYear:MakeModel][DrivQuality|RiskAversion:DrivingSkill]",
            "[Theft|CarValue:HomeBase:AntiTheft][Cushioning|RuggedAuto:Airbag]",
            "[DrivHist|RiskAversion:DrivingSkill][Accident|DrivQuality:Mileage:Antilock]",
            "[ThisCarDam|RuggedAuto:Accident][OtherCarCost|RuggedAuto:Accident]",
            "[MedCost|Age:Accident:Cushioning][ILiCost|Accident]",
            "[ThisCarCost|ThisCarDam:Theft:CarValue][PropCost|ThisCarCost:OtherCarCost]",
            sep = "")
          ## Not run: 
          # there are too many nodes for plot(), use graphviz.plot().
          graphviz.plot(res)

so the question is do you have to TRANFORM alexander data like this above if you type data after all the above commands you will get some CODE !!!

==================

Marian: 

 * tryng to start mongo becayse [21/10/14 12:49:42] kantale1: Adding new user: 16537989
Adding new edge: 30098421 --> 16537989   ORDER: 280
Adding new user: 17093617
Adding new edge: 30098421 --> 17093617   ORDER: 281
Updating followers for user: 30098421
Killed
[21/10/14 12:49:48] kantale1: "Killed"

Auto sumbainei otan uperbainei th mnhmh
[21/10/14 12:52:12] kantale1: krasare otan phge na balei tous followers tou: https://twitter.com/HOUSEonFOX
[21/10/14 12:52:19] kantale1: 284K
Nodes: 2.907.671
Edges: 3.439.424
Xmm.. auto shmainei oti den mporoume na diaxeiristoume ena diktuo me 2.9M users kai 3.4M edges?
To mhxanima exei 8G
MemTotal:        8009880 kB
MemFree:         5844188 kB --------------------------------- >>> import networkx as nx
>>> G = nx.gnm_random_graph(2907671, 3439424) --------------------------------- MemTotal:        8009880 kB
MemFree:         2666908 kB

MONGO !

alla : 
mongodb-linux-x86_64-2.4.6/bin/mongod --port 27089 --dbpath  /storage2/mongodb_data_marienbad
Tue Oct 21 15:33:13.701 [initandlisten] MongoDB starting : pid=28435 port=27089 dbpath=/storage2/mongodb_data_marienbad 64-bit host=aneipero
Tue Oct 21 15:33:13.701 [initandlisten] db version v2.4.6
Tue Oct 21 15:33:13.701 [initandlisten] git version: b9925db5eac369d77a3a5f5d98a145eaaacd9673
Tue Oct 21 15:33:13.701 [initandlisten] build info: Linux ip-10-2-29-40 2.6.21.7-2.ec2.v1.2.fc8xen #1 SMP Fri Nov 20 17:48:28 EST 2009 x86_64 BOOST_LIB_VERSION=1_49
Tue Oct 21 15:33:13.701 [initandlisten] allocator: tcmalloc
Tue Oct 21 15:33:13.701 [initandlisten] options: { dbpath: "/storage2/mongodb_data_marienbad", port: 27089 }
Tue Oct 21 15:33:13.753 [initandlisten] exception in initAndListen std::exception: locale::facet::_S_create_c_locale name not valid, terminating
Tue Oct 21 15:33:13.753 dbexit: 


alla solved: export LC_ALL=C
despoina@aneipero:~$ sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --port 27089 --dbpath  /storage2/mongodb_data_marienbad
Tue Oct 21 15:33:58.285 [initan

up and waiting ..
screen 28361
prosoxh to onoma tou arxieou einai to id enos xrhsth atomou kai epishs to idio id einai mesa sto arxeio excel e ta questionaires . 
p.x. psychographicsNWDAY exoume mia sthlh ID_NWDAY pou einai to id enos atomou p.x to 112
kai sto arxeio 112.csv exoume tis klhseis autou tou atomou 


26/9/2014=========================================================================================================================================================================================================================================================================================================

serach related work: user experience + churn prediction  perceived quality of experience personality 


* factor analysis (he has done this) + bayes networks +  exploritory analyisis anayiss of how theese features are related..to churn intention 
not sure of Qoexpreince can be seen here 
 * set up in levels look at ppt 
 lifestyle : diameter or number of places 

if highly skewed...

we have a socila network. Play around with : 3 factors The size of the network,  social influence (18) , attitude play these and see how this affect churn againgst 

how many people a person calls the more you call the more you influence other people

we cannot connect build people graph . one two people between each other. 

he made a sna: social network analysis : all daya evening night() : 


name of the file: id 
discart some columsn 
INR: voice messages

NWDAYS non working days 

less that 13 days discart in Number od days (use this for normalization)

NWdays nono working days 

diameter per day : maximum distnace between two point a user has been in one day 

not use  culture depentnd 


we do thi sstudy in the small dataset     then again in the big dataset if it works 


==========================================================================================
==========================================================================================
www.bnlearn.com/documentation/man/asia.html

25/9/2014 - poster to cp for print, mail to Kolja for other poster, meeting with Ilias@Telefonica about related work & data 
  * related work: 
      * Social network analysis for customer churn prediction -- no full text available 
      * Improved churn prediction in telecommunication industry by analyzing a large network  -- no full text available
      *  Keramati, A., et al. "Improved churn prediction in telecommunication industry using data mining techniques." Applied Soft Computing (2014).

         

        We have employed Decision Tree, Artificial Neural Networks, K-Nearest Neighbors, and Support Vector Machine to improve churn prediction.
        Using the data of an Iranian mobile company these techniques were experienced and were compared to each other
        We proposed a hybrid methodology which made considerable improvements to the value of some of evaluations metrics.
        Results showed that above 95% accuracy for Recall and Precision is easily achievable.
        A new methodology for extracting influential features is introduced and experienced.



24/9/2014  - Merce

23/9/2014

==========================================================================================
------------------------------------------


------------------------------------------
========================================================================================================================================================================================================================================================================================================================================================================
--------------------------------churn prediction for CDR data  ----------
Backiel, Aimée, Bart Baesens, and Gerda Claeskens. "Mining telecommunication networks to enhance customer lifetime predictions." Artificial Intelligence and Soft Computing. Springer International Publishing, 2014.

  Customer retention has become a necessity in many markets, including mobile telecommunications. As it becomes easier for customers to switch providers, the providers seek to improve prediction models in an effort to intervene with potential churners. Many studies have evaluated different models seeking any improvement to prediction accuracy. This study proposes that the attributes, not the model, need to be reconsidered. By representing call detail records as a social network of customers, network attributes can be extracted for use in various traditional prediction models. The use of network attributes exhibits a significant increase in the area under the receiver operating curve (AUC) when compared to using just individual customer attributes.
------------------------------------------

Verbeke, Wouter, David Martens, and Bart Baesens. "Social network analysis for customer churn prediction." Applied Soft Computing 14 (2014): 431-446.  

    We examine the use of social network information for customer churn prediction.
    We develop an alternative modeling approach using relational learning algorithms.
    We present the results of two large scale real life case studies in the telco industry.
    A large group of classifiers yields comparable performance.
    A significant impact of (higher order) social network effects on the performance of a customer churn prediction model is found.

------------------------------------------
Kim, Kyoungok, Chi-Hyuk Jun, and Jaewook Lee. "Improved churn prediction in telecommunication industry by analyzing a large network." Expert Systems with Applications (2014).


  Customer retention in telecommunication companies is one of the most important issues in customer relationship management, and customer churn prediction is a major instrument in customer retention. Churn prediction aims at identifying potential churning customers. Traditional approaches for determining potential churning customers are based only on customer personal information without considering the relationship among customers. However, the subscribers of telecommunication companies are connected with other customers, and network properties among people may affect the churn. For this reason, we proposed a new procedure of the churn prediction by examining the communication patterns among subscribers and considering a propagation process in a network based on call detail records which transfers churning information from churners to non-churners. A fast and effective propagation process is possible through community detection and through setting the initial energy of churners (the amount of information transferred) differently in churn date or centrality. The proposed procedure was evaluated based on the performance of the prediction model trained with a social network feature and traditional personal features.


------------------------------------------

Georges, Olle Olle, Shu Qin Cai, and Qian Yuan. "A New Framework for Churners’ Influence Analysis Using Call Data Records." Advanced Materials Research. Vol. 989. 2014.

    Predicting customer churn is of paramount importance in telecommunication companies. The taxonomy of churn reports that, not only individual constraints but also social factors can create users’ propensity to churn. This study uses real world call data records (CDR) to extract the social relationships among mobile phone users and build a multi relational social network, where the influence of users diffuses. The research is conducted to propose a framework that enhances the actionable value of social influence of predicted churners and to examine the parameters that control the churn information diffusion in the telecommunication networks.

------------------------------------------

 Archambault, Daniel, and Neil Hurley. "Visualization of trends in subscriber attributes of communities on mobile telecommunications networks." Social Network Analysis and Mining 4.1 (2014): 1-17.

     Churn, the decision for a subscriber to leave a provider, is frequently of interest in the telecommunications industry. Previous research provides evidence that social influence can be a factor in mobile telecommunications churn. In our work, presented at ASONAM, we presented a system, called ChurnVis, to visualize the evolution of mobile telecommunications churn and subscriber actions over time. First, we infer a social network from call detail records. Then, we compute components based on an overlay of this social network and churn activity. We compute summaries of the attributes associated with the subscribers and finally, we visualize the components in a privacy preserving way. The system is able to present summaries of thousands of churn components in graphs of hundreds of millions of edges. One of the drawbacks of the original approach was that churn components were sometimes very large, leading to over-aggregation in the summary data. In this extension of the ASONAM paper, we adapt the ChurnVis approach to operate on the output of a community finding algorithm and present new results based on this adaptation.
 
------------------------------------------


Droftina, Uroš, Mitja Štular, and Andrej Košir. "Predicting influential mobile-subscriber churners using social network measures." (2014).
     The aim of this study is to nd good predictors of churn influence in a mobile service
    network. To this end, a procedure for determining the weak ground truth on churn influence is presented and used to determine the churn influence of prepaid customers. The determined scores are used to identify good churn-infl uence predictors among 74 candidate features. The identied
    predictors are nally used to build two churn-influence-prediction models.
    The results show that considerably better churn prediction results can
    be achieved using the proposed model together with the classical churn-
    prediction-model than by using the classical churn-prediction model alone.
    Moreover, the successfully predicted churners by the combined approach
    also have a greater number of churn followers. A successful retention of
    the predicted churners could greatly aect churn reduction since it could
    also prevent the churns of these followers.
------------------------------------------


Dairo, Adeolu O., and Temitope Akinwumi. "DORMANCY PREDICTION MODEL IN A PREPAID PREDOMINANT MOBILE MARKET: A CUSTOMER VALUE MANAGEMENT APPROACH." International Journal of Data Mining & Knowledge Management Process 4.1 (2014).

     Previous studies have predicted customer churn in the mobile indutry especially the postpaid customer 
    segment of the market. However, only few studies have been published on the prepaid segment that could 
    be used and operationalised within the marketing team that are responsible for the management of incident 
    of prepaid churn. This is the first identifiable literature where customer dormancy is predicted along the 
    customer value segmentation. In this article, we use a popular data mining technique to predict when a
    customer will go dormant or stop performing revenue generating events in a prepaid predominant market.
    Our study is unique as we considered ~1,451 attributes derived from CDR and SIM registration database 
    (previous studies only considered maximum of ~1,381 potential variables). We built 3 different models for 
    Very High, High and Low value segments. We applied our models on the prepaid base and the output was 
    later compared with the actual dormant customers. Very High segment has the highest accuracy and lift 
    while Low segment has the least at the same threshold. We show that once the problem of prepaid churn is 
    well defined, it can be predicted. We recommend a value segmentation dormancy prediction with decision
    tree for prepaid segment with a certain threshold. Our study shows that this approach can be easily 
    adopted and operationalised by the campaign management team responsible for the management of 
    prepaid churn in a mobile industry   

------------------------------------------

    Baras, Dorit, and Amir Ronen. "Extracting social relations from calling time data." U.S. Patent No. 8,681,957. 25 Mar. 2014.

      A method, apparatus, and computer program product for generating a social network data structure, the method comprising: receiving a corpus comprising one or more communication indications for one or more customers, each communication indication indicating start time and end time of a communication of the customer; and generating a social network data structure indicating connections between customers based upon the start time and end time indications of communication indication comprised in the communication indications.

------------------------------------------

Motahari, Sara, et al. "Predicting the Influencers on Wireless Subscriber Churn."

    Abstract—Wireless carriers have various churn models that are 
    mainly based on profiling the customers and assigning churn 
    probabilities to them. Profiling is usually limited to their 
    individual data, such as their subscription history, demographics, 
    usage, etc. However, our analysis of a major wireless carrier data 
    shows that such churn prediction methods do not fully model 
    wireless subscriber churn, and that the subscribers can be 
    influenced by other subscribers’ churn in their social network. 

    We propose a novel method to identify ‘churn influencers’, whose 
    influence makes their social contacts churn subsequently. To 
    build our model, we scored the subscribers’ influence level in a 
    way that can take current churn models into account. We further 
    used large scale call records to identify social network and 
    communication features that abstract the strong influencers. 
    Using real world churn data, we trained classification tools to 
    classify high influencers with up to ninety nine percent precision.

------------------------------------------

Ranjan, Preetish, and Abhishek Vaish. "A COMPREHENSIVE TECHNICAL REVIEW ON THE DIVERSE EXECUTION OF CALL DETAIL RECORD."

    Social Network is gaining popularity; the society is evolving as e-society. One of the most
    prevailing factors for the phenomenal growth of e-society is due to the proliferation of digital
    technologies and very inexpensive cost of telecom service. Smart phones are very easily
    available and value added services by the Telecom Service Providers are encouraging users to
    connect with multiple motivations. The advancement in the field of computer science and
    artificial intelligence has led to the advancement of exploration opportunities as well.
    Researchers are trying to look in to the all possible places to extract information exploitable
    of it due to very obvious reasons i.e. the economic value associated with the information. The
    implication of such phenomena is raising various breach of privacy. Unfortunately, very
    limited study has been done to explore how the Call Detail Record (CDR) is being used in the
    business world. The current study helps society to be aware for their mobile CDR. Also; it will
    help the researcher to get insight of various domains of research in the social network
    analysis through CDRs

-----------------------------------------
Kushwaha, Abhishek, Rahul Das, and Chandan Sharma. "Trusted Third Party-based CDR Management System."


      Abstract—Call Detail Records (CDRs) are computer
      generated records which contain details about the calls
      which pass through the operator’s particular telephone
      switch. CDRs are stored for a particular period of time
      identified by company policy and country legislation.
      During their storage lifetime the CDRs are subjected to
      various kinds of analysis and mining procedures to enable
      the operator to obtain such factors which will help to serve
      the consumers in a better way and generate more revenue
      for the operator. Sometimes such procedures violate the
      privacy and security requirement of the consumer and the
      country legislation. This paper proposes a Trusted Third
      Party (TTP) based CDR Management System which can
      help the operators reduce regulatory burden and IT
      infrastructure requirements. TTP based CDR
      Management System stores several operators’ CDRs,
      under contract, with a single entity which can analyse,
      mine and regulate the data on behalf of operators and
      government and provide better value to business.  

-----------------------------------------
Konopnicki, David, and Michal Shmueli-Scheuer. "Customer Analyst for the Telecom Industry." Large-Scale Data Analytics. Springer New York, 2014. 101-127.


      The telecommunications industry is particularly rich in customer data, and telecom companies want to use this data to prevent customer churn, and improve the revenue per user through personalization and customer acquisition. Massive-scale analytics tools provide an opportunity to achieve this in is a flexible and scalable way. In this context, we have developed IBM Customer Analyst, a components library to analyze customer behavioral data and enable new insights and business scenarios based on the analysis of the relationship between users and the content they create and consume. Due to the massive amount of data and large number of users, this technology is built on IBM Infosphere BigInsights and Apache Hadoop. In this work, we first describe an efficient user profiling framework, with high user profiling quality guarantees, based on mobile web browsing log analysis. We describe the use of the Open Directory Project categories to generate user profiles. We then describe an end-to-end analysis flow and discuss its challenges. Last, we validate our methods through extensive experiments based on real data sets.

-----------------------------------------

Han, Qiwei, and Pedro Ferreira. "The Role of Peer Influence in Churn in Wireless Networks." arXiv preprint arXiv:1409.1102 (2014).

  Subscriber churn remains a top challenge for wireless carriers. These carriers need to understand the determinants of churn to confidently apply effective retention strategies to ensure their profitability and growth. In this paper, we look at the effect of peer influence on churn and we try to disentangle it from other effects that drive simultaneous churn across friends but that do not relate to peer influence. We analyze a random sample of roughly 10 thousand subscribers from large dataset from a major wireless carrier over a period of 10 months. We apply survival models and generalized propensity score to identify the role of peer influence. We show that the propensity to churn increases when friends do and that it increases more when many strong friends churn. Therefore, our results suggest that churn managers should consider strategies aimed at preventing group churn. We also show that survival models fail to disentangle homophily from peer influence over-estimating the effect of peer influence.
-----------------------------------------
Dantressangle, Patrick, et al. "Carrying out predictive analysis relating to nodes of a communication network." U.S. Patent No. 8,644,468. 4 Feb. 2014.

  Predictive analysis relating to nodes of a communication network is carried out by providing communication event information for a first set of nodes and a second set of nodes of the communication network, providing a set of attributes for the nodes of the first set, using the attributes and the communication event information for determining a set of groups among the first set of nodes, assigning each node of the second set to at least one group of the set of groups based at least on the communication event information available for the second group, the assigning resulting in membership information of the nodes of the second set, and deriving or applying a prediction model for the second set of nodes based on the communication event information for the second set and the membership information.
-----------------------------------------

  Brea, Jorge, et al. "Harnessing Mobile Phone Social Network Topology to Infer Users Demographic Attributes."

      We study the structure of the social graph of mobile phone
    users in the country of Mexico, with a focus on demographic
    attributes of the users (more specically the users' age). We
    examine assortativity patterns in the graph, and observe a
    strong age homophily in the communications preferences.
    We propose a graph based algorithm for the prediction of
    the age of mobile phone users. The algorithm exploits the
    topology of the mobile phone network, together with a subset
    of known users ages (seeds), to infer the age of remaining
    users. We provide the details of the methodology, and show
    experimental results on a network GT with more than 70 million
    users. By carefully examining the topological relations
    of the seeds to the rest of the nodes in GT , we nd topological
    metrics which have a direct in
    uence on the performance of
    the algorithm. In particular we characterize subsets of users
    for which the accuracy of the algorithm is 62% when predicting
    between 4 age categories (whereas a pure random
    guess would yield an accuracy of 25%). We also show that
    we can use the probabilistic information computed by the
    algorithm to further increase its inference power to 72% on
    a signicant subset of users

-----------------------------------------

Shama, Yaacov, et al. "Systems and methods for identifying provider noncustomers as likely acquisition targets." U.S. Patent No. 8,700,551. 15 Apr. 2014.

  The present invention is directed towards systems and methods for predicting one or more desired properties of external nodes or properties of their relations with internal nodes, based on a selected group of nodes about which it is known whether the nodes have the desired properties, or it is known whether they have a desired relation property with an internal node. The method comprises storing in one or more data structures a first data set regarding external nodes and a second data set regarding nodes with known properties in a selected group, each data set having one or more data items representing one or more events relating to or attributes of each node in the data set, the second data set including one or more types of data items not included in the first data set. The method then models the second data set to identify from the second data one or more modeled events or attributes of internal nodes in the selected group that are statistically likely to identify the nodes or their relations, that have the desired properties and predicts which of the external nodes are statistically likely to have the one or more desired properties, or desired relation property with internal node, based on the identified plurality of modeled events or attributes and the events or attributes in the first data set.

-----------------------------------------

Theeten, Bart, et al. "Towards the Optimization of a Parallel Streaming Engine for Telco Applications." Bell Labs Technical Journal 18.4 (2014): 181-197.

  Parallel and distributed computing is becoming essential to process in real time the increasingly massive volume of data collected by telecommunications companies. Existing computational paradigms such as MapReduce (and its popular open-source implementation Hadoop) provide a scalable, fault tolerant mechanism for large scale batch computations. However, many applications in the telco ecosystem require a real time, incremental streaming approach to process data in real time and enable proactive care. Storm is a scalable, fault tolerant framework for the analysis of real time streaming data. In this paper we provide a motivation for the use of real time streaming analytics in the telco ecosystem. We perform an experimental investigation into the performance of Storm, focusing in particular on the impact of parameter configuration. This investigation reveals that optimal parameter choice is highly non-trivial and we use this as motivation to create a parameter configuration engine. As first steps towards the creation of this engine we provide a deep analysis of the inner workings of Storm and provide a set of models describing data flow cost, central processing unit (CPU) cost, and system management cost. © 2014 Alcatel-Lucent.



-----------------------------------------

Mohan, Saravanan, and Manisha Subramanian. "A New Method of Identifying Individuals’ Roles in Mobile Telecom Subscriber Data for Improved Group Recommendations." Multidisciplinary Social Networks Research. Springer Berlin Heidelberg, 2014. 213-227.

  The presently available methods are highly capable of offering personalized recommendations to individuals and also group recommendations to the subscriber hub. Operators who generate recommendations expect the information to be dissipated to a large number of subscribers in a specific space and time. In this paper, our interest is to combine the concepts of recommendations and information dissipation to identify the unique role players who can spread information rapidly with more specific to mobile telecom communities. It generates two improvements: reduces the extra cost incurred by the service provider in advertising to the entire community and also establishes a spatio-temporal mechanism to understand the sphere of influence of users in a dynamic environment. This is done by considering some essential factors to assign weights to each user in terms of the amount of influence they can exert within the group. Recent studies indicate that the feedback of a campaign is higher when recommended by peers rather than by operators. Our proposed method has another advantage that it can easily be extended to social network communities for similar purposes. We have also looked into the roles played by the individuals for different recommendations and the significance of the different role players’ impact on the community with the help of domain experts. Finally, we have evaluated our proposed method on mobile telecom data and compared with customer ranking algorithm statistically through paired t-test method.

-----------------------------------------
BOOKS Andrade, Henrique, Buğra Gedik, and Deepak Turaga. Fundamentals of Stream Processing: Application Design, Systems, and Analytics. Cambridge University Press, 2014.

Ballard, Chuck, et al. Information Governance Principles and Practices for a Big Data Landscape. IBM Redbooks, 2014.


-----------------------------------------
Soulie-Fogelman, Françoise. "Method and system for selecting a target with respect to a behavior in a population of communicating entities." U.S. Patent No. 8,712,952. 29 Apr. 2014.

The method uses predictive analysis to determine a model based on past data including a first social network built between communicating entities for a first observation period and behavioral centrality measures derived from behavioral data observed in a following time period. The model thus determined is then applied to a second social network built for a second observation period more recent than the first one. This provides predicted behavioral centrality measures for a future period, which can be used to perform an efficient selection of entities in the target, which may maximize virality with respect to the specific behavior of interest.

-----------------------------------------
=============================================================================================================================================================non exclusively CDRs but general churn prediction===============================================================================================================================================================================================================================================================================================================================================================================================
------------------------------------------
Faris, Hossam, Bashar Al-Shboul, and Nazeeh Ghatasheh. "A Genetic Programming Based Framework for Churn Prediction in Telecommunication Industry." Computational Collective Intelligence. Technologies and Applications. Springer International Publishing, 2014. 353-362.

In this paper, a churn prediction framework is proposed aiming at enhancing the ability to forecast customer churn. The framework combine two heuristic approaches: Self Organizing Maps (SOM) and Genetic Programming (GP). At first, SOM is used to cluster the customers in the dataset, and then remove outliers representing abnormal customer behaviors. After that, GP is used to build an enhanced classification tree. The dataset used for this study contains anonymized real customer information provided by a major local telecom operator in Jordan. Our work shows that using the proposed method surpasses various state-of-the-art classification methods for this particular dataset.


------------------------------------------
------------------------------------------
Kaur, Kiranjot, and Sheveta Vashisht. "Enhanced Boosted Trees Technique for Customer Churn Prediction Model." IOSR Journal of Engineering 4.3 (2014): 41-45.

 In this paper, enhanced boosted trees technique is used for customer churn prediction. This 
approach will improve the performance of existing boosted trees technique. The process of customer churn 
prediction is discussed in this paper. It will be used to identify churn customers and effective marketing 
strategies could be planned for this group of customers.

------------------------------------------
------------------------------------------
Mohammadi, M., et al. "Hierarchical Alpha-cut Fuzzy C-means, Fuzzy ARTMAP and Cox Regression Model for Customer Churn Prediction." International Journal of Engineering-Transactions C: Aspects 27.9 (2014): 1405.
  
  This paper considers a hierarchical model by combining three data mining techniques containing two different fuzzy prediction networks and a regression technique for churn prediction, namely Alpha-cut Fuzzy C-Means (αFCM), Improved Fuzzy ARTMAP and Cox proportional hazards regression model, respectively. In particular, the first component of the hybrid model aims to cluster data in two churner and non-churner groups applying the alpha-cut algorithm and filter out unrepresentative data or outliers. Then, the clustered and representative data as the outputs are used to assign customers to churner and non-churner groups by the second technique. Finally, the correctly classified data are used to create the Cox proportional hazards model. To evaluate the performance of the proposed hierarchical model, the Iranian mobile dataset is considered. The experimental results show that the proposed model outperforms the single Cox regression baseline model in terms of prediction accuracy, Type I and II errors, RMSE and MAD metrics.

------------------------------------------

He, Benlan, et al. "Prediction of Customer Attrition of Commercial Banks based on SVM Model." Procedia Computer Science 31 (2014): 423-430.

    Currently, Chinese commercial banks are facing triple tremendous pressure, including financial disintermediation, interest rate marketization and Internet finance. Meanwhile, increasing financial consumption demand of customers further intensifies the competition among commercial banks. To increase their profits for continuing operations and enhance the core competitiveness, commercial banks must avoid the loss of customers while acquiring new customers. This paper discusses commercial bank customer churn prediction based on SVM model, and uses random sampling method to improve SVM model, considering the imbalance characteristics of customer data sets. The results show that this method can effectively enhance the prediction accuracy of the selected model.


------------------------------------------

Xiao, Jin, et al. "One-Step Classifier Ensemble Model for Customer Churn Prediction with Imbalanced Class." Proceedings of the Eighth International Conference on Management Science and Engineering Management. Springer Berlin Heidelberg, 2014.


  In customer churn prediction, an important yet challenging problem is the class imbalance of data distribution. After analyzing the disadvantages of the commonly used “two-step” methods, this study combines multiple classifiers ensemble technique, self-organizing data mining with cost-sensitive learning, and proposes one-step classifier ensemble model for imbalance data (OCEMI). For each test customer, it can adaptively select out the more appropriate one from the two kinds of dynamic ensemble approach: dynamic classifier selection (DCS) and dynamic ensemble selection (DES). Meanwhile, new cost-sensitive selection criteria for DCS and DES are constructed respectively to improve the classification ability for imbalanced data. The empirical results show that this strategy can be used to predict customer churn more effectively.


-----------------------------------
Jiang, Min, Na Chu, and Xiao Ming Bi. "Research on Customers Churn Prediction Model Based on Logistic." Advanced Materials Research. Vol. 989. 2014.

    At present, the competition is increasingly fierce between the securities company, whether can effectively prevent the loss of users, reducing loss rate is a difficult problem at present each securities company urgently needs to solve. The model based on the principle of data mining, proposes a prediction method based on Logistic regression algorithm. Prediction model is built based on Logistic regression algorithm and the validity and accuracy of the model is verified by experiment, provides a new method and thinking for the securities company customer churn prediction.


----------------------------------
Lin, Wei-Chao, Chih-Fong Tsai, and Shih-Wen Ke. "Dimensionality and data reduction in telecom churn prediction." Kybernetes 43.5 (2014): 737-749.

      – Purpose

    – Churn prediction is a very important task for successful customer relationship management. In general, churn prediction can be achieved by many data mining techniques. However, during data mining, dimensionality reduction (or feature selection) and data reduction are the two important data preprocessing steps. In particular, the aims of feature selection and data reduction are to filter out irrelevant features and noisy data samples, respectively. The purpose of this paper, performing these data preprocessing tasks, is to make the mining algorithm produce good quality mining results.

    Design/methodology/approach
    – Based on a real telecom customer churn data set, seven different preprocessed data sets based on performing feature selection and data reduction by different priorities are used to train the artificial neural network as the churn prediction model.

    Findings
    – The results show that performing data reduction first by self-organizing maps and feature selection second by principal component analysis can allow the prediction model to provide the highest prediction accuracy. In addition, this priority allows the prediction model for more efficient learning since 66 and 62 percent of the original features and data samples are reduced, respectively.

    Originality/value
    – The contribution of this paper is to understand the better procedure of performing the two important data preprocessing steps for telecom churn prediction.
----------------------------------
   Keramati, A., et al. "Improved churn prediction in telecommunication industry using data mining techniques." Applied Soft Computing (2014).
       We have employed Decision Tree, Artificial Neural Networks, K-Nearest Neighbors, and Support Vector Machine to improve churn prediction.
    Using the data of an Iranian mobile company these techniques were experienced and were compared to each other
    We proposed a hybrid methodology which made considerable improvements to the value of some of evaluations metrics.
    Results showed that above 95% accuracy for Recall and Precision is easily achievable.
    A new methodology for extracting influential features is introduced and experienced.

----------------------------------
----------------------------------
    Zhu, Bing, Jin Xiao, and Changzheng He. "A Balanced Transfer Learning Model for Customer Churn Prediction." Proceedings of the Eighth International Conference on Management Science and Engineering Management. Springer Berlin Heidelberg, 2014.

    Class imbalance presents significant challenges to customer churn prediction. Most of previous research efforts addressing class imbalance focus on the usage of in-domain information. In fact, due to the development of information technology, customer data of related domains may be gathered. These data come from different time-periods, districts or product categories. In this paper, we develop a new churn prediction model based on transfer learning model, which uses customer data from related domains to address the issue of data imbalance. The new model is applied to a real-world churn prediction problem in the bank industry. The results show that the new model provides better performance than traditional method such as resampling and cost-sensitive learning in dealing with class balance. 
    
----------------------------------
----------------------------------
    Verbraken, Thomas, Wouter Verbeke, and Bart Baesens. "Profit optimizing customer churn prediction with Bayesian network classifiers." Intelligent Data Analysis 18.1 (2014): 3-24.

    This paper investigates the predictive power of a number of Bayesian Network algorithms, ranging from the Naive Bayes classifier to General Bayesian Network classifiers. Furthermore, a feature selection method based on the concept of the Markov Blanket, which is genuinely related to Bayesian Networks, is tested. The performance of the classifiers is evaluated with both the Area under the Receiver Operating Characteristic Curve and the recently introduced Maximum Profit criterion. The Maximum Profit criterion performs an intelligent optimization by targeting this fraction of the customer base which would maximize the profit generated by a retention campaign.



----------------------------------
----------------------------------
Kim, Kyoungok, Chi-Hyuk Jun, and Jaewook Lee. "Improved churn prediction in telecommunication industry by analyzing a large network." Expert Systems with Applications (2014).

      We improved churn prediction by analyzing a large social network.
      The applied community detection showed a faster propagation time.
      Simulation verifies better performance of the proposed method.

----------------------------------

Gür Ali, Özden, and Umut Arıtürk. "Dynamic churn prediction framework with more effective use of rare event data: The case of private banking." Expert Systems with Applications 41.17 (2014): 7889-7903.

    Dynamic churn prediction framework for creating training data from customer records.    Improves accuracy significantly even vs. balanced data, across prediction horizons. Independently trained binary classifiers approach outperforms survival analysis.
    Horizon specific ranking allows targeting retention efforts across time and customers.Allows capturing the effect of the environmental conditions on churn probability.

    The proposed framework includes customer observations from different time periods, and thus addresses the absolute rarity issue that is relevant for the most valuable customer segment of many companies. It also increases the sampling density in the training data and allows the models to generalize across behaviors in different time periods while incorporating the impact of the environmental drivers.
----------------------------------
----------------------------------stackoverflow.com -------------------

User churn in focused question answering sites: characterizations and prediction -  stackoverflow.com  stackoverflow.com  stackoverflow.com 

Pudipeddi, Jagat Sastry, Leman Akoglu, and Hanghang Tong. " Proceedings of the companion publication of the 23rd international conference on World wide web companion. International World Wide Web Conferences Steering Committee, 2014. - 

  study a large data collection from stackoverflow.com to identify significant factors that correlate with newcomer user churn in the early stage and those that relate to veterans leaving in the later stage. We consider the problem under two settings: given (i) the first k posts, or (ii) first T days
  of activity of a user, we aim to identify evidential features to automatically classify users so as to spot those who are about to leave. We find that in both cases, the time gap between subsequent posts is the most significant indicator of diminishing interest of users, besides other indicative factors like answering speed, reputation of those who answer their questions, and number of answers received by the user.


----------------------------------

Auto fainetai endiaferon alla anaferetai se p2p networks kai einai tou 2006 : Understanding churn in peer-to-peer networks

----------------------------------
Epishs pio profato kai endiaferon , alla den exw full text  Predicting Customer Churn in Telecom Industry using Multilayer Preceptron Neural Networks: Modeling and Analysis

----------------------------------
2011: Customer Churn Prediction Using Local Linear Model Tree for Iranian Telecommunication Companies 

----------------------------------
Revisiting BGP Churn Growth apo 2014 SigComm

----------------------------------
Churn Analysis of Online Social Network Users Using Data Mining Techniques - 2012 IMECS

----------------------------------
Predicting Player Churn in the Wild - 2014  - 
    Churn prediction for mobile games can be realized with decision trees and game independent features
    classic technique used Choose training date and split user in churners and non-churners. - Binary classification task
    Compared different classifiers (Logistic Regression, Neural Networks, Naive Bayes & Decision Trees) found that Decision Trees to perform best

----------------------------------
Miniizing Churn in Distributed Systems, SIGCOMM 2006 polu kalo alla palio 

----------------------------------
SPSS Churn prediction framework of prepaid, postpaid and fixed line customers  -Sanket Jain GBS Business Analytics and Optimization Center of Competence, CMS Analytics India Date of writing: July 18 2011: 
    
    This paper enlists the key significant variables or churn factors for all the three market segments – prepaid, postpaid and fixed landline markets 

----------------------------------
The Importance of Social Embeddedness: Churn Models at Mobile Providers†: Article first published online: 29 JAN 2014Benedek, G., Lublóy, Á., & Vastag, G. (2014). The Importance of Social Embeddedness: Churn Models at Mobile Providers. Decision Sciences, 45(1), 175-201.
Chicago 

----------------------------------

Social network analysis for customer churn prediction - January 2014Appl. Soft Comput. 

----------------------------------
Prediction of Subscriber Churn Using Social Network Analysis - 27 FEB 2013 - Bell Labs Technical Journal

----------------------------------
Lin, Wei-Chao, Chih-Fong Tsai, and Shih-Wen Ke. "Dimensionality and data reduction in telecom churn prediction." Kybernetes 43.5 (2014): 737-749.

    Improving churn prediction in telecommunications using complementary fusion of multilayer features based on factorization and construction - Control and Decision Conference (2014 CCDC), The 26th Chinese - . The effective features were selected by multilayer complementary fusion which according to the contribution of feature subsets and new features. In this way, the imbalance defects of class distributions can be fixed, prediction accuracy can be improved and system stability can be reinforced. Five data mining models were applied in customer churn.

----------------------------------
Churn prediction using comprehensible support vector machine: An analytical CRM application Applied Soft Computing Volume 19, June 2014, Pages 31–40

    - Support vector machine (SVM) is made transparent by hybridizing it with NBTree.•Its effectiveness is tested on a medium scale unbalanced dataset related to bank credit card customer churn in analytical CRM
    Feature selection is carried out by SVM-RFE algorithm.Proposed hybrid outperformed other techniques. Feature selection resulted in rules with short lengths and better comprehensibility of the system. The generated rules act as an early warning expert system to the bank management.

----------------------------------
Feature-selection-based dynamic transfer ensemble model for customer churn prediction - Jin Xiao, Yi Xiao, Anqiang Huang, Dunhu Liu, Shouyang Wang

    feature-selection-based dynamic transfer ensemble (FSDTE) model that aims to introduce transfer learning theory for utilizing the customer data in both the target and related source domains. The model mainly conducts a two-layer feature selection. In the first layer, an initial feature subset is selected by GMDH-type neural network only in the target domain. In the second layer, several appropriate patterns from the source domain to target training set are selected, and some features with higher mutual information between them and the class variable are combined with the initial subset to construct a new feature subset. The selection in the second layer is repeated several times to generate a series of new feature subsets, and then, we train a base classifier in each one. Finally, a best base classifier is selected dynamically for each test pattern.

----------------------------------
Churn Prediction in Telecommunication Industry Using Rough Set Approach Adnan Amin, Saeed Shehzad, Changez Khan, Imtiaz Ali, Sajid Anwar - 

    a rule-based decision making technique, to extract rules for churn prediction. Experiments were performed to explore the performance of four different algorithms (Exhaustive, Genetic, Covering, and LEM2). It is observed that rough set classification based on genetic algorithm, rules generation yields most suitable performance out of the four rules generation algorithms. Moreover, by applying the proposed technique on publicly available dataset, the results show that the proposed technique can fully predict all those customers that will churn or possibly may churn and also provides useful information to strategic decision makers as well.

----------------------------------

Churn Prediction in MMORPGs: A Social Influence Based Approach 2009 

----------------------------------

Customer Churn Prediction Based on Feature Clustering and Nonparallel Support Vector Machine - International Journal of Information Technology & Decision Making Volume 13, Issue 05, September 2014 - 
  
  feature clustering and classification technique to help commercial banks make an effective decision on customer churn problem. The proposed method benefits from the result of data explorations, clusters the customer features, and makes a decision with a state-of-the-art classifier. When facing the data with large amount of missing items, it does not directly remove the features by some subjective threshold, but clusters the features through the consideration of the relationship and the missing ratio. Real-world data from a major commercial bank of China verifies the feasibility of our framework in industrial applications.

--------------------------------
==========================================================================================
==========================================================================================
==========================================================================================
==========================================================================================
* Related work  : 

  * http://bugzilla.cs.umn.edu/tech_reports_upload/tr2009/09-013.pdf: Churn Prediction in MMORPGs: A Social Influence Based Approach
  * Huang, B.; Buckley, B.; and Kechadi, T. M. 2010. Multi-objective feature selection by using nsga-ii for customer churn prediction in telecommunications  Expert Syst. Appl. 37(5).
  * In the services industry, churn has been observed to be the outcome of several factors such as pricing, convenience, service contract expiry, core service failures, customer service failures and dissatisfaction of provider ethics

  * churn preeiction in Twutter user browsing? of facebook user browsing ?

  * churn on web page:  The importance of a Web page is an inherently subjective matter, which depends on the readers interests, knowledge and attitudes. But there is still much that can be said ob jectively about the relative importance of Web pages. This paper describes PageRank, a method for rating Web pages ob jectively and mechanically, eectively measuring the human interest and attention devoted to them. We compare PageRank to an idealized random Web surfer. We show how to eciently compute PageRank for large numbers of pages. And, we show how to apply PageRank to search and to user navigation.




* Churn prediction from CDR Analysis Based Telco Churn Prediction and Customer Behavior
Insights: A Real-Life Case Study: 
  Churn management involves not only predicting customers likely to churn based on demo graphic and behavioral data, it also involves preventive actions and running campaigns to try and salvage customer. Understanding behavior of customers involves several factors, like understanding calling patterns using social network call graph analysis techniques, modeling social influence, and nding interesting communities of users that are actionable for the operator.
  * This study was performed on 3 months of Call Detail Record (CDR) data provided by the operator in raw format. We had 2 months to process all the data,
  * We ran several graph
  based community detection algorithms to nd commu-
  nities like cliques, stars, and dense subgraphs among
  customers to understand social calling behavior.

     * was CDR dumps of voice calls and SMS
  for prepaid and postpaid subscribers of the telecom
  operator for the months of M1, M2, and M3.

* churn prediction  
pote ena pelaths einai se fash na fugei apo mia etairia  - fetaures opws pote oi filoi tou feugoun  - datamining 
uparxei to 8ema oti den isws na mhn prolavoume kai ta data den mporoun na fugoun apo telefonica alla 8a doume pws 8a ginei 
gia to internet mporoume na valoume mia adsl gia ana mhna san xpat 
akomh den exoume data - 8a xeroume shmera to vradu, an den mporesoume na exoume prosvash 8a vroume ena allo plan b 

pi8ana features gia churn predtcion : 
 * loss of quality of service - signal strength - move of customer to another place so change of signal strength?
 * economical reason : loss  of job too much to pay - or the opposite : need for better quality 
 * social reasons: change of friends circle - cheaper talk between same company - or mouth to mouth 
 *    

movistar 9D
jFKSY7qS7XqCNKo0JetH

* Abstract 
prepie na ginei 150 

* "Detecting Spammers on twitter": This work also focuses on spamming activity of Twitter, taking advantage the success of trending topics. 
 * They collect 54 million users 54 million users, 1.9 billion links and aproximately 1.8 billion tweets whereas they focus on only three trending topics. (Do we have a number of treding topics ??)
By focusing on three trending topics they investigate on statistical measurements like daily frequency of tweets, weekly paters of usage, fraction of tweets containing URLs/ spam words and cdf on different features of Twitter. They also include the aggressive spammers towards the trending topics . 

We do this .... epishs gia auta exoun piasei ena piasariko titlo Susan Boyle on tv , MJ's death ..mporoume na entipisoume ki emeis kati gamato tetoi sta trends?

* epishs vlepw sto paper pou diavazw twra Detecting Spammers on twitter
   daily frequencey tweets aboyt a trend
   * mporoume na paroume 3-4 polu dhmofilh trends ...cdf : 
     * (a) Fraction of tweets containing URLs
     * (b) Fraction of tweets with spam words
     (b) Age of the user account
     (a) Fraction of followers per followees
     (c) Number of tweets received

ta parapanw exei hdh to DIKO tous paper : emeis mporoume na paixoume me keywords apo sugkkekrimeno spam : 

       * (b) Fraction of tweets with spam words: "follower" - adf.ly - Wakeupnow   - MMORPG  - crowd funding
       * (b) Fraction of spam tweets form Turkey !! 
       * (b) Fraction of spam users form Turkey !! 
        * 





* * prepei n a dwsoume mia social analysis xreia sto paper (des perigrafh sunedriou ) -  8a to kanei o Hlias
* o Hlias epimenei oti o classifer denexei nohma giati kanoum classify me vash tis times emeis kai meta tou leme xanalane classifu 
* 8a anw egw tis allages pou nomizw oti prpeie na ginoun ROC - alexa - ...
* apo thn perigrafh toy sunedriou: http://www.wosinf.org/#about 
  *observing humans’ behaviour, especially the one expressed on the Internet,(twitter) 
  * how the social influence occurs in society at the level of an individual and at the network level (empirical research), 
    * user graph on Twitter --> could this be the profile of a user on the spam campaigns graph?
  * how to simplify or find theoretical representation for this complex phenomenon (models),
    * could our network(nodes: user /links edges : tweeted links) be an example model?
  * how to target the society to maximize the spread of influence or innovations diffusion (heuristics, analytical solutions),



  * 8a 8a allaxw ta pinakes - grafhmata pou ephreazountai 
* selida 7 pinakes me feutrues auta ta petaei o classifier ??

 * Vivi: mporoume na testaroume ton classifier pou exei ginei trained me ton march na tou dwsoume test allous mhnes APril May June July na doume ti noumera 8a vgalei ? eipa oti 8a to dokimasw na douome 
 * defence of tye classifier : 
    Auto pou kanoume einai mia klassikh paradosiakh me8odo sto machine learning gia na metrisoume thn apodosh 
    (dld poso kala mporei na kanei classify) enas algorithmos h' ena montelo
    Blepoume kai edw: http://en.wikipedia.org/wiki/Cross-validation_(statistics)

     In a prediction problem, a model is usually given a dataset of known data on which training is run (training dataset), and a dataset of unknown data (or first seen data) against which the model is tested (testing dataset)

    Ta testing data o algori8mos DEN ta exei 3anadei.
    Dld auta ta testing data DEN ta exei xrhsimopoihsei ka8olou gia na kanei train to model.

    Ta testing data ta xrhsimopoioume mono gia prediction, dld o algori8mos DEN 3erei to class tous.

    Kanei predict to class tous kai emeis tsekaroume an kanei la8os h' swsta.
    KANOUME AKRIBWS OTI KANEI KAI O "Towards online spam filtering in social networks"


    DEN kanoume classify me bash tis times. Kanoume TRAIN me bash tis times
    Kai meta kanoume classify ta test data, dld data pou den exei 3anadei o algori8mos!

    To skhniko me ta 100 random sub-splits, einai epishs klassikh cross-validation methodos (uparxei sth wikipedia!! http://en.wikipedia.org/wiki/Cross-validation_(statistics)#Repeated_random_sub-sampling_validation)

    O,ti kanoume einai by the book!

* prepei n a dwsoume mia social analysis xreia sto paper (des perigrafh sunedriou ) -  8a to kanei o Hlias
* o Hlias epimenei oti o classifer denexei nohma giati kanoum classify me vash tis times emeis kai meta tou leme xanalane classifu 
* 8a anw egw tis allages pou nomizw oti prpeie na ginoun ROC - alexa - ...
* 8a diavasw thn perigrafh toy usunedriou 
* 8a 8a allaxw ta pinakes - grafhmata pou ephreazountai 
* selida 7 pinakes me feutrues auta ta petaei o classifier ??

* The reviewers made three main points:



    1. The Classification results were not good
    2. We should focus on GMF
    3. These features have been studied in the past.

    About the 1:
    In the section: {The Classifier}
    I present the updated classifier which has 

    ston classifers dinoume users .  Gia ka8e enan exoume ki ena class (plh8os spam tweets/ plh8os apo active days
    prin eixame class gia ka8e xrhsth 0 h 1 (spam or not spam) 
    opote o classifier pernei gia ka8e xrhsth normalized(diairesh me active days) times fetures kai thn antistoixh classh (sunexomenh twra) 

    phram olon martion  xwrisame tous spammer kai tous legit . spammer einai osoi exoun #spam tweets/active days > 0 (this is class information) spam tweet einai otan exei google heuristic + blacklists me GMF 

    spammer = 5152/622 000 kai tous legit 622000-5152


    akomh den to exoume xwrisei se train kai test apla se spam kai legit. 

    (h epilogh 90-10 einia sunh8hs) epaixa me aythn thn timh den allaxe kati.

    pernoume to TUXAIO 90% twn legit kai to TUXAIO 90% twn spammers 
    ta enonoume auta ta duo kai ftiaxnoume to TRAIN SET 

    pernoume to upoloipo 10% twn legit kai to 10% twn spammers
    ta enonoume auta ta duo kai ftiaxnoume to TEST SET VGAZEIS THN CLASS 

    sthn scikit -learn enai to standr lib ths python gia classify machine learnig paketo ths python 

    etrexa gia osous classifiers tairiaze to input 

    xrhsimopioume mia veltiwmenh ekdosh tou decision tree (pou xrhsimopoiei o The state of the art paper: Towards Online Spam Filtering in Social Networks me ton opoio sugkrinomaste ) 

    regresion tou decision tree 


    genika to input pou dinoume einia 

    TRAIN
    m1 spammer followers = 10 trends = 20 
    m2htsos spammer followers = 10 trends = 20 
    mh3tsos spammer followers = 10 trends = 20 
    mht4sos spammer followers = 10 trends = 20 

    TEST (parolo pou xerw)
    mhts5os ? followers = 10 trends = 20 
    mhtso6s ? followers = 10 trends = 20 

    to decision tree vgazei kanones pou xarakthrizoun thn classh 

    TWRA ti kanoume 
    TRAIN
    mhts1os spammer =0,3 followers = 10 trends = 20 
    mhtso2s spammer=0 followers = 10 trends = 20 
    mhtsos3 spammer=16 followers = 10 trends = 20 
    mhtsos4 spammer=90 followers = 10 trends = 20 

    TEST (parolo pou xerw)
    mhtsos5 ? followers = 10 trends = 20 
    mhtsos6 ? followers = 10 trends = 20 


    regression :  sou vgazei kanones pali alla anti gia 0 /1 klash vgazei sunexomanh timh 
    pws to kanei : pernei ta train kai dokimazei diafora decision trees .

    http://en.wikipedia.org/wiki/Regression_analysis#mediaviewer/File:Linear_regression.svg

    Mean Square Error = O Mesos oron twn tetragwnon twn apostasewn meta3u pragmatikwn kai problepsewn

    epeidh parapanw anaferame gia TUXAIO xwrismo train kai test - epanalavame to peirama polles fores (100   : Giati: Afou kanoume xwrismo tuxaia 90/10 se train/test, tote se ka8e split ena sample exei pi8anothta 9/10 na bre8ei sto train (kai 1/10 na bre8ei sto test), an epanalaboume to peirama 100 fores tote eimaste 99.999999% sigouroi oti ola ta samples exoun par8ei toulaxiston mia fora KAI sto train KAI sto test)
    pernoume 90 - 10  
    Auto legetai: Repeated random sub-sampling validation (http://en.wikipedia.org/wiki/Cross-validation_(statistics))

    opote ektos apo tis parapanw diafores sthn me8odologia tou clasificaton exoume kai tis parakatw 
    1/. phrame idio mhna (march ) gia test + train . prin eixame train february kai test stom martio . allh fush katanomh timwn twn  features ston ena mhna kai allh ston allo

    2/ omogenopoihmana ta dedomena 
    twra exoume gia olous tous xrhstes ola ta features

    3/ tuning  
    phrame ola ta features enw prin den eixame ola ta features. 

    Uparxoyn features dependent sto xrono : plh8os apo totatl trends, enw to followers den exei na kanei me ton xrono . 

    ta dependent ston xrono ta dieiresame me to plh8os twn active 
    =========================
    GMF : 

    next step : 8a xanapaixoume me RBL (isws na exoume polla false positives) 


    ===
    spam campaigns ? 

    ftiaxnoume grafo pou exei komvo exei tous xrhstesh ta links kai san akmes sundeontai . 
    algori8mo pou kanei cluster kai vriskei tous upografous . 

    ===
    ena comment: auta ta features exoun polloi meleti8ei ...alla to alexa ranking den exei meleth8ei opote to vazoume : 

* sunnathsh Hlias sotiris Vivi 
 *  ti eixame kanei  - ti diafora eexei o classifier me ton palio  giati toso kalutera apotelesmata auth thn fora
  * ti eixame kanei thn prohgoumenh fora kai na sugkrinoume  
  * o hlias proteinei measurement paper : 

katarxhn proteinei an ginetai na paixoume me ton classifier  kai ana tweet an spam h oxi OXI ana user


oson afora to measuremnt hfos tou paper : 

trends se poso xrono ginetai hijack 

gia gmf campaigns ti exoume kata nou …mporei na vgei arketh douleia se campaigns?
  * Kaname train se enan mhna kai test se enan allo mhna (Febrouario vs Martio)
  * Auto mporei na exei kapoia problhmata giati ta datasets mporei na diaferoun.
  * Dld se enan mhna na exoume perissotera trends ligotera hashes ktl apo enan allo mhna
  * Epishs den eixame followers/following gia olous tous users
  *  Twra:
   * Pairnoume mono enan mhna
   * pairmoume mono users pou 3eroume oti exoume followers / followings
   * kai kanoume cross validation
   * O algori8mos exei alla3ei alla den kanei auto thn megalh diafora
   * Prin htan: Decision Tree Classification
   * Twra einai: Decision Tree Regression
   * H diafora einai oti prin: O classifier ebgaze binary times
   * twra o classifier bgazei kapoia timh. apo -1 mexri 1
   * an einai <0 twte NEG (=legit). An einai >0 tote POS (=spam)


* classifier: 
    * python ../experiment_451.py --action classifier --input_filename ../experiment_10_1_14.SAT.results.json --output_filename experiment_10_1_14.SAT.gheuristic.results.urls.json.output --days_to_plot "11-01-2014"


* From mobile phone data to the spatial structures of cities:
    * studying phone data recorded during 55 days in 31 Spanish metropolitan areas.
    * rst dene an urban dilatation index which measures how the average distance between individuals evolves during the day, allowing us to highlight dierent types of city structure.
    * focus on hotspots
    * study the lifetime of these hotspots and show in particular that the hierarchy of permanent ones, which constitute the `heart' of the city, is very stable whatever the size of the city.
    * Our analysis is based on aggregated and annonymized mobile phone traces provided by a Spanish telecommunications operator, which concerns 31 Spanish urban areas studied during weekdays 


* From Cross-checking different sources of mobility information
    * perform instead a cross-check analysis by comparing results obtained with data collected from three different sources: Twitter, census and cell phones.
    * Analysis is focused on the urban areas of Barcelona and Madrid, for which data of the three types is available. We assess the correlation between the datasets on different aspects: the spatial distribution of people concentration, the temporal evolution of people density and the mobility patterns of individuals. Our results show that the three data sources are providing comparable information. Even though the representativeness of Twitter geolocated data is lower than that of mobile phone and census data, the correlations between the population density profiles and mobility patterns detected by the three datasets are close to one in a grid with cells of 2x2 and 1x1 square kilometers. This level of correlation supports the feasibility of interchanging the three data sources at the spatio-temporal scales considered.

* From Crowdsourcing Land Use Maps via Twitter: 
      * Twitter important sensor of the interactions between individuals and their environment.proposes the use of geolocated tweets as a complementary source of information for urban planning applications, focusing on the characterization of land use.
      * unsupervised learning and automatically determines land uses in urban areas by clustering geographical regions with similar tweeting activity patterns.
      * We propose an unsupervised approach for the automatic
        identification of urban land uses from geolocated tweets. It
        consists of two steps: (1) land segmentation, to divide the
        urban area under study into smaller geographic regions (SOMS KOHONENE 1990) and
        (2) land use detection, to determine the type of land use for
        each geographic region.


* Telefonica intership : crowd modeling, urban computing (for urban planning)
          * exploit geolocated tweets + semantics to interpret individual & crowd behavior (how individuals and groups of people move across geographical areas)
          * Recently, in the area of urban computing for urban planning we can find a variety of results using
          geolocated information to model land use. The approaches can be divided according to its source of
          information: 
            (1) location-based social networks (LBSN) traces from Foursquare or Twitter; 
            (2) call detail records (CDRs) from cell-phones; and 
            (3) GPS traces. 
                The three data sources represent a compromise
            between granularity and data generality: while GPS data has longitude-latitude information every couple
            of seconds for usually a very limited number of individuals (usually less than one hundred); CDRs have
            location information for millions of individuals at a tower level only when an interaction (call or SMS)
            takes place. LBSN offer an intermediate solution where location information is in the form of longitudelatitude
            for an intermediate number of individuals (usually hundred of thousands).

          * The technique we propose for the automatic identification of urban land uses from geolocated tweets has
        two steps: (1) land segmentation and (2) land use detection.
           * SOMS : partitioning the land into different segments,   
           * Characterize each land segment by its average tweeting activity which will then be used to identify
        common land uses. For each land segment s, a tweet-activity vector Xs representing the average tweeting
        behavior is built as:  
  
  * S. Isaacman, R. Becker, R. C´aceres, S. Kobourov, M. Martonosi, J. Rowland, and A. Varshavsky,
      “Identifying Important Places in People’s Lives from Cellular Network Data.,” in Pervasive Computing, 2011.
            * Identifying Important Places in People’s Lives from Cellular Network Data  - as an attack pervasive
            xrhsh ths methodologias (opws egine xrhsh kai apo to prosfat paper pou estiel o leontidis Assessing the Potential of Ride-Sharing Using Mobile and Social Data) an sundiasteu me twitter tagged data - mporw na vrw thn poreia pou exei enas xrhsths kai na parakolou8w to location tou ...(attack opws antistoixo me to skype)
            *  opote exoume user location inference me vash ta cdr data (S. Isaacman' technique) + twitter data + foursquare 
          polles douleies se auto ton tomea - I know where you went and what you did last night -- alla pou diaferoume apo olous tous allous?

  find my friends efarmogh 

  From 'Assessing the Potential of Ride-Sharing Using Mobile and Social Data': (opou einia kai ta references)
        + related studies that focus on characterizing crowd mobility and urban environments using information
        from Twitter or Foursquare. "Urban Area Characterization Based on
        Semantics of Crowd Activities in Twitter
        Shoko Wakamiya1,":
          * Geographic characteristics based on crowd activities: extracting urban characteristics using Twitter - reveal an urban area’s features relevant to crowd activities.
          characterize urban areas: (backgound work): 
           * Vieira et al. [17] have proposed a Dense Area Discovery (DAD-MST) algorithm for automatically detecting dense areas using the ubiquitous infrastructure provided by a cell phone network.
           * Kurashima et al. [7] have developed a Blog Map of Experiences, which can share personal experiences of
              tourists at specific locations and times extracted by using association rules from blog
              entries and present them visually; their method could characterize sightseeing spots
              by means of visitors’ activities and evaluations.
           * geo-social tweets database, Fujisaka et al. [1 proposed a method for detecting geo-social events including unexpected events based on crowd moving pattern; aggregation and dispersion.
           * Lee et al. [8, 9] presented to detect geo-social events by measuring crowd activities’ regularity.
           * These previous methods applied to a similar approach with our work, however, the
            difference is these work’s goal aiming to detect geo-social events borrowing crowd
            power obtained from Twitter. On the other hand, our proposed work’s purpose is to
            characterize urban areas on the basis of geo-social tweets database
            * Krishnamurthy et al. [6], Java et al. [4], Zhao et al. [19], and examined focusing on utilization of Twitter by making a relation to its impact on lifestyles and topical tendencies. Also, Iwaki et al. [3] have proposed a method for the discovery of useful topics from microblogs. These studies mostly dealt with content analyses of textual messages and the link structure of the followers of certain users.

Wakamiya et al. [13] and Fujisaka et al. [14] have used geo-tagged Twitter datasets
and its semantic content to study and characterize crowd mobility, and Frias-Martinez et al. [15] for the characterization of land use. 

Foursquare has been used by Noulas et al. [16], [17] for modeling crowd activity patterns. To the
best of our knowledge, Twitter and Foursquare data have not been used for carpooling.

The question is ...how to use cdr data combined or in some way connected to social network data ...One road is inference? 
Maybe recommendation systems?
According to the area a user is a recommendation application will propose food - entertainment - choices..?Maybe social networks could indicate the location of the user + the recommended place 

=================(from http://enriquefrias-martinez.info/publications)=============
other ideas implemented in publications : 
 * use of geolocated tweets as a complementary source of information for urban planning applications, focusing on the
characterization of land use
===================================================================================
* just use social network data ...an den sundeontai me ta cdr toso ro xeirotero gai ta cdr data...den ta xrhsimopoioume ...!
* use geolocated tweets  + cdr data if it is possible to connect with the tweets. otherwise can it be as a parallele study ?

===================================================================================
* Based on the snap framework we inspired a custom based network that manipulates twitter data (tredns- tweets- users)

* 24  July 
 * POST / HTTP/1.1" 200 - Thu, 24 Jul 2014 08:11:23 +0000 Tweets sent: 30944127/30944127
 * JSON : 
 * start playing around with hadoop : 
  * follow http://www.michael-noll.com/tutorials/running-hadoop-on-ubuntu-linux-single-node-cluster/
        but problem with espoina@aneipero:~/svn/twitter_spam/twitter_spam$ sudo apt-get install sun-java6-jdk
        Reading package lists... Done
        Building dependency tree       
        Reading state information... Done
        Package sun-java6-jdk is not available, but is referred to by another package.
        This may mean that the package is missing, has been obsoleted, or
        is only available from another source

        E: Package 'sun-java6-jdk' has no installation candidate
  So followed  instruction from here:
  http://www.webupd8.org/2012/01/install-oracle-java-jdk-7-in-ubuntu-via.html
 
 *Map reduce : The term MapReduce actually refers to two separate and distinct tasks that Hadoop programs perform. 
  * The first is the map job, which takes a set of data and converts it into another set of data, where individual elements are broken down into tuples (key/value pairs). 
  * The reduce job takes the output from a map as input and combines those data tuples into a smaller set of tuples. As the sequence of the name MapReduce implies, the reduce job is always performed after the map job.
  * e.g you have five files and each file has 2 columns (the key and value in Hadoop terms) e.g. 
  * MAP: 
   1 . As the Map operation is parallelized the input file set is first split to several pieces called FileSplits. 

   If an individual file is so large that it will affect seek time it will be split to several Splits. 

   The splitting does not know anything about the input file's internal logical structure, for example line-oriented text files are split on arbitrary byte boundaries. Then a new map task is created per FileSplit.

   2.JAVA at 

  

* 23 July 
 * http://www.simafore.com/blog/bid/94454/A-simple-explanation-of-how-entropy-fuels-a-decision-tree-model
  * to sxhma einai kalh idea kai gia to diko mas paper wste na dixoume pw sienai ta featires tou twitter  
 * JSON EXTRACTED AT aneipero 
 * EXPANDER
started at 23 July 12:37:03
 python experiment_451.py --action cdfs --trends_database_name experiment_25_4_14 --trends_database_host localhost --database_name experiment_25_4_14 --database_host localhost --results_filename experiment_25_4_14_extracted_on_23_July.SAT.gheuristic.results.urls.json --from_date "Sat Apr 26 00:00:01 +0000 2014" --to_date "Sat Apr 27 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424
at screen 

eleipe ena orisma  exclude_users_without_urls: restarted as : python experiment_451.py --action cdfs --trends_database_name experiment_25_4_14 --trends_database_host localhost --database_name experiment_25_4_14 --database_host localhost --results_filename experiment_25_4_14_extracted_on_23_July.json --from_date "Sun Jul 20 10:00:00 +0000 2014" --to_date "Mon Jul 21 10:00:00 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False  
 
 started 23 July 12:45:14 --- finished at 23 July 12:57

 when finished run expander 

 Run tweet_server for url expander:
   * Run tweet_server for url expander:
    * python experiment_451.py --action tweet_server --database_name experiment_25_4_14 --database_host localhost --port 8081
    python experiment_451.py --action tweets_server --database_name experiment_25_4_14 --database_host localhost --port 8081
    * screen: 20071. 

* Run tweet expander in anipero
    * python experiment_451.py --action expand_multithread --database_name experiment_25_4_14 --database_host localhost --threads 100 --tweet_server_url http://139.91.70.42:8081  
    * screen:  20146

* Run tweet expander in grid-wn3:
ssh to grid-wn3: WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED: ssh-keygen -R server.example.com: ssh-keygen -R {grid-wn3.ics.forth.gr} + ssh-keygen -R grid-wn3.ics.forth.gr
    * python Github/phd/code/experiment_451.py --action expand_multithread --database_name experiment_25_4_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 2276

*  Run tweet expander in grid-wn4:
      ssh-keygen -R {grid-wn4.ics.forth.gr}
      ssh-keygen -R grid-wn4.ics.forth.gr
    * python experiment_451.py --action expand_multithread --database_name experiment_25_4_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen:   11097

*  Run tweet expander in grid-wn5:
    * python experiment_451.py --action expand_multithread --database_name experiment_25_4_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 22975

*  Run tweet expander in grid-wn6:
    ssh-keygen -R {grid-wn6.ics.forth.gr}
      ssh-keygen -R grid-wn6.ics.forth.gr
    * python experiment_451.py --action expand_multithread --database_name experiment_25_4_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 18731

    *************************
    Gia auta pou epistrefoun 403 mallon einai spam 
https://support.google.com/mail/answer/12088?hl=en

opote isws na tsekarame an einai 403 ...na ta kanoume mark as spam.
---rror 403: Forbidden
Failed to expand url:http://t.co/ddG3Te5XJ1
The problem was: <urlopen error timed out>
Failed to expand url:http://t.co/wd6P9OVeg8
The problem was: HTTP Error 403: Forbidden
Failed to expand url:http://t.co/aOLt0XZuke
The problem was: timed out
Failed to expand url:http://t.co/T4Qzn6D72A
The problem was: HTTP Error 302: The HTTP server returned a redirect error that would lead to an infinite loop.
The last 30x error message was:
Found
Failed to expand url:https://t.co/a16ZXwJMWJ
The problem was: HTTP Error 404:
********************************************************************* 

* 18 July 
 * papers from ilias leontiadis @telefonica: 
  * From mobile phone data to the spatial structure of cities
    *  studying phone data: capture large amounts of human behavioral data
    * provide information about the structure of cities
    *  focus on hotspots,propose a parameter free method to detect them - lifetime of these hotspots -  show in particular that the hierarchy of permanent ones, which constitute the ‘heart’ of the city,
is very stable whatever the size of the city.
    * data :  aggregated and anonymized mobile phone data(mobile phone dataset provided by a Spanish telecommunications operator)  and concerns 31 Spanish urban areas studied during weekdays.
    * wide range of population sizes will allow us to test some scaling relations and also to identify various behaviors.
******************************************
*Assessing the Potential of Ride-Sharing Using Mobile and Social Data A Tale of Four Cities:
 * They are trying to understand the potential decrease in the number of cars in a city if people with similar mobility patterns were willing to use ride-sharing in their daily commute between home and work.

They use CDRs (call description records) + Twitter data (NY+LA) 
They infer home and work locations for individual users
They obtain information about communication and explicitly stated “friendship” relations between users, which later used to restrict rides between users that know each other or have common friends, in order to address concerns about riding with strangers.

They match users that could share a ride so as to minimize the total numbers of cars and provide rides to all users.
Results.there is indeed significant potential for reducing traffic using-ride sharing.

The traffic in the city of Madrid can be reduced by 59% if users are willing to share a ride with people who live and work within 1 km; if they can only accept a pick-up and drop-off delay up to 10 minutes, this potential benefit drops to 24%;
****************************************
To call or to Tweet ? 
* 3-1-1 phone services: @Canada / US acces to non emergency municipal services . Agencies have
started to offer new communication channels through social media including Twitter accounts. Twitter is also being used by citizens to share issues about their communities with friends and colleagues

IN this study they analyze the behavioral similarities and differences between the use of formal 3-1-1 phone services and informal channels – like Twitter – to report about issues that affect a community. 

* 11 July 
* telco me telefonica 
 * sybil attack detection @ twitter
 * spam campaign analysis (grafos.ml)
 * dataset of tuenti maybe available (whole lifetime) to analyse the evolution of the graph ? (in collaboration with Marian Boguna)
  * is it feasible...how could we do a sampling in a huge dataset such that of tuenti 

* 8 July : ma8hmata Ferrari &  paper parousiashs@dcs
 * the key distribution can be either symmetric (both parties same key) or assymentric ancryption - public key . 
 * a, b can physically exchange the secret key 
 * if a and b each have an e 
* 7 July : spiti logw adia8esias - sartori episkeyh - paper parousiashs@dcs

* apo to paper Trafficking Fraudulent Accounts: The Role of the
Underground Market in Twitter Spam and Abuse: analyzing social graph properties of sybil accounts
[6, 33, 34],: 
  * G. Danezis and P. Mittal. Sybilinfer: Detecting sybil nodes using social networks. In Proceedings of the Network and Distributed System Security Symposium (NDSS), 2009.
  * C. Yang, R. Harkreader, J. Zhang, S. Shin, and G. Gu. Analyzing Spammers’ Social Networks for Fun and Profit: a Case Study of Cyber Criminal Ecosystem on Twitter. In Proceedings of the 21st International Conference on World Wide Web, 2012.
  * H. Yu, M. Kaminsky, P.B. Gibbons, and A. Flaxman. Sybilguard: defending against sybil attacks via social networks. ACM SIGCOMM Computer Communication Review, 2006.
  KAI ALLA : multitude of detection strategies. These include analyzing social graph properties of sybil accounts
  [6, 33, 34], characterizing the arrival rate and distribution of posts [8], analyzing statistical properties of
   account profiles [3, 26], detecting spam URLs posted by accounts [27], and identifying common spam redirect
   paths [15].


* 3  July katrea plhrwmh : 5751-045928-245 492,15€.

* 2/7/2014@trust 
  * "Trust in Future Internet: the potential of Trustworthiness Enabling Technologies"
    *  trust of a system ..too high / too low??
    * OPTET approach : platform projects .......
  * "Who turned off the lights? Detecting ATPs in electricity networks"
    * staxnet, http://www.symantec.com/content/en/us/enterprise/media/security_response/whitepapers/Dragonfly_Threat_Against_Western_Energy_Suppliers.pdf
  * "PUFs : Where are we standing?"
    * silcon(more preferable)/optical pufs
    * math: one way function : robustness - physical (hardware) unclonability - unpredictability 
      *  verayo (company) : delay path -  race condition 
      * instristic id (company) : sram cell noise background makes error correction required
      * unclonable???
        * inspect and notice ...
        * chip --> light: photonic emission analysis: measuring emission of photons 
          * mac of memmory SRAM --> LOOK carefully !: raws of bits ...1 01 1 0....read the sram , distinguish WHICH transistorm sending teh "light" = 1
          * (reverse engineer?) so you read from teh photonic emmission analysis ...1100101011000 (transistors ) --> manufacture chip like "cloning" with the answers above..
          * from reading out the target we try to copy and create a clone...that behaves like ...
        * arbiter pufs from VERAYO : delays ...clone?
          * nobody gives a chip!!
          * you have to program an arbiter puf ..
           *  pico second analysis...every 6 ps read the again photonic analysis ?? reverse angineer again 
           * measureemts results of challenge combination with hamming distnace one 
           * n + 1 measurements
           * in real life this does not exist ???   ALICE & BOB? next presenation : 
    * "How puffy are PUFs? - On the state of the art of PUF-based protocol design and analysis"
      * not random number geerators..wrong assumption        
      * invasive hardware attacks ...cryptography not enough 
        * physical tampered protection ...? nt enough 
        * PUFs!! is the answer 
         * but still breakable ...so what to do ?
        * puf types: delay - memory - non electric
        * applications: ientification/auth, secure storage, used as phudorandom function 
    *  Papou : physical one way function     
    * physical randm function (noise..)
    * generic and modular game-based definitions: 
     * 



* 1 Ιουlη trust 
 * general4tpm
   * tpms smart card create keys, key storage cryptography ,local access control , authorization ..attached to platforms  
   * @ phones, servers 
   * rollback protection 
   * crypto agile : easy to add new algorithms 
   * symmetric cryptography 
   * create, import keys, secure login, secure clock , 
 * authorization in tpm :  
   * wriite file/unseal a key/sign using a key/

    what kind of modue could trigger the execution of the policysigned()?   *in which level of administration is it available to the end user?is device/applicaton  driven execution? if available could I choose a specific command ?(advanced users)does it ofer an API ?could I trigger the execution of a specific policy command ? execution..algorithm?  so this would also be an entry for vulnerability... 

    * behavioral specification 
    * c code : stackoverflows!! http://security.stackexchange.com/questions/47008/trusted-platform-module-daughterboard-vs-onboard-tpm 
    trustedcomputinggroup .org 
    
  * "Large-scale Security Analysis of the Web: Challenges and Findings": 
   * security score of websites 
   * 1000 website per country TLD 
    * phantomJS 
    * 8 defence mechanisms 
     * transport layer security : attribute & cookies , cross site scripting , ssl scripting , xss, info leakage ...
     * JS inclusion (register-me.com , when not registered, adversay can register it ...)
     * score : how dor you finally assign to a website? how do you actually check if a website is vulnerable? do you seta virtual machine and is nected 

     if visit a website? did you finally hide the fact that you are away form home?
     

     statistical inference on the published vector could be used by an adversary ...although hiddedn and obfuscated loation but could relate patterns of vectors when home and when not home?
     
     mongo ?

  * Bitcoin
    * a lot of users  2 hundred fifty thousand users 
    * university of cyprus only accepts bitcoins??? 
    * enhance user privacy
    * rob the private key: people put private keys at "banks" and then banks dissapear.
    * on top of p2p
    * broadcat in entire net
    * prevent linking between transaction -inutsoutputs
     * bitcoin A--> transform in zerocoin ZEro knwolegde proof of knowledge--> bitcoin B : A and B canot be connected

     zero coin does not prevent statystical analisis -> leakage !
 
  * "Integration of Data-minimising Authentication into Authorization"
    *  !!!!!!!!pws perase auto to paper!!;;;
 * Evaluating Trustworthiness through Monitoring:
  *  The Foot, the Horse and the Elephant
    * attacked by a fly!

 * sweet dreams & nighmares: 
  *  ..

 
=====================
     * 46% of which dataset ? all 
     * evaluation of security scor by alexa popularity : more popular --> more secur e mallon !
     * by country : small variances 
     * regitser a project @ google code.. assign teh js vulnerable code...asto ekei na trexei !scehedule it for deletion after x days
     * no sql injection (legal issues)

  * "Towards A Vulnerability Tree Security Evaluation of OpenStack's Logical Architecture"
    * cloud computing service types: SaaS Paas Laas
    *  top issue in cloud computing is security (survey)
    *  OpenStack': components: external api , compute service, image , volume, network service
    * svss score ( vulnerability) 

  * "PrivLoc: Preventing Location Tracking in Geofencing Services"
    * spatial data types : point line polygon 
    * spatial operations: overlap, distance neighrest neighbor
    * spatial indexes  R tree
    * background work ; 
     * location blurring
     * insert false dummies  
     * landmark obfuscation 
    *  send a vector : 2 points 
    * attack model : honest but curious db server  - differenct db servers do not collude
    * rely on trusted server  
    * transform, divide into tiles ...
remove notion of loatcion per tile!
movenmenst are in >2 tiles ..solution : distributes db servers: each process different key per 
  * how big is the palz tiles area that you transform ?
    * did not solve the problem of missing form home!! someone vcan rob you!
-----------------------    
* 30/6/14 trust 

  dAA : RSA random oracle 

  30/6/2014
  cloud computing security 

  association of attributes is confidential so store the two attribute sin different data storage
  and keep secretly the mapping betweetn thwem (name -illness)

  of course the fielsd that are sensitive per se ARE ecrypted


  --------------
  again the k anonymiy problesm arise : 
  if not sorted , you can associate the two table taht reside in two different places. 

  she mentiones other way of info leakage so...apply 
  selective encryption

    key per user
  over encryption (multiple layer of encryption )

  * Access (user waants specific data) and pattern confidentiality (access of a user of teh same daty of same data, or 2 users access same data):
    complexity of analysis of this
    --> shuffle index 
      ...cover searches, cached searches(for confusion not for traditional reasn taht cache is used) , shuffling
  Integrity : correctness comleteness of data fresh ness..: two approaches authenticates structure (signature Merkle hash trees) or probabilistic (depending on the amount of control (markers and twins) inserted))
  put 10 fake patients ...if you dont find them ,..then the server is lying 

  dublicate some users (twite the Alice tuple), provide twice the protection 

  you need BOTH (fake & twin)
if you miss one alice the server is 

encryption in onions
--------------------------------------------------------------------------------
* egkatastash hadoop: 
 * http://wiki.apache.org/hadoop/Running_Hadoop_On_OS_X_10.5_64-bit_(Single-Node_Cluster)
 * get JDK latest : 
   * http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html
   * http://docs.oracle.com/javase/7/docs/webnotes/install/mac/mac-jdk.html
   * ssh-keygen -t rsa -f .ssh/hadoop -P ""
      Generating public/private rsa key pair.
      Your identification has been saved in .ssh/hadoop.
      Your public key has been saved in .ssh/hadoop.pub.
      The key fingerprint is:
      b2:6e:63:9e:ef:b8:38:35:ad:aa:01:87:4c:26:8b:16 antonakd@despoina.macAir
      The key's randomart image is:
      +--[ RSA 2048]----+
      |                 |
      |                 |
      |.E               |
      |*o.              |
      |=o.   ..S        |
      |.o    oo.        |
      |  .  ..o         |
      |   ..o=o         |
      |  ..o**=o        |
      +-----------------+
      despoina:~ antonakd$ 
* ssh: connect to host localhost port 22: Connection refused
  * http://stackoverflow.com/questions/6313929/how-do-i-open-port-22-in-osx-10-6-7: The Apple Mac OS X operating system has SSH installed by default but the SSH daemon is not enabled. This means you can’t login remotely or do remote copies until you enable it.
* OK fixed ! (apo setting enable remote login )
* and the rest of the files 
 *http://spawgi.wordpress.com/2012/09/08/installing-hadoop-on-a-single-node-part-2/ 
 * In file hadoop-env.sh set the JAVA_HOME :#export JAVA_HOME=${JAVA_HOME} ->export JAVA_HOME=/Library/Java/Home
 *...
 * sudo chown hadoop:hadoop hadoop/tmp/
chown: hadoop: illegal group name
 * should create a group hadoop and user member hadoop
 * 


* 24 June
 * Γεια σας, 

      κοιταξα το paper απο telefonica για Fake account detection και σκεφτομουνα πως θα μπορούσαμε να το εφαρμοσουμε στην περιπτωση του Twitter. 
      ΒΗΜΑ 1. Social Followers Graph 
      Μια ιδεα ειναι να κατεβασουμε tweets οχι specifically for trending topics. 
      Στο dataset αυτο θα χτισουμε ενα social relationship graph (παρομοιο με αυτό που χρησιμοποιησαμε για τα spam campains, οπου κάθε κόμβος χαρακτηρίζεται απο #friends (followers/followings) ...θα κανω μια ερευνα γαι τα ποια features του twitter  χαρακτηριζουν τα fake accounts, αν και αυτό ειναι ουσιαστικά ενα απο τους στοχους της ερευνας αυτής. 

      Μια αλλη ιδέα ειναι να χτισουμε το παραπανω social relationship graph στο dataset που εχουμε ήδη και να δουμε αν τα fake accounts χρησιμοποιουν με παρομοιο τροπο τα trending topics. 

      Τα παραπανω graphs και στις δυο περιπτωσεις ιδανικα σχηματιζουν 2 υποσυνολα. Το ενα περιλαμβανει non sybil accounts οπου η αποσταση 2 φιλων/followers που δεν ειναι fake ειναι μικρότερη απο την αποσταση μεταξή ενος non sybil account και ενος Sybil. 

      To non Sybil region toy grafou einai kala sundedemeno opou sto paper ginetai anafora gia random walks ta opoia mporoyn na montelopoih8oyn me *irreducible* kai aperiodic Markov chain.]
      H texnikh exasfalizei thn sugklish se stationary distribution sthn opia h landing probability gia ka8e komvo meta apo kapoio (sufficient ) ari8mo vhmatwn is proportinal to its degree. 

       Tha suzhthsoume gia to kata poso h parapanw texnikh einai efarmosimh sthn periptwsh mas.  

       Εδώ θα χρειαστεί μελέτη και αναλυση περισοτερων features των nodes που θα βοηθήσουν στο να γινει ξεχωρισμός των 2 υπογραφων. Μια αλλη ιδέα ειναι ο βαθμός συνεκρικότητας ενος κομβου, διαισθητικα ενας καλα συνδεδεμένος κόμβος, μαλλον δεν ειναι fake. 

       epihs apo     http://chrismakara.com/social-media/11-easy-ways-to-spot-a-fake-twitter-account/: 
         * 11-easy-ways-to-spot-a-fake-twitter-account: 
          * They Are An Egghead
          * They Use Stock Profile Images 
          * No Bio
          * Excessive Duplicate Tweets
          * Confusing Screen Name / URL Combination 
          * Incoherent Tweets
          *  Has Not Tweeted in Years
          *  Follows 2,001 People  
          * No Interaction With Others 
          *  No or Low Follower Counts]
          * An Unrealistic Amount of Tweets

          Paradeigma : https://twitter.com/CecileKincey

       =================================

        http://www.newser.com/story/178143/meet-the-man-who-can-buy-you-a-twitter-following.html
       http://online.wsj.com/news/articles/SB10001424052702304607104579212122084821400:
       Jim Vidmar : "απο Linked iCEO at MyCheapJobs, Inc..."http://www.newser.com/story/178143/meet-the-man-who-can-buy-you-a-twitter-following.html  Jim Vidmar has rather unusual job: He oversees 10,000 fake Twitter accounts.""

      Σε αυτό το σημείο θα κάνω μια ερευνα για real fake accounts στο twitter. 


       Στην προσπαθεια αυτή να ανιχνευσει καποιος fake καποιος θα μπορούσε να πεσει θημα και να δωσει προσβαση στον λογαριασμό του σε  apps οπως :http://fakers.statuspeople.com/       https://api.twitter.com/oauth/authorize?oauth_token=jltN8rGbFxTO2e0urdLYZy7RoETn0WpLCCIvpmIUwbsAuthorize StatusPeople Fake Followers to use your account?

                              StatusPeople Fake Followers
                              By StatusPeople Ltd
                              fakers.statuspeople.com
                              Check your Twitter account for Fake Followers
                              This application will be able to:
                              Read Tweets from your timeline.
                              See who you follow, and follow new people.
                              Update your profile.
                              Post Tweets for you.



      BHMA 2. Sybil Rank


      ---
      Χαιρετισμούς,
      Despoina Antonakaki



      2014-06-20 23:59 GMT+03:00 Despoina Antonakaki <antonakd@gmail.com>:
      γεια σας, 

      Για την Πέμπτη είναι οκ, την επόμενη εβδομάδα δεν εχω υποχρέωση απο csd εκτός απο μια βαθμολόγηση τελικού διαγωνίσματος στο hy255 για την οποία δεν έχουμε ορίσει ώρα/μέρα ακόμη. 
       Όσον αφορά το paper αν  δεν περάσει, φαντάζομαι θα το ξαναδουλέψουμε ..αλλιώς :

      είχαμε μια πρώτη σκέψη να εφαρμόζαμε μια παρόμοια τεχνική όχι το Tuenti  άλλα στο Twitter ώστε να κινηθούμε στην ανίχνευσηsybil (fake accounts). 


      Μια άλλη σκέψη που συζητήσαμε ήταν να χρησιμοποιήσουμε το grafos.ml για την αναπαράσταση και μελέτη των spam campaigns. 

      Εσείς τι λέτε; καμιά άλλη ιδέα ;

      ---
      Χαιρετισμούς,
      Despoina Antonakaki



      2014-06-20 18:33 GMT+03:00 Fragopoulou Paraskevi <fragopou@ics.forth.gr>:

      Δέσποινα τελικά δε μιλήσαμε, αλλά νομίζω ότι πρέπει αν κάνουμε
      μια συνάντηση την πέμπτη (δευ-τετ λείπω).

      H δουλεία στο twitter  έχει ολοκλήρωθεί η υπάρχει follow up κατα τη
      γνώμη σου?

      Βιβη

      > Γεια σας,
      >
      > στο summer school είχα μιλήσει λίγο με τον Διονύση Λογοθέτη http://
      > logothetis.me/
      > Στην παρουσίαση του μίλησε για τον grafos.ml http://grafos.ml/ το οποίο
      > γενικά είναι μια δουλειά σεgraph mining &  machine learning. περιλαμβάνει
      > εργαλεία για  large-scale graph mining.
      >
      > Ο ίδιος μου πρότεινε το paper : https://www.usenix.org/system/files/
      > conference/nsdi12/nsdi12-final42_2.pdf.
      >
      > Ο Qiang Cao (παλιός Intern στην telefonica)  είχε δουλέψει με τον Michael
      > Sirivianos(http://www.cut.ac.cy/eecei/staff//michael.sirivianos?languageId=2)
      > και είχαμε μια πρώτη σκέψη να εφαρμόζαμε μια παρόμοια τεχνική όχι το
      > Tuenti  άλλα
      > στο Twitter ώστε να κινηθούμε στην ανίχνευσηsybil (fake accounts).
      >
      > Μια άλλη σκέψη που συζητήσαμε ήταν να χρησιμοποιήσουμε το grafos.ml για
      > την
      > αναπαράσταση και μελέτη των spam campaigns.
      >
      > Πότε μπορείτε να κάνουμε μια συνάντηση να τα δούμε απο κοντά;
      > ---
      > Χαιρετισμούς,
      > Despoina Antonakaki
      >





#20 June
* Hadoop: 
 * http://pythonhosted.org/mrjob/index.html : pip install mrjob


#19June
* Sybil attacks: Aiding the Detection of Fake Accounts in Large Scale Social Online Services
Qiang Cao † Michael Sirivianos ‡ Xiaowei Yang Tiago Pregueiro
Duke University Telefonica Research Duke University Tuenti, Telefonica Digital
qiangcao@cs.duke.edu msirivi@tid.es xwy@cs.duke.edu tiago@tuenti.com
 * Tuenti social network maybe is available for the study of evolution for Boguna?
 * Use this study ...for Twitter? secondment at Telefonica?
* Sybilattacks at Twitter?  

# @Summer school
gia ta properties twn graph 8a mporousame na xrhsiopouhsoume apo telefonica to : 
* https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final42_2.pdf
* http://grafos.ml/okapi.html
* polu endiaferon exei to subilRank: The SybilRank algorithm is used in Online Social Network analysis to detect fake accounts. When seeded with a set of known fake accounts, it ranks the nodes in the graph according to the probability to be fake.
 * me usenix : https://www.usenix.org/system/files/conference/nsdi12/nsdi12-final42_2.pdf
  * opou anaferei gia Twitter accounts... 


#2June 
* apo thn parousiash toy Kojlia , empneusmenh ..me ton Boguna mporoune na melethsoume to evolution of trend in twitter (gennhsh-exelixh-8anatos) ka8ws kai twn spamcampaign...se sxesh me to trending topic poso grhgora sxhmatizontai pws megalwnoun kai pote pai8ainoun ...
* [02/06/14 11:11:54] Despoina Antonakaki: epishs sugkrish twn networks of trends pou hmiourgounta se ka8e xwra
[02/06/14 11:12:25] Despoina Antonakaki: kai thn sugkrish twn spammer se ka8e xwra???
# 13 May
 * askhsh hy459  epeish h malakismenh ekdosh tou  mac eixe tcpdump 444 eixe bug : 
  *   anafora kai sto http://stackoverflow.com/questions/22489139/simple-way-to-verify-valid-bpf-filter
    That's... awesome. I get the following error though tcpdump: unknown file format | on Mac OS X 10.9 GNU bash, version 3.2.51(1)-release (x86_64-apple-darwin13) tcpdump version tcpdump version 4.3.0 -- Apple version 56 –  RyPeck Mar 20 at 17:17
   egkatasthsame thn prohgoumeh eksosh ths libpcap & tcpdump opote to 
   despoina:sbin antonakd$ gunzip -c ~/Documents/__icosial/_____hy459/Assignment2/200702011400.dump.gz | ./tcpdump -n -r - 
    works lika a charm.  

ALL = RBL + Google Heuristic
FLW = Google Heuristic + RBL |grep follow

* katevazoume gurw sta 2 000 000 thn hmera ...

* ideas 

ti orizoume san   spam emeis? kati exei ginei blacklisted men alla to lag time? 
google heuristic + … 


fruad @ twitter 
idea apo markato gia meta estw oti kanw follow mia selida . sto request auto mhpws ginese fololwer kai mia allhs selidas wst na fainetai oti exoun reuma

px. kana follow to tsipra kai fainetai na eimai follower tou tsipra + tou samara 

————————————

 * 1d_feb_all.Active_days : katarxhn ti vlepoume edw . den exei nohma me thn enoia oti den exei polu plhrofora exei 2 data point to   (1.0) to opoio shmainei oti 0 spammer einai energoi ligotero apo 1 mera. to allo shmeio (3,1) to 100% twn spammer einai energoi ligotero apo 3 meres) Giati 3 giati se ola ta cdf vaze ston axona xona x MAX + 2 . giati ? gia na mporei na vgei to cdf, nauparxoun shmeia na kanw pro8esw . na morw na pros8ew 2 shmeia. kai allo ena gia na exei ligo xwro dexia  . h mple grammh einai katw apo thn kokkinh. kapou giati anevainei etsi ? ti einai to  3 ston axona x ? gia na kanw ena cdf  oi spammers pws vghkan edw : google heuristic? blacklists? manually ? einai data 1 meras ? 

 to to ALL sto file name shmainei oti oi spammer exoun vgei ws exhs : google heuristic + realtime blackhole lists blacklists 89 sto sunolo - whitelists


 * 1d_feb_all.Different_hashtags_per_day :  to 95% twn spammer xrhsimopoioun ligotera apo 5? 6 different hshtag per day   EINAI gia mia mera auto to grafhma. enw to  95% twn legin 1,2 .ti einai to 450 ston axona x: h megisth timh tou different hashtga per day (toso htan to megisto plh8so hashtags pou xrhsimopoihse enas xrhstsh) ,

 Giati exei auth th morfh . to 99% perilamvanoun katw apo 50 hashtag. alla dustuxws uparxoun mporei 1 h 2 xrhstes pou xrhsimopoihsan 450 se mia mera (oi gnwstoi kai ws outliers). Mporoume na tous vgaloume kai na kanoume beutification alla meta to cdf DEN 8a phgainei mexri to 1!! (mexri to0.999) 


 * 1d_feb_all.Different_Trends_per_day: 8elei zoom kapws na fanoun oi ari8moi .... to 80% twn spammers xrhsimopoun ligotero 3-4 different trends per day anw to 80 % twn legin 1,2  To 95% twn spam : 8-9  95% twn legit2,3 . 


 *  1d_feb_all.Different_User_Mentions_per_dayto 92% twn spammer xrhsimopoiou9 me 10 different user mention enw to 92% twn legit 1 different user mention . 


* 1d_feb_all.Followers_per_day: den uphrxan data giayto eina etsi ?
* 1d_feb_all.Following_per_day: den uphrxan data giayto eina etsi ? delete

* 1d_feb_all.Hash_Tags_per_day.png: pali prbolhma na fanoun oi ari8moi zoom ? ti einia to 6000? #hashtags 

* 1d_feb_all.Number_of_blacklist_hits_pers_day : 80 einai oles oi blacklists , to 93% twn spamm IP addresses entopistikna se apo ligotero apo  2-3 blacklists, alla to 98% twn spam entopisthna apo 5 blaclists. Giati h mple grammh den einai sto 0 ? shmeianioti to 100% twn legit eixan ligotero apo 1 blacklist hit ara 0! h mple profanws 8a vgei apo to grafhma gia na mpei sto paper.

estw enas spammer pou steleni 1 tweet me 1 url mesa an 50 blacklists ton entopisoun 8a parei 50 
an ena spammer steilei 50 tweets me 50 url sunolika kai ka8e ena url to vrei 1 blacklist 8a parei 50 
an ena spammer steilei 50 tweets me 50 url sunolika kai ka8e ena url to vrei 50 blacklist 8a parei 50* 50  

* 1d_feb_all.Number_of_spam_links_per_day.png.  to 90% twn spammers exoun ligotero apo 2 spam links per day. to 97% exoun ligotero apo 3 spam links per day.. ti einai to 40 ? ena xrhstsh esteile 40 smap link se 1 mera!!(mporei kai to idio 

* Sunanthsh gia cdfs 
outliers : 

* 3months_flw.Total_Trends_per_day : 
 python /Users/antonakd/GitHub/phd/code/experiment_451.py --action plot_cdf_data --input_filename 3months_flw.Total_Trends_per_day.data  --x_label "Total Trends per day " --title "3months_flw Total Trends per day" --legit_count 8120783 --spammers_count 93156

 alla tipota ..opote afhsa mexri to 160 !! to plot einai edw : 

python /Users/antonakd/GitHub/phd/code/experiment_451.py --action plot_cdf_data --input_filename 1d_feb_all.Different_User_Mentions_per_day.data --x_label "Different User Mentions per day" --title "1d_feb_all Different User Mentions per day" --legit_count 201237 --spammers_count 12981

* 3months_flw.Total_Links_per_day.data: 
* 3months_flw.Number_of_tweets_per_day.data οχι καλο !
* 3months_flw.Hash_Tags_per_day.data πολθ καλο 
* 3months_flw.Following_per_day.data: poly kalo  emeis omws sullegoume following gia kapoies meres apo ton martio kai meta opote gia tous perissoterous xrhstes fainetai oti exoun 0 following  gia auto kai 3ekinaie apo to 0O i legit exoun perissoterous followers!To oti den exoume bug sta plots mas Ola ta plots pou exoume deixnoune tous spammers na exoune megalutero X apo tous legit opou X TT, TOT, ...
alla auto to metric deixnei tous legit < spammers. apla prepei na to 3anakanoume, gia tis meres mono pou exoume stats
* OXI 3months_flw.Different User Mentions per day LA*OS den mas leei kati giati den exoume swsta data gia ol ato diasthma mhn to diexeis!OXI 
* KALO 3months_flw.Different_hashtags_per_day.data 
* isws 3months_all.User_Mentions_per_day.data.png: for large number of user mentions (>5) spammers are more than legit , but for low number (<=5) there are the same..
* polu kalo 3months_all.Total_Trends_per_day.data.png 

For low number of user mentios (UM) per day , user percentages are indistinctable between legit and spam users. Nevertheless for larger number of UMs per day there is a distinct trend that favours spammers

*3months_all.Number_of_tweets_per_day.data.png --> GAMATO
* 3months_all.Different_Trends_per_day gamato 
* ee polu kalo 1w_mar_flw.Total_Trends_per_day.data

* next TODOS:
 * vgazoume ta outliers 
 * poia eina ta pio shmantika 
ß * poies times mas xehwxrizoun tous spammers apo tous legit 

  As dialexoume ta kalutera apo apo ta grafhmata 
  * ena grafhma apo ta 1 day plots
  * ena grafhma apo ta 1 week
  * ena grafhma apo ta 1 months 
  * ena grafhma apo ta 3 months plots

# to data einai to cdf prwta oi spammmer kai meta oi legit  
flw. : google heuristic 
all: google heuristic + realtime blackhole lists blacklists 89 sto sunolo - whitelists
# 7 May 
* 1m_feb_all.Active_days.png: DEN exei nohma ana mera mono ana mhna h evdomada poses meres einai active o xrhstsh , na exei sthlei toulaxiston 1 tweets. to 20 einai polu kalo giati katarxhn den katevazoume ana xrhsth alla ana mera opote einai peristatsiako oti katevasame petuxame ton idio xrhsth. 

 * 1d_feb_all.Active_days : katarxhn ti vlepoume edw . den exei nohma me thn enoia oti den exei polu plhrofora exei 2 data point to   (1.0) to opoio shmainei oti 0 spammer einai energoi ligotero apo 1 mera. to allo shmeio (3,1) to 100% twn spammer einai energoi ligotero apo 3 meres) Giati 3 giati se ola ta cdf vaze ston axona xona x MAX + 2 . giati ? gia na mporei na vgei to cdf, nauparxoun shmeia na kanw pro8esw . na morw na pros8ew 2 shmeia. kai allo ena gia na exei ligo xwro dexia  . h mple grammh einai katw apo thn kokkinh. kapou giati anevainei etsi ? ti einai to  3 ston axona x ? gia na kanw ena cdf  oi spammers pws vghkan edw : google heuristic? blacklists? manually ? einai data 1 meras ? 

 to to ALL sto file name shmainei oti oi spammer exoun vgei ws exhs : google heuristic + realtime blackhole lists blacklists 89 sto sunolo - whitelists


 * 1d_feb_all.Different_hashtags_per_day :  to 95% twn spammer xrhsimopoioun ligotera apo 5? 6 different hshtag per day   EINAI gia mia mera auto to grafhma. enw to  95% twn legin 1,2 .ti einai to 450 ston axona x: h megisth timh tou different hashtga per day (toso htan to megisto plh8so hashtags pou xrhsimopoihse enas xrhstsh) ,

 Giati exei auth th morfh . to 99% perilamvanoun katw apo 50 hashtag. alla dustuxws uparxoun mporei 1 h 2 xrhstes pou xrhsimopoihsan 450 se mia mera (oi gnwstoi kai ws outliers). Mporoume na tous vgaloume kai na kanoume beutification alla meta to cdf DEN 8a phgainei mexri to 1!! (mexri to0.999) 


 * 1d_feb_all.Different_Trends_per_day: 8elei zoom kapws na fanoun oi ari8moi .... to 80% twn spammers xrhsimopoun ligotero 3-4 different trends per day anw to 80 % twn legin 1,2  To 95% twn spam : 8-9  95% twn legit2,3 . 


 *  1d_feb_all.Different_User_Mentions_per_dayto 92% twn spammer xrhsimopoiou9 me 10 different user mention enw to 92% twn legit 1 different user mention . 


* 1d_feb_all.Followers_per_day: den uphrxan data giayto eina etsi ?
* 1d_feb_all.Following_per_day: den uphrxan data giayto eina etsi ? delete

* 1d_feb_all.Hash_Tags_per_day.png: pali prbolhma na fanoun oi ari8moi zoom ? ti einia to 6000? #hashtags 

* 1d_feb_all.Number_of_blacklist_hits_pers_day : 80 einai oles oi blacklists , to 93% twn spamm IP addresses entopistikna se apo ligotero apo  2-3 blacklists, alla to 98% twn spam entopisthna apo 5 blaclists. Giati h mple grammh den einai sto 0 ? shmeianioti to 100% twn legit eixan ligotero apo 1 blacklist hit ara 0! h mple profanws 8a vgei apo to grafhma gia na mpei sto paper.

estw enas spammer pou steleni 1 tweet me 1 url mesa an 50 blacklists ton entopisoun 8a parei 50 
an ena spammer steilei 50 tweets me 50 url sunolika kai ka8e ena url to vrei 1 blacklist 8a parei 50 
an ena spammer steilei 50 tweets me 50 url sunolika kai ka8e ena url to vrei 50 blacklist 8a parei 50* 50  

* 1d_feb_all.Number_of_spam_links_per_day.png.  to 90% twn spammers exoun ligotero apo 2 spam links per day. to 97% exoun ligotero apo 3 spam links per day.. ti einai to 40 ? ena xrhstsh esteile 40 smap link se 1 mera!!(den einai to idio eniia diafretika links )


* 1d_feb_all.Number_of_tweets_per_day ti einai to 1200? to 98% twn spammers stelnoun ligotero apo 50 tweets per day to 98% twn legi stelnoun ligotero po 10 tweets per day ?
* 1d_feb_all.Total_Links_per_day.png: ti enia to 500?
* 1d_feb_all.Total_Trends_per_day ti enian to 1400?
* 1d_feb_all.User_Mentions_per_day.png: ti enia to 1800? to 98% twn spammers kanoun 50 user mention per day ? enw to  98% twn legit 1 user mention per day 
* fainontai polu kala : 
  * 1d_jan_flw.Number_of_blacklist_hits_pers_day
  * 3months_flw.Number_of_spam_links_per_day.png
  * 3months_flw.Number_of_blacklist_hits_pers_day
  * 3months_flw.Different_Trends_per_day.png  <--------
  * 3months_flw.Different_hashtags_per_day
  * 3months_flw.Active_days.png oi meres pou einai active enas spammer???
  * 3months_all.Different_User_Mentions_per_day.png alla 8elei zoom opws polla alla
  * 3months_all.Different_Trends_per_day.png
  * 3months_all.Active_days polu kalo alla ti einia ??
  * 1w_mar_flw.Active_days.png auto einia periergo 
  * 3months_flw.Active_days.png <-------- tous spammmer poios tous kanei follow?

  * 3months_flw.Different_Trends_per_day.png PLU KALO KAI TA SKALOPATIA pou deixnoun ta bursts!
ta skalopatia : einai bursts twn spammers . polu klassiko fainomano se spamming ..enas xrhsths stelnei polla kai meta stamataei .

sto 3months_flw.Different_Trends_per_day.png : otan mettrame to different trends (GENIKA SE OLA TA METRIC)  per day estw enan xrhstsh pou esteile 10 tweets apo tis 80  meres kai oi active meres tou htan 3 : ta data points einia sthn cdf : 10/3 oxi 10/80 

Skalopatia vlepoume giati polles fore exoume to exhs fainomano. enas xrhsths katevazoume gia nean xrhsth 10 tweets kai meta den ton xanasuantame tto dataset. eimai 8uma tou filtering h aplws mporei ena xrhstsh ontws na stelnei polla kai meta na exafanizetai . 

 * 3months_flw.Followers_per_day.png exei ena kokkono shmerio . alla opws kai prin exoun pi8ann ena celebrity edw me 600000 followers pou katastrefei to cdf isws na fainotan edw power law ...
 * gia ton idio logo den vlepoume tpota sto 3months_flw.Following_per_day.png 1.4 * 10 ^7 = 14 000 000 !!


# 6 May 
ideas 

ti orizoume san   spam emeis? kati exei ginei blacklisted men alla to lag time? 
google heuristic + … 


fruad @ twitter 
idea apo markato gia meta estw oti kanw follow mia selida . sto request auto mhpws ginese fololwer kai mia allhs selidas wst na fainetai oti exoun reuma

px. kana follow to tsipra kai fainetai na eimai follower tou tsipra + tou samara 

Eixan uolpohsei kati me ton ligoura paliotera . ekanes like sto fc ston pana8hnaiko kai fainotan to like ston olymoiako . etsi ginotan fraud sta likes. 

* ti orizoume san   spam emeis? kati exei ginei blacklisted men alla to lag time? 
 * google heuristic + … 
* τι οριζουμε σαν  spam campaign?
review paper : 
Check orthography (metions instead of mentions several times) Paxsony should be Paxson  @ 23 reference, 3rd line of introduction should be through instead of though?
our honeypots trap spammers 26 time faster? where is this proved?
Although the don't experiment with all the features of Twitter, missing including a honeypot with big  number of retweets (RT) and similarly with number of followers # following (WRONG! this is spammish technique NOT a reason for a spammer to smap!)

# 2 May 2014
* blacklists ckecks 
 * 16074 DONE
 * 16001 DONE
 * 15935 DONE
 *  15864 DONE (274 spam)
 * 15792 done
 * 15725 DONE
 * 15658 DONE (97 SPAM)
 * 15520 DONE (16 spam)
 * 15458 DONE (1 SPAM..)
 * 15397 DONE (0)
 * 15336 DONE (10 spam)
 * 15269 DONE ( 0 )
 * 15208 DONE (123)
 * 15127 DONE (113)
 *  15036 DONE ( 0 )
 * 14970 DONE ( 0 )
 * 14903 DONE ( 0 )
 * 14842 DONE ( 2 )
 * 14780 DONE (284) wow..
 * 14713 DONE ( 0 )
 * 14587 DONE (471) !!! O b.barracudacentral.org htan autos
 * cat blacklists_* | grep "true]" | wc -l
 * 2094 ..8.8% Oso akribws lene kai ta papers..
 * UNIQUE ! cat blacklists_* | grep "true]" | sort | uniq -u | wc -l
  * 1405  5.9 %
* Sunolika  1497 : 6.3 % + google heuristic  : 
 * alla to google heiristic: 
  *   poloi kanoun copy paste to link apo to search sto google kai to stelnoun sto twitter!
  * opote autos einai kai  o logos pou to twitter den to exei stamathsei
  * brhka 2060 tetoia links
  * apo auta kamia 50aria einai spam
  * to wraio einai oti uparxoun kai 650 link ta opoia periexoun to search
  * kai oxi kapoio link
  * dld auto ποu kanoun obfuscate den einai ena link, alla ena google query
  * Sta 30.000.000 URLs exoume 686 google search queries, 2060 google links  - apo ayta 50 einai spam 

  1. Set up a server that downloads trends from twitter. Ration: 10 trends per 10 minutes
  2. Set up a server that serves trend for a specific date. When trends are finished, go round robbin
  3. Run downloaders. Each downloaders, get a trend, get the previous max_id for this trend and downloads all tweets with id > max_id. This means that each downloaders downloads different tweets even if the are assigned the same trend. Run for January, February, March collect 150.000.000 tweets
  --- ALL STEPS 1,2,3 Are Running by using mongodb. ----
  4. Index all tweets according to date. (field: created_at)
  5. For each day: 
      Create a temporary mongodb table that contains all the tweets for this day
      Create an index for this temp table according to users.
      For each user:
          Calculate stats: {DT, TOT, Links, mentions, hashtags, followers, followings}
      Make a graph that contains the following edges: USER <--> LINK if a USER has posted this link. In total these graphs contain 9.3 million links, 16.4 million users. Divide these number by 90 to get an average per day. 
      Extract the nodes of this graph that have >= 10 edges. This will give us all the links that have been posted by more that 10 users.
  6. After step 5 we have around 28.000 links: Links that have been posted by more than 10 users in a single day.
  7. For these links extract the domains. For these domain get the ip, the Alexa Ranking and the Alexa Links
  8. For these domains, run as many as possible blacklists. A thorough list is here: https://github.com/egeland/nagios-rbl-check/blob/master/check_rbl.py
  9. For these domains check which one is using the "google heuristic" 
  10. Assign categories to each domain: {LEGIT, SPAM_BY_<BLACKLIST>, HIGH_ALEXA_RANKING, LOW_ALEXA_LINKS, NOT_WORKING, GOOGLE_HEURISTIC}
  ---------------THIS IS WHAT I HAVE DONE SO FAR--------------------------
  11. For each one of these categories C and each statistic S make CDF: S, {LEGIT vs. C} 
  12. since we have collected stats per links. Do the same for links: (CDF of total times sent for legit vs spam links), (CDF of total trends in tweets that have posted these links for legit vs spam links) 
  13. Plot spam campaigns. Take the graphs from step 5 and plot by using (1) only spammer and (2) only legit. Extract graph properties for each category and compare them.
  14. According to plots from 11,13 build filtering mechanisms. (For example if TD > 2 then spammer) . If needed (and if we have enough time) us ML methods to build classification mechanisms 


#1 May 
* python experiment_451.py --action check_blacklists_2 --input_filename alexa_rankings.txt --output_filename blacklists_b.barracudacentral.org.txt --blacklist_name b.barracudacentral.org  14587
* python experiment_451.py --action check_blacklists_2 --input_filename alexa_rankings.txt --output_filename blacklists_bl.deadbeef.com.txt --blacklist_name bl.deadbeef.com  14713
* 14780 bl.spamcannibal.org
* 14842 bl.spamcop.net
* 14903 blackholes.five-ten-sg.com
* 14970 blacklist.sci.kun.nl
* 15036 blacklist.woody.ch
* 15127  python experiment_451.py --action check_blacklists_2 --input_filename alexa_rankings.txt --output_filename DEFAULT --blacklist_name bogons.cymru.com
* 15208 cbl.abuseat.org
* 15269 cdl.anti-spam.org.cn
* 15336 combined.abuse.ch
* 15397 combined.rbl.msrbl.net
* 15458 db.wpbl.info
* 15520 dnsbl-1.uceprotect.net
* 15590 dnsbl.cyberlogic.net
* 15658 dnsbl.inps.de
* 15725 dnsbl.kempt.net
* 15792 dnsbl.solid.net
* 15864 dnsbl.sorbs.net
* 15935 drone.abuse.ch
* 16001 duinv.aupads.org
* 16074 dul.ru
* 16140 dyna.spamrats.com
* screen -d -m sh do.sh dyna.spamrats.com


#29 April 2014
 *  Alexa ranking ckek for link found in tweets :
  *  https://github.com/muhuk/python-awis
 * hy459 : https://code.google.com/p/dpkt/

# 28 April 2014
 * http://magp.ie/2012/02/29/how-to-access-attached-screen-after-connection-dropped/
 * The mongodb python connection command we are using is DEPRECATED!

###################
sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --port 27018 --dbpath /storage/mongodb_data 
* [detached from 3175.pts-2.aneipero]
restarted aneipero:
* 2418 mongo : sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage2/mongodb_data
* Started store_daily_trends ats screen session 2488
  python experiment_451.py --action store_daily_trends --database_name experiment_25_4_14 --database_host localhost --account_name despoinaAnt1
 * Started trends_server at screen session : 2551
  python experiment_451.py --action trends_server --database_name experiment_25_4_14 --database_host localhost
  *****************************downloading tweets****************************************
 * Started store_daily_tweets_from_trend_server ats screen session 2615
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 2677
   python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 2739
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 2802
   python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 2864
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 2926
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server at screen session 2988
 python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At   3050
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At   store_daily_tweets_from_trend_server 3112
  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080

#################################################






######################

#25 April ############MONGO in  NEW DISK 

despoina@aneipero:/etc/ssl$ sudo openssl req -new -x509 -days 365 -nodes -out mongodb-cert.crt -keyout mongodb-cert.key
[sudo] password for despoina: 
Generating a 1024 bit RSA private key
...................................................................++++++
...........................++++++
writing new private key to 'mongodb-cert.key'
-----
You are about to be asked to enter information that will be incorporated
into your certificate request.
What you are about to enter is what is called a Distinguished Name or a DN.
There are quite a few fields but you can leave some blank
For some fields there will be a default value,
If you enter '.', the field will be left blank.
-----
Country Name (2 letter code) [AU]:GR
State or Province Name (full name) [Some-State]:HERAKLION
Locality Name (eg, city) []:HERAKLION
Organization Name (eg, company) [Internet Widgits Pty Ltd]:ICS
Organizational Unit Name (eg, section) []:DCS
Common Name (e.g. server FQDN or YOUR name) []:aneipero
Email Address []:antonakd@gmail.com
despoina@aneipero:/etc/ssl$ 
######################################################################################
mongod --sslMode requireSSL --sslPEMKeyFile <pem>
  * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --sslMode requireSSL --sslPEMKeyFile /etc/ssl/mongodb.pem --dbpath /storage/mongodb_data 
FAIL!: error command line: unknown option sslMode
use --help for help

#################################################
OPOTE xana mongo xwris password!; 
sudo mkdir /storage2/mongodb_data
 * Started mongo at screen session 3534: 
  * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage2/mongodb_data
* Started store_daily_trends ats screen session 3653
  * python experiment_451.py --action store_daily_trends --database_name experiment_25_4_14 --database_host localhost --account_name despoinaAnt1
 * Started trends_server at screen session 4029: 
  * python experiment_451.py --action trends_server --database_name experiment_25_4_14 --database_host localhost
  *****************************downloading tweets****************************************
 * Started store_daily_tweets_from_trend_server ats screen session 4100
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 4209
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 4272
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 4334
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 4397
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server ats screen session 4459
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_tweets_from_trend_server at screen session 4521
 * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At 3482  
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At  3544 store_daily_tweets_from_trend_server 4645
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_25_4_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080

#################################################



######################################################################################
# 24 April 
* new disk @ aneipero @ storage2 
 *  sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage/mongodb_data
 * prepei na arxisoume ta script na katevazoun se allh db asto neo storage. Exome akomh ligo xwro sthn storage 
 * h mongo xekinoume ws exhs :  
 * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage/mongodb_data
 *********************************************************************New Sessions*******************************************************
 * Started mongo at screen session 2897: 
  * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage/mongodb_data
 * Started trends_server at screen session 2973: 
  * python experiment_451.py --action trends_server --database_name experiment_10_1_14 --database_host localhost
 * Started store_daily_trends ats screen session 3039
  * python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name despoinaAnt1
 * Started store_daily_trends ats screen session 3102
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends ats screen session 3166
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends ats screen session 3232
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends ats screen session 3295
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends ats screen session 3357
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends ats screen session 3419
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
* Started store_daily_trends at screen session
 * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At 3482
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
 * At  3544
  * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080

** lala test!
* h mongo db mas epistrefei twra me ena query:
 * OLA ta tweets ENOS xrhsth gia mia mera apo 00:00:01 mexri 23:59:59
  * meta upologizoume ola ta metrics gia auton ton xristh
  * meta epanalambanoume gia olous tous xristes gia auth th mera
  * meta kanoume spam campaigns
  * meta briskoume ta links ta kentrika gia ka8e spam campaign me to mati
  * meta xaraktirizoume ws spammers autous pou exoun auta ta links
  * meta kanoume OLA ta CDFs gia olous tous xrhstes auths ths mera
  * epanalambanoume gia OLES tis meres
* Tuesday 15 April 
* Experiment 10_1_14 , 10 January 2014 
    * python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name despoinaAnt1
        * Session: 8088
    * python experiment_451.py --action trends_server --database_name experiment_10_1_14 --database_host localhost
        * (Serving at port 8080)
        * Session: 8252 
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 8347
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 8914
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 8977
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9039
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9101
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9164
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9226 
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9288 
    * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
        * Session: 9350 

    2470
    MONGO

8252 
    python experiment_451.py --action trends_server --database_name experiment_10_1_14 --database_host localhost
    Started: Tue Apr 15 12:35:07 EEST 2014

8347 
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:35:59 EEST 2014

8914
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:36:42 EEST 2014

8977 
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:37:27 EEST 2014

9039
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url localhost:8080
    Started: Tue Apr 15 12:38:12 EEST 2014

9101 
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:38:38 EEST 2014

9164
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:39:06 EEST 2014

9226
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:39:41 EEST 2014

9350
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
    Started: Tue Apr 15 12:40:23 EEST 2014

18222
    python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name despoinaAnt1
    Started: Tue, 15 Apr 2014 09:33:54

17389
    terminated

22046
    terminated

22103 
    terminated

30340
    experimenting! Leave it there! (build_index.py)
* MOnday 7 April 
* * Get JSON for 30 March 2014. Limit to 500.000 users skip initial tweets 
    * python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename pwd --from_date "Sat Mar 29 10:00:00 +0000 2014" --to_date "Sun Mar 30 10:00:00 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False  --max_users 500000 --greater_than_id 448068394331271168
 * * Plot trends/tweets 
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.30_march_2014.results.json --what_to_plot "__week___metric:TrendsPerTweets___CDF__line__xlabel:#Trends/#Tweets___ylabel:% of Users (CDF)__legend:4__maximum:10__step:0.2__" --days_to_plot "29-03-2014,30-03-2014" 
    * figure_67.png 

grid expansion 
* wn2 139.91.90.230
    * wn3 139.91.90.225
    * wn4 139.91.90.226
    * wn5 139.91.90.227
    * wn6 139.91.90.231

# 3 April
* * grid-wn2
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen 6002
*  grid-wn6
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * 32557

* patched twitter.py with : 
   + except socket_error as e:
   +    print '''socket.error caught while opening url %s. Try again..''' % url
   +    print str(e)
   +    return 34533 
GIATI ta scripts eixan crasarei sto aneipero : 
* To screen sto 22537 aneipero eixe crasarei, to ekana restart
* omoiws to 8347
munhma la8ous : 
===============================================================================================
===============================================================================================

 trend: %23Build2014 Fetched tweets: 100 total for this process: 1715412 tweets in db: 144639097 max_id: 451418514197213183
Traceback (most recent call last):
  File "experiment_451.py", line 2308, in <module>
    elif args.action == 'cdfs3':
  File "experiment_451.py", line 133, in store_daily_tweets_from_trend_server
    tweets, new_max_id = get_twitts_max_id(trend_query, trend_max_id, account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 624, in get_twitts_max_id
    content = query_oauth(query, account_name=account_name, access_token_filename='access_token_%s.txt' % account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 602, in query_oauth
    content = fetch_dict(query_url, oauth_parameters, verbose=False)
  File "/home/despoina/Github/phd/code/twitter.py", line 220, in fetch_dict
    content = fetch_content(url, values, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 213, in fetch_content
    return fetch_url(request_url, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 173, in fetch_url
    fp = urllib2.urlopen(url)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 127, in urlopen
    return _opener.open(url, data, timeout)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 404, in open
    response = self._open(req, data)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 422, in _open
    '_open', req)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 382, in _call_chain
    result = func(*args)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 1222, in https_open
    return self.do_open(httplib.HTTPSConnection, req)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 1187, in do_open
    r = h.getresponse(buffering=True)
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 1045, in getresponse
    response.begin()
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 409, in begin
    version, status, reason = self._read_status()
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 365, in _read_status
    line = self.fp.readline(_MAXLINE + 1)
  File "/home/despoina/anaconda/lib/python2.7/socket.py", line 476, in readline
    data = self._sock.recv(self._rbufsize)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 241, in recv
    return self.read(buflen)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 160, in read
    return self._sslobj.read(len)
socket.error: [Errno 104] Connection reset by peer
You have new mail in /var/mail/despoina

retarts me 
===============================================================================================
===============================================================================================
restart me entolh 

despoina@aneipero:~/Github/phd/code$ python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080


* Omoiws to 8914
munhma la8ous :
===============================================================================================
===============================================================================================

uotethiswithsomethingiwouldsay
Wed, 02 Apr 2014 17:08:10 +0000 trend: %23votekatniss Fetched tweets: 100 total for this process: 1751004 tweets in db: 144601735 max_id: 451151202475327487
Traceback (most recent call last):
  File "experiment_451.py", line 2308, in <module>
    elif args.action == 'cdfs3':
  File "experiment_451.py", line 133, in store_daily_tweets_from_trend_server
    tweets, new_max_id = get_twitts_max_id(trend_query, trend_max_id, account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 624, in get_twitts_max_id
    content = query_oauth(query, account_name=account_name, access_token_filename='access_token_%s.txt' % account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 602, in query_oauth
    content = fetch_dict(query_url, oauth_parameters, verbose=False)
  File "/home/despoina/Github/phd/code/twitter.py", line 220, in fetch_dict
    content = fetch_content(url, values, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 213, in fetch_content
    return fetch_url(request_url, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 174, in fetch_url
    ret = fp.read()
  File "/home/despoina/anaconda/lib/python2.7/socket.py", line 351, in read
    data = self._sock.recv(rbufsize)
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 567, in read
    s = self.fp.read(amt)
  File "/home/despoina/anaconda/lib/python2.7/socket.py", line 380, in read
    data = self._sock.recv(left)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 241, in recv
    return self.read(buflen)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 160, in read
    return self._sslobj.read(len)
socket.error: [Errno 104] Connection reset by peer
You have new mail in /var/mail/despoina
===============================================================================================
===============================================================================================



* Omoiws to 9164
restart me 
python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080


munhma pou petaxe 
===============================================================================================
===============================================================================================
0000 trend: %23votekatniss Fetched tweets: 100 total for this process: 1711316 tweets in db: 144595453 max_id: 451151279851454463
Traceback (most recent call last):
  File "experiment_451.py", line 2308, in <module>
    elif args.action == 'cdfs3':
  File "experiment_451.py", line 133, in store_daily_tweets_from_trend_server
    tweets, new_max_id = get_twitts_max_id(trend_query, trend_max_id, account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 624, in get_twitts_max_id
    content = query_oauth(query, account_name=account_name, access_token_filename='access_token_%s.txt' % account_name)
  File "/home/despoina/Github/phd/code/twitter.py", line 602, in query_oauth
    content = fetch_dict(query_url, oauth_parameters, verbose=False)
  File "/home/despoina/Github/phd/code/twitter.py", line 220, in fetch_dict
    content = fetch_content(url, values, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 213, in fetch_content
    return fetch_url(request_url, verbose=verbose)
  File "/home/despoina/Github/phd/code/twitter.py", line 173, in fetch_url
    fp = urllib2.urlopen(url)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 127, in urlopen
    return _opener.open(url, data, timeout)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 404, in open
    response = self._open(req, data)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 422, in _open
    '_open', req)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 382, in _call_chain
    result = func(*args)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 1222, in https_open
    return self.do_open(httplib.HTTPSConnection, req)
  File "/home/despoina/anaconda/lib/python2.7/urllib2.py", line 1187, in do_open
    r = h.getresponse(buffering=True)
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 1045, in getresponse
    response.begin()
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 409, in begin
    version, status, reason = self._read_status()
  File "/home/despoina/anaconda/lib/python2.7/httplib.py", line 365, in _read_status
    line = self.fp.readline(_MAXLINE + 1)
  File "/home/despoina/anaconda/lib/python2.7/socket.py", line 476, in readline
    data = self._sock.recv(self._rbufsize)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 241, in recv
    return self.read(buflen)
  File "/home/despoina/anaconda/lib/python2.7/ssl.py", line 160, in read
    return self._sslobj.read(len)
socket.error: [Errno 104] Connection reset by peer
You have new mail in /var/mail/despoina
===============================================================================================
===============================================================================================

#2April
* cloud set up of tiny url expansion :
 *  Run tweet_server for expanders 
    * python experiment_451.py --action tweets_server --database_name experiment_10_1_14 --database_host localhost --port 8081
    * screen 27258

* Cloud: ssh -i ~/.ssh/amazoncloud.pem ubuntu@ec2-54-234-120-165.compute-1.amazonaws.com
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen 3276

* Cloud: ssh -i ~/.ssh/amazoncloud.pem ubuntu@ec2-54-234-85-188.compute-1.amazonaws.com
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen 5230

* Cloud: ssh -i amazoncloud.pem ubuntu@ec2-54-80-209-94.compute-1.amazonaws.com
    *  python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen 5223

* Cloud: ssh -i amazoncloud.pem ubuntu@ec2-54-234-141-232.compute-1.amazonaws.com
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen 5225 

Wed, 02 Apr 2014 17:22:02 +0000 Tweets sent: 6359000/144377346
Wed, 02 Apr 2014 18:17:51 +0000 Tweets sent: 7104000/144377346
* =========BUT new grid installatio of redhat linux and all necessary packets (git, screen..) are ready so ..xana anaconda...

* ok 1 hour approximately to save the data tweets from mongo (ne data with all features mentions, RT, followering...: ) :
   * Get JSON for 30 March 2014. Limit to 500.000 users
    1.  python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.30_march_2014.results.json --from_date "Sat Mar 29 10:00:00 +0000 2014" --to_date "Sun Mar 30 10:00:00 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False  --max_users 500000
    2. find smaller user id: wste na xreiastei na 4anaftia3oume to json na mhn perimenoume tosh wra 448068394331271168
      * Id of the earliest tweet fetched between dates: "Sat Mar 29 10:00:00 +0000 2014" , "Sun Mar 30 10:00:00 +0000 2014" 
      * 448068394331271168
* --> sth bash uparxei ena keno apo 20 martiou mexri 29 martiou..
* sunolika h bash exei 150.000.000 tweets 
* sto mellon 8a pernei ena extra argument : 8a na parnei apo th bash ta tweets pou exoun id megalutero apo mia command line parametro
  * DHLADH Twra 8a dw poio einai to mikrotero id pou einai sto zhtoumeno diasthma:"Sat Mar 29 10:00:00 +0000 2014" , "Sun Mar 30 10:00:00 +0000 2014"
  * kai an  xreiastei na to 3anatre3w na tou pw na mou ferei mono auta pou exoun id megalutero apo auto
  * 
* python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.30_march_2014.results.json --from_date "Sat Mar 29 10:00:00 +0000 2014" --to_date "Sun Mar 30 10:00:00 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False --max_users 500000
* Gia to 8ema apo 1 apriliou me mnhmh : 8a balw --max_users 500000
* auta pou eixame tre3ei 1 April kai eixan problhma mnhmhs eixan htan gia > 2.000.000 ... gia osous katevsame apo Kuriakh 30 matriou mexri 1 apriliou 

#1April 
  * Memory issue : despoina@aneipero:~/Github/phd/code$ python
  Python 2.7.5 |Anaconda 1.8.0 (64-bit)| (default, Nov  4 2013, 15:30:26) 
  [GCC 4.1.2 20080704 (Red Hat 4.1.2-54)] on linux2
  Type "help", "copyright", "credits" or "license" for more information.
  >>> a=open('experiment_10_1_14.30_march_2014.results.json')
  >>> import json
  >>> b,c,d = json.load(a)
  Killed
* * Get JSON for 30 March 2014 
    * python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.30_march_2014.results.json --from_date "Sat Mar 29 10:00:00 +0000 2014" --to_date "Sun Mar 30 10:00:00 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False

#29 march 
* changes 12:22 experimtn451 so it dowloads mentions,RTs, following , hashtag
* restarted  at all screens in aneipero : 
 *  
  22537.pts-25.aneipero (01/16/2014 12:05:21 PM)  (Detached) python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080 
  9350.pts-9.aneipero (01/10/2014 11:00:45 PM)  (Detached)  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
  9226.pts-9.aneipero (01/10/2014 10:58:45 PM)  (Detached)python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
  9164.pts-9.aneipero (01/10/2014 10:57:37 PM)  (Detached) python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
  9101.pts-9.aneipero (01/10/2014 10:56:52 PM)  (Detached) python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
  9039.pts-9.aneipero (01/10/2014 10:55:52 PM)  (Detached)ython experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
  * 
  8977.pts-9.aneipero (01/10/2014 10:54:36 PM)  (Attached)python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
  8914.pts-9.aneipero (01/10/2014 10:52:37 PM)  (Detached) python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
  *
  8347.pts-9.aneipero  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
  *

5 tweets se mia mera , mesa exoun 10 trends  = 2 trends / tweets ara einai trends ana tweets kai oxi tweet!

#21 March 
* sapila pliatsiko restart!!
* screen 
* sudo python /home/antonakd/Github/phd/code/twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000 --account_name despoinaAnt2 --output /storage/twitter-spam/DATA/tweets_21_01_2014.txt

# 20 March 
* ston pinaka anaferei google heuristic 2706 users  kai auto exei vgei apo to arxiko sunolo twn spammer pou evgale to google heuristic alla gia >2 

apo to cdf #trends / #tweets an travhxw mia grammh sto 2 antistoixei sto ~49% twn xrhstwn. to opoio einia 3467  diaforetiko mikrotero apo 2706

pws ginete auto ?

yparxei mia exhghsh apo to 5294 ( = 2706 + 1509+ 905 + 103 + 71 alla ata den einai mono to google heuristuc alla to a8roisma olwsn twn campaigns!! to google xheiristis ston pinaka fainetai na einai MONO 2706) 

epishs to google heuristic cdf leipei apo to pdf pou esteila xtes 


http://www.tug.org/mactex/index.html
http://pages.uoregon.edu/koch/texshop/obtaining.html
http://guides.macrumors.com/Installing_LaTeX_on_a_Mac
http://www.latex-community.org/forum/viewtopic.php?f=50&p=47519

#March 13 
* sunanthsh polakis elias sotiris vivi
 * secondments, lessons online lessons ....
 * graphs of /Users/antonakd/Documents/__icosial/__spam_campaigns_latest
  * apories: 
   * "26.000 users out of how many?"
   * me ti seira petaei to pyplot tous grafous? (#xrhstwn?) etsi fainetai
   * oi komvoi pou (xrhstes pou einai pio makria apo to node tou url giati einai poio markia . px. sto campaign 1 exoume 2 pou einai pi okatw 2.0 kai 2.0 ara den einai me vash to etric value giati kai oi duo einai 2.0 )
   * ti akrivws kanei h lib pou ta plotarei pyplot
   kai telika zhthsame extra :  
   Δυο plots 
   *   Plot με δυο  γραμμές cdf αξονας x trends/tweet , αξονας y % χρηστών για την τιμή του trends/tweet
     * αυτο θα βγει στο συνολο χρηστών που εχουν kanei tweet το  google heuristic
     * και στο υπολοιπο συνολο χρηστών (big dataset) 
   * cdf μονο για το campaign 1 : ενα  plot ωστε να φανει το distribution της μετρικής  (αξονα x : τιμή μετρικης (trends / tweet) αξονα y: %  χρηστών με βαση την τιμή της μετρικής ) cdf
 * check if scripts ok 
 * added motivation to paper
 * καλησπέρα,

εχοντας λοιπον ενα αρχικο σύνολο  402470 χρηστών για μια μέρα
εχω πλοτάρει 3 cdf: 
ποσοστο ολων των χρηστών (big dataset ) X=402470 ΜΑΥΡΗ ΓΡΑΜΜΗ
ποσοστο των χρηστών που περιεχουν spam link (google heuristic) X1 = 3467 ΚΟΚΚΙΝΗ ΓΡΑΜΜΗ
ποσοστο των χρηστών που απομένει αν αφαιρεσουμε απο το big_dataset - google_heuristic_dataset  (X - X1 =  X2 =399.003 ) ΜΠΛΕ ΓΡΑΜΜΗ 
Το μπλε και το μαυρο ειναι πολύ κοντά γιατί η διαφορά τους ειναι μόνο 3467 χρήστες.
Γιατι εχουμε μια ευεία γραμμή (μπλε και  μαυρή γραμμή) επειδή υπάρχουν παρα πολλόι χρηστες που εχουν στείλει 1 tweet με 1  trend . 
Βλεπουμε μετατοπισμένη την μαυρη προς τα δεξιά μιας και απο αυτήν δεν εχουμε βγαλεί τους spammer . H διαφορά ειναι μικρή (3467 στους 402470)  αρα και η μετατόπιση ειναι πολύ μικρή. 
(Μπορεί να ειναι φαινεται οτι ειναι η μαυρη γραμμή πανώ στην μπλέ αλλα δεν ειναι, εχω συμπεριλάβει επιπλεον ενα zoom οπου φαίνεται) 

Η κοκκινη απο την αλλη δειχνει ξεκαθαρα την συμπεριφορά των spammers για τους οποίους αντιστοιχούν για τους 15% 1 trend/tweets, 20% των χρηστών εχουν 2 trend/tweets, kok 85% 3 trend/tweet kok 

Plot CSD of trends/tweets for google, ALL and google-ALL
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week___metric:TrendsPerTweets___CDF__line___plot_all___xlabel:#Trends/#Tweets___ylabel:% of Users (CDF)__legend:4__maximum:10__step:0.2__" --days_to_plot "11-01-2014" 

figure_63


#March 6 
* sunanthsh me ViVi 
 * mallon gia ta secondments 8a prowrhsei me ton ena h meton allon tropo (eite diakoph spoudwn )
  * gia ta secondments titlo 8a prpeie na kanoume sunanthsh kai me ton laoutari 
 * gai th nparousiash mia mikrh dior8wsw stho trends/twitts --> trends/tweet
 * gia to progress report na valw gia to  trend expoloitantion alla perilhptika kai aplws na tonisw ta apotelesmata 
* sapila tweet download has crashed : at screen id 27398
 * sudo python /home/antonakd/Github/phd/code/twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000 --account_name despoinaAnt2 --output /storage/twitter-spam/DATA/tweets_21_01_2014.txt
  * gia kapoio logw xanazhthse authoriazation token...restarted ok 
 * dialexeis apo kth : nees :   

#March 5
* ma8hma iplane frothsthrio, petsas rise of planet apps (558, 459)
* screen on aneipero with id 22537 had crashed.  restarted it 
# March 4 
* checked scripts on sapila: restarted
* aneipero : 
 * crashed at screen 8977 : python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080 - restarted 
* crashed on screen id: 22537 : python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080 
* trend server seem down! python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name despoinaAnt1
**restarted trend server so have to restart everything : 
  * trend_server @ 8252 : python experiment_451.py --action trends_server --database_name experiment_10_1_14 --database_host localhost
  * screen id 22537: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 9350: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 9226: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screeb id 9164: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 9101: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 9039: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 8914: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080
  * screen id 8347: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080
  *********************la8os : 
  * prwta   python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name despoinaAnt1 -- screen id: 18222
  * python experiment_451.py --action trends_server --database_name experiment_451 --database_host localhost
  * kai meta python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080

#28 Febryary
* Presentation "You are what you like: " https://docs.google.com/presentation/d/1QvNzzV7-Y67ooUrHizLGvse73mz5IH-RWW15vo6vMgk/edit#slide=id.gab1d7a26_05
* check scripts:
  * @sapila ps seems fine, screen gets me to command line--> has crashed: restart: 
  * sudo kill -s SIGINT 5321, sudo kill -9 5321
  * cd /home/antonakd/twitter-spam/twitter-spam
  * sh RunTwitterSpam.sh
   * this does not work!! 
  * just run : python /home/antonakd/Github/phd/code/twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000 --account_name despoinaAnt2 --output /storage/twitter-spam/DATA/tweets_28_02_2014.txt
    * restarted but output seems like this: 
     * Fetch tweets for trend #1, %23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0, %23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0
      Current trend: ('%23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0', u'%23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0')  Trend index: 1
      2014-02-28 10:10:36 query: 1 Trend:  ('%23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0', u'%23%EC%86%8C%EB%85%80%EC%8B%9C%EB%8C%80%EB%AF%B8%EC%8A%A4%ED%84%B0%EB%AF%B8%EC%8A%A4%ED%84%B0') trend index:  1  Twitts requested:  100 Tweets for this trend: 0 Total tweets harvested: 0 Today's tweets: 100
        * Mporei giauto na crasare
     * sapila restarted screen id : 4314,,xanacrasare  
     * to account despoinaAnt2 xrhsimopoihtai kai sto aneipero ..try desTwitter !
      * restarted : sudo python /home/antonakd/Github/phd/code/twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000 --account_name desTwitter --output /storage/twitter-spam/DATA/tweets_28_02_2014.txt - to acount den uparxei

      * https://dev.twitter.com/discussions/25637

=============
* Create .stats file
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__create_stats__"  --days_to_plot "11-01-2014"

    python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__create_stats__"  --days_to_plot "11-01-2014" 

* Plot .stats file
   * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats___"  --days_to_plot "11-01-2014" 

* plot campaigns 
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets___plot_campaigns__"  --days_to_plot "11-01-2014"

* plot specific campaign in .stats file:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats__subplot_index:13__"  --days_to_plot "11-01-2014" 

=============

#Tuesday 25/2
* plot campaigns : * plot specific campaign in .stats file:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats__subplot_index:13__"  --days_to_plot "11-01-2014" 

 *   python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets___plot_campaigns__"  --days_to_plot "11-01-2014"
*  plot specific campaign in .stats file:
  *  python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_24_2_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats__subplot_index:13__"  --days_to_plot "11-01-2014" 
* _AverageNumberOfDifferentTrendingTopics_
*  _AverageNumberOfTotalTrendingTopics_
*  _TweetsWithTrendsPercentage_
*  _TweetsWithUrlsPercentage_
*  _TrendsPerTweets_

#Monday 24 February 
 *  python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__create_stats__"  --days_to_plot "11-01-2014" 
 *    * python /Users/antoakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats___"  --days_to_plot "11-01-2014" 
 * ma8hma mexri tis 2 
 * twitter spam : 
  * tweets sth mongo database 
  * Apo th mongo database xtiaxnoume ena dictionary opou ta kleidia einai oi xrhstes kai ta values einai ta metrics twn xrhstwn autwn
  * auto ginetai me to --action cdfs
  * to dictionary auto to swzoume se json format me to onoma experiment_10_1_14.SAT.results.json 
  * Sth synexeia trexoume:  --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__create_stats__"
  * auto kanei: create_stats
  * diladei ftiaxnei ena arxeio:  experiment_10_1_14.SAT.results.json.stats to opoio periexei:
  * json pou exei gia olous tous xrhstes #tweets, #trends , ..
  * to .stats arxeio exei:
   * USER    METRIC   LINKS (Einai ta links pou exei postarei autos o xrhsths)
   * mitsos   7.0     www.goole.com 
   * p.x
   *  to 7.0 einai to TrendsPerTweets
   * afou ftiaxei to .stats arxeio
   * trexeis to -action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TrendsPerTweets__process_stats___"
    * to process_stats kanei plot ta stats
    * Opou: nodes = users
    * Kai nodes = links
    * kai edges = users pou exoun steilei ta links
    * An to kaneis auto bgainei mia mountzoura
    * an kaneis plot olo ton grafo bgainei ena koubari (gia spam links): alla 
     *  http://networkx.lanl.gov/reference/generated/networkx.algorithms.components.connected.connected_component_subgraphs.html
       * uparxei mia entolh pou pairnei ena graph kai sou epistrefei OLA ta unconnected subplots
       *  dld me mia entolh pairnoume ola ta spam campaigns
       * malista einai ordered analoga me to plh8os twn nodes pou periexoun
       * gia ka8e spam campaign meta upologzoume diafora stats
       * 1: Mesos orws metric
       * Dld: an sto spam campaign einai 3 xrhstes o A me metric 2 o B me metric 3 kai o C me metric 4
       * tote o mesos oros einai 3
       * Kai
       * 2: Mesos oros xristwn ana link
       * Dld an to spam campaign exei 3 links
       * kai sto 1o to kanoun link 3 xristes, sto 2o 4 xristes kai sto 3o 5 xrishtes , o mesos oros einai 4

#
* To graph  figire 51 einia la8os
* Epomena action points einai na ta idia graphs alla se ena dataset pou den pernei to google heuristic spam san ground truth alla ola ta metrics pou exoume pei (trends per day, total trends , unique trends, percentage tweets with urls, percentage tweets with trends (argotera ta plh8os RTs, specific keywords) .
* ena allo action point einai na doume apo tous "legit" tou figure52 manually an einai spam kai poi apo ta metrics ikanopoioun kai se poio threshold
* ena allo action point einai na doume manualy ta upopoila metrics se poia timh kai panw leme oti einia spam or not. 

#18 February 

# last week only ma8hma apo kth distributed systems !!

# MOnday 10/2 

# Friday 7/2 Saturday Sunday: 
* Lessons KTH quiz 5,6,7 (1.8/5, redo)
 * Programming ass0 , programming ass1 (not finished)
 * Notes fro meetning Boguna mail
 * Plots redo with % 
  *  neo option sth --what_to_plot gia na tupwnei tous users me pososta apo 0% mexri 100%
   * To option auto einai: _users01_
   * Figure 50 with users 0 - 100
    * slide 20 (de3ia)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TrendsPerTweets___singleline__users01__maximum:103__step:0.2__xlabel:Users__ylabel:Trends per Tweets__legend:2__dot__" --days_to_plot "11-01-2014"
    * figure_51.png

* figure 49 with users 0 - 100
    * slide 20 (aristera)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TrendsPerTweets___CDFABSOLUTEIVERTED__line__TwoXScales__users01__xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Trends per tweets__legend:2__maximum:10_ step:0.2__" --days_to_plot "11-01-2014"
    * figure_52.png

* figure 48 with users 0 - 100
    * slide 17 (de3ia)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfTotalTrendingTopics__users01__singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Total Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure_53.png

* figure 47 with users 0 - 100
    * slide 17 (aristera)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfDifferentTrendingTopics__users01__singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Unique Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure_54.png

* figure_44 with users 0 - 100
    * slide 16 (aristera)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot
"__week__AverageNumberOfDifferentTrendingTopics__CDFABSOLUTEIVERTED__users01__line___TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Unique trends___legend:2__maximum:20__step:1__xmin:0__" --days_to_plot
"11-01-2014"
    * figure_55.png

* figure_43 with users 0 - 100
    * slide 16 (de3ia)
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py
--action cdfs2 --input_filename
experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TotalTrends__CDFABSOLUTEIVERTED__line__TwoXScales__users01__xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Total trends__legend:2__maximum:1000__step:5__" --days_to_plot "11-01-2014"
    * figure_56.png

###################################
#Stockholm isocial meeting : 
Stockholm 4 february


  --------------------------------------------------------------------------------------------------
  Sarunas presentation 
  --------------------------------------------------------------------------------------------------
  looking for post docs
  online courses : 




  sixmonth newslettre
  half page every fellow 
  combine with semi annual progress
  TODO :semi annual report  (every half year) - written by fellow (end of March)  - abstract not too technical ...so the abstract can be adapted in the newsletter 
  TODO: newsletter :small article (atricle) , not too technical, appealing to wider audience...for online  -- reviewed as articles by translator in FORTH 


  reasearch & innovation challenge with prize (trip-tablet) : diagwnismos gia mia isocial idea - isws kai mplemenation fb application socila netwrk applocation ...8a akolou8hsei mail - prs to paron as rspa8oume na skeftoume kamia kalh idea 
  http://www.kaggle.com/


  sixmonth newslettre
  half page every fellow 
  combine with semi annual progres

  TOdo : financial reports

  ***credit of Seif's course:  course(master's version) + presentation of a paper (phd'd version)---> https://www.kth.se/social/course/ID2203/calendar/


  are the slides online?(sarunas)

  --------------------------------------------------------------------------------------------------
  ---------------fellows presentations-----------------------

  --------------------------------------------------------------------------------------------------
  Cyprus: 

  friendica commercial
  lorea (reasearch)

  boguna: kleineberg fellow

  the topological evolution of sn 

  decentralization of online sn  in monetary sector 
  TODO : erwthsh ..will a snapshot of twitter dat be enough . should we start download ? 

  -------------------
  http://graphlab.org/graphchi/



  run a histogram instead of the plot ...maybe results shown better 
  poia htan  ta false positives , true negative apo tous cuprious ti times vgalame 

  --------------------------------------------------------------------------------------------------
  ----------------------sunanthsh me boguna: --------------------------------
  --------------------------------------------------------------------------------------------------
  1st priority : when to go check with csd lessosn , and send them an email with final answer when...
  2nd we need 2 (best case senario) social networks s  and data from the very beginning to compare their evolution  (diaspora 2 nodes? myspace? 2 groups of datasets from same sn)
  we need two similar like sns so dataset is not heterogenous

  ---
  Diaspora
  Friend-of-a-Friend (FOAF)


  Peer-to-Peer (P2P) OSNs
   
  Safebook
  PeerSoN
  Vis-à-Vis
  DECENT



  http://techcrunch.com/2008/06/26/myspace-opens-up-the-data-pipe-with-launch-of-data-availability/  
  http://www.theawl.com/2013/05/the-beginning-of-big-data

  ============================================================================
  TWITTER OLD DATA 
  ".....s not make "available" tweets older than three weeks. Ihttp://stackoverflow.com/questions/1662151/getting-historical-data-from-twitter

  BUT : DataSift claims to have a twitter historical data api coming soon, you can signup to be notified when its available here.


  ========================================================
  https://developer.peoplebrowsr.com/pb 

  ========================================================
  http://keyhole.co/conversation_tracking

  http://venturebeat.com/2013/02/07/search-old-tweets/

  OLD RESULT IS AVAILABLE : "As we roll this out over the coming days, the Tweets that you’ll see in search results represent a fairly small percentage of total Tweets ever sent."
  https://blog.twitter.com/2013/now-showing-older-tweets-in-search-results
  "...e the best content for your query. For now, enjoy your trip down memory lane! "




  n"
  do somwe research in this.  

  ==============ALTERNATIVE SNs??====================
  http://www.businessinsider.com/foreign-social-networks-take-on-facebook-2013-5



  --------------------------------------------------------------------------------------------------
  ======================DATASETs =====================
  --------------------------------------------------------------------------------------------------
  twenty social network
  contact telefonica, diaspora other industrial partners 


  --------------------------------------------------------------------------------------------------
  secondments? TODO: agree on secondment and set titles, BY THE END OF  THIS MONTH ! could be later not exactly what the contract says 
  HOW ?maybe flexible on time?maybe 2 monthsis enough ...
  end of march six month progress report 


  http://www.youtube.com/watch?v=cRt0JvfbXfI jama3ati 



  ====================6/2/2013========================

  Synanthsh Vivi, Sotiris(FRNK airport)


  secondments : sto cdf twn unique trends na vgaloume pososton ston axona  x 

  google heuristic1 () validate : 

  1. tous sortaroume 
  2)pososta
  enas axonas y : tredns 
              x pososto xrhstwn  (normalize me vash to plh8os tous) normalized 

  to idio gia to 17 dexia grafhma 
  ------------


  log scale sto axona x 18 slide 
  allo ena me pososta ston x axona 



  log + possoat ston x axona 21 slide

  ligo na exhghsoume to slide 21 false negatives (#Plot: #Trends / #Tweets)


  sugkrish me emal (des parousiash barkelonhs)
  gaiti einai sumantiko na asxolh8oume me to spam sto 

  1) notes apo sunanthsh
  2) xana ta plots me allages pou grafw parapanw
  3) xekina paper me idea giati ienia shmantiko (des shmeiwseis sto xarti )
  4) metra to pososto xrhswthn h apoluto ari8mo gia spam se email  - sugrish me spam @twitter 
  5) yaxe gia sns gia Boguna
  6) ma8hmata kth 
  7) proposal twitter grant



#Friday 31/1
* Papaer journal club : metric : text similarity: "gain new followers" ... or n similar words + link similarity (8a xasoume ebay, itunes...)
  similarity groups --> campaigns (400) --> tuxaio deigma tweets/accounts --> manually inspection (2500) --> 4% fp
* Spam campaigns : 
* Fix google safe api sto blacklists experiment
* next steps : add new features ston classifier (Rts , #followers, #following ??)

#Thurday
* presentation
* Make the json again so that it has the tld on
    * python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.SAT.results.json --from_date "Sat Jan 11 00:00:01 +0000 2014" --to_date "Sat Jan 11 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --exclude_users_without_urls False
* Plot campaign graph
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action spam_campaigns --input_filename experiment_10_1_14.SAT.results.json --min_different_trends_threshold 9 --days_to_plot "11-01-2014"

* Plot Total Trends CDF, x axes = users, spammers = googleHeuristic 
   * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TotalTrends__CDFABSOLUTEIVERTED__line__TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Total trends__legend:2__maximum:1000__step:5__" --days_to_plot "11-01-2014"
    * figure 41 (y axes: 0.0 -- 1.0
    * figure 43 (y axes: 1 - #trends)

* Plot Unique Trends CDF, x axes = users, spammers = googleHeuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__CDFABSOLUTEIVERTED___line___TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Unique trends___legend:2__maximum:20__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 42 (y axes: 0.0 -- 1.0)
    * figure 44 (y axes: 1 - #unique trends0

*  Plot percentage of tweets with urls, x axes = users, spammers = googleHeuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TweetsWithUrlsPercentage__CDFABSOLUTEIVERTED___line__TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:percentage of tweets with urls__legend:4__maximum:101__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 45 (y axes: 1 - #percentage of tweets with urls)

* Plot single line. Percentage of tweets with URLs. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week___TweetsWithUrlsPercentage___singleline__maximum:103__step:1__xlabel:Users__ylabel:percentage of url tweets__legend:2__" --days_to_plot "11-01-2014"
    * figure 46
* Plot single line. Number of unique trends. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfDifferentTrendingTopics____singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Unique Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure 47
* Plot single line. Number of total trends. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfTotalTrendingTopics____singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Total Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure 48
 * 10-fold cross validation:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py
--action classifier --input_filename
experiment_10_1_14.SAT.gheuristic.results.urls.json --output_filename
experiment_10_1_14.SAT.gheuristic.results.urls.json.output
--days_to_plot "11-01-2014"

    {'TN': 494047, 'FP': 205, 'FN': 1557, 'TP': 1916} # LogisticRegression <--
    {'TN': 494204, 'FP': 48, 'FN': 3342, 'TP': 131} # LinearRegression
    {'TN': 494204, 'FP': 48, 'FN': 3342, 'TP': 131} # Ridge
    {'TN': 494252, 'FP': 0, 'FN': 3473, 'TP': 0} # Lasso
    {'TN': 494252, 'FP': 0, 'FN': 3473, 'TP': 0} # ElasticNet
    {'TN': 494252, 'FP': 0, 'FN': 3473, 'TP': 0} #  MultiTaskLasso
    {'TN': 494252, 'FP': 0, 'FN': 3473, 'TP': 0} # LassoLars
    {'TN': 494251, 'FP': 1, 'FN': 3470, 'TP': 3} # OrthogonalMatchingPursuit
    {'TN': 494204, 'FP': 48, 'FN': 3343, 'TP': 130} # BayesianRidge
    {'TN': 494237, 'FP': 15, 'FN': 3309, 'TP': 164} # Perceptron
    {'TN': 493485, 'FP': 767, 'FN': 1561, 'TP': 1912} # SGDClassifier
    {'TN': 491509, 'FP': 2743, 'FN': 2721, 'TP': 752} # MultinomialNB
    {'TN': 494003, 'FP': 249, 'FN': 1545, 'TP': 1928} #
PassiveAggressiveClassifier
    {'TN': 493926, 'FP': 326, 'FN': 1418, 'TP': 2055} #
DecisionTreeClassifier <-- BEST
    {'TN': 493880, 'FP': 372, 'FN': 1404, 'TP': 2069} # DecisionTreeRegressor
    {'TN': 494024, 'FP': 228, 'FN': 1414, 'TP': 2059} # RandomForestClassifier

 * Plot single line. Percentage of tweets with URLs. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week___TweetsWithUrlsPercentage___singleline__maximum:103__step:1__xlabel:Users__ylabel:percentage of url tweets__legend:2__" --days_to_plot "11-01-2014"
    * figure 46
* Plot single line. Number of unique trends. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfDifferentTrendingTopics____singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Unique Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure 47
* Plot single line. Number of total trends. spammers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week____AverageNumberOfTotalTrendingTopics____singleline__maximum:103__step:1__xlabel:Users__ylabel:Number of Total Trends__legend:2__" --days_to_plot "11-01-2014"
    * figure 48
* Plot trends / tweets . Two lines . spamusers = google heuristic
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot
"__week___TrendsPerTweets___CDFABSOLUTEIVERTED__line__TwoXScales___xlabelLegit:Legit users___xlabelSpammers: Spam users__ylabel:Trends per tweets__legend:2__maximum:10__step:0.2__" --days_to_plot "11-01-2014"
    * figure_49
* Plot trends / tweets . Single line . spam users = google heuristic
* python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --what_to_plot "__week__TrendsPerTweets___singleline__maximum:103__step:0.2__xlabel:Users__ylabel:Trends xrhstesper Tweets__legend:2__dot__" --days_to_plot "11-01-2014"
    * figure_50
* first test on KTH distributed ssystems
* classification re-run

#Wendesday 
* presentation for meeting in Stockholm on February, lessons & tests (1st assignment till 3/2)
* restarted screen 9039 i n aneipro which had exited. 


#Thuesday lessons, graphs
restrated sapila download

#MOnday
 python /Users/antonakd/GitHub/phd/code/experiment_451.py --action spam_campaigns --input_filename experiment_10_1_14.SAT.results.json --min_different_trends_threshold 9 --days_to_plot "11-01-2014"
svm overfitting ;
http://decisiontrees.net/decision-trees-tutorial/tutorial-13-overfitting/
#MOnday 
* Apo to mail tou NIklas https://mail.google.com/mail/u/0/?ui=2&shva=1#search/canvas/1435809eeed83c33
 * parampomph sto Kompics: http://www.ict.kth.se/courses/ID2203/material/assignments/ID2203-Tutorial1.pdf

#Sunday 19 January 
* Metric 2 : unique_trends
* 
      Exoume 4 metrics:
      total trends 
      unique trends
      percentage tweets with urls
      percentage tweets with trends

      dika mou metric ...plh8os RT? specific keywordd? google heuristic ? allo ? 
      vlepw ena spammer 
      --------p.x. to CheyenneBreese : 
      1) exei to link tou me google obfuscation (opote den to entopizeoun oi blacklists)
      2) se ena tweets exei polla @ gia na kanei personalization 
      3) sto epomeno exei polla #  (den vlepw sto idio   tweets kai polla @ KAI polla #)
      4) AND RT IF YOU WANT FOLLOWERS
      --------pame ston Shridhar_Shukla
      1) exei POlla @
      2) ola ta links einai google heuristic 
      3) polla # 
      4) AND★RT★IF★YOU★WANT★FOLLOWERS★
      5) ta tweets enalasontai ws exhs : 
        * ena me polla #, visit google...urllink
        * ena me polla @, visit google...urllink
        * ena me "I recommend to get more followers" se @ xrhstes, 
        * WANT TO GET 1000 FOLLOWERS ? =>

 *        

#Saturday 18 january
---------------------METRIC google heuristic: run classifier in aneiero---------------------------
1)python ../experiment_451.py --action classifier --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --output_filename output_filename_experiment_10_1_14.SAT.gheuristic.results.urls --days_to_plot 11-01-2014 to ian einai hardcodes kai oxi sta parameter. Currenly einai se sxolia. epishs dio8wsa to spammeer pou 

ppote me thn teleutaia allagh to xanaevala na trexei sto aneiperp : 
python ../experiment_451.py --action classifier --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --output_filename output_filename_experiment_10_1_14.SAT.gheuristic.results2.urls --days_to_plot 11-01-2014

scree : 27536
to eiuxa xanavalei xtes kai evgale kalutera noumera apo to diko mou nhxamhna : 

Warning: using -h 0 may be faster
*.....
Warning: using -h 0 may be faster
*.
Warning: using -h 0 may be faster
*
optimization finished, #iter = 11450
obj = -3405.064779, rho = -0.854126
nSV = 6274, nBSV = 3188
Total nSV = 6274
Fri, 17 Jan 2014 12:37:26 +0000 End of running SVM
{'TN': 494082, 'FP': 170, 'FN': 1374, 'TP': 2099}
*******[1/17/14 4:08:49 PM] Despoina Antonakaki: {'TN': 494082, 'FP': 170, 'FN': 1374, 'TP': 2099}
[1/17/14 4:08:52 PM] Despoina Antonakaki: kalo ?


FINISHED OF NEW VERSION : ----------------------------

490000
Sat, 18 Jan 2014 17:51:02 +0000 Running SVM..
[LibSVM]......
Warning: using -h 0 may be faster
*.....
Warning: using -h 0 may be faster
*.
Warning: using -h 0 may be faster
*
optimization finished, #iter = 11450
obj = -3405.064779, rho = -0.854126
nSV = 6274, nBSV = 3188
Total nSV = 6274
Sat, 18 Jan 2014 20:00:46 +0000 End of running SVM
{'TN': 494082, 'FP': 170, 'FN': 1374, 'TP': 2099}
--------------------METRIC #tredns----------------------------------
pros8esa mia sunarthsh count_number_user_trends()
typwnei aplos usernam kai plh8os trends
sortara to arxeio me vash to # trends: sort -n -k 3 users_trends

pernw tous top users kai tous tsekarw an einai spammers: 
 MAnually cheked in twitter 
____________:Vampirsenior 724  : SPAMMER
___________: Mrs_bieber28 545  xmm not spammer turkos
___________: xxHazzax 457  xmm not spammer turkos
___________: bellllieberss 448  not spammer
___________: BieberTroopHere 433 not spammer
___________: BeyzaTekin29 416    ???????
___________: bellamerve6 415  not spam
___________: HazzasBraceletz 410  not spam
___________: CheyenneBreese 407  spammer
___________: sevcan26935367 405  not spam
___________: _JDB___ 385  not spam
___________: ZeynepJBiebss 385  not spam
___________: Ohhmyjerryy 384 not spam
___________: LilianaCamacho0 374  not spma
___________: fulya_1mart 364  not spam
___________: puciohenzaaap 363
___________: ElifAyguul 363
___________: dragana9 354
___________: Pixara50 343
___________: mor_kidrauhl 342
___________: iostha 337
___________: WackZouisPants 334
___________: meryem65457481 333
___________: hearthekidrauhl 332
___________: BeyzaaUhl 331
___________: bieberp3rfect 328
___________: nextyoujb 324
___________: kidrauhl_61 321
___________: Busenurelik20 321
___________: 1DISMYDALAK 318
___________: IfmqNf_Qmfbtf 316
___________: areely_bieber 314
___________: ioanna_250 307
___________: suhedahazar 306
___________: drug_smoke_sex 300
___________: HesiquioD 296
___________: esrakandemiir 295

**********************************************************
#Friday 17 January 
*********************************
sunanthsh me polaki: 
1)uparxei polus  8oruvos , as epilexoume prwta thn metrikh 
OPOTE check manually ta metrics
2) opote manually to ggogle heuristic
3) AUTO AS KANOUME PRWTA: 
mannually vale threshols gia ta metrics kai xontrika poia ienia ta noumera gia tis metrikes pou mas voleuoun
poio noumero mporw na 8ewrhsw kalo threshold se ka8e metrikh 
4)  kfold validation : 10 kommatia twn 5000 x/10
 
    k  x ekteleseis random epilogh 1 train kai ta iupoloipa test
auto na to kanoume MONO an tsekatroume oti sigoura h metrikh tou google heuristic petaei 90%> accuracy. Giati twra den exoume kapoio ground truth gia na trexoume svm

***********************************     
    Yesterday I tried the following:

    I created a file that contained the following columns (one line per user):

    USERNAME 
    #TWEETS 
    #TRENDS 
    #TREND_PER_TWEETS  (this is consider the 1st metric/filter we mentioned yesterday) 
    #UNIQUE_TRENDS 
    #UNIQUE_TRENDS_PER_TWEETS (2nd metric)
    #TWEETS_WITH_URLS 
    #TWEETS_WITH_URLS/#TWEETS (3rd metric)
    #TWEETS_WITH_TRENDS
    #TWEETS_WITH_TRENDS/#TWEETS 
    SPAMMER/LEGIT (According to the google heuristic) (4rth metric)
    I plan to add : 
    #mentions (@) (5th metric)
    #RTs (6th metric)
    #number_of_followings (7th metric)
    #number of followers (8th metric)

    Then I run a Support Vector Machine classifier (according to a linear Support Vector Classifier: package: scikit-learn, svm.LinearSVC() )

    The classification was a following:
    Legit classified as Legit: 488407
    Legit classified as spammers: 5845
    Spammers classified as Legit: 1411
    Spammers classified as Spammers: 2062 

    Maybe if I include more information (for example #Retweets, #references) I can improve these classification results.
*********************************
*  ta stkotwsa ola sto dikomou mhxanhma kai to evala sto aneipero :
      python ../experiment_451.py --action classifier --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --output_filename output_filename_experiment_10_1_14.SAT.gheuristic.results.urls --days_to_plot 11-01-2014
 ---------SCREEEN ANEIPERO: -------------->  sto aneipero : screen  [detached from 25480.pts-25.aneipero]
       xa sto aneipero proxwrhse : Fri, 17 Jan 2014 10:27:28 +0000 Running SVM..
      [LibSVM]...
********************** IDEAS next steps: 
1) dhmiourgia enos training set me known spammers (autous pou xrhsimopoihsame sto prhgoumeno perirama)
    test tou arxeiou tou sabbatou
  2) confirm ta apotelesmata tou google heuristic ...maybe select a subset of this for a second training set
  3) play around with scikit if it provides the regularization parameter, C,??? to avoid pverfitting????? (http://stats.stackexchange.com/questions/35276/svm-overfitting-curse-of-dimensionality)
  4) I plan to add : 
    #mentions (@) (5th metric)
    #RTs (6th metric)
    #number_of_followings (7th metric)
    #number of followers (8th metric)



#Thurday 
 * IDEA : pare tous users me ta perissera trends, kai des an mporeis na bgaleis enan kanona me to pws tweetaroun
 * http://en.wikipedia.org/wiki/Latent_semantic_analysis, http://blog.josephwilk.net/projects/latent-semantic-analysis-in-python.html ( apo sxolia : LSA assumes the Normal distribution where the Poisson distribution has actually been observed. One major problem with LSA is that is doesn't scale well to large sizes, because of the LDU matrix decomposition.... it's O(docs^2 + unique_terms^2), even when calculated using sparse methods. It can also be very hard interpret what the "factors" really mean.)
  * apo ta sxolia pali  My next release will be Latent Dirichlet allocation and this will be implemented in ruby.
   *  http://scg.unibe.ch/staff/adriankuhn/hapax/
 * apo anazhthsh gia scaling se big data of LSA: 
  * https://lirias.kuleuven.be/bitstream/123456789/321960/1/MSI_1114.pdf
     * In practice this is done by an indexer splitting text documents into tokens or terms and 
      compiling a list on how many times a given term appears in a given document. We use 
      Apache-LuceneTM, an open source text search engine library, for the indexing15. During 
      the indexing process, a minimal number of stop words is removed16, numbers are 
      removed17 and stemming is applied (Porter stemmer)18.
 *****************************
 * sunanthsh gia ta plots: 
   * parathrhsh gia to plot 35, oi xrhstes xekinane apo to 85% . auto sumainei oti oi upoloipoi einai sto 0?? kalo 8a htan gia ka8e plot na kratame kapou tis times pou kanoume plot.  
   * panw sthn mple grammh sto graph Fig33 exei kai spammers pws kai den xehwrizoun autoi ? 
   * gia to dataset pou exoume twra (den 8eloume megalutero) 8a kanoume to exhs: 

     na vroume panw sthn mple grammh tous spammers me vash ta metric pou exoume. 
     ta metric einai oti exei to ka8e spam. p.x. #unique trends #
      as to fantastoume me sourwthria 
      oloi oi xrhstes einia sen ena megalo tsouvali
      twra 8eloume 4 sourwthria (osa ta metrics ) kai 8a prpeei na paixoume ligo me to mege8os ths trupas tou gia ka8e sourwthri

    etsi 8a perasoume to tsouvali apo to 1o souwthri kai 8a meinoun 4 px. mpales  8a dw ti  vgainei apo to sourwthri, mhpws na megalwsw to ari8mo tou metric? 
    na to mikrinw ? 8a deixei me vash to ti perase apo to sourhthri ...einai news? einai spammer? (check manually)

    to idio 8a ginei gia ola ta sourhthria/ metrics kai meta 8a doume poia metric mazi mas vgazoun tous sigourous spammers. 

    prepei na skeftoume pws 8a ulopoihsoume ta sourwthria /...

  
    mhpws na pros8esoume kialla sourhthria?
    ----------------
      Exoume 4 metrics:
      total trends 
      unique trends
      percentage tweets with urls
      percentage tweets with trends

      dika mou metric ...plh8os RT? specific keywordd? google heuristic ? allo ? 
      vlepw ena spammer 
      --------p.x. to CheyenneBreese : 
      1) exei to link tou me google obfuscation (opote den to entopizeoun oi blacklists)
      2) se ena tweets exei polla @ gia na kanei personalization 
      3) sto epomeno exei polla #  (den vlepw sto idio   tweets kai polla @ KAI polla #)
      4) AND RT IF YOU WANT FOLLOWERS
      --------pame ston Shridhar_Shukla
      1) exei POlla @
      2) ola ta links einai google heuristic 
      3) polla # 
      4) AND★RT★IF★YOU★WANT★FOLLOWERS★
      5) ta tweets enalasontai ws exhs : 
        * ena me polla #, visit google...urllink
        * ena me polla @, visit google...urllink
        * ena me "I recommend to get more followers" se @ xrhstes, 
        * WANT TO GET 1000 FOLLOWERS ? =>

     -------------------------
     mporoume na kanoume kati me auta ?
      I think I spotted two patterns: a) always-popular hashtags (like FilmPrequels), and b) ephemeral hashtags (deaths, new albums, etc.). In the (b) case I think there must be two options for the spammer (1) completely ignore the trend, and (2) try to hijack the trend, but eventually lose synchronization with the actual trend (remember: the attacker runs a bot/script and might not even know what the trend is actually about).

      I think both case share interest. I can now see that the idea is *also* interesting from an attack-perspective: how can the spammer blend with the legitimate twitter crowed in a realistic fashion? I.e., when the attacker *stops* hijacking a trend?   
 
 *  ULOPOIHSH  : python experiment_451.py --action find_users_with_many_trends --database
    1) find users with top trends and manually see  
       
      ETREXA AUTO :   
      python experiment_451.py --action find_users_with_many_trends --database_name experiment_10_1_14 --specific_date 11-01-2014 --results_filename users_top_trends_11Jan.json
      2) let's run google heuristic first since it gives very accurate results about spammers 
       a)evale sthn vash to apoteslesma apo google heuristic : python experiment_451.py --action check_blacklist --database_name experiment_10_1_14 --database_host localhost --blacklist_name googleheuristic --get_tld_from_database True

      b) swzoume apo thn db se json :
      python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --from_date "Sat Jan 11 00:00:01 +0000 2014" --to_date "Sat Jan 11 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977
 
      c) decision treess! :


      python ../experiment_451.py --action classifier --input_filename experiment_10_1_14.SAT.gheuristic.results.urls.json --output_filename output_filename_experiment_10_1_14.SAT.gheuristic.results.urls --days_to_plot 11-01-2014


       -->  sto aneipero : screen  [detached from 25480.pts-25.aneipero]
       
       I tried the following:

        I created a file that contained the following columns (one line per user):

        USERNAME 
        #TWEETS 
        #TRENDS 
        #TREND_PER_TWEETS 
        #UNIQUE_TRENDS
        #UNIQUE_TRENDS_PER_TWEETS
        #TWEETS_WITH_URLS
        #TWEETS_WITH_URLS/#TWEETS
        #TWEETS_WITH_TRENDS
        #TWEETS_WITH_TRENDS/#TWEETS
        SPAMMER/LEGIT (According to the google heuristic)

        Then I run a Support Vector Machine classifier (according to a linear Support Vector Classifier: package: scikit-learn, svm.LinearSVC() )

        The classification was a following:
        Legit classified as Legit: 488407
        Legit classified as spammers: 5845
        Spammers classified as Legit: 1411
        Spammers classified as Spammers: 2062 

        Maybe if I include more information (for example #Retweets, #references) I can improve these classification results.
 *********************
  *  crasaran kapoia apo ta scripts : 
    * screen 21723: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
    * screen 21607: python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
    * screen  9226  auto eixe kolhsei sto aith verification response to opoio omes eixe leixei opote to xanaxekinhsa : 
    python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
    * omoiws me to prohgoumeno to 9164 : What is the oauth_verifier? python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
    * omoiws me to prohgoumeno to  9101 : restart python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
    * 9039 : python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080 OMOIWS me prohgoumeno restarted
    * 8977  omoiws python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt3 --database_host localhost --trend_server_url http://127.0.0.1:8080
    * 8914 : python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt1 --database_host localhost --trend_server_url http://127.0.0.1:8080 OMOIWS 
    ....ok xanatrexoun.
 ************************


#Wendesday 
* https://pypi.python.org/pypi/phishtank new blacklists 
* new plots : 
 * /Users/antonakd/Documents/__icosial/January_15.pptx  
  * * Plot Total Trends CDF, x axes = users
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TotalTrends__CDFABSOLUTEIVERTED__line__TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Total trends__legend:2__maximum:1000__step:5__" --days_to_plot "11-01-2014"
    * figure 37
* Plot Unique Trends CDF, x axes = users
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__CDFABSOLUTEIVERTED___line___TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:Unique trends___legend:2__maximum:20__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 38
* Plot percentage of tweets with urls, x axes = users
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TweetsWithUrlsPercentage__CDFABSOLUTEIVERTED___line__TwoXScales___xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:percentage of tweets with urls__legend:2__maximum:101__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 39
* Plot of percentage of tweets with trends, x axes = users
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TweetsWithTrendsPercentage__CDFABSOLUTEIVERTED___line__TwoXScales__xlabelLegit: Legit users___xlabelSpammers: Spam users__ylabel:percentage of tweets with trends___legend:4__maximum:101__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 40
* IKA ETAM εκδοση βιβλιαριου δικου μου και της μικρής. Θα ισχύσει μέχρι το τέλος Φεβρουαρίου. Μετα θα πρέπει να πάω εγώ να τα ασφαλίσω ή (μη κανόνικά  κάποιος αλλος με την ταυτότητά μου ; πολύ κοντινός συγγενής ;)
* ruby in macos , thn teleutaia fora pou egkatesthsa ruby ta gamhse ola milame(eutuxws htan ton laptop tou umcg!!), opote twra 8a dokinmasw na egkatasthsw me home brew. http://blog.zerosharp.com/installing-ruby-with-homebrew-and-rbenv-on-mac-os-x-mountain-lion/
 * Install new version of xcode but still error about command line tools : 
   * http://stackoverflow.com/questions/18690218/xcode-command-line-tools-homebrew-warning
   * ok with comman line tools . Now I get the error Warning: Your Homebrew is not installed to /usr/local
    You can install Homebrew anywhere you want, but some brews may only build
    correctly if you install in /usr/local. Sorry!

     * Uninstall home brew : attempt : 
      * rm -rf /opt/homebrew/bin/brew 
      * install again brew:  bash < <(curl -s https://raw.github.com/wilmoore/homebrew-home/master/go)
      ********************************************
              rm -rf /opt/homebrew/bin/brew 
        Despoinas-MacBook-Air:code antonakd$ bash < <(curl -s https://raw.github.com/wilmoore/homebrew-home/master/go)
         [ .. ] Preparing to install homebrew to (/Users/antonakd/.homebrew).
         [ .. ] attempting to create (/Users/antonakd/.homebrew) directory.
         [ OK ] successfully created (/Users/antonakd/.homebrew) directory.
         [ .. ] attempting to download homebrew.
         [ OK ] successfully downloaded homebrew.
        Initialized empty Git repository in /Users/antonakd/.homebrew/.git/
        remote: Counting objects: 146640, done.
        remote: Compressing objects: 100% (47939/47939), done.
        remote: Total 146640 (delta 103977), reused 138953 (delta 97590)
        Receiving objects: 100% (146640/146640), 21.97 MiB | 362.00 KiB/s, done.
        Resolving deltas: 100% (103977/103977), done.
        From https://github.com/Homebrew/homebrew
         * [new branch]      gh-pages   -> origin/gh-pages
         * [new branch]      go         -> origin/go
         * [new branch]      master     -> origin/master
        HEAD is now at 16ac283 influxdb: update bottles.
        Already up-to-date.
         [ .. ] You should add the following to your $PATH and $MANPATH respectively
         [ .. ] $HOME/.homebrew/bin
         [ .. ] $HOME/.homebrew/share/man
         [ OK ] homebrew installed successfully!
         ************************************************
           export PATH=$PATH:$HOME/.homebrew/bin
            Despoinas-MacBook-Air:code antonakd$ echo $PATH
            /opt/homebrew/bin:/opt/homebrew/bin:/Users/antonakd/anaconda/bin:/Users/antonakd/anaconda/bin:/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/homebrew/bin:/Users/antonakd/.homebrew/bin
            Despoinas-MacBook-Air:code antonakd$ export PATH=$PATH:$HOME/.homebrew/bin 

            export MANPATH=$MANPATH:$HOME/.homebrew/bin
            Despoinas-MacBook-Air:code antonakd$ echo $MANPATH
            :/Users/antonakd/.homebrew/bin

            *********************************************
            xana to idio la8os : 
            * rm -rf /opt/homebrew/bin/brew 
            * brew install wget ...........OK 
              pali to idio 
              our Homebrew is not installed to /usr/local
              You can install Homebrew anywhere you want, but some brews may only build
              correctly if you install in /usr/local. Sorry!
            ***************************************

            ruby -e "$(curl -fsSL https://raw.github.com/Homebrew/homebrew/go/install)"
            now seems again ok !
            but ............brew doctor: 

                Warning: Some directories in /usr/local/share/man aren't writable.
                This can happen if you "sudo make install" software that isn't managed
                by Homebrew. If a brew tries to add locale information to one of these
                directories, then the install will fail during the link step.
                You should probably `chown` them:

                    /usr/local/share/man/de
                    /usr/local/share/man/de/man1

                Warning: /usr/bin occurs before /usr/local/bin
                This means that system-provided programs will be used instead of those
                provided by Homebrew. The following tools exist at both paths:

                    easy_install
                    easy_install-2.7

                Consider setting your PATH so that /usr/local/bin
                occurs before /usr/bin. Here is a one-liner:
                    echo export PATH='/usr/local/bin:$PATH' >> ~/.bash_profile

                Warning: You have a non-Homebrew 'pkg-config' in your PATH:
                  /opt/homebrew/bin/pkg-config

                `./configure` may have problems finding brew-installed packages using
                this other pkg-config.

                 EMEINE mono auto : 
                 brew doctor
                  Warning: You have a non-Homebrew 'pkg-config' in your PATH:
                    /opt/homebrew/bin/pkg-config

                  `./configure` may have problems finding brew-installed packages using
                  this other pkg-config.
                APO EDW : http://stackoverflow.com/questions/13517286/homebrew-wont-link-git-on-mountain-lion
                * sudo vi /etc/paths
                change order of 
                apo 

                /usr/bin
                /bin
                /usr/sbin
                /sbin 
                /usr/local/bin

                egine 

                /usr/bin
                /bin
                /usr/local/bin
                /usr/sbin
                /sbin
            **************************************

                emeine pali auto 

                Warning: You have a non-Homebrew 'pkg-config' in your PATH:
                /opt/homebrew/bin/pkg-config

              `./configure` may have problems finding brew-installed packages using
              this other pkg-config.

              -----> https://teamtreehouse.com/forum/brew-doctor-errors-homebrew-help-please
          ******************************************
          ok evgala to opt/homebrew/bin apo to path alla h mongo eniai ekei which mongo  /opt/homebrew/bin/mongo, opote den mporw na to svhsw !!
          prepeei na tsekaroume ti data exei mesa ...
          *******************************************

#print json.dumps(tweet, indent=4)
#Tuesday
 * sunanthsh gia ta plots  
 * 1) cdf posa trends (total) exoun steilei OLOI oi xrhstes (legit spam), 2 grammes
 * 2) cdf posa trends (unique) exoun steilei OLOI oi xrhstes (legit spam), 2 grammes
 * 3) cdf % tweets pou exoun estw ena url 
 * 4) cdf % tweets me trending topic
Prosoxh to cdf na phgainei mexri 100 (efoson einai cdf)
kai ston axona x na einai panta o user
Shmeiwsh tou sotiri: merika legend den vgazoun nohma opws : sto 27, 28  32
 Plot Total Trends , CDF 
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TotalTrends___CDF___line___xlabel:Total trends__ylabel:CDF__legend:4__maximum:1000__step:5__" --days_to_plot "11-01-2014"
    * figure 33
* Plot Unique trends, CDF
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__CDF___line___xlabel:Unique trends__ylabel:CDF__legend:4__maximum:20__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 34
* Plot percentage of tweets with URLs, CDF
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TweetsWithUrlsPercentage__CDF___line___xlabel:Percentage of tweets with urls__ylabel:CDF__legend:4__maximum:101__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 35
* Plot percentage of tweets with trends, CDF
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__TweetsWithTrendsPercentage__CDF___line___xlabel:Percentage of tweets with trends__ylabel:CDF__legend:2__maximum:101__step:1__xmin:0__" --days_to_plot "11-01-2014"
    * figure 36

#Monday 13 January
* TA IDIA me ta BELOW graphs alla me pososto twn xrhstwn ston x axona: 
  Kanoume plot to pososto pou exei trends, CDF, inverted axes
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithTrendsPercentage___userpercentage__maximum:103__step:1__ylabel:Percentage of trend tweets__xlabel:percentage of users with less than x percentage of trend tweets__legend:4__xmax:110__ymax:110__" --days_to_plot "11-01-2014"
    * figure_31
* Kanoume plot to pososto pou exei URLS, CDF, inverted axes
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithUrlsPercentage___userpercentage__maximum:103__step:1__ylabel:Percentage of url tweets__xlabel:percentage of users with less than x percentage of url tweets__legend:2__xmax:110__xmay:110__" --days_to_plot "11-01-2014"
    * figure_32
********************************************************************    
* Kaname edit wste to json na periexei auth th plhroforia:

Upologise kai ta ekshs metric: (a) % of tweets for each user that contain a trending topic. (b) % of tweets that contain a URL.
gia auta ta 2 nea metric, ftiakse mas ola ta graphs (1 cdf k 1 me absolute numbers opws auta pou esteiles twra).

3anatrexoume sto anipero me:
* python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.SAT.results.json --from_date "Sat Jan 11 00:00:01 +0000 2014" --to_date "Sat Jan 11 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --max_users_per_date 10000 --exclude_users_without_urls False 

* Katebazoume to arxeio: experiment_10_1_14.SAT.results.json 
* Kanoume plot to pososto pou exei trends, CDF:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithTrendsPercentage___userpercentage__maximum:103__step:1__xlabel:Percentage of trend tweets__ylabel:percentage of users with less than x percentage of trend tweets__legend:2__ymax:110__xmax:110__" --days_to_plot "11-01-2014"
    * figure_27 
     * me dots : 
       python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithTrendsPercentage___userpercentage__maximum:103__step:1__xlabel:Percentage of trend tweets__ylabel:percentage of users with less than x percentage of trend tweets__legend:2__ymax:110__xmax:110__dot__" --days_to_plot "11-01-2014"
* Kanoume plot to pososto pou exei trends, Singel Line:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithTrendsPercentage___singleline__maximum:103__step:1__xlabel:Users__ylabel:pecentage of trend tweets__legend:4__" --days_to_plot "11-01-2014"
    * figure_30
* Kanoume plot to pososto pou exei urls, CDF:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithUrlsPercentage___userpercentage__maximum:103__step:1__xlabel:Percentage of url tweets__ylabel:percentage of users with less than x percentage of url tweets__legend:2__ymax:110__xmax:110__" --days_to_plot "11-01-2014"
    * figure_28 ....32!!
* Kanoume plot to pososto pou exei urls, Single line:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week___TweetsWithUrlsPercentage___singleline__maximum:103__step:1__xlabel:Users__ylabel:percentage of url tweets__legend:2__" --days_to_plot "11-01-2014"
    * figure_29
* Plot Different Trends:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.urls.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__singleline__line___xlabel:All users sorted per different trends per day for a week__ylabel:Average of different trends per day for a week__title:Total trends per day for a week__legend:2" --days_to_plot "11-01-2014"
        * figure_5.png
              * figure_26.png 
* Wraia nomizw oti auto to graph einai polu pio konta se auto pou perimename....
isws me merika akoma graphs me auta ta data na exoume pio plhrhs eikona tou ti ginetai.
opote 8a h8ela na etoimaseis ta ekshs:
- Thn cdf ekdosh twn 2 graphs: me 2 plot lines, 1 gia tous "legit" kai 1 gia tous 10 spammers.
- Upologise kai ta ekshs metric: (a) % of tweets for each user that contain a trending topic. (b) % of tweets that contain a URL.
gia auta ta 2 nea metric, ftiakse mas ola ta graphs (1 cdf k 1 me absolute numbers opws auta pou esteiles twra).

Xairetw,
Iasonas

#Sunday 12 January 
* Run tweet_server for url expander:
    * python experiment_451.py --action tweet_server --database_name experiment_10_1_14 --database_host localhost --port 8081
    * screen: 13370. FINISHED

* Run tweet expander in anipero
    * python experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host localhost --threads 100 --tweet_server_url http://139.91.70.42:8081  
    * screen: 13442 

* Run tweet expander in grid-wn3:
    * python Github/phd/code/experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 769
   * Attention: Den exoume kanei pull 

*  Run tweet expander in grid-wn4:
    * python Github/phd/code/experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 2596

*  Run tweet expander in grid-wn5:
    * python Github/phd/code/experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 25729

*  Run tweet expander in grid-wn6:
    * python Github/phd/code/experiment_451.py --action expand_multithread --database_name experiment_10_1_14 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
    * screen: 20803

* Get TLDs:
    * python experiment_451.py --action get_TLD --database_name  experiment_10_1_14 --database_host localhost 
    * Total 412597 urls , 15677 TLDs
    * FINISHED

* Extract json FOR SATURDAY 11 January 2014 ONLY
    * python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.SAT.results.json --from_date "Sat Jan 11 00:00:01 +0000 2014" --to_date "Sat Jan 11 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --max_users_per_date 10000 
    * Maximum users: 10000
    * In total 1.926.507 downloaded for this date.

* Copy results to EDET (password: rS9W2FkAIQ )
    * scp experiment_10_1_14.SAT.results.json user@snf-14105.vm.okeanos.grnet.gr:./
* Copy results from EDET to local
    * Locally: mkdir plots; cd plots
    * scp user@snf-14105.vm.okeanos.grnet.gr:./experiment_10_1_14.SAT.results.json ./

* Plot all users: 
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.json --what_to_plot "__week__AverageNumberOfTotalTrendingTopics__singleline__line___xlabel:All users sorted per total trends per day for a week__ylabel:Average of total trends per day for a week__title:Total trends per day for a week__removeYOutlier:250__legend:2" --days_to_plot "11-01-2014"
    * figure_1.png (With 4 identified spammers). THIS PLOT IS WRONG
    * figure_2.png (without identified spammers)
10 HIGHEST USERS:
[u'MossMica', u'myworldjustind', u'NayellyLucatero', u'1D_qalp', u'niallhiccup', u'sekerlilly', u'idolssmjles', u'arditaJDB', u'snugglysam', u'EbrumrttJB']
    * We notice that the top users are crazy (biliebers.. but do not have urls. We exlude everyone that does not have urls

* Extract json FOR SATURDAY 11 January 2014 ONLY. REMOVE TWEETS WITHOUT URLS
    * python experiment_451.py --action cdfs --trends_database_name experiment_10_1_14 --trends_database_host localhost --database_name experiment_10_1_14 --database_host localhost --results_filename experiment_10_1_14.SAT.results.urls.json --from_date "Sat Jan 11 00:00:01 +0000 2014" --to_date "Sat Jan 11 23:59:59 +0000 2014" --blacklist_contains_TLD True --WOEID 23424977 --max_users_per_date 10000 --exclude_users_without_urls True 
    * Maximum users: 10000
    * In total 1.926.507 downloaded for this date.

* Copy locally:
    * From anipero: scp experiment_10_1_14.SAT.results.urls.json user@snf-14105.vm.okeanos.grnet.gr:./
    * from macbook: scp user@snf-14105.vm.okeanos.grnet.gr:./experiment_10_1_14.SAT.results.urls.json ./

* Plot all users:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.urls.json --what_to_plot "__week__AverageNumberOfTotalTrendingTopics__singleline__line___xlabel:All users sorted per total trends per day for a week__ylabel:Average of total trends per day for a week__title:Total trends per day for a week__removeYOutlier:250__legend:2" --days_to_plot "11-01-2014"
    * figure_3.png
    * Top 10 users: [u'BieberImVoting', u'Luciagonzalez68', u'BBBblogger', u'rcksmehoran', u'Chris_Frantorff', u'danni_zarate', u'SuryaAji_PHR', u'myvotefactor', u'HollyweirdTimes', u'marialabastida']
    * u'marialabastida : Belieber ..
    * u'HollyweirdTimes : Not spammer per se, but uses the same trend unrelated trend to post link to his site. 
    * u'myvotefactor : The same as above . Uses unrelated trends to post link to a certain site
    * u'SuryaAji_PHR: Spammer: Get new followers
    * u'danni_zarate' : Belieber..
    * u'Chris_Frantorff' : Spammer: Get more followers
    * u'rcksmehoran' : Belieber..
    * u'BBBblogger' : Spammer: Get more followers
    * u'Luciagonzalez68' : Belieber
    * u'BieberImVoting' : Belieber 

* Found spam user: BrilliantSegav (with the polakis method) . Get this user's stats: <-- CHECKA USER
    * python experiment_451.py --action make_user_stats --username BrilliantSegav --account_name despoinaAnt1 --not_older_than "Sat Jan 11 00:00:01 +0000 2014" --not_younger_than "Sat Jan 11 23:59:59 +0000 2014" --database_name experiment_10_1_14 --database_host localhost 
        * No Trend found

* plot Total trends:

    known_spammers = {
        'Shridhar_Shukla' : {'unique': 3.0, 'total':32.0},
        'Pixara50' : {'unique' : 5.0, 'total' : 345.0},
        'HARDINTHEPAINT5' : {'unique': 4.0, 'total' : 19.0},
        'FourteenEshLOVE' : {'unique' : 3.0, 'total' : 3.0},
        'FunSmashing' : {'unique' : 5.0, 'total' : 8.0},
        'BelindaaJohnson' : {'unique' : 1.0, 'total' : 22.0},
        'calmxxstyles' : {'unique' : 1.0, 'total' : 63.0},
        'marcoscano360' :  {'unique' : 4.0, 'total' : 4.0},
        'Vampirsenior' :  {'unique' : 2.0, 'total' : 731.0},
        'CheyenneBreese' :  {'unique' : 15.0, 'total' : 407.0},
      }


    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.urls.json --what_to_plot "__week__AverageNumberOfTotalTrendingTopics__singleline__line___xlabel:All users sorted per total trends per day for a week__ylabel:Average of total trends per day for a week__title:Total trends per day for a week__legend:2" --days_to_plot "11-01-2014"
        * figure_4.png 

* Plot Different Trends:
    * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename experiment_10_1_14.SAT.results.urls.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__singleline__line___xlabel:All users sorted per different trends per day for a week__ylabel:Average of different trends per day for a week__title:Total trends per day for a week__legend:2" --days_to_plot "11-01-2014"
        * figure_5.png

* python code/experiment_451.py --action cdfs2 --input_filename dec_20_2013_urls.SH_G_GH.results.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__singleline__line___xlabel:All users sorted per different trends per day for a week__ylabel:Average of different trends per day for a week__title:Different trends per day for a week__removeYOutlier:25__legend:2"

#Saturday
* mail elias: 
 * It's hard to find for some very ephemeral hashtags. Since, you have collected the tweets, we can search in them and spot some spammers manually. 
 * BTW, now that I was looking for spammers manually, I think I spotted two patterns:
  *  a) always-popular hashtags (like FilmPrequels), and 
  *  b) ephemeral hashtags (deaths, new albums, etc.). 
  * In the (b) case I think there must be two options for the spammer 
   * (1) completely ignore the trend, and 
   * (2) try to hijack the trend, but eventually lose synchronization with the actual trend (remember: the attacker runs a bot/script and might not even know what the trend is actually about).
 * I think both case share interest. I can now see that the idea is *also* interesting from an attack-perspective: 
  * how can the spammer blend with the legitimate twitter crowed in a realistic fashion? I.e., when the attacker *stops* hijacking a trend?
* ---------------------------------------------------------------
* mail jason
 * what i find perplexing/interesting is the amount of tweets with the "retweet and visit for followers" campaigns.
    for one of the topics i was looking at, they were close to 1/3 of the tweets.
    from what i've seen most of them, contain multiple trending topics within each tweet, as well as mentions towards
    other users (@username). 
    While i clicked a couple URLs yesterday from such tweets, i was redirected to sites that did advertise the same thing:
    give money to add followers etc....i clicked on one today and got a warning from twitter (screenshot attached).
    The URL is:
    http://goo.gl/vo4INS?shridhar_shukla152957384.html
    I removed the parameter that is *most likely* used for accounting purposes (the name of the twitter account) 
    and searched google for the url, which returned 7 results from tweets that contained the specific URL (with a different 
    id parameter of course), and 4 of them have been suspended.
    One of the accounts that has not been suspended is:
    https://twitter.com/LPertiwi05
    The account is 8-9 days old...The first 6 days the account exhibits a normal behavior with only legit tweets (foreign language,
    so i cant understand what they are saying, but no tren.topics etc).
    Then, during 1 day (Jan 9th) the account sends ~17 tweets with the "get followers" campaign and has zero activity since then.
    Maybe this is some type of behavior used to bypass any detection mechanisms by Twitter?

    I wonder if we could find anything interesting through this experiment:
    1)collect X accounts that send multiple "get more followers" campaigns.
    2)extract URLs from those tweets, and google search them
    3)also check our collected dataset to find overlapping URLs from "get followers" accounts
    4)plot graph of "related" accounts, i.e., a graph where each account is a node, and 2 nodes are connected if they have sent the same URL
    Might give us a visual representation of different spam campaigns etc...or uncover a larger network of spammers.
    Could also use followers/followees info from all those accounts to search for overlaps -> potential spammers?
 * SO /: 
 * using http://networkx.github.io/documentation/latest/reference/generated/networkx.drawing.nx_pylab.draw_networkx_labels.html#networkx.drawing.nx_pylab.draw_networkx_labels to create network
 *  

#Friday 10 January
* ---------------------------------------------------------------
* sunantsh gia ta plots. den mas lene kati mallon giati to woeid =1 kai emeis koitame tous spammers apo usa. opote as orisoume neo peirama : 
 * 1) collect trends for USA (10) steilta me mail ston iasona kai hlia 
 * 2) collect tweets for y users osous mas epistrefei to titter gia mia mera 
 * 3) Hlias & Jason tha yaxoun manually 10 spammers gia ayta ta trends 
 * 4) collect tODAY's  tweets for random y  users an oxi 100 300 osa exoun steilei se mia mera
 * 5) Polt mono auths ths meras oxi ola + twn known spammers na ta doume sto idio plot MIA GRAMMH gia olous y xrhstes kai eidika  shmadia gia tous upoloipous 
  * allaxa to twitter.py : 
    * 1) evala allo ena account sto twitter desTwitter
    * 2) allaxa to WOEID se USA 
    * screen to trends server (trexei hdh enas sto experiment_451) twra 8a swzei sto experiment_10_1_14, : 
     sto aneiperoda petaei to exhs error  : 


  python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name desTwitter
     
                  Could not find access token. Trying to get a new one.. Exception: Failed to validate oauth signature and token
                   Is your time set correctly? http://www.blainegarrett.com/2009/07/14/failed-to-validate-oauth-signature-and-token-on-twitter-oauth-check-your-cloc/
    As dokimasoume TOPIKA STO DKO MOU !
      TO IDIO LATHOS    

    OK to etrexe TOPIKA me allo username: 

-SCREEN 86371

kill a screens pou einai 

DOWNLOAD TWEETS : 

python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080


-----------------

xanavazoume ton trends server sto aneipero me :
python experiment_451.py --action store_daily_trends --database_name experiment_10_1_14 --database_host localhost --account_name desTwitter
8088 screen 

download tweets

python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_10_1_14 --account_name despoinaAnt2 --database_host localhost --trend_server_url http://127.0.0.1:8080 

*  Plot total trends: (figure_21.png)
* python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename dec_20_2013_urls.SH_G_GH.results.json --what_to_plot "__week__AverageNumberOfTotalTrendingTopics__singleline__line___xlabel:All users sorted per total trends per day for a week__ylabel:Average of total trends per day for a week__title:Total trends per day for a week__removeYOutlier:250__legend:2"
* Plot different trends: (figure_22.png)
* python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename dec_20_2013_urls.SH_G_GH.results.json --what_to_plot "__week__AverageNumberOfDifferentTrendingTopics__singleline__line___xlabel:All users sorted per different trends per day for a week__ylabel:Average of different trends per day for a week__title:Different trends per day for a week__removeYOutlier:25__legend:2"

#Thurdsay 9 January 
* twitter_experiment,py for producing the plots of the known spammers. finalized: 
 * Erwin_moriston:  unique_trends_average:  4.0 total_trends_average :  99.5  - 
 * IndioPolaris:  number_total_user_trends 41 unique_number_trends 14
   unique_trends_average:  3.5 total_trends_average :  10.25
 * Champion_player: unique_trends_average:  12.25 total_trends_average :  19.0  
 * sujeetMaury4 :   unique_trends_average:  4.0 total_trends_average :  5.33333333333
* Four new plots in /Users/antonakd/Documents/__icosial/twitter_spam/plot/10_January.pdf

# Wendesday 8 January
* sunanthsh sotiris, iasonas, hlias: 
 * 1)whitelists (na vgoun exw ta news sites ...)
 * 2)na vevaiw8oume oti ontws ienia spammers autoi pou fainontai san spammers apo to grafhma: ta 10 pio xamhla kai 10 pio yula accounts opws fainontai sto grafhma(se trends)
 dhladh 8eloume apo tous spammers tous top 10 pou exounn ligotero trends kai 10 top pou exoun perissotera trends --> 
 * 3) %tweets pou periexoun trending topics se cdf 
 * 4) as yaxoume sta mail ta accounts pou einani sigoura spammers pou exoun steilei ana kairous me mail kai na tous polaroume na fanoun sto grafhma
   gia tous known spammers to mono pou 8eloume einai collect tweets + run heuristic. expand den creiazetai afou xeorume oti einai spammers
 * 5) plotaroume olous tous xrhstes se mia grammh(spammers & legit) kai vazoume ta accounts pou xeorume oti eiani spammers kai vlepoume tous geitones tous. 
   * ta accounts pou einia spammers einai  kapoia pou eixan steilei se paliotera email : 
    * https://mail.google.com/mail/u/0/#search/spammer/142c224adc6a9f5d
    * 
        genika to grafhma fainaitai exofrenika la8os

    1)whitelists (na vgoun exw ta news sites ...)
    2)na vevaiw8oume oti ontws ienia spammers autoi pou fainontai san spammers apo to grafhma: ta 10 pio xamhla kai 10 pio yula accounts opws fainontai sto grafhma(se trends)
     dhladh 8eloume apo tous spammers tous top 10 pou exounn ligotero trends kai 10 top pou exoun perissotera trends --> 

    3) %tweets pou periexoun trending topics se cdf 
    4) as yaxoume sta mail ta accounts pou einani sigoura spammers pou exoun steilei ana kairous me mail kai na tous polaroume na fanoun sto grafhma 

    5) plotaroume olous tous xrhstes se mia grammh(spammers & legit) kai vazoume ta accounts pou xeorume oti eiani spammers kai vlepoume tous geitones tous. 

    gia tous known spammers to mono pou 8eloume einai collect tweets + run heuristic. expand den creiazetai afou xeorume oti einai spammers

  
# Tuesday  7 January 
 *  plots :
 * Plot cdfs:
   * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013.results.json 
  * Feedback from Vivi: https://mail.google.com/mail/u/0/?shva=1#inbox/1435482d63762b91 
    * spam links percentage cdf:
      * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "_week__onlyspammers__spamlinkspercent__xlabel:percentage of spam links__ylabel:percentage of users with percentage of spam links < x"
      * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "_week__onlyspammers__spamlinkstotal__xlabel:Total of spam links__ylabel:percentage of users with total spam links < x"
    * Feedback from Jason: https://mail.google.com/mail/u/0/?shva=1#inbox/1435482d63762b91
      * Dld: ston x-aksona tha einai xrhstes, kathe shmeio enas xrhsths. Ston y-aksona to average number of trending topics pou exei autos o xristis ana mera. Mia grammh gia legit k mia gia spammers. Den to thelw se CDf h kati tetoio.
      * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "__AverageNumberOfDifferentTrendingTopics__NOCDF__week__xlabel:Users sorted per trending_topics/day__ylabel:trending_topics/day__legend:__removeYOutlier:40__"
      * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "__AverageNumberOfTotalTrendingTopics__NOCDF__week__xlabel:Users sorted per total_trending_topics/day__ylabel:total_trending_topics/day__legend:__removeYOutlier:500"
    * SCALED:
      * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "__AverageNumberOfDifferentTrendingTopics__NOCDF__week__xlabelLegit:Legit users sorted per different_trending_topics/day__xlabelSpammers:Spam users sorted per different_trending_topics/day__ylabel:different_trending_topics/day__legend:__removeYOutlier:40___TwoXScales__"
     * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013_links.results.json --what_to_plot "__AverageNumberOfTotalTrendingTopics__NOCDF__week__xlabelLegit:Legit users sorted per total_trending_topics/day__xlabelSpammers:Spam users sorted per total_trending_topics/day__ylabel:total_trending_topics/day__legend:__removeYOutlier:500___TwoXScales__"

#Sunday Monday plots plots plots

#Saturday 4/1/14
* ma8hmata kth: 
* xanavalame to google blacklists na trexei . se 10(account gmail) merh twn 10.000
* ma8ha kth:
* mail amira: 
 *  
  Hello Amira, 
    happy new year !

    I hope you had a good time on Christmas holidays!

    I am very interested in this methodology. I already have fine-tuned some heuristics and techniques to identify spam, malware and phishing tweets. 
    Moreover, Vivi Fragkopoulou (my supervisor) suggested that it would be a good idea to prepare a shared presentation for the oncoming meeting in Stockholm regarding this analysis. 
    This presentation should be about merging gossip protocols with spam detection in DOSN. This presentation will be a part of a 30 minutes presentation that each fellow of the project should present. So our presentation can be 2-6 slides. What do you think? We can start by exchanging some slides regarding our methods. Keep in mind that the meeting is on 4-5 Feb 2014. That means that we should have the presentation ready by the end of January.

    ---
    regards,
* mail viv gia apivevaiwsh sthn Meltini gia taxidi, mail katrea gia eishthria, mail 

#Friday 3/1/14
* next setp : blacklists : 
 * google : 10.000 ana google account: 
  * exoume 107.000 urls / 10.000 = 10 acounts  \
   * python experiment_451.py --action check_blacklist --database_name experiment_451 --database_host 139.91.70.42 --blacklist_name googleapi --tld_server_url http://139.91.70.42:8082 --google_account_name antonakd@gmail.com --max_urls 10000
   * crasare kai to valame xana na trexei to sabbato to apogeuma eprepe  na perasou 24 wres ...
* expansion on experument_451 finished 
* python experiment_451.py --action get_TLD  --database_name experiment_451 --database_host localhost
 * auto argouse opote dhmiourghse ena index : self.tld_collection.create_index('tld')
 * eteleise 
* expansion on tweets db???
 * 199.425.976 tweets
 * 28.899.207 urls
* KTH distributed lessons : https://canvas.instructure.com/courses/408989/modules/items/4434681 
#Thursday  2/1/14
* aneipero : make plots for data downloaded in experiment451 all these days : 
 * expander sthn db experiment451
  *  in parallel:
     * run tweets server (multithread se polla mhxanhmata)
      * sto aneipero : python experimeent451.py --action tweets_server
      *  python experiment_451.py --action expand_multithread --database_name experiment_451 --database_host 139.91.70.42 --threads 100 --tweet_server_url http://139.91.70.42:8081
      * grid wn1:screen --------6717
      * grid wn2:screen --------
      * grid wn3:screen --------32413
      * grid wn4:screen --------13538
      * grid wn5:screen --------27740
      * grid wn6:screen --------11157
      * sapila : 32716

    

#Sunday 22/12/2013
 * Run cdfs:
  * python experiment_451.py --action cdfs --trends_database_name experiment_451 --trends_database_host 139.91.70.42 --database_name dec_20_2013 --database_host localhost --results_filename dec_20_2013.results.json
 * Plot cdfs:
  * python experiment_451.py --action cdfs2 --input_filename  dec_20_2013.results.json

#Saturday 21/12/2013
* O expander TELEIWSE .....!!let's chec the mongo ...........db.URL_collection.count() - 28899207
* stamathsa to wteiiter spam giati atevaze POLUU argga
* stamathsa ta panta 
* Run trend (worldwide)  downloader :
        * python experiment_451.py --action store_daily_trends --database_name experiment_451 --database_host localhost --account_name despoinaAnt1
          * [detached from 31483.pts-13.aneipero]
* Twitter.py @sapila : me account despoinaAnt2 , screen id : 27938 
* Run trends Server for popoular trending topics : 
   * python experiment_451.py --action trends_server --database_name experiment_451 --database_host localhost
        * [detached from 2094.pts-13.aneipero]
* Dowload tweets me vash ta trends apo ton prohgoumeno server: 
    *  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name despoinaAnt4 --database_host localhost --trend_server_url http://127.0.0.1:8080
     * [detached from 2547.pts-13.aneipero]
  *  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name minotis --database_host localhost --trend_server_url http://127.0.0.1:8080
   * [detached from 2689.pts-13.aneipero]
  *  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name sofiakisofia --database_host localhost --trend_server_url http://127.0.0.1:8080
   * [detached from 2809.pts-13.aneipero]
  *  python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name mariasifaki6 --database_host localhost --trend_server_url http://127.0.0.1:8080
   * [detached from 2928.pts-13.aneipero]
  *   python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name antonakakistavroula --database_host localhost --trend_server_url http://127.0.0.1:8080
   * [detached from 3049.pts-13.aneipero]
 * python experiment_451.py --action store_daily_tweets_from_trend_server --database_name experiment_451 --account_name antonakMs --database_host localhost --trend_server_url http://127.0.0.1:8080
  * [detached from 3225.pts-13.aneipero]


   


* 







    * Get 5000 users that have tweeted with todays trends:
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_daily_tweets --database_name dec_20_2013 --account_name despoinaAnt2 --database_host localhost 
    * Run a http server that serves these 5000 users
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action users_server  --database_name dec_20_2013 --database_host localhost 
    * Get tweets for these users
        * Started: 20 Dec 2013 01:44:31
        * 450: 2:09:43
        * 500: 2:12:09  4 min 50 = 400 mins 5000 = 7 hrs
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name despoinaAnt2 --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name despoinaAnt3 --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name minotis --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name sofiakisofia --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name mariasifaki6 --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name antonakakistavroula --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action store_tweets_for_specific_users --database_name dec_20_2013 --account_name antonakMs --database_host localhost --not_older_than "Mon Dec 09 01:01:01 +0000 2013" --users_server_url http://127.0.0.1:8080
        * Finished: 04:37:27
    * Run tweet server for the mutithread expander
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action tweets_server --database_name dec_20_2013 --database_host localhost 
        * On EDET:
            * python /home/user/Github/phd/code/experiment_451.py --action tweets_server --database_name dec_20_2013 --database_host localhost 
        * On anipero:
            * python experiment_451.py --action tweets_server --database_name dec_20_2013 --database_host localhost --port 8081
    * Run multithread expander
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action expand_multithread --database_name dec_20_2013 --database_host 127.0.0.1 --threads 50 --tweet_server_url http://127.0.0.1:8080 
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action expand_multithread --database_name dec_20_2013 --database_host 94.71.125.79 --threads 50 --tweet_server_url http://94.71.125.79:8080 
        * 08:58:32 +0000 Tweets sent: 300000 
        * 09:18:31 +0000 Tweets sent: 400000
        * 20 mins / 100.000 => 200mins 1.000.000 => 4hrs
        * On EDET:
            * python /home/user/Github/phd/code/experiment_451.py --action expand_multithread --database_name dec_20_2013 --database_host localhost --threads 50 --tweet_server_url http://127.0.0.1:8080 
        * On anipero:
            * python experiment_451.py --action expand_multithread --database_name dec_20_2013 --database_host localhost --threads 50 --tweet_server_url http://127.0.0.1:8081 
    * Run blacklists:
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action check_blacklist --database_name dec_20_2013 --database_host 127.0.0.1 --blacklist_name googleheuristic 
        * 242.000 urls
        * google heuristic 811
        * www.bahiscasinopoker.com 1923
        * http://takipabi.com/clearsessions.php 895 
    * Run get_TLD:
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action get_TLD  --database_name dec_20_2013 --database_host localhost
        * 9137 TLDs 
    * Run check_TLDs
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action check_TLD  --database_name dec_20_2013 --database_host localhost  
        * 1 True: http://www.graduate.edu.kw 
    * Run blacklist custom_urls 
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action check_blacklist --database_name dec_20_2013 --database_host 127.0.0.1 --blacklist_name customList --custom_urls 'http://www.graduate.edu.kw,http://www.bahiscasinopoker.com,http://takipabi.com'  
    * Run cdfs:
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs --trends_database_name experiment_451 --trends_database_host 139.91.70.42 --database_name dec_20_2013 --database_host localhost --results_filename dec_20_2013.results.json
    * Plot cdfs:
        * python /Users/antonakd/GitHub/phd/code/experiment_451.py --action cdfs2 --input_filename  dec_20_2013.results.json

#Friday 20/12/2013
 * check expansion on big dataset: server at aneipero :   * server @ aneipero : 2115.pts-13.aneipero --->  175216000/195875471
 * check to download twn 5000 xrhstwn - 1000 tweets (xwris tat trends)
  * > db.tweet_collection.count()  ...3323122
 

# Thursday 19/12/2013
 * check number of threads : ps aux | grep python kai briskeis to pid ths process Se emas einai 32052 Meta kaneis: cat /proc/32052/status kapou leei Threads: 4

 * trexoume expander sthn sapila: 
   * python experiment_451.py --action expand_multithread --database_name experiment_7_Dec --database_host 139.91.70.42 --threads 50
   * perimenoume ..............
 * Google safe api :   
  * apo edw:  http://en.wikipedia.org/wiki/Google_Safe_Browsing exei ena diagnwstic: 
  * http://www.google.com/safebrowsing/diagnostic?site=http://www.camkuri.com/   safe!!! 
  * check gia http://freebitco.in/?r=23860 safe!!
  * check gia http://www.google.com/safebrowsing/diagnostic?site=http://www.trkconvert.com/cpa.php?mt=436777&ofid=13103&tid=1  safe!!
  * kati dn paei kala ...
  * deutros tropos a tesekaroume 
   * https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey=ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw&appver=1.0&pver=3.0&url=http%3A%2F%2Fianfette.org%2F
   * ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw   KEY 
   * https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey=ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw&appver=1.0&pver=3.0&url=http%3A%2F%2Fianfette.org%2F - DOULEUEI !! - results = malware
   *  https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey=ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw&appver=1.0&pver=3.0&url=http://www.camkuri.com/ no results ---error
   * 
 * Sunanthsh elias, polakis, vivi, sotiris: 
  * Gia to peirmata 5000 xrhste/1000 tweets: 
   * tous eipa exoume 750.000 ana xiliada ara peripou 750 tweets ana xrhsth...eipa ee ftanoun.. As to afhsoume na sunexizie na katevasei kai AS TREXOUME GIA AUTA .
   * trexoume expander, blacklists
   * edw 8eloume 2 grafhmata. ena gia tous kalous kakous xrhstes(me vash tis blacklists)
   * gia ta graphs ..poio einia to peirama , giati to kanoume (p.x. oi xrhste me mple mallia einai spammmers)
   * trexoume to gnwsto heuristic : posa trends ana mera, posa trends ana evdomada, posa trends ana mhna (ante ast to kanoume gia thn mera prwta)
    * 2 cdfs (kaloi /kakoi xrhstes) loipon me 3 grammes to ka8e grafhma (mera, evdomada,mhnas)---h mia grammh gia twra thn hmera kai meta tis alles (week/month)
    * 
  * Gia to experiment 451: 
    * isws na katevazame gia europh pou xeroume ti paizei me ta trends. meta eipe h vivi, as stamathsoume na katevazoume epoitelous, exoume polaa tweets, as kanoume mia epexergasia. bottomline an 8eloume to vazoume na katevazei .

 ***********************************
 * experiment 451 check progress : 
 ************************************
  * python blacklists.py --database_name experiment_451 --blacklist_name googleheuristic  --from_date "2013-12-09 00:00:01" --to_date "2013-12-19 00:00:01" --log_filename aa
  * python blacklists.py --database_name experiment_451 --blacklist_name googleapi  --from_date "2013-12-09 00:00:01" --to_date "2013-12-19 00:00:01" --log_filename googleapi
  * 
*expander in thhreads:
  * python experiment_451.py --action tweets_server --database_name tweets --database_host localhost --skip_tweets 2784000
  * python experiment_451.py --action expand_multithread --database_name tweets --database_host 139.91.70.42 --threads 50 --tweet_server_url http://139.91.70.42:8080
  * wn2 ": [despoina@grid-wn2 ~]$ screen -r 8517.pts-3.grid-wn2
  * wn3 :screen -r 19203.pts-2.grid-wn3
  * wn4 no screen". running in bg
  * wn5 no screen . runing in bg
  * wn6 : screen -r 26453.pts-3.grid-wn6
  * aneipero: [detached from 2544.pts-16.aneipero]
  * server @ aneipero : 2115.pts-13.aneipero
  -----------------------------
  * Wed, 18 Dec 2013 22:06:10 +0000 Tweets sent: 10483000/195875471
    Wed, 18 Dec 2013 22:08:11 +0000 Tweets sent: 10763000/195875471

2minute 280000
x=        195875471
* Tetarth 18/12/2013
 * As valoume ton expander multithreaded me xwrismenh thn vash gia to aneipero - grid wn 2-6 multitheraded
  * 1. let's kill all the previous: kill `ps -ef | grep dinesh | awk '{ print $2 }'` 
  * epi thn eukairia as doume ti trexei :
   * screen -r 2470.pts-3.aneipero auto paei san trelo ....
   * 8eloume dld 100.000 tweets / 10 mins 
   ara gia       165964925     x
   x=1659649250/100000 = 16596,49250 /60 = 
* READY multithreaing: python experiment_451.py --action tweets_server --database_name tweets --database_host localhost --skip_tweets 2784000
  *  Skipping tweets..
  *  Wed, 18 Dec 2013 13:25:26 +0000 tweets skipped: 100000
  *  ........    Wed, 18 Dec 2013 13:25:53 +0000 tweets skipped: 2700000
  *  Done Skipping tweets
  *  serving at port 8080
* ---SCREEN : 1087.pts-13.aneipero]
* despoina@aneipero:~/Github/phd/code$  python experiment_451.py --action expand_multithread --database_name tweets --database_host 139.91.70.42 --threads 50 --tweet_server url http://139.91.70.42:8080
  * [detached from 1471.pts-15.aneipero]
  *  Auto kanei ta exhs: 
  * 
  * Cannot fetch tweets from http://139.91.70.42:8080. Waiting two minutes..


#`TRith 17 December
* eleni pureto 
* expander : 9.683.600 ews  165.964.925 , 195.875.471
* screen  -d -m python expander_parts.py expander_parts_log3 9683600 500000
screen  -d -m python expander_parts.py expander_parts_log10 9683600 500000
screen  -S s17 -d -m python expander_parts.py expander_parts_log11 9683600 500000
screen  -S s18 -d -m python expander_parts.py expander_parts_log12 10183600 500000

skotwse ola ta isntances pou trexoun kai vale to run 
anepero vazw ta prwa 195875471/6 = 32645911.833333332
* Google results semantic heuristic :
  * This heuristic

  1. Takes all tweets for a single day (9 Dec 2013, in this case)
  2. Takes all trends for this single day
  3. Checks which tweets have more than 2 trends
  4. For these trends checks the number of google results.
  5. Applies the http://en.wikipedia.org/wiki/Normalized_Google_distance to check for semantic relationship between trends.

  Auto pou menei einai na:
  Plots the results.

  To arxeio einai attached

  Ka8e grammh einai gia ena tweet pou stal8hke stis 9 Dek 2013 kai exei apo 2 trend h' panw. 

  H prwth sthlh einai to metric (to megalutero toso pio asxeta einia ta terms. Ara sto telos einai ta hot..)
  H deuterh sthlh einai Ta trends pou exei
  H trith sthlh einai 1 an einai spam kai tpt an den einai. Den to koita3a me kana scriptaki, alla me to mati!
  H tetarth sthlh einai to link.
  Excel
  gmetric.xlsx



#Deutera 16 December
* blacklist experiment:
* xeka8arisa ligo ta logs sto blacklist_experiment wste na exoume sto /home/despoina/blacklists_experiment/logs mono ta apotelmesmata mono apo to current experiment :
 * to opoio einai : xekinhse Sabbato 7 December me vash dedomenwn blacklist_experiment_7_12 
* Xanaeida ta apotelesmata tou     451 kai egraya gia tous top trend users sto twitter_paper. den vlepw spammers... :(
* We developed a system, called SpiderWeb, which is able to detect malicious web pages by looking at their redirection graphs, and we show that the system works well in practice, by running it on a dataset collected from the users of a popular anti-virus tool.
* mia idea gia ton expander
* eiani na xwrisoume thn vash se polla merh kai na ton valoume na trexei gia ka8e ena apo ayta ta tmhmata.
* h allh idea einai na dwsoume ena orisma kai auto toorisma na to dinoume sthn mongo kai na pas epistefei auta ta records
* esti ka8e fora pou ton trexoume na dinoume p.x 1-10.000 urls, 10.000-20.000 kok
SCREEN -S s10 -d -m python expander_parts.py expander_parts_log3 3683600 1000000
SCREEN -S s11 -d -m python expander_parts.py expander_parts_log4 4683600 1000000
SCREEN -S s12 -d -m python expander_parts.py expander_parts_log5 5683600 1000000
SCREEN -S s13 -d -m python expander_parts.py expander_parts_log6 6683600 1000000
SCREEN -S s14 -d -m python expander_parts.py expander_parts_log7 783600 1000000
SCREEN -S s15 -d -m python expander_parts.py expander_parts_log8 8683600 1000000
SCREEN -S s16 -d -m python expander_parts.py expander_parts_log9 9683600 1000000

9683600 - 

#Friday 13 december 
* use experiment_7_Dec_4000_till_5000
* switched to db experiment_7_Dec_4000_till_5000
*> db.tweet_collection.count()
* 289495
( > use experiment_7_Dec_3000_till_4000
switched to db experiment_7_Dec_3000_till_4000
> db.tweet_collection.count()
322047
> use experiment_7_Dec_2000_till_3000
switched to db experiment_7_Dec_2000_till_3000
> db.tweet_collection.count()
282875
> use experiment_7_Dec_1000_till_2000
switched to db experiment_7_Dec_1000_till_2000
> db.tweet_collection.count()
326589
> 
* parser continue with November files 
* paper Stringhini http://www.cs.ucsb.edu/~gangw/twitter_imc13.pdf : a detailed study of Twitter follower markets ,  develop
and evaluate multiple techniques for detecting these activities. 
* evaluate PARSER progress: 
 * mongo tweets count URL_collection 
 * Fri Dec 13 15:22:09 EET 2013: db.URL_collection.count() 666489
 * Fri Dec 13 15:35:20 EET 2013 666699  
 * 13 minute : 210  => 16 to mi
 * 165964925 /16=10372807.8125 /60 ->  


#12 December
* aneipero, Github path, resutls file:  
 * c = sorted(b, key = lambda x : len(b[x][u'09-12-2013'][2])) h opoia na parinei san key to u'Xstina98 kai na dinei to plh8os twn diaforetikwn trends
 * c = sorted(b, key = lambda x : b[x][u'09-12-2013'][0]) etsi sortareu me vash plh8os twn tweets, kai malista prepei na ginei anapoda 
  * c = sorted(b, key = lambda x : b[x][u'09-12-2013'][0], reverse=True) h 
  * c = sorted(b, key = lambda x : b[x][u'09-12-2013'][0])
  * print c[-1]to -1 einai to teleutaio , to -2 einai to protelautio ktl..
  * bres ton xrhsth pou exei xrhshmopoihsei to makrutero trend!
  * hint 1: Mporeis na pareis to mikos enos string me thn len. p.x. len('mitsos')
  * hint 2: Mporeis na pareis to megisto enos pinaka me thn max
  * >>> c = sorted(b, key = lambda x : max ( [ len(x) for x in b[u'Xstina98'][u'09-12-2013'][2] ] ) )
  * print c[-1]
  * 8eloume na paroume to max twn (  #How many times this link was tweeted  )
   * c = sorted(b, key = lambda x : max ([ b[x][u'09-12-2013'][3].values() ]  ))
* Follow the Green: Growth and Dynamics in Twitter Follower Markets Gianluca Stringhini: 
 * 


#11 December\
* At 16:41 : 
   * db.tweet_collection.count()
  50689
  > use experiment_7_Dec_1000_till_2000
  switched to db experiment_7_Dec_1000_till_2000
  > db.tweet_collection.count()
  234999
  > use experiment_7_Dec_2000_till_3000
  switched to db experiment_7_Dec_2000_till_3000
  > db.tweet_collection.count()
  167908
  > use experiment_7_Dec_3000_till_4000
  switched to db experiment_7_Dec_3000_till_4000
  > db.tweet_collection.count()
  228661
  > use experiment_7_Dec_4000_till_5000
  switched to db experiment_7_Dec_4000_till_5000
  > db.tweet_collection.count()
  179647
  > 
*
* TODO :http://www.spamhaus.org/whitelist/
* check  the extract_usernames 
 * --------@aneipero : uparxoun 2 diergasies: despoina 17398  0.0  0.6 114108 54688 pts/129  S+   Dec08   3:05 python extract_usernames.py --database_name experiment_7_Dec
   *  despoina 27901  0.0  0.5 113396 47184 pts/130  S+   Dec07   3:20 python extract_usernames.py --database_name experiment_7_Dec
 * *******
   * --------GRID wn4 :     194 users              python extract_usernames.py --database_name experiment_7_Dec_2000_till_3000 --users_filename users_5000_2000_till_3000.txt --account_name mariasifaki6  --database_host 139.91.70.42> log_wn4_experiment_7_Dec_2000_till_3000
   * accesstoken was wrong!
   * screenscreen -r 2955.pts-2.grid-wn4
   *  Wed, 11 Dec 2013 08:46:29 +0000 tweet: 158
   * Wed, 11 Dec 2013 08:47:29 +0000 tweet: 213
   * 1 minute = 213-158 = 55tweets
   * x  1000*1000tweets
   * x=1000000/55 min = 303 h = 12 meres
 * -----------GRID 5 : GRID 5 :screen -r 21543.pts-26.grid-wn5
 * Apo xtes(?) exei kanei 253? 
 * Wed, 11 Dec 2013 09:02:48 +0000 tweet: 683
 * Wed, 11 Dec 2013 09:04:48 +0000 tweet: 773
 * 2 minutes  90 tweets 
 * x  1000000 
 * x=22222min=370h = 15 meres!
 *-------------GRID 6  
* check expanders: 
**********aneipero: 
**********wn1:  
**********wn2: 
**********wn3: 
**********wn4: 
**********wn5: 

#10 December 
* Heuristic :
* trexei ws exhs: 
 python experiment_451.py --database_name experiment_451 --database_host localhost --action find_users_with_many_trends  --account_name despoinaAnt4 --results_filename experiment_451.results.json --specific_date 09-12-2013 
* # trends ana xrhsth. Gia ka8e xrhsth gia ka8e mer a posa tweets esteile suth thn mera, posa trends exoun ayta ta tweets kai posa tredns xrhstimopoiei. 
  *  otan milame gia expoli twn trends oxi me tto paradosiako spam alla me alles texnikes  
  * gia ka8e xrhsth  
 * Many trends are unicode, For example: #민호야생일축하해But if a user use an ascii equivalent of this trend (in our case: #minhoyasaengilcughahae)
 * then tweeter counts this trend as used by this user
 * This is a problem for our heuristic because while I was counting how many trends have a user used for a day
 * I noticed that some had 0 which was strange given that we were downloading according to some trends
 * With some search I noticed that these users where using the ascii version of the trend and not the unicde
 * fortunately this package exists: https://pypi.python.org/pypi/Unidecode
 * That allows the conversion of unicode to the "closest" ascii
 * (This is perfect convertor from Greek to greeklish btw)
 * so: >>> from unidecode import unidecode
 * >>> print unidecode(u'Μήτσακλας'), Mitsaklas
 *  I use this when we search if a tweet has today's trends and it works  since there isn't any tweet without at least one trend


********************
* blacklists experiment
 * db.blacklist_collection.count()  - 2441
 * Spamhaus vriskei ka8hmerina, kai google heuristic. Ta alla eumperilamvanomenou tou google api den vriskoun tipota !
 * query mongo db: 
  *  db.blacklist_collection.find( { "blacklist" : "SpamHaus" } ).count() 
  * > db.blacklist_collection.find( {  "blacklist" : "googleheuristic" , "date" :  ISODate("2013-12-07T22:14:42.800Z")  } )
*********************** 
* extract usernames: experiment deuteras : 
 *******
 * Sto aneipero trexei to extract usernames me input olo to arxeio opote to pernei apo thn arxh opote 8a kaluyei thn prwth xiliada xrhstwn                                        *                                                                                         7_Dec_0_till_1000 
 *******
 * GRID NODE 5                                                                              APO 1000 mexri 2000
 * screen -r 21543.pts-26.grid-wn5 
 * python extract_usernames.py --database_name experiment_7_Dec_1000_till_2000 --users_filename users_5000_1000_till_2000.txt --account_name sofiakisofia --database_host 139.91.70.42
 * as doume kai thn vash : b.tweet_collection.count() 147592- 
 *******
 * GRID wn4 :                       python extract_usernames.py --database_name experiment_7_Dec_2000_till_3000 --users_filename users_5000_2000_till_3000.txt --account_name mariasifaki6  --database_host 139.91.70.42> log_wn4_experiment_7_Dec_2000_till_3000
 * accesstoken was wrong!
 * screen

 *******
 * GRID WN6: fainetai na trexei. As doume thn Db :                               experiment_7_Dec_3000_till_4000   
  * petaei :  db.tweet_collection.count() 136783
 *******
 *  GRID WN2:8a eprepe na trexei :  python extract_usernames.py --database_name experiment_7_Dec_4000_till_5000 --users_filename users_5000_4000_till_5000.txt --account_name antonakMs --database_host 139.91.70.42
 problem with clock!! move to 3 !
 *********
 * GRID NODE 3 4000_till_5000
     * 4000_till_5000
     * tail -n 1000 usernames_5000. > users_5000_4000_till_5000.txt
     * sudo yum install git    mkdir Github  cd Github/
     *  git clone https://github.com/kantale/phd.git
     * head -n 4000 usernames_5000.txt | tail -n 1000 > users_5000_4000_till_50000.txt
     * wget https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/master/safebrowsinglookup.py
     * python safebrowsinglookup.py
     * pip install twython
     * pip install spam-blocklists
     * pip install surblclient
     * python extract_usernames.py --database_name experiment_7_Dec_4000_till_5000 --users_filename users_5000_4000_till_5000.txt --account_name antonakMs --database_host 139.91.70.42
    *
 
***********************
* experiment451: 
 * wn2: screen -r 16832.pts-0.grid-wn2


############################################## 
# MOnday 9 December 2013
* to download tah diarkesie 19 meres!: 
 * 3 nea accounts sto twitter : 
  * git pull
  * trexei me: 
   * python extract_usernames.py --database_name <DATABASE_NAME> --users_filename <USERS_FILENAME> --account_name <ACCOUNT_NAME> 
   * USERS_FILENAME = to arxeio me tous users
   * dld kapoio uposunolo tou users_5000.txt 
   * mporeis na ftia3eis ena uposunolo tou users_5000.txt me tis entoles head kai tail
   * p.x. an 8es na pareis tis grammes apo 1000 mexri 2000 kane:
   * head -n 2000 users_5000.txt | tail -n 1000 > users_5000_1000_2000.txt
   * To < ACCOUNT_NAME > mporei na einia otidipote apo:
   * sofiakisofia, mariasifaki6, despoinaAnt1, despoinaAnt2, 
    *************************************
    * GRID NODE 5 APO 1000 mexri 2000: 
     * head -n 2000 users_5000.txt | tail -n 1000 > users_5000_1000_till_2000.txt 
     * pip install twython
     * pip install spam-blocklists
     * pip install surblclient
     * pou  na ta swzei ? topika h sthn mongo sto aneipero? As kanoume ena test . poso grhfoa ta swzei sto aneipro ?
     * python extract_usernames.py --database_name experiment_7_Dec_1000_till_2000 --users_filename users_5000_1000_till_2000.txt --account_name sofiakisofia --database_host 139.91.70.42 
    ***************************OK
    *************************************
    * GRID NODE 4 APO 2000 - 3000
    Apo 2000 - 3000
       * head -n 3000 usernames_5000.txt | tail -n 1000 > users_5000_2000_till_3000.txt
     * wget https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/master/safebrowsinglookup.py
     * python 

     * pip install twython
     * pip install spam-blocklists
     * pip install surblclient
     * python extract_usernames.py --database_name experiment_7_Dec_2000_till_3000 --users_filename users_5000_2000_till_3000.txt --account_name mariasifaki6 --database_host 139.91.70.42 
    ***************************OK
    *************************************
    * GRID NODE 6 3000_till_4000
     Apo 3000_till_4000
     * sudo yum install git    mkdir Github  cd Github/
     *  git clone https://github.com/kantale/phd.git
     * head -n 4000 usernames_5000.txt | tail -n 1000 > users_5000_3000_till_4000.txt
     * wget https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/master/safebrowsinglookup.py
     * python safebrowsinglookup.py
     * pip install twython
     * pip install spam-blocklists
     * pip install surblclient
     * python extract_usernames.py --database_name experiment_7_Dec_3000_till_4000 --users_filename users_5000_3000_till_4000.txt --account_name SAntonakaki --database_host 139.91.70.42 
    *************************** 
     * GRID NODE 2 4000_till_5000
     * 4000_till_5000
     * tail -n 1000 usernames_5000. > users_5000_4000_till_5000.txt
     * sudo yum install git    mkdir Github  cd Github/
     *  git clone https://github.com/kantale/phd.git
     * head -n 4000 usernames_5000.txt | tail -n 1000 > users_5000_4000_till_50000.txt
     * wget https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/master/safebrowsinglookup.py
     * python safebrowsinglookup.py
     * pip install twython
     * pip install spam-blocklists
     * pip install surblclient
     * python extract_usernames.py --database_name experiment_7_Dec_4000_till_5000 --users_filename users_5000_4000_till_5000.txt --account_name antonakMs --database_host 139.91.70.42  
    *
* http://www.razorsocial.com/free-twitter-analytics/
* Blacklists experiment : cron job every mornig at 10:10 : running  home/despoina/blacklists_experiment/run_bl_exp.sh
*  etrexe olh thn prohgoumenh evdomada, alla dior8wsame ena bug sto google api opote epreep na to epanalavoume. Xekinhse to Sabbato ta xhmerwmata, opote kai katevasa, parsara kai ekana expand to dataset Sabbato 7 december
* Experiment_7_decemeber: 
 * task mexri thn deutera : 
     * katevazoue gia tuxaious 5000 xrhstes tous opoious epilegoume apo to megalo dataset(oxi to dataset mias meras tou blacklists experiment)
     * tuxaious tou Noembriou, prosfatous tespa unique xrhstes. 
     * gia autous tous xrhstes katevazoume ta tweets tou ~1000 tweets h tespa prospata tou Noembriou tweets analoga me to limit poy mas dinei to twitter
     * Sthn sunexeia trexw ta blacklists kai vlepw tous legit kai mh legit xrhstes 
     * opote dhmiourgw duo omades apo xrhstes legint./mh legit xrhstes 
       * gia autes tis duo omades xrhstwn trexw to heuristic kai vgazw GRAFHMATA cdf gia : 
         * posa trends ana mera
         * posa trends ana evdomada
         * posa trends ana mhna
      * PROSOXH   : 
      1) 8a prpeie OPWSDHPOTE NA douleyei to googlesafe api blacklist giati einai h pio axiopisth blacklist kai 8a prpeie n a trexei me authn . 
      2) otan trexoume to heuristic exoume 1 account , 1 tweet posa trends gia thn SUGKEKIMENH hmera poy stal8hke to tweet ...poia htan ta trENDS THS IDIA HMERAS! 
      ....gia ka8e tweet, na koitas ta trending topics pou epestrepse to twitter gia ekeinh thn hmera. Epishs, mporei to heuristic na einai apotelesmatiko, an checkaroume oxi ta trends san apoluto ari8mo, alla se sugkrish me ta
    tweets: p.x.  (avg number of trending topics / tweets) gia tis 3 periodous pou leme.
* Experiment_451 - Action expand:  
  * screen: 16005
  * kantale1: wn5
  * python experiment_451.py --action expand --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
*  Experiment_451 - Action:store_daily_tweets
 * wn: 4 
 * screen: 26552
 *  kantale1: python experiment_451.py --action store_daily_tweets --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
* experiment451: action store_daily_trends
 * Sto Grid: WN2 
 * screen: 16832.pts-0.grid-wn2 
 * python experiment_451.py --action store_daily_trends --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4 
* Sto Grid: WN2 screen: 16832 
* python experiment_451.py --action store_daily_trends --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
*dir: /home/despoina/Github_zip

#8 december
* misc links: https://dev.twitter.com/discussions/6942 
 *  twitter supports only specific WOEIDs ! 
* Experiment_451 - Action expand:  
  * screen: 16005
  * kantale1: wn5
  * python experiment_451.py --action expand --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
*  Experiment_451 - Action:
 * wn: 4 
 * screen: 26552
 *  kantale1: python experiment_451.py --action store_daily_tweets --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
* experiment451: 
 * Sto Grid: WN2 screen: 16832 
 * python experiment_451.py --action store_daily_trends --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4 
* Sto Grid: WN2 screen: 16832 
* python experiment_451.py --action store_daily_trends --database_name experiment_451 --database_host 139.91.70.42 --account_name despoinaAnt4
*dir: /home/despoina/Github_zip

#7 dec
* experiment 7 december: (same name in db) 
      * task mexri thn deutera : 
     * katevazoue gia tuxaious 5000 xrhstes tous opoious epilegoume apo to megalo dataset(oxi to dataset mias meras tou blacklists experiment)
     * tuxaious tou Noembriou, prosfatous tespa unique xrhstes. 
     * gia autous tous xrhstes katevazo   00 tweets h tespa prospata tou Noembriou tweets analoga me to limit poy mas dinei to twitter
     * Sthn sunexeia trexw ta blacklists kai vlepw tous legit kai mh legit xrhstes 
     * opote dhmiourgw duo omades apo xrhstes legint./mh legit xrhstes 
       * gia autes tis duo omades xrhstwn trexw to heuristic kai vgazw GRAFHMATA cdf gia : 
         * posa trends ana mera
         * posa trends ana evdomada
         * posa trends ana mhna
      * PROSOXH   : 
      1) 8a prpeie OPWSDHPOTE NA douleyei to googlesafe api blacklist giati einai h pio axiopisth blacklist kai 8a prpeie n a trexei me authn . 
      2) otan trexoume to heuristic exoume 1 account , 1 tweet posa trends gia thn SUGKEKIMENH hmera poy stal8hke to tweet ...poia htan ta trENDS THS IDIA HMERAS! 
      ....gia ka8e tweet, na koitas ta trending topics pou epestrepse to twitter gia ekeinh thn hmera. Epishs, mporei to heuristic na einai apotelesmatiko, an checkaroume oxi ta trends san apoluto ari8mo, alla se sugkrish me ta
    tweets: p.x.  (avg number of trending topics / tweets) gia tis 3 periodous pou leme.
*today progres: 
xana evala na katevoun ta tweets gia to blacklista experimen

nomiza oti me periorizei san xrhsth antonak opote na mpw san elenh kanterakh
python parser_3.py tweets_06_december_2013
expander : [detached from 29825.pts-111.aneipero]

#5dec
* debug google safe browsing : 
 * to google api alla3e kai otan den briskei tpt den epistrefei kai tpt . to googlesafeapi pou  eixa agkatasthsei perimenei na parei ena respond gia ka8e url. 
 * einai  den einai spam den pairnei tpt kai petaei error. opote to error shmainei no spam.  
* Opote xanatrexe to blaclists experiment : 
  * 1) katevase xana shmerina tweets screen -r 7979.pts-125.aneipero
  * 2) MHN adeiaseis thn vash mongo blaclist-experimen - xrhsimopoihse thn blacklists_experimentNew 
  * 3) trexe parser (prosoxh na ta valei sthn blacklists oxi tweets
  * 4) trexe expander 
  * trexe blaclists gia shmera
  * chejk cron if ok  
* debug google safe browsing : 
 * to google api alla3e kai otan den briskei tpt den epistrefei kai tpt . to googlesafeapi pou  eixa agkatasthsei perimenei na parei ena respond gia ka8e url. 
 * einai  den einai spam den pairnei tpt kai petaei error. opote to error shmainei no spam.  
* google safe api returns error in aneipero . aneipero blacklistsed? or reches limit ? 
* google safe api returns error in aneipero . aneipero blacklistsed? or reches limit ?
 *PROXY sto aneipero : tunneling  ssh -C2qTnNf -D 8181  forthple_dcsITN@ple1.ait.ac.th
 * pali to google petaei error opote : 
  * tunneling  ssh -C2qTnNf -D 8181  forthple_dcsITN@planetlab2.cis.upenn.edu
   * ssh -C2qTnNf -D 8181  forthple_dcsITN@planetlab2.cis.upenn.edu
      * pali error , ayth thn fora kai apotwitter limit exceeded
    * ssh -C2qTnNf -D 8181  forthple_dcsITN@vn4.cse.wustl.edu
    ********************************************************************************   
    * Quick and dirty solution for SOCKS5 proxy through ssh tunneling.
    * $ ssh -C2qTnN -D 8181 -i <planetlab_key> <planetlab_username>@<planetlab_node>
    * Test the connection using:
    * $ curl --socks5 localhost:8181 http://ifconfig.me
    * If successful, the above command will return the IP address of the Planetlab node.
    * credits to https://calomel.org/firefox_ssh_proxy.html
    ********************************************************************************
 * python extract_usernames.py --database_name tweets
 * Swzei ta apotelsmata sto arxeio usernames_5000.txt.results (to usernames_5000.txt exei ta usernames)

#4 dec
* to plh8os twn trends ana hmera mporei na ftasei 1000 (11/9). Posa apo ayta na ginoun hijack?
* etoimo to extract usernames: 
 * despoina@aneipero:~/Github/phd/code$ python extract_usernames.py --database_name tweets --from_date "2013-10-15 00:00:01" --to_date "2013-11-15 00:00:01" 
* sunanthsh(vivi, polakis, sotiris) : 
* task mexri thn deutera : 
 * katevazoue gia tuxaious 5000 xrhstes tous opoious epilegoume apo to megalo dataset(oxi to dataset mias meras tou blacklists experiment)
 * tuxaious tou Noembriou, prosfatous tespa unique xrhstes. 
 * gia autous tous xrhstes katevazoume ta tweets tou ~1000 tweets h tespa prospata tou Noembriou tweets analoga me to limit poy mas dinei to twitter
 * Sthn sunexeia trexw ta blacklists kai vlepw tous legit kai mh legit xrhstes 
 * opote dhmiourgw duo omades apo xrhstes legint./mh legit xrhstes 
 * gia autes tis duo omades xrhstwn trexw to heuristic kai vgazw GRAFHMATA cdf gia : 
   * posa trends ana mera
   * posa trends ana evdomada
   * posa trends ana mhna
  * PROSOXH   : 
  1) 8a prpeie OPWSDHPOTE NA douleyei to googlesafe api blacklist giati einai h pio axiopisth blacklist kai 8a prpeie n a trexei me authn . 
  2) otan trexoume to heuristic exoume 1 account , 1 tweet posa trends gia thn SUGKEKIMENH hmera poy stal8hke to tweet ...poia htan ta trENDS THS IDIA HMERAS! 
  ....gia ka8e tweet, na koitas ta trending topics pou epestrepse to twitter gia ekeinh thn hmera. Epishs, mporei to heuristic na einai apotelesmatiko, an checkaroume oxi ta trends san apoluto ari8mo, alla se sugkrish me ta
tweets: p.x.  (avg number of trending topics / tweets) gia tis 3 periodous pou leme.

* started expander in aneipero : measuring the rate of url expansion ..3urls /minute (1 instance), 30 urls/minute ...
* anaconda for each grid node:
 * wget http://09c8d0b2229f813c1b93-c95ac804525aac4b6dba79b00b39d1d3.r79.cf1.rackcdn.com/Anaconda-1.8.0-Linux-x86_64.sh
 * pip install pymongo
* expander.py : connect to aneipero mongo :   self.connection = Connection('139.91.70.42', 27017)
* expander speed
 * run in aneipero by 45 instances
  * Wed Dec  4 21:55:32 EET 2013   446437
  * Wed Dec  4 21:56:33 EET 2013   446468
  * -----------------------------------------
  * 1 minute ...31urls ()

#3 dec
* experimenting with wtython 
* srcipt for getting tweets from twitter for specific username, script for retrieving form mongo all the tweets for a specifc username

#2 dec 
 * blacklists_experiment:
 python blacklists.py --database_name blacklists_experiment --blacklist_name SpamHaus --log_filename blacklist_2_dec.SpamHaus.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name SublChecker --log_filename blacklist_2_dec.SublChecker.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name surbl --log_filename blacklist_2_dec.surbl.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleapi --log_filename blacklist_2_dec.googleapi.log  
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleheuristic --log_filename blacklist_2_dec.googleheuristic.log
 python print_blacklist.py --database_name blacklists_experiment --from_date "2013-11-27 00:00:01" --to_date "2013-11-30 00:00:01" --output_filename aa
 * heyristic.py :   failed: exception: group() can't handle more than 20000 unique keys - fixed!
 * copy July in aneipero for parsing i, August 1 file

#30

 python blacklists.py --database_name blacklists_experiment --blacklist_name SpamHaus --log_filename blacklist_1_dec.SpamHaus.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name SublChecker --log_filename blacklist_1_dec.SublChecker.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name surbl --log_filename blacklist_1_dec.surbl.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleapi --log_filename blacklist_1_dec.googleapi.log  
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleheuristic --log_filename blacklist_1_dec.googleheuristic.log
 python print_blacklist.py --database_name blacklists_experiment --from_date "2013-11-27 00:00:01" --to_date "2013-11-30 00:00:01" --output_filename aa

#29
* 
* to 28 july metaferete sto aneipero 
* ssh tunneling sthn tailand :
 * ssh -C2qTnNf -D 8181  forthple_dcsITN@ple1.ait.ac.th &
 * curl --socks5 localhost:8181 http://ifconfig.me
 *   503  ssh -C2qTnNf -D 8181  forthple_dcsITN@ple1.ait.ac.th 
 *   512  curl --socks5 localhost:8181 http://ifconfig.me
 *   513  ssh -C2qTnNf -D 8181  forthple_dcsITN@ple1.ait.ac.th &
 *   514  curl --socks5 localhost:8181 http://ifconfig.me
 *   517  curl --socks5 localhost:8181 http://ifconfig.me
* blacklists experiment : 
 * tweet_collection
 *  db.tweet_collection.count()
  * 63653
 * db.URL_collection.count()
  * 8313
 * db.blacklist_collection.count()
  * 427
 * despoina@aneipero:~/blacklists_experiment$ python print_blacklist.py --database_name blacklists_experiment --from_date "2013-11-28 00:00:01" --to_date "2013-11-29 00:00:01" --output_filename aaa
 
* planet labe new node ok!
* sdwnload, parse expand & 
 python blacklists.py --database_name blacklists_experiment --blacklist_name SpamHaus --log_filename blacklist_29_nov.SpamHaus.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name SublChecker --log_filename blacklist_29_nov.SublChecker.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name surbl --log_filename blacklist_29_nov.surbl.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleapi --log_filename blacklist_29_nov.googleapi.log  
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleheuristic --log_filename blacklist_29_nov.googleheuristic.log

#28nov
 python blacklists.py --database_name blacklists_experiment --blacklist_name SpamHaus --log_filename blacklist_28_nov.SpamHaus.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name SublChecker --log_filename blacklist_28_nov.SublChecker.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name surbl --log_filename blacklist_28_nov.surbl.log
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleapi --log_filename blacklist_28_nov.googleapi.log  
 python blacklists.py --database_name blacklists_experiment --blacklist_name googleheuristic --log_filename blacklist_28_nov.googleheuristic.log
 * Planetlab:  peirama pou mou zhthse h vivi
 * Vivi: apo 2 komvous germany mpi & usa wustl pare 1000 tweets kai kane extract ta id tous. 
  * etrexa ton parser_3 gia ta arxeia auta 
  * opote exw 3 vaseis 
  (kanw copy paset to id otan mou to petaei to programma tou parser_3.py Obama_b
   * Tweet id already exists in the database: 403922476096176128
   * ta vazw sto excel kai ta sugkrinw
*  python blacklists.py --database_name blacklist_experiment --blacklist_name SpamHaus --log_filename blacklist_28_nov.log
 * new planet lab nodes: 
    * netlab-01.naist.j
  * vn4.cse.wustl.edu
  * planetlab1.di.fct.unl.pt  
  * ple1.ait.ac.th 
  * planetlab1.mta.ac.il
  * planetlab2.research.nicta.com.a
  * planet-plc-1.mpi-sws.org  
  * planetlab2.cnds.jhu.edu
  * planetlab2.cis.upenn.
 * python print_blacklist.py --database_name blacklist_experiment --from_date "2013-11-28 00:00:01" --to_date "2013-11-28 00:00:01" --output_filename aaa 
 * run  blaclists for today python
 * python blacklists.py --database_name blacklist_experiment --blacklist_name SpamHaus --log_filename blacklist_28_nov.log
  * blacklists.py  changed with: 
   * The new model is more simple:

{
        'e_url' : The_exanded_url,
        'blakclist' : The name of the blacklist that identified it as spam,
        'date' : The date when this blacklist identified this url as spam 
}

If you specify from_date and to_date then the script will
ignore all the spam urls that exist in the database and have
already been characterized as spam from this blacklist between the dates from_date and to_date 

For example:
Let's say that a url has been characterized as spam by SpamHaus at: "2013-01-01 12:00:00"
If you specify these dates:
"2013-01-01 00:00:01", "2013-01-02 00:00:01" 
Then if the same URL is found and the selected blakclist is SpamHaus then this URL 
will NOT be checked. 

This is for cases when you don't want to double check your urls for a certain period of time

If you don't specify them then it doesn't check if a
url already exists in the database

Examples:

python blacklists.py --database_name tweets --blacklist_name SpamHaus --log_filename None 

python blacklists.py --database_name tweets --blacklist_name SpamHaus --log_filename None --from_date "2012-01-01 00:00:01" --to_date "2014-01-01 00:00:01"
'''

#27 nov
 * at 12:00 deleted from blacklist_experiment : URL_collection.remove, db.tweet_collection.remove, db.blacklist_collection.remove
  * python /home/despoina/blacklists_experiment/twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000 --max_overall_tweets 75000 --output tweets_27_nov_2013
  * parseer_3 
  * expander etoimo mexri to prwi 
  * blacklists: 
   * OK . finished.
 * synanthsh me polaki, 8elei 3 pragmata: 
  * thelei ta paotelesmata se eana pinaka popws exoume pei 
  * vale to heuristics tous to opiio einai to exeh s exoume mi atomh anamesa sthn backlista kai sto Elias heuristic to poio einai to exhs : 
   * count #trends per account in an hour/day/week
  * check to para8uro tou googleapi kai prosarmosw ton kwdika 
  * vale date sto blacklist collection kai xanatrexe to (auto einia dikia  mou idea) svhse mono to collection me ta blacklists_urls kai xanatrexe to blacklists    

# 26 nov 
 * bug fixed in blacklists.py
 * blacklists experiment
  * xtes to vradu teleiwse xtes to blacklist  experiment. Prolavan na ginoun download, expand (hortened urls) & check blacklists gia na mikro set 25 November tweets(panta apo trending topics) se mia mera (kai me arketh ka8usterhsh debugging time) Koitaxa ligo ta apotelesmata kai auth thn fora ola eina apo google api, opote mallon uparxei bug. To koitazw twra. Opote xanakatevazw allo dataset shmerina tweets wste na to epanalavoume me 1h mera peiramatos shmera. Entwmetaxu exoun ginei parse 55G tweets sthn main vash, exoun ginei expand ola alla den exw trexei ton elegxo me tis blacklists mexri na vrw to bug.Allwste 8a vallw kai ton Iounio na ginei parse + expand shmera . 
  * python twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000  --max_overall_tweets 75000 --output tweets_26_November_2013
Script started: 2013-11-26 10:38:18
 * arxeio gia na mpei to blacklist experiment sto cron.(


# 25 nov
* to vazeis na katevazei 15k url tweets
 * sudo python /home/antonakd/twitter-spam/twitter-spam/twitter.py \ --run_trend_server \ > trends_server_log09_09_2013.out 2> trends_server.09_09_2013.err
 * python twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000  --max_overall_tweets 75000
* to parsareies se mia nea vash na exei mono extra : blacklist_experiment
 * python parser_3.py tweets_25_November_2013
 * expander 
  * encoding bugs fixed  
* trexeis to blacklist.py gia to blacklists experiment DB ...prosoxh allxe ton kwdika wste na mhn ta valei sthn tweets vash !!
 * parallhla kai stis 3 listes:
  * python blakclists.py SpamHaus
  * python blakclists.py SublChecker
  * python blakclists.py  surbl
  * python blakclists.py  googleapi
  * python blakclists.py  googleheuristic
* xanaevala na katevaonoun ta tweets alla  crasare me munhma:
 * 1238 Today's tweets: 100
 Oops!  Something went wrong when opening url https://api.twitter.com/1.1/search/tweets.json?q=%23BlackFridayCA&count=100&max_id=405160925788766208&oauth_body_hash=2jmj7l5rSw0yVb%2FvlWAYkK%2FYBwk%3D&oauth_nonce=97743269&oauth_timestamp=1385432878&oauth_consumer_key=saQIypbIp6oojQLHzoCaAA&oauth_signature_method=HMAC-SHA1&oauth_version=1.0&oauth_token=51018124-DPQnlm6dT72OQxwvOXJIQdTSuOQZ0YM2lJNVBjWrB&oauth_signature=vVzIn0lRWhGt9tNKeqhSU5ZNMAI%3D. Try again...
desp
 * oppote to xanavala > python twitter.py --runtime_trends --wait 1 --max_tweets_per_trend 5000  --max_overall_tweets 75000 --output  tweets_26_November_2013 >  tweets_26_November_2013.log2
 


#24 nov
* etoimo kai to blacklists ..:
 * backup sto aneipero thn vash pou exei mesa > db.copyDatabase('tweets', 'tweets_backup')
  * treximo twn blacklists
   * bugs ........
  * parser_3: tweets_10_June_2013,  

#23 nov

* restarted twitter in sapila due to bug.Also last 2 days had tweets from WOEID = us  
* testing expander, parser_3
  * ετρεχα τπον parser_3 gia to arxeio : python parser_3.py /storage/data_tmp/tweets_8_May_2013.txt kai evale sthn vash mongo.tweets 1.953125GB.
* Amira experiment. to etrexa gia  : 
  * node a: grep -o '"in_reply_to_status_id"' GayMarriage_a | wc -l 285 tweets
  * node b: 285
  * node c: 230
   opote katarxhn to plh8os pou mas dinei einai diaforetiko. 
 *parser_3 gia tweets_6_May_2013, ok done 
 *  tweets_7_May_2013 
 * tweets_8_May_2013 tweets_8_May_2013 ok  
  * vtweets_9_May_2013 tweets_9_May_2013 ok 
  * tweets_10_May_2013 tweets_10_May_2013 ok 
  * tweets_28_April_2013 tweets_28_April_2013 ok 
  * tweets_30_April_2013
  * tweets_09_11_2013
* Polla apo ta shortedned urls : 
 *  Failed to expand url: http://t.co/xZDXnun1sC
 * Problem: HTTP Error 404: Not Found 
 * https://dev.twitter.com/discussions/5197

* 22nov 
 * Amira sunexizw me to paper kai vazw sta planet lab nodes na trexei to script pou legame wste na katevasei gia mia mera oxi polles ta trends : 
    * obama,  gyus rights, burga, isocial, bill laden, abortion, cencorship
      * apo ola ta planet lab alla na einai se diaforetika merh ston kosmo. kai talevazei gia ta idia trends!
       * OK ala trexw XWRIS server  SE OLA TA PLANET LAB NODES: 
         * [forthple_dcsITN@planet-plc-1 twitter-spam]$ sudo python2.7 /home/forthple_dcsITN/twitter-spam/twitter-spam/twitter.py --trend "obama" --output tweets_21_nov_obama_limit100 --limit 100
          *  sudo python2.7 twitter.py --trend "obama" --output tweets_21_nov_obama_limit100 --limit 100
          * mallon kalutera 1 tweet arxika : 
           sudo python2.7 twitter.py --trend "obama" --output tweets_21_nov_obama_limit100 --limit 100 --max_tweets_per_trend 1
           sudo python2.7 twitter.py --trend "burka" --output tweets_21_nov_burka_limit100 --limit 100 --max_tweets_per_trend 1
           sudo python2.7 twitter.py --trend "christmans" --output tweets_21_nov_christmans_limit100 --limit 100 --max_tweets_per_trend 1
           sudo python2.7 twitter.py --trend "gay wedding" --output tweets_21_nov_gay_wedding_limit100 --limit 100 --max_tweets_per_trend 1
           sudo python2.7 twitter.py --trend "isocial" --output tweets_21_isocial_wedding_limit100 --limit 100 --max_tweets_per_trend 1

           * OK trexei sta exhs: forthple_dcsITN@planet-plc-1 twitter-spam]
                                ,forthple_dcsITN@planet-plc-1 
                                 forthple_dcsITN@planetlab2
                                 forthple_dcsITN@vn4 

* 21 nov

 * sunanthsh me polaki: 
  * to arxeio me ta spam kalo eini na ieni ws exhs:
   * shorted uls kai apotelesma apo ka8e blacklist me spam/not spam sthlh gia ka8e blacklist
    * sto arxeio na mpoun dhladh oles oi blacklists
   * sthn mongo swzzoume extracted urls, expanded ursl KAI ENA link PROS TO TWEET 
   * o parser prepei na kanei ta exhs: 
    * handle tweets + METADATA
     * extract URLS
     * extract trending topics
     * extract twitter keywords e.g. RTs, @callouts etc
    * XREAZOMATSE XEHWRISTA scripts , xehwrizoume to extractinhg twn urls & blacklists check.  : 
     * parser.py 8a dhmiourgei ton pinaka tweet_table sthn mongo : 
      * sthles: USER, date, location, URLS, #trends, #twitter_words (isws twitter_id gia na sundesoume me ton epomeno pinaka vlepe apo katw)
     * expander.py 8a dhmiourgeu ton pinaka URL_table me tis exhs sthles: AYTO to stcript DEN DIAVAZEI to file alla ton pinaka tweets_table
      * user, date, stortened url, expanded url, URL  isws kai  (isws twitter_id gia na sundesoume me ton apo panw pinaka)
     * blacklusts checker :  xehwrista scripts gia na tsekaroun ka8e blacklists:
      * blaclist1 checker
      * blaclist2 checker
      * blaclist3 checker
      * blaclist4 checker
      * auto to script diavazei ton URL_table
      * for each expanded ask blacklist
      * upadte table 
    * allagh tou parser wste na kanei to exhs:
     * gia ka8e hashtag lookup an uparxei lista me ta trending topics apo twitter . POsa trending topics exei to tweeter, alliws 8a pernei oti tag tou exei kapnisei tou ka8e xrhsth
     * oxi whitelists akomh
     * na valoume na trexei o expander kai na apo8hkeuoume ta expanded wste na mhn xanoume xrono
     * to arxeio pou tou esteila me ta spam ulrs exei kati periergo..apokleietei oi blacklists na mhn eixan overlap. mono h spamhaus? check if something is wronhg !
     * gia o peirama me tis blaclists : to x8esino arxeio pou katevasame 8eloume na to rwthsoume thn idia mera OLES tis blacklists .   An prolavoume na rwtsoume se mia mera 15000 urls se oles tis listes ..cool kratame auto to plh8os urls. An den prolavoume , 8a paroume san plh8os urls to mikrotero  plh8os pou mporei na tsekarei mia apo tis listes. wste na prolavoume na rwtame ka8e mera oles tis listes. Meta afou apofasisoume ton ari8mo vazoume auto to arxeio na trexei ka8e mera kai 8a mas epistrefeu apotelesma apo ka8e lista  spam or not apo ka8e lista! einai shmantiko thn idia mera poy to katevasame thn idia mera na to trexoume san prwth mera peiramatos ! 
  * synanthsh vivi sotiris: 
   * Amira sunexizw me to paper kai vazw sta planet lab nodes na trexei to script pou legame wste na katevasei gia mia mera oxi polles ta trends : 
    * obama,  gyus rights, burga, isocial, bill laden, abortion, cencorship
      * apo ola ta planet lab alla na einai se diaforetika merh ston kosmo. kai talevazei gia ta idia trends!
       * OK ala trexw XWRIS server  SE OLA TA PLANET LAB NODES: 
         * [forthple_dcsITN@planet-plc-1 twitter-spam]$ sudo python2.7 /home/forthple_dcsITN/twitter-spam/twitter-spam/twitter.py --trend "obama" --output tweets_21_nov_obama_limit100 --limit 100
          *  sudo python2.7 twitter.py --trend "obama" --output tweets_21_nov_obama_limit100 --limit 100

       * sugkrine ta  
   * twitter spam:
    * na to xanavalw na trexei sto grid, me ea stable version tou parser. 
    * statistics: dior8wsame to plot pou eixe problhma kai twra vgazei 7 arxeia ta opoia einai  
     * to stats1 periexei:
      * Gia olous tous xrhstes, To a8roisma twn trends pou eixan ola ta tweets tous, to plh8os twn tweets pou steilane, O mesos oros twn trends pou eixe ka8e tweet tous
      * To stats2 periexei: Ola ta diaforetika texts pou exoun stalei se md5, To plh8os twn tweets pou exoun auto to text, oi xrhstes pou to exoun steilei ka8os kai poses fores to exei steilei o ka8e xrhsths
      *  To stats3 periexei: Antistoixhsh meta3u tou md5 apo to stats2 kai tou pragmatikou text
      * To stats4 periexei: Ola ta trends pou exoun stalei, posa tweets exoun auto to trend
      * To stats5 periexei: Ola ta diaforetika URLs pou exoun stalei kai posa tweets exoun auto to URL
      * To stats6 periexei: Oles tis blacklists kai posa tweets exei "piasei" auth h blacklist
      * To stats7 periexei: Ola ta urls kai poies blacklists exoun "piasei" auto to url ws spam
     *   Anaferontai MONO se spam tweets. Dhladh ola auta ta stoixeia einia mono gia spam tweets. 
     * Opote den exoume ta trends gia ta MH spam!
   * Sugxish me ta trends kai ta hashtags: 
    * To twitter mas dinei trending topics. Ta trending topics mporei na einai eite apla keywords (p.x. Christmas) eite hashtags (p.x. #Christmas)
    * Mexri extes oti mas edine to twitter auto kaname dld an mas edine trending topic apla psaxname gia tweets pou eixan auto to trending topic Dld psaxnme gia tweets pou eixan mesa to "Christmas". An apo thn allh mas edine hashtag tote katebazame tweet pou eixan auto to hashtag. Auto to alla3a twra etsi wste panta na exei hashtag.* ........To twitter exei ena api mesa apo auto to api mporeis na katebazeis trending topics tou twitter . Yparxoun omws duo eidwn trending topics keywords (Christma)kai hashtags (#Christmas) kai ta duo einai trending topics pla to ena exei ginei trend ws aplo keyword kai to allo exei ginei trend ws hashtag
     * To API den kanei diakrish kai mas epistrefei oti 8ewrei auto oti einai trend. Mporei  na einia keyword, mporei na einai hashtag.  Palia oute emeis kaname diakrish: 
      * an epestrefe keyword tote fairname ta tweet pou eixan auto to keyword
      * an epestrefe hashtag tote fairname ta tweet pou eixan auto to hashtag
      * kai ta duo omws eimai einai trending sumfwna me to twitter
       * Auto allaxe twra etsi wste otan  to api mas epistrefei kapoio keyword  emeis na bazoume ena # mprosta tou kai na to kanoume hashtag
---  

* 20 Nov
 *tespa auto einai pleon mia parametros sto script, mporoume na valoume oti 8eloume. opote aplws to vazw ena neo arxeio na trexei xwris whitelist me --limit 50.000 (auto anaferetai se limit #tweets) 25% of tweets contain a link in them according to recently released Twitter stats.http://techcrunch.com/2010/09/14/twitter-seeing-90-million-tweets-per-day/
  * sudo python parser.py --file /storage/data_tmp/tweets_27_April_2013.txtpartaf --limit 50000  --query --db_name tweets > ~/logs/tweets_27_April_2013.txtpartaf.log
  * kaname mia dior8wsh giati se meriktwes den uparxei user. opote to xanaarxisa me allo dbname alla ekana copy to expanded url table apo thn palia vash : 
   *  mongodump -d some_database -c some_collection
   * mongorestore -d some_other_database -c some_collection dump/some_collection.bson
   * sudo python parser.py --file /storage/data_tmp/tweets_27_April_2013.txtpartag --query --limit 50000 --db_name tweetsNew > ~/logs/tweets_27_April_2013.txtpartag.log
    * finished - to 8ema edw einai oti 8a mporoume na pernoume ta prwta 50000 kai meta 8a phgainoume sto sepomeno arxeio 
    * 
   *   


 * Start mongo in aneipero: 
  * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage/mongodb_data
  * sudo /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongo
  * remove database $ python code/parser.py  --file /storage/data_tmp/tweets_27_April_2013.txtpartac --db_name tweets --remove
  * run parser with mongo : $ sudo python code/parser.py  --file /storage/data_tmp/tweets_27_April_2013.txtpartac --db_name tweets --query
#19 Nov
 * CHANGES:
1. In mongodb we save:
   url --> expanded_url
For every url expansion that we do

2. Each link is checked over all blacklists. For every spam url we
save in mongodb:
  spam_url --> [list of blacklisted that identified this spam]

TODO (among others):
1. connection from the script to mongodb is local. Meaning that mongodb
should run from the same location as the script. We need to find a
place to run mongodb so that the client scripts can connect to it.

2. Run blacklists in parallel

 * sunanthsh gia twitter spam  (elias, sotiris, polakis)
  * gia tis blacklists eipame xreiazomatse ena ground trust gia to ti einai spam kai exoume 3 phges:
      *  blacklists
      *  deactivated accounts from twitter
      * http://cs.ucsb.edu/~gianluca/publications.html  stringlini etoimo tool
    * eipame ti exei ginei opote ligh orgamnwsh:
      * as douleyw ena mikro dataset 10.000 tweets arxika 
      * na ta vale sthn mongo db
      * se ena pinaka me sthles : tweet URL, tiny, expanded url (link se tweet)
      * kai siga siga autos o pinakas 8a ginei expand me ta apotelesmata apo blacklists
   * Na apo8hkeuoume expanded url giati ayto 8elei xrono. 
   * epishs na dhmkourghsw parallhla twitter.py kai ka8ena na tsekarei thn mia blacklist parallhla wste na mhn ka8usteroume
   * vasiko einai na douleuoume se bulks dhladh pernoumr ena arxeio ..to vazoume se mongo …kanoume parse …uparxei h DB kapou kai sinexizoume
 * amira paper: http://arxiv.org/pdf/1109.1396v3.pdf
 * sotiris paper 
 * plan the experiment: Laoutaris: Effect of competition (I used to love but not I hate Aegean). Eg lets take routes of similar length and or similar end-point type (eg International hubs like LON-FRA, or regional BCN-ATH or mix LON-BCN) and see how competition (# of airlines flying the route) impact on price. I bet that for the same distance and endpoint type, places where the market has failed (GREECE) are paying much more.
  *  3pthsh ath-barca: 
  * 3 pthsh ams-
  * katarxhn xreiazomai ena calculator gia distance se pthseis http://www.airplanemanager.com/FlightCalculator.aspx
   *  http://www.travelmath.com/flying-time/from/ATH/to/AMS
    * http://europetravel.net/europe-distance-calculator.php
    *    http://www.tripit.com/destinations/calculate-the-distance-between-two-cities/ 
    * gdb: http://data.worldbank.org/indicator/NY.GDP.PCAP.CD/countries/1W-GR?order=wbapi_data_value_2012%20wbapi_data_value%20wbapi_data_value-last&sort=asc&display=default
       * greece 22,083
      * spain 29,195
       * italy 33,049
      * United Kingdom 38,514
       * france 39,772  
       * germany 41,514
       * netherlands 46,054
       * sweden 55,245
       * Switzerland 79,052
       * Luxembourg 107,476 

paragontes: season ? hub, gdb, kms, number of stops , 
    -----------------------------
flight for 15/01
    εκανα μια μικρή ερευνα στις τιμές για τις παρακάτω ομάδες για τις  15/01 απο momondo. 
Σε μερικές ομάδες ειναι προφανές το price discrimination ακόμη και στην ίδια εταιρία. 

    ==============
Frankfurt - London : 638 km  (Hub-Hub, )  lowest 17euro raynair  - 84 - 123  
Barcelona - rome : 859km (regional-regional ) lowest 27  raynair  - 82 iberia - 103 alitalia 
Rome - Thessaloniki : 886 (regional-regional)  lowest 27 raynair  - 82 aegean - 139 aegean - 
    
Heraklion - Thessaloniki : 621 km (regional-regional, one country) lowest 43 aegean  - 69 olympic 
Umea - Stockholm 514: 26 norwegian direct  
Marseille - paris  661km : 27 treno! ti kanoume gia aytes tis apostaseis se xwres poy kaluvontai me treno?  - 40air france direct 

Αν και η αποσταση ειναι λιγο μικροτερη ειναι σχετικα πιο ακριβες για (regional-regional ) και οπως περιμενα πιο ακριβα στην ιδια χωρα αν εινια regional-regional σε σχεση με πιο βορειες χωρες

    -----------------------------
   Athens - Rome : 1053 km (regional-regional ) 135 direct alitalia - 154 british 1 stop - 
   Berlin - London : 932 km (Hub-Hub) raynair 30 eurw - 33 easyjet - germanwings 50 

Εμφανως πιο ακριβη η περιφερεια εδώ

    ------------------------------
    London - Stockholm  :1433 k m (Hub-Hub) 18 eurw ryanair  - 37 easyjet  - norwegian 45 
    Paris - Stockholm : 1545 km (Hub-Hub)  15 raynair   - 57 norwegian - 60 air france 
    
    Zurich - Stockholm : 1471 km (Hub-Hub)  103  air berlin 1 stop - 193  sas direct- 
    Athens - Barcelona: 1880 km   79 direct aegean  - 125 1 stop british 
    
    ---------------------------
    Heraklion  - Barcelona: 2107    124 aegean 1 stop - 137 2 stops
     
    London - Βerlin : 1805 km (Hub-Hub) 20 raynair direct  - 39 easyjet direct  - 53 german wings direct  
    paris - Minsk : 1828km (Hub-regional north) 125 baltic 1 stop   -  147 baltic 1 stop 
    stockholm - rome : 1979km (Hub-regional south) 61 norwegian  1 stop - 67  baltic  1 stop - 
    Helsinki  - paris: 1911 km (Hub-regional north) 57 norwegian  direct  - 79 baltic 1 stop
    -----------------------------
    Cadiz - Heraklion : 2824  -- no flights
    Madrid - Athens : 2653  : 97 aegean direct , british 164 1 stop

    I would like to take a look for prices in 
    same distance , same gdb , hub-hub
    same distance , same gdb , hub-regional
    same distance , different gdb , hub-hub
    same distance , different gdb , hub-regional
    different distance , different gdb , hub-hub
    different distance , different gdb , hub-regional 


ομαδα Α
      * greece 22,083
      * spain 29,195
      * italy 33,049
ομαδα Β

      * United Kingdom 38,514
      * france 39,772  
      * germany 41,514
      * netherlands 46,054
ομαδα Γ
       * sweden 55,245
       * Switzerland 79,052
       * Luxembourg 107,476 
       * norway 99,558

Στην ιδια χώρα: 
ομαδα Α : Heraklion - Thessaloniki : 621 km (regional-regional, one country)                                     lowest 43 aegean  - 69 olympic 
ομαδα Β : Marseille - paris  661km : 27 treno! ti kanoume gia aytes tis apostaseis se xwres poy kaluvontai me treno?  - 40air france direct 
ομαδα Γ : Umea - Stockholm 514:                                                                                         26 norwegian direct  

Απο χώρα σε χώρα παρομοια χιλιομετρικη αποσταση : 
ομαδα Α : Barcelona - Ρome :    859km (regional-regional )  lowest 27  raynair  - 82 iberia - 103 alitalia 
          Rome - Thessaloniki : 886 (regional-regional)  lowest    27 raynair  - 82 aegean - 139 aegean - 
ομαδα Β : Frankfurt - London :  638 km  (Hub-Hub, )       lowest   17euro raynair  - 84 - 123  
ομαδα Γ : Stockholm - Trodheim: 612:                               66 eurw norwegian 1 stop
          Stockholm - Oslo :    417 :                              32 eurw norwegian direct

Απο χώρα σε χώρα παρομοια χιλιομετρικη αποσταση ( λιγο μεγαλύτερη απο την παραπάνω):
ομαδα Α :    Heraklion  - Barcelona: 2107    124 aegean 1 stop - 137 2 stops


ομαδα Β :     London - Βerlin : 1805 km (Hub-Hub) 20 raynair direct  - 39 easyjet direct  - 53 german wings direct  

ομαδα Γ :   Geneva - Umea : 2148km - 75 eurw 1 stop norwegian  
================================
     


#18
 * Evala na trexei o neos parser gia palia tweets file (maios)
 * Evala na trexei to twiiter.py loccaly gia us 
   * Current trend: [u'#HappyMonday', u'%23HappyMonday']  Trend index: 1
   * Current trend: [u'#MQBJohnnyVota', u'%23MQBJohnnyVota']  Trend index: 2
   * Current trend: [u'#mcm', u'%23mcm']  Trend index: 3
   * Current trend: [u'Christmas', u'Christmas']  Trend index: 4
   * Current trend: [u'Chicago', u'Chicago']  Trend index: 5
   * Current trend: [u'Starbucks', u'Starbucks']  Trend index: 6
   * Current trend: [u'Glad', u'Glad']  Trend index: 7
   * Current trend: [u'America', u'America']  Trend index: 8
   * Current trend: [u'#MQBMarjorieVOTA', u'%23MQBMarjorieVOTA']  Trend index: 9
   * Current trend: [u'#MAVEN', u'%23MAVEN']  Trend index: 10
   * Current trend: [u'Ruiz', u'Ruiz']  Trend index: 11
   * Current trend: [u'Pandora', u'Pandora']  Trend index: 12
   * 
#17 Oct 
* push tis allages sto git. Oi allages autes einai:
 * 1. Corrected bug in google safe browsing API. The problem was that if the API returned 'ok' we considered this as a spam!
 * 2. Added a white_list as a global_list
 * 3. Added function: heuristic_google_search_obfuscation(url)
  * Checks if the url contains is a google obfuscation link. If it is then it returns the link
  * Otherwise returns False
 * 4. Deactivated spamhaus blacklist. The reason is:
  * spamhaus blacklist is not a domain name blacklist.
   * It is a IP blacklist.
   * So if a legal domain is under a blacklisted IP that would create a False Positive.
 * 5. If we identify a spam we also save the url that was identified.
 * 6. The plot_spam.py contains the following ADDITIONAL metrics on spams:
   *  - The number of tweets of each trend (.spam4)
   * - The number of tweets of each URL  (.spam5)
   * - The number of tweets of each blacklist (.spam6)
 * 7. twitter.py only gets trends from USA (WOEID = 23424977)

#16 Oct
* to ggogle safe api 8ewrei ta shortened urls as spam? 
*  categorise the false positive urls and see if there is a pattern of mistreated domain names (instagram) and add them in a white list


#14 Oct
*koitaxe ta urls pou exei mesa to spam arxeio gia ton gugkekrimeno xrhsth, den uparei spam. koitaxe ta usernames kai mou zhthse gia poia trends (ta pio dhmofilh? )
* meta evgale to sumperasma oti exei problhma h ulopoihsh !
* gunzip -S "zip" tweets_25_April_2013.zip 
* all instances in grid2 had crashed : disk full: 
* kill all screen
 * sunanthsh polakis, sotiris, tzermias, vivi
  * amira: 
    * We have to set a research question: 
     * "retrieve from all planet lab host nodes (HPA, venezuela, iran , irak, ...) trending topics nd then retrieve tweets concerning cultural/controversial tags like:
        obama, burga, ktl"
     * on the fly tweet spam detection of tweets om each planet lab node ? 
    * sent mail : Dear Amira, currently I am processing the spam results from the trending topics. 

      I was wondering how to continue taking advantage the distributed processing with gossip algorithms that you mention. 
      The issue is I need some literature to make things more specific. 

      Could you please sent me the top 10 publications on gossip algorithms concerning the task that you mention?

      with kind regards,
      Despoina Antonakaki
  *grid & baby sit nodes...!!:
   * CensMon: A Web censorship monitor A Sfakianakis, E Athanasopoulos, S Ioannidis FOCI’11: USENIX Workshop on Free and Open Communications on the Internet
  * script gia management twn grid nodes...ask tzermias...tzermias says ask cp !
  * twitter spam results: 
   * poio url exei ginei characterize as spam apo tis blacklist? H plhroforia auth uparxei mesa sto spam arxeio..8a thn kanoume extract. 
   * kalo einai na pianoume mono ta top trends
   * whitelist add intagram!
   * heuristic has been impemented has not show results yet.
   * graphs: %spams, % rest of tweets, dcf popular trends 
  * conference usenix, ccs  
#13 Oct
* Plot spam: extract statistics (heuristic discussed with polakis yesterday) . Two scripts: 
 *  plot_spam.py : python plot_spam.py FILE.spam kai ftiaxnei tria arxeia:
    *  FILE.spam.stats1: To arxeio stats1 Sou deixnei olous tous xrhstes sortarismenous me posa trends/tweets exoun
    *  FILE.spam.stats2: Auto to arxeio exei tis e3hs sthles: 
     * 1. md5 tou text
     * 2. Poses fores exei ginei tweet auto to text
     * 3. Poioi xrhstes kai poses fores o ka8enas tous exei kanei tweet auto to text
     * To arxeio einai sortarismeno me bash th sthlh 2 dld panw panw exei to md5 tou text pou exei ginei tweet tis perissoteress fores
     * Sthlh 3 einai sortarismenh analoga me to poses fores to exei kanei tweet auto to text o ka8e xrhsths
      * dld:
      * An mia grammh einai: abababababab 3 mitsos:2 kwstas:1
      * Shmainei: yparxei ena spam tweet tou opoiou to md5 einai abababababab auto spam tweet exei stal8ei 3 fores 2 to exei steilei o mitsos kai 1 o kwstas
      * uparxei kai ena trito arxio to .stats3, auto periexei antistoixeia meta3u twn md5 kai tou text twn tweets


#12 Oct
* Sunanthsh me polaki: 
 * apply tou sugkekrimenou heuristic: 
  * gia ena spam 
   * gia ka8e account
     *  posa  trends exei xrhsikopoihsei
     * average...
    * Gia ka8e spam tweet 
      * extract accounts
      * posa trends/account
------------------------
  * poia h diafora anamesa sta parapanw spam kai sta remaining accounts
*skype with laoutaris,sotiris,zaxarias
 * Ερωτήσεις: εστιασαμε στην 1 και 5 με highlighted την 5 ερώτηση. Έχουμε λοιπόν (απο προηγούμενο mail):
   * 1. Using cookies or IP/browser fingerprinting to keep a history of your visits and increase the price each time in order to put presure on you to buy
      * α. κατηγοριοποίηση αεροδρομίων σε περιφερειακά,  κεντρικά
      * β. correlate τιμή με level of competition: 
   * Για κάποια συγκεκριμένη χιλιομετρική απόσταση και συγκεκριμένη πληρότητα πτήσεων : 
      *   correlate price-distance-πληρότητα- economy status - airplane size -hub airport, 
    * Επίσης μπορεί να γίνει quantify: 
      * σύγκριση τιμών αν ειναι σε  hub αεροδρομίο
      *   ποσες πτησεις πετάνε στις διαθέσιμες αεροπορικές που πετάνε στο συγκεκριμένο προορισμό.
      * Σωτήρης: 
      * 1) data retrieval κοντά στην ημερομηνία της πτήσης 
      * 2) πόσες available θέσεις υπάρχουν στην πτήση
      * 3) χρηση software ταξιδιωτικού agent; 
 * 5. Effect of competition (I used to love but not I hate Aegean). Eg lets take routes of similar length and or similar end-point type (eg International hubs like LON-FRA, or regional BCN-ATH or mix LON-BCN) and see how competition (# of airlines flying the route) impact on price. I bet that for the same distance and endpoint type, places where the market has failed (GREECE) are paying much more.
* data sources
* related work: αναζητηση στην βιβλιογραφια για συγκεκριμενες ερωτησεις. 
---------------------------
* Arxika mporei na ginei enas sxeediasmos tou peiramatos (I/O, pou tha trexei) 

#9 Oct
* arxeio 29 April exie kollhsei ...opote xwrisa 
 *  sudo split -b 13824m tweets_29_April_2013.txt tweets_29_April_2013.txtpart

#8 Oct
* proxeiros upologismos: 
 * Geia sas,

ekana kapoious proxeirous upologismous gia to poso 8a kostisei se xrono h epexergasia tous stous 5 komvous tou grid pou exoume twra

sunolika exoume 388.3G tweets

An upo8esoume oti mporoun na xwristoun se isa merh stou 5 komvous antistoixoun 390 / 5 = 78 G ana grid node

Apo ta x8esina apotelesmata eida peripou oti xreiazetai ~18h ana Giga, Ara 78 * 18 = 1404 hours => 59 meres


oi 59 meres vevaia einai ka8ara epexergasia, opote 8a pros8esw 2 gia metafora data, start processes mia kai ginontai me to xeri.
* ekana copy OLA ta data apo planet lab komvous 
*  python_des parser.py --file tweets_27_April_2013.txtpartag --query > tweets_27_April_2013.txtpartag.log  RESTARTED with new parser
* mv new parser se osa grid nodes exei termatisei ! 
* wn3 parsing .... error : 
 *  The error was:
No JSON object could be decoded
Expanding url: http://t.co/57VNJZUY5N
[despoina@grid-wn3 ~]$ rm tweets_27_April_2013.txtpartac.log
[despoina@grid-wn3 ~]$ python_des parser.py --file tweets_27_April_2013.txtpartac --query > tweets_27_April_2013.txtpartac.log
parser.py:411: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded in checked_urls:
parser.py:417: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
* Omoiws sto wn6 : arser.py:411: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded in checked_urls:
parser.py:417: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
Traceback (most recent call last):
  File "parser.py", line 711, in <module>
    query_filename(args.file, args.limit)
  File "parser.py", line 557, in query_filename
    save_spam(tweet, file_to_save)
  File "parser.py", line 533, in save_spam
    file_to_save.write(json.dumps(spam_tweet) + '\n')
  File "/home/despoina/python/python/lib/python2.7/json/__init__.py", line 243, in dumps
    return _default_encoder.encode(obj)
  File "/home/despoina/python/python/lib/python2.7/json/encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/despoina/python/python/lib/python2.7/json/encoder.py", line 270, in iterencode 
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0x92 in position 59: invalid start byte
 
* server for downloading tweets at sapila stopped due to : 
 * sudo cat run.10_16_2013.err 
Traceback (most recent call last):
  File "/home/antonakd/twitter-spam/twitter-spam/twitter.py", line 710, in <module>
    max_output_size = args.max_output_size)
  File "/home/antonakd/twitter-spam/twitter-spam/twitter.py", line 572, in get_trend_twitts
    for trend in trend_generator:
  File "/home/antonakd/twitter-spam/twitter-spam/twitter.py", line 267, in get_trends_from_twitter
    for trend in trends:
TypeError: 'int' object is not iterable

#7 Oct

*Setting next file fro parsing at wn2:  python_des parser.py --file tweets_29_April_2013.txt --query > log_tweets_29_April_2013.txt.log 
* http://www.cc.gatech.edu/~feamster/ 
* node 2 not OK with exception : File "parser.py", line 711, in <module>
    query_filename(args.file, args.limit)
  File "parser.py", line 557, in query_filename
    save_spam(tweet, file_to_save)
  File "parser.py", line 533, in save_spam
    file_to_save.write(json.dumps(spam_tweet) + '\n')
  File "/home/despoina/python/python/lib/python2.7/json/__init__.py", line 243, in dumps
    return _default_encoder.encode(obj)
  File "/home/despoina/python/python/lib/python2.7/json/encoder.py", line 207, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/home/despoina/python/python/lib/python2.7/json/encoder.py", line 270, in iterencode
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xd8 in position 56: invalid continuation byte

* Started next files: wn3 which finished successfully : 
 * aneipero: sudo python ~/svn/twitter-spam/parser.py --file  tweets_09_11_2013.txt --query > ~/logs/tweets_09_11_2013.txt.log 
 * wn6 :  4.2G 2013-04-29 10:05 tweets_28_April_2013.txt @ wn6 started at Nov  7 12:27 
 * wn5 : $ python_des parser.py --file tweets_27_April_2013.txtpartaf --query > tweets_27_April_2013.txtpartaf.log 
 * wn3 : python_des parser.py --file tweets_27_April_2013.txtpartag --query > tweets_27_April_2013.txtpartag.log
 * wn4 : python_des  parser.py --file tweets_27_April_2013.txtpartah --query > tweets_27_April_2013.txtpartah.log
 
* svistike kata la8os to tweets_27_April_2013.txtpartac.spam sto node3 opote to xanaevala na trexei 
*  grid node filename  File parts : part/all number of tweets  number of spam  date & time started date & time finished  % spam/tweets terminated uniterrupted?
  tweets_27_April_2013  txtpartaa txtpartab txtpartac txtpartad txtpartae txtpartaf txtpartag txtpartah  for i in *.txtpartaa; do  grep -o '"in_reply_to_status_id"' $i | wc -l; done         
* grid-wn2  tweets_27_April_2013.txtpartaa.spam 1 of 8  400163  33363 6/10/13 11:53 11/7/13 8:24  8.337352529 
* grid-wn3  tweets_27_April_2013.txtpartab.spam 2 of 8  410931  33663 6/10/13 14:56 11/7/13 9:26  8.191886229 OK
* grid-wn4  tweets_27_April_2013.txtpartac.spam 3 of 8  407315  17255 6/10/13 15:05 11/7/13 0:05  4.236279047 ?
* grid-wn5  tweets_27_April_2013.txtpartad.spam 4 of 8  411323  24268 6/10/13 14:03 11/7/13 3:18  5.899986142 
* grid-wn6  tweets_27_April_2013.txtpartae.spam 5 of 8  405813  32621 6/10/13 15:03 11/7/13 8:03  8.038431494 

#6 Oct
* still problems in despoina@grid-wn2: 
 *  yum install screen sto grid . problem with new python: 
   *    179  sudo ln -s /home/despoina/python/python/bin/python /usr/bin/python2.7
   * 180  cp /usr/bin/python_old /usr/bin/python
   *  181  sudo cp /usr/bin/python_old /usr/bin/python
   *  182  sudo yum install screen
   * kai xana pisw 
   * meta apo : https://github.com/kantale/phd/blob/master/log_6_11_2013_node2GRID.md
  *  NEW prepare_cloud: https://github.com/kantale/phd/blob/master/code/prepare_cloud.sh
 * As valoume to prwto na trexei: 
  * script /dev/null
  * screen 
  * python_des parser.py --file tweets_27_April_2013.txtpartaa --query > log_tweets_27_April_2013.txt 
* despoina@grid-wn5 PAME sto epomeno: 
  * scp code/prepare_cloud.sh  despoina@grid-wn5.ics.forth.gr:./
  * scp ../../svn/twitter-spam/parser.py   despoina@grid-wn5.ics.forth.gr:./
  * scp /storage/data_tmp/tweets_27_April_2013.txtpartab    despoina@grid-wn5.ics.forth.gr:./
  * as trexoume to prepare cloud!
   * [despoina@grid-wn5 ~]$  /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartab  --query
   *OK !!
   * script /dev/null
  * screen 
 * [despoina@grid-wn5 ~]$ /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartab --query > log_tweets_27_April_2013txtpartab.txt
* despoina@grid-wn3 : 
  * scp code/prepare_cloud.sh  despoina@grid-wn3.ics.forth.gr:./
  * scp ../../svn/twitter-spam/parser.py   despoina@grid-wn3.ics.forth.gr:./
  * scp /storage/data_tmp/tweets_27_April_2013.txtpartac    despoina@grid-wn3.ics.forth.gr:./
  * as trexoume to prepare cloud!
   * [despoina@grid-wn3 ~]$  /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartac  --query
   *OK !!
   * script /dev/null
  * screen 
 * [despoina@grid-wn3 ~]$ /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartac --query > log_tweets_27_April_2013txtpartac.txt
 * [despoina@grid-wn3 ~]$ python_des parser.py --file tweets_27_April_2013.txtpartac --query > tweets_27_April_2013.txtpartac.log 
* despoina@grid-wn4 : 
  * scp code/prepare_cloud.sh  despoina@grid-wn4.ics.forth.gr:./
  * scp ../../svn/twitter-spam/parser.py   despoina@grid-wn4.ics.forth.gr:./
  * scp /storage/data_tmp/tweets_27_April_2013.txtpartad    despoina@grid-wn4.ics.forth.gr:./
  * as trexoume to prepare cloud!
   * [despoina@grid-wn4 ~]$  /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartad  --query
   *OK !!
   * script /dev/null
  * screen 
 * [despoina@grid-wn4 ~]$ /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartad --query > log_tweets_27_April_2013txtpartad.txt
* despoina@grid-wn6 : 
  * scp code/prepare_cloud.sh  despoina@grid-wn6.ics.forth.gr:./
  * scp ../../svn/twitter-spam/parser.py   despoina@grid-wn6.ics.forth.gr:./
  * scp /storage/data_tmp/tweets_27_April_2013.txtpartaf    despoina@grid-wn6.ics.forth.gr:./
  * as trexoume to prepare cloud!
   * [despoina@grid-wn46~]$  /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartae  --query
   *OK !!
   * script /dev/null
  * screen 
 * [despoina@grid-wn6 ~]$ /home/despoina/python/python/bin/python parser.py --file tweets_27_April_2013.txtpartae --query > log_tweets_27_April_2013txtpartae.txt

   
#5 Oct 
* Laoutaris: 
  * bibliografia + scrapping API gia osa den exoun API
* Amira mail gia telco gia distributed 
* komvoi sto grid 
 *  scp  tweets_27_April_2013.txtpartaa  despoina@grid-wn2.ics.forth.gr:./
 *    

* tweets_27_April_2013.txt: 
  * split ena arxeio kai test gia ton parser
  * sudo split -b 1024m tweets_27_April_2013.txt tweets_27_April_2013.txtpart


#31 Oct
* python parser_test_with_gogolesafebrowsing.py --file /storage/data_tmp/tweets_10_June_2013.txt --query
 *  

#30 Oct
* xanaparse to arxeio tweets_09_30_2013 sto screen [detached from 9689.pts-12.aneipero]


#29 Oct 
* Conferences : 
* Ayta pou prolavainoume einai  
 * http://www.secrypt.icete.org/  

Dont Follow Me - Spam Detection in Twitter.Alex Hai Wang. SECRYPT, page 142-151. SciTePress, (2010))UPCOMING DEADLINES
Regular Paper Submission: April 15, 2014
Regular Paper Authors Notification: June 16, 2014
Regular Paper Camera Ready and Registration: June 30, 2014 

 *  TrustCom 2014 : The 13th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom-14)

When  Sep 24, 2014 - Sep 26, 2014
Where  Beijing, China
Submission Deadline May 5, 2014
Notification Due  Jun 26, 2014
Final Version Due Jul 20, 2014

 *  http://www.ieee-security.org/TC/SP2014/ 
RegistrationEarly-bird registrationTBD
Travel GrantsStudent travel grant applications dueTBD
PapersPaper submissions due November 13, 2013
Rebuttal January 11-14, 2014
Acceptance notification February 3, 2014
Final papers dueTBD
PostersPoster abstracts dueTBD
Poster acceptance notificationTBD
Poster abstracts final (for website)TBD
Short TalksTalk abstracts dueTBD

 * TrustCom 2014 : The 13th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom-14)

When  Sep 24, 2014 - Sep 26, 2014
Where Beijing, China
Submission Deadline May 5, 2014
Notification Due  Jun 26, 2014
Final Version Due Jul 20, 2014

 * ASIACCS 2014 : ACM Symposium on Information, Computer and Communications Security
Conference Series : ACM Symposium on Information, Computer and Communications Security
 
Link: http://asiaccs2014.nict.go.jp
 
When  Jun 4, 2014 - Jun 6, 2014
Where Kyoto, Japan
Submission Deadline Dec 6, 2013
Notification Due  Jan 27, 2014
Final Version Due Feb 28, 2014

 *  KDD 2014 : 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining

When   Aug 10, 2014 - Aug 13, 2014
Where New York, USA
Abstract Registration Due Feb 14, 2014
Submission Deadline Feb 21, 2014
Notification Due  May 14, 2014

* other

=======================================
=======================================

 * Research in Attacks, Intrusions and Defenses (RAID) Symposium

Oct 23, 2013 - Oct 25, 2013 Saint LuciaApr 1, 2013

Internet Measurement Conference 2011  - Suspended Accounts in Retrospect An Analysis of Twitter Spam.imc2011
Internet Measurement Conference
Oct 23, 2013 - Oct 25, 2013Barcelona, SpainMay 8, 2013 (May 1, 2013

 * http://www.secrypt.icete.org/
  

Don't Follow Me - Spam Detection in Twitter.Alex Hai Wang. SECRYPT, page 142-151. SciTePress, (2010))UPCOMING DEADLINES

Regular Paper Submission: April 15, 2014

Regular Paper Authors Notification: June 16, 2014
Regular Paper Camera Ready and Registration: June 30, 2014
http://comsnets.org/  November 19, 2013
Annual Computer Security Applications Conference (ACSAC) 2012 Searching for Spam- Detecting Fraudulent  Accounts via Web Search, Twitter Games: How Successful Spammers Pick Targets  June 4, 2013
Privacy, Security, Risk and Trust (PASSAT), 2012 International Conference on and 2012 International Confernece on Social Computing (SocialCom) September 8-14, 2013
SocialCom 2013International Conference on Social Computing
Sep 8, 2013 - Sep 14, 2013Washington, DC, USAJun 1, 2013
tbannounced
SOSP 2013

Camera-ready deadline September 15, 2013
BoF Proposal Deadline October 1, 2013 at 23:59 PDT
Papers posted online  October 3, 2013

 * NDSS Symposium 2014
 Titles and abstracts of papers due:  Monday, 5 August 2013 (11:59 pm EDT) (Firm)
• Full paper and panel submissions due:  Friday, 9 August 2013 (11:59 pm EDT) (Firm)
• Rebuttal period:  9–11 October 2013
• Author notification:  Friday, 1 November 2013
• Final version of papers and panels due:  Friday, 6 December 2013 (Firm)
 
http://www.ieee-security.org/TC/SP2014/ 
RegistrationEarly-bird registrationTBD
Travel GrantsStudent travel grant applications dueTBD
PapersPaper submissions due November 13, 2013
Rebuttal January 11-14, 2014
Acceptance notification February 3, 2014
Final papers dueTBD
PostersPoster abstracts dueTBD
Poster acceptance notificationTBD
Poster abstracts final (for website)TBD
Short TalksTalk abstracts dueTBD
ACSAC: Sept. 1, 2013 , Annual Computer Security Applications Conference (ACSAC) 2013.
CCS: May 8, 2013: ACM Conference on Computer and Communications Security
TrustCom 2014 : The 13th IEEE International Conference on Trust, Security and Privacy in Computing and Communications (IEEE TrustCom-14)

When  Sep 24, 2014 - Sep 26, 2014
Where  Beijing, China
Submission Deadline May 5, 2014
Notification Due  Jun 26, 2014
Final Version Due Jul 20, 2014

 * ASIACCS 2014 : ACM Symposium on Information, Computer and Communications Security
Conference Series : ACM Symposium on Information, Computer and Communications Security
 
Link: http://asiaccs2014.nict.go.jp
 
When  Jun 4, 2014 - Jun 6, 2014
Where Kyoto, Japan
Submission Deadline Dec 6, 2013
Notification Due  Jan 27, 2014
Final Version Due Feb 28, 2014

===========
* not suitable for twitter spam: 
 * KDD : CM SIGKDD Conference on Knowledge Discovery and Data Mining (KDD) 
KDD 2014 : 20th ACM SIGKDD Conference on Knowledge Discovery and Data Mining

When  Aug 10, 2014 - Aug 13, 2014
Where  New York, USA
Abstract Registration Due Feb 14, 2014
Submission Deadline Feb 21, 2014
Notification Due  May 14, 2014
SIGIR 2014 : The 37th Annual ACM SIGIR Conference
Conference Series : International ACM SIGIR Conference on Research and Development in Information Retrieval
 
 * Link: http://sigir.org/sigir2014/
 
When  Jul 6, 2014 - Jul 11, 2014
Where Gold Coast
Abstract Registration Due Jan 20, 2014
Submission Deadline Jan 27, 2014
Notification Due  Apr 18, 2014
Final Version Due May 11, 2014
Categories    information retrieval
 

#26 Oct
* screen -r 29115.pts-0.aneipero
 * stack at parser.py:417: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
   * terminated
    
* omoiws gia 22115
#25 Oct
* Xanavazoume na trexoun: 
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_09_11_2013.txt --query > ~/logs/tweets_09_11_2013.txt.log
  * [detached from 29115.pts-0.aneipero] 
*  Added blaclist name in the log and in the .spam file
* Parser changed. let's test it!: 
 * screen 
*  Copied parser3.py to parser.py and added log .
 * "merged changes of adding all blacklists: googlesape api & offline to the parser. Also logs the blacklist  that found the spam"
* log sto .spam arxe apo poio checker vre8hke
* So far (without googlesafeBrowsing) : 
 *  5761 tweets_09_11_2013.txt.spam
  *   3177 tweets_10_June_2013.txt.spam
  *    854 tweets_10_May_2013.txt.spam
  *      0 tweets_21_July_2013.txt.spam
  *    798 tweets_22_May_2013.txt.spam
  *    421 tweets_27_April_2013.txt.spam
  *   1462 tweets_28_April_2013.txt.spam
  *   1007 tweets_28_July_2013.txt.spam
  *    672 tweets_2_May_2013.txt.spam
  *  4223 tweets_2_Sept_2013.txt.spam
  *      0 tweets_30_April_2013.txt.spam
  *   3019 tweets_3_June_2013.txt.spam
  *   5836 tweets_3_May_2013.txt.spam
  *   3119 tweets_4_May_2013.txt.spam
  *   5047 tweets_5_May_2013.txt.spam
  *  6682 tweets_6_May_2013.txt.spam
  *   3188 tweets_7_May_2013.txt.spam
  *   2386 tweets_8_May_2013.txt.spam
  *      0 tweets_tweets_28_July_2013.txt.spam
  *  47652 total 
TO OPOIO  GIA einai 97666587 : 0.048790483  % 
* screen : 25013.pts-13.aneipero  
 * I killed it. it is stack in   if url in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:307: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:314: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
* screen : 22330.pts-23.aneipero 
 * finished 
    URL: http://t.co/8ktuI0WlNR is already_checked
URL: http://t.co/DtMyrQMTWI is already_checked
Total tweets stored: 1703171
 
* screen : 21952.pts-14.aneipero  
 * terminated with exception : 
  /home/despoina/svn/twitter-spam/parser.py:314: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:307: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
Traceback (most recent call last):
  File "/home/despoina/svn/twitter-spam/parser.py", line 596, in <module>
    query_filename(args.file, args.limit)
  File "/home/despoina/svn/twitter-spam/parser.py", line 444, in query_filename
    save_spam(tweet, file_to_save)
  File "/home/despoina/svn/twitter-spam/parser.py", line 423, in save_spam
    file_to_save.write(json.dumps(spam_tweet) + '\n')
  File "/usr/lib/python2.7/json/__init__.py", line 231, in dumps
    return _default_encoder.encode(obj)
  File "/usr/lib/python2.7/json/encoder.py", line 201, in encode
    chunks = self.iterencode(o, _one_shot=True)
  File "/usr/lib/python2.7/json/encoder.py", line 264, in iterencode
    return _iterencode(o, 0)
UnicodeDecodeError: 'utf8' codec can't decode byte 0xc3 in position 56: invalid continuation byte


#24 Oct
* terminated and retarted /storage/data_tmp/tweets_28_July_2013.txt  the filename was strong
* the 22513.pts-2.aneipero was terminated and the carachgter in teh terminal had chenaged to the omned contained in the file log_1.md
* eval;a se sxolia olous  tous blaclists checkers kai afhsa mono ton offline na doume posos xrono kanei. xekinhse to arxeio 30_pril_2013 stis 14:20 24/10 
*  oipon
* eval;a se sxolia olous  tous blaclists checkers kai afhsa mono ton offline na doume posos xrono kanei. xekinhse to arxeio 30_pril_2013 stis 14:20 24/10
* Url expansion causing the time delay? http://www.forumtopics.com/busobj/viewtopic.php?t=206957&sid=00a431cbbef694d4b379b7f075fb658e
 * However, using urllib2.urlopen to resolve the destination URL is even slower than using a single expander service. problem solved
 * evgala aviasta sto sumperasma oti to xrono ton twrei to url wxpansion h akomh kai an den ton trwei to url expansion h oflline den einia arketh opote!
rwthsa twra ton polaki
kai mou eipe mia lugih:
GRID
milhsa me ton cp
kai mou zhthse 3 pragmata script
input arxeio
output arxeio
aplws ta input mas as ta xwrisoume (ta megala arxeia se mikrotera) 
#23 Oct
* offline blacklis apo polaki : http://urlblacklist.com/?sec=download
* Added more scripts for parsing : 
 * script /dev/null
 * screen
 *  python /home/despoina/svn/twitter-spam/parser.py --file tw --query
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_21_July_2013.txt  --query > ~/tweets_21_July_2013.txt.txt.log 
  * [detached from 21633.pts-0.aneipero]
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_28_July_2013.txt  --query > ~/tweets_28_July_2013.txt.log 
  * [detached from 25013.pts-13.aneipero] 
 *  sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_2_May_2013.txt  --query > ~/tweets_2_May_2013.txt.log 
  * [detached from 21952.pts-14.aneipero]
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_2_Sept_2013.txt  --query > ~/tweets_2_Sept_2013.txt.log 
  * [detached from 22115.pts-19.aneipero]
 *  
*      4505 tweets_09_11_2013.txt.spam
     3177 tweets_10_June_2013.txt.spam
      854 tweets_10_May_2013.txt.spam
        0 tweets_21_July_2013.txt.spam
      798 tweets_22_May_2013.txt.spam
      421 tweets_27_April_2013.txt.spam
     1462 tweets_28_April_2013.txt.spam
        0 tweets_28_July_2013.txt.spam
        0 tweets_2_May_2013.txt.spam
     1149 tweets_30_April_2013.txt.spam
     3019 tweets_3_June_2013.txt.spam
     4334 tweets_3_May_2013.txt.spam
     3119 tweets_4_May_2013.txt.spam
     5047 tweets_5_May_2013.txt.spam
     6618 tweets_6_May_2013.txt.spam
     3188 tweets_7_May_2013.txt.spam
     2386 tweets_8_May_2013.txt.spam
    40077 total
* finished  screen -r 15359.pts-6.aneipero 
* finished  15521.pts-19.aneipero
* Edw kai 5 meres exei kollhsei me auto to munhma opote to ekana control c
 *  screen -r 15783.pts-19.aneipero 
 * /home/despoina/svn/twitter-spam/parser.py:305: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:311: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:339: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:346: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
* Omoiws me to prohgoumeno, termatisa to screen -r 16109.pts-26.aneipero giati meres twra eixe kollhsei sto :   
  * if url_expanded in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:339: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
* Finished presentation 
* Count of tweets: 
 *   for i in *.txt; do grep -o '"in_reply_to_status_id"' $i | wc -l; done
22038027
1841713
2363155
0
1657317
3138869
1692636
37364884
2182627
7666750
919177
1873841
2333021
1956300
2261161
2093649
2131642
2056790
2095028
---------sum: 


 22 Oct
* 3932 tweets_09_11_2013.txt.spam
     3177 tweets_10_June_2013.txt.spam
      854 tweets_10_May_2013.txt.spam
        0 tweets_21_July_2013.txt.spam
      798 tweets_22_May_2013.txt.spam
      421 tweets_27_April_2013.txt.spam
     1462 tweets_28_April_2013.txt.spam
        0 tweets_28_July_2013.txt.spam
        0 tweets_2_May_2013.txt.spam
     1149 tweets_30_April_2013.txt.spam
     3019 tweets_3_June_2013.txt.spam
     3386 tweets_3_May_2013.txt.spam
     2487 tweets_4_May_2013.txt.spam
     4432 tweets_5_May_2013.txt.spam
     3840 tweets_6_May_2013.txt.spam
     2420 tweets_7_May_2013.txt.spam
     1740 tweets_8_May_2013.txt.spam
 *  33117 total
303687 688
#21 Oct
* 570 eyrw ston Fvth Maragkakh gia to Amaxi - aerio : 5761-024010-979 - iban : 
 Ο IBAN είναι: "GR63 0172 7610 0057 6102 4010 979"
 * teleiwse to screen -r 11301.pts-6.aneipero: 
 * kai to screen -r 7146.pts-5.aneipero : /home/despoina/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_10_June_2013.txt --query
 * wc -l *.spam
    3745 tweets_09_11_2013.txt.spam
    3177 tweets_10_June_2013.txt.spam
     854 tweets_10_May_2013.txt.spam
       0 tweets_21_July_2013.txt.spam
     798 tweets_22_May_2013.txt.spam
     421 tweets_27_April_2013.txt.spam
    1462 tweets_28_April_2013.txt.spam
       0 tweets_28_July_2013.txt.spam
       0 tweets_2_May_2013.txt.spam
    1149 tweets_30_April_2013.txt.spam
    3019 tweets_3_June_2013.txt.spam
    2397 tweets_3_May_2013.txt.spam
    1815 tweets_4_May_2013.txt.spam
    3172 tweets_5_May_2013.txt.spam
    2884 tweets_6_May_2013.txt.spam
    1952 tweets_7_May_2013.txt.spam
    1157 tweets_8_May_2013.txt.spam
   28002 total 
 * mail ston swthrh : 
  * to antiphish-malware-cap-req@google.com

Hello,

I am a Professor at the University of Crete and Principal Researcher with the Institute of Computer Science at the Foundation for Research and Technology, in Crete, Greece. 

Currently one of my phd students (Despoina Antonakaki - antonakd@gmail.com) is building a script that checks for spam urls contained in Tweets though your Safebrowsing API.

According to the developer's guide provided here: 
https://developers.google.com/safe-browsing/developers_guide_v2

"...We will limit the number of users you can support with a single API key.
If you expect to have more than 10,000 users sending regular requests to
the API, you must contact us to have your API key provisioned for
additional users. At the present time there is no cost for this; we want
to make sure that we have contact information for any large users that
may potentially affect the service and its availability. For further
questions about large deployments, contact us by sending email to
antiphish-malware-cap-req@google.com
<mailto:antiphish-malware-cap-req@google.com>."

Is it possible to avoid this limitation of checking <10000 urls per day? 

with kind regards,


#20 Oct
* grep '00000 2013-10'  /home/despoina/tweets_28_April_2013.txt.log
* 100000 2013-10-17 08:43:25
* 200000 2013-10-17 21:58:41
* 300000 2013-10-18 00:43:01
* 400000 2013-10-18 04:06:08
* 500000 2013-10-18 07:49:30
* 600000 2013-10-18 10:54:01
* 700000 2013-10-18 15:53:18
* 800000 2013-10-18 20:27:28
* 900000 2013-10-18 23:56:25
* 1000000 2013-10-19 03:19:34
* 1100000 2013-10-19 07:03:21
* 1200000 2013-10-19 13:33:52
* epishs mhpws exeis link apo tis blacklist pou xrhsimopoioume gai na dw an uarxoun offline na tis katevasoume ?
* to url_expanded omws standard den einai unicode
 * otan pairnei ena url apo ena tweet tote auto to url einai unicde epeidh ta panta pou stelnei to tweeter einai unicode,  spania omws periexontai unicode xarakthres
dld sth python dhlwneis ena string ws unicode bazontas mprosta to 'u' p.x: 
 * a = u'αλέκος' mporeis na kaneis meta sugkriseis meta3u unicode kai mh unicode strings. h python exei enan eswteriko mhxanismo sto na metatrepei unicode se mh unicode
p.x.
print u'alekos' == 'alekos'
auto tha tupwsei True
alla auto:
print u'αλέκος' == 'alekos'8a tupwsei False
 * http://stackoverflow.com/questions/3400171/python-utf-8-comparison
  * : to warning auto pou ebgale mporoume na to agonisoume
  * xwris kanena problhma giati h default sumperifora kanei auto pou 8eloume
  * dld 8ewrei oti to url_expanded einai diaforetiko apo to url opote sth xeiroterh periptwsh na elenxoume duo fores to idio link stis blacklists



* screen -r [detached from 16109.pts-26.aneipero]
 * /home/despoina/svn/twitter-spam/parser.py:305: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:311: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:339: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:346: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:294: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:307: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:314: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
  
  [detached from 15783.pts-19.aneipero]
* [sudo] password for despoina:
/home/despoina/svn/twitter-spam/parser.py:305: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:311: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:339: UnicodeWarning: Unicode unequal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url_expanded is not None and url_expanded != url:
/home/despoina/svn/twitter-spam/parser.py:346: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:294: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:307: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
/home/despoina/svn/twitter-spam/parser.py:314: UnicodeWarning: Unicode equal comparison failed to convert both arguments to Unicode - interpreting them as being unequal
  if url not in checked_urls:
  
    
    
#18 Oct 
* python ~/svn/twitter-spam/parser.py  --file tweets_3_May_2013.txt --query
 * [detached from 15236.pts-2.aneipero]
* sudo python ~/svn/twitter-spam/parser.py  --file tweets_4_May_2013.txt --query 
 * [detached from 15359.pts-6.aneipero]
*  sudo python ~/svn/twitter-spam/parser.py  --file tweets_6_May_2013.txt --query 
 *  [detached from 15623.pts-19.aneipero]
*  sudo python ~/svn/twitter-spam/parser.py  --file tweets_7_May_2013.txt --query 
 * [detached from 15783.pts-19.aneipero]
*  sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_8_May_2013.txt  --query > ~/tweets_8_May_2013.txt.log 

 *[detached from 16109.pts-26.aneipero]


 
   
"Tue Apr 30 02:54:46 +0000 2013", "in_reply_to_status_id_str": null, "place": null, "metadata": {"iso_language_code": "en", "result_type": "recent"}}, {"contributors": null, "truncated": false, "text": "Dix provides a clear, direct answer to viewer's q, gets slammed by Clark for doing so (Clark avoids the q) #bcdebate2013 #bcpoli", "in_reply_to_status_id": null, "id": 329066261545906177, "favorite_count": 0, "source": "<a href=\"http://www.tweetdeck.com\" rel=\"nofollow\">TweetDeck</a>", "retweeted": false, "coordinates": null, "entities": {"symbols": [], "user_mentions": [], "hashtags": [{"indices": [107, 120], "text": "bcdebate2013"}, {"indices": [121, 128], "text": "bcpoli"}], "urls": []}, "in_reply_to_screen_name": null, "in_reply_to_user_id": null, "retweet_count": 0, "id_str": "329066261545906177", "favorited": false, "user": {"follow_request_sent": null, "profile_use_background_image": true, "default_profile_image": false, "id": 157086810, "verified": false, "profile_text_color": "333333", "profile_image_url_https": "https://si0.twimg.com/profile_images/1537802775/WhitecapsFC_normal.jpg", "profile_sidebar_fill_color": "DDEEF6", "entities": {"description": {"urls": []}}, "followers_count": 557, "profile_sidebar_border_color": "C0DEED", "id_str": "157086810", "profile_background_color": "C0DEED", "listed_count": 29, "profile_background_image_url_https": "https://si0.twimg.com/profile_background_images/382774199/IMG_1667-2.jpg", "utc_offset": -28800, "statuses_count": 11600, "description": "#WhitecapsFC, #FCEd, #vanpoli, #bcpoli, #cdnpoli, #urbanism, #craftbeer and more...", "friends_co
-------------------- The error was:
Unterminated string starting at: line 1 column 338026 (char 338026)
Total tweets stored: 672273
SURBL False
False
('sogoodmastering.com', ['sc', 'ws', 'ob', 'ab', 'jp'])
('qrubyclubhot.com', ['jp'])
('googleapps-jobs.com', ['ws', 'ph', 'jp'])
False
False
google None
None
None
googleApi safebrowsing
{'http://www.gumblar.cn/': 'malware'}
{'http://www.google.com/': 'error'}


#17 Oct
*  python ~/svn/twitter-spam/parser.py  --file tweets_30_April_2013.txt  --quer
 * [detached from 11167.pts-6.aneipero]
* root     11408  2.4  0.2  73720 23600 pts/17   S+   17:06   0:01 python /home
 * [detached from 11301.pts-6.aneipero]
 * despoina@aneipero:/storage/data_tmp$ sudo python ~/svn/twitter-spam/parser.py
  * screen -r 9063.pts-2.aneipero
 *Added gogole safeAPi in parser2.py  
- 
* eftiaxa mia sunarthsh gia to json loads:

ston parser2.py

#HERE safejsondump subst

* despoina@aneipero:/storage/data_tmp$ sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_28_April_2013.txt --query > ~/tweets_28_April_2013.txt.log
 * screen -r 9063.pts-2.aneipero
*Added gogole safeAPi in parser2.py 
* Another exception: line 334-339
 * safe json dumping
    * kati pou den kanoume sth 384 opote antikatasthsh
     print json.dumps(tweet_line, indent=4) me to:
      try:
                       print json.dumps(temp_json, indent = 4)
               except UnicodeDecodeError as e:
                       print 'Warning: Could not print temp_json (UnicodeDecodeError) . Error:', str(e)
                       print 'Trying pprint:'
                       print pprint.pprint(temp_json, indent=4)
   * stis grammers 334-339. kanonika prepei na ftia3oume mia sunarthsh pou na legetai: safe_json_dump
   h opoia na einai immune se oles autes tis malakies me ta unicde encodings 
  * sthn parser2.py
  * mail gia ta tweets + spams => Hello, 

I have added more blacklists to check the urls that are contained in the tweets. 
These are the following: 
SpamHausChecker
SurblChecker
SafebrowsinglookupClient
I have run the parser with these blacklist checkers for some of the tweet files. 
I had some problems with some old versions of these tools,(surbl old version was waiting for login on command line, which caused some delay on the script. I changed this to the new version, which works fine.)

Currently I have seen that in a bunch of files of 1.555.693 trends that have been parsed, 2826 total spams where recognised. These results are without the GoogleSafeBrowsing API.

I am still working on the GoogleSafeBrowsing API, which by the way has the restriction of the number of total urls that I can check in one day is < 10.000. 

I hope the GoogleSafeBrowsing API will make this result of 2% ( 282600/1.555.693 = 
0.181655378) better. 

================
8eloume ta exhs: 

1) # unique urls flagged as spamed (anexarthta gia to plh8os mesa sta tweets)  => unique spam urls 
2) # posa tweets eixan toulaxiston 1 spamed 
3) #tweets: for i in *.txt; do                   grep -o '"in_reply_to_status_id"' $i | wc -l; done


epishs leei gia thn google safe api sigoura mporoume na zhthsoume na mas valoun se white list kai namhn exoume ton perirosmo : Esteila mail kai 8a zhthsw apo Swthrh 
* About the limitation of the Google Api could we request at antiphish-malware-cap-req@google.com?



#16 Oct
* Google Safebrowsing API install: to installpou eixe ginei (python install) htan la8os mias kai uphrexe sto pypy opote: 
 * Odhgies: https://github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/tests/test_safebrowsinglookup.py 
 * from safebrowsinglookup import SafebrowsinglookupClient
 * key = 'ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw'
 * client = SafebrowsinglookupClient(key)
 * results = client.lookup('http://www.gumblar.cn/')
 * print results
 * {'http://www.gumblar.cn/': 'malware'}
 * results_2 = client.lookup('http://www.google.com/')
 * print results_2
 * {'http://www.google.com/': 'error'}
* O parser kremouse giati to expand url perimene input(!): 
 * Enter username for User name : wikyou     Password : 0000 at wikyou.org: Enter password for  in User 
  * FIXED : 
   * killed processes
   * anti gia import urllib  import urllib2
   * Kai sth grammh 183:antikatesthse:
   * resp = urllib.urlopen(url)- > resp = urllib2.urlopen(url, timeout=10)
   * kai meta apo kialles dior8wseis ….:
    * Apply sanity check
if not type(tweet_line) is list:
   print 'Warning: The JSON object is not what I expected:'
   print json.dumps(tweet_line, indent=4)
   continue
trend = tweet_line[0]
    
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_09_11_2013.txt  --query
  * [detached from 7011.pts-5.aneipero]
*  sudo python /home/despoina/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_10_June_2013.txt --query
  *  [detached from 7146.pts-5.aneipero]
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_10_May_2013.txt --query
  * [detached from 5095.pts-17.aneipero] TREXEI 
* sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_21_July_2013.txt --query
 * PRIN evgaze : Exception : [sudo] password for despoina: 
  Exmmm kati den phge kala
  No JSON object could be decoded
  Traceback (most recent call last):
    File "/home/despoina/svn/twitter-spam/parser.py", line 572, in <module>
      query_filename(args.file, args.limit)
    File "/home/despoina/svn/twitter-spam/parser.py", line 413, in query_filename
     for tweet in generate_tweets(tweets_filename):
    File "/home/despoina/svn/twitter-spam/parser.py", line 357, in generate_tweets
      trend = tweet_line[0] 
  * TWRA OMWS: [[detached from 7287.pts-5.aneipero]
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_22_May_2013.txt --query
  * [detached from 5348.pts-22.aneipero] TREXEI 
 * sudo python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_27_April_2013.txt --query
  * [detached from 5468.pts-24.aneipero] TREXEI 
 
   
#15 Oct 
* Skype with Boguna: 
 * when: o sunergaths tou 8a einia Kupro ton Aprilio (8a epivevaiwsei pote) opote protimaei Septemvrio wste na mporesoume na sunergastoume
* some initial ideas on 
 * evolution of online social networks
 * network of followers on trending topics 
  * which and how followers are connected according to trends
 * validate model that describes the evolution of social networks. (How connectionction between users are cteated and terminated, how this network of users is changing)
  * the hard part is the data . They don't have expertise on gathering data, so they could take advantage of my expertise on this. It sounds hard on twitter to capture past data on twitter . A simple snapshot is not enough. 
* sapila to script enw exei Value err crasare
* to aneipero; cinammon mallon exei crasarei apo xtes. Top : firefox kill. Still hanging . 
 * top : epomeno mongo db. As ginei kill kai meta: 
  * /home/despoina/tools/mongodb-linux-x86_64-2.4.6/bin/mongod --dbpath /storage/mongodb_data
  * still hanging 
  * killall -9 cinnamon
  * OK!
 * but python parser still running :
  * For 54G Sep 30 19:16 tweets_09_11_2013.txt ok einia 54 G alla gia to :
  * 24hours + for small file also: 4.6G Sep 29 00:31 tweets_10_June_2013.txt ?? wtf?
  * let's try the smallest one: 26M Sep 28 03:11 tweets_29_April_2013.txt
  * ,...fininshed normally OPOTE AS PERIMENOUME TA ALLA DUO 
  * ALso started : despoina@aneipero:~$ cat /storage/data_tmp/tweets_29_April_2013.txt.spam
  * KILLED ALL AND restarted. .spam files renamed with suffix .SPAMFOrcedKilled
  
## parsing restarted

1.   sudo  python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_09_11_2013.txt   --query 
  * screen -r 30117.pts-16.aneipero
2.  sudo  python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_29_April_2013.txt   --query 
 * screen -r 30372.pts-19.aneipero
3. python /home/despoina/svn/twitter-spam/parser.py --file tweets_10_May_2013.txt --query
  * screen -r 30685.pts-22.aneipero
4.  sudo python /home/despoina/svn/twitter-spam/parser.py --file tweets_22_May_2013.txt --query
 * screen -r 30887.pts-24.aneipero 
  
  
  script /dev/null
  screen
  python /home/despoina/svn/twitter-spam/parser.py --file tw --query


#14 Oct 
Brainstrorming ideas: 
Question: 
What is the geographic spread of a trending topic in tweeter? Most trends are affiliated with an event that spans over a specific region. Can we identify and plot this region on google maps? Can we associate these regions with known demographic data? 

Example:
After recent political developments in Greece, the hashtag: #nazis_behind_bars became very popular. Can we plot the density of this hashtag over the areas where it appeared? Does this match voting data?

Implementation:
1. Set as input a specific hashtag. 
2. Collect tweets with this hashtag. Collect geo-data regarding these tweets
3. Plot density of tweets over a map (use google maps API)
4. On the same plot, overlay known demographic data

Why:
Researchers, journalists and individuals may find this tool useful. Basically it augments a hashtag with geo information. 
Extra: Does a hashtag "moves" over time? Plot its velocity! (http://xkcd.com/723/)

-----------------------------------------------------------------------------
Question:
How are the semantics of a hashtag evolve over time? Can we identify and plot the significance of keywords that are associated with a hashtag over time? Some hashtags are associated with specific events from news reports. While the event evolves and new aspects come into light, the trend itself remains the same. Can we get additional insights for a hashtag from the frequency of specific keywords as they appear in urls posted by tweeter users? 

Example:
After recent political developments in Greece, the hashtag: #nazis_behind_bars became very popular. The event was covered by the media extensively and new sides of this story were revealed each day. The plethora of information make it difficult to get a quick, short and coherent overview of the event.

Implementation:
1. Collect tweets for a specific hashtag
2. Keep only these that contain a url
3. Short urls chronologically
4. For each url, visit the targeted page and make a tag cloud
5. With a clever algorithm, fuse together tag clouds and make an animation with a sliding bar. The sliding bar should move from past to future by the user. While the bar moves keywords in the tag cloud should become bigger, smaller, disappear or appear according to their respective frequency over time.

Why:
Researchers, journalists and individuals may find this tool useful. Patterns may emerge that are not obvious from raw urls or tweets. 

----------------------------------------------------------------------
Question:
Can we use tweeter to diagnose (or at least indicate that individuals may suffer from) specific psychological diseases that affect oral and writing behaviour? It is known that diseases like bipolar disorder, schizophrenia, psychosis and depression affect the writing style of an individual. Does this affect tweets as well? If yes, can we build a classification tool for users? 

Example:
Users can be alerted that their tweet patterns resemble these of individuals that have been diagnosed with bipolar disorder, hence they are advised to seek help from a specialised medical doctor. 

Implementation:
1. Locate users that they report that they are diagnosed with the disease X (i.e. X=bipolar disorder). Do that by applying specific queries in tweeter. 
2. Collect all tweets from these users. 
3. Collect tweets from 'control' users
4. Build a classification mechanism based on natural language processing patterns (use NLTK?) 
5. Make a tool where users can get a 'diagnosis' (input: username)

Why:
It known that many people suffer from these diseases and they are not aware of that. Moreover, it can help specialists to get further insights about a disease by studying these patterns. It will assess the question whether twitter can be used a diagnostic tool. 

-----------------------------------------------------------------
#10 Oct
* Brainstorming Laouteris ideas
* 1. Comparison of prices between used and new products.
  *  - Which products have the best after sale price?
  * - Does it worth getting a used one?
  * 
  * 2. Fake book reviews:
   *  http://www.nytimes.com/2012/08/26/business/book-reviewers-for-hire-meet-a-demand-for-online-raves.html?adxnnl=1&adxnnlx=1380301261-FkvNsI3h7TZgXR6wLG2Vqw&_r=2&
    * Expand in general identifying fake reviews in retail sites

    * http://asserttrue.blogspot.nl/

    * Other link about fake reivews: http://arstechnica.com/tech-policy/2013/09/yelp-sues-small-san-diego-law-firm-over-alleged-fake-reviews/
   * Yelp sues small San Diego law firm over alleged fake reviews 
  * http://arstechnica.com/tech-policy/2013/09/astroturfers-shut-down-after-flooding-yelp-and-google-with-fake-reviews/
  * Suggestion: Identify fake reviews, fake users/ ....

#9 Oct 
* lessons KTH
* aisthseis phd

#8 Oct
* TODOs: Vasiko heuristics!: Poses  fores uparxei ena Username se Diaforetika trends ?
 * Afairesh keimenou twitter feature specfic opws rt @ wste na fanei xekathara to keimemo tou spam
* URL whitelists: https://github.com/snd/url-whitelist
  * npm install url-whitelist
  * sudo apt-get install npm : OK
  * npm install url-whitelist
   * ERROR No compatible version found: url-whitelist
    * http://stackoverflow.com/questions/17791664/grunt-install-failure
     * http://nodejs.org/
      * https://github.com/joyent/node/wiki/Installing-Node.js-via-package-manager
       * sudo apt-get install nodejs Reading package lists... Done
       * sudo apt-get update
       * sudo apt-get install python-software-properties python g++ make
       * sudo add-apt-repository ppa:chris-lea/node.js
       * sudo apt-get update
       * sudo apt-get install nodejs 
  * npm install url-whitelist OK !
* ma8hmata KTH distributed
* https://www.dropbox.com/home/ITN/2013%20Sep%20Barcelona/iSocial%20workshop/iSocial%20meeting/Presentation%20Slides
 * • 1 Workshop on “Complex Systems” UB M6 /(1 day) Barcelona
 * • 2 Online course on “Distributed Systems” KTH M7-M12 ---
 * – All fellows should take it!. 
 * • 3 Summer School on “Distributed Technologies for Social Networks” KTH M12/(3 days) Stockholm
 * • 4 Online course on “Internet Infrastructures for OSNs” UCY M12-17 ---
 * • 5 Online course on “Data and Network security” INSUB M13-M18 ---
 * • 6 Online course on “Privacy-aware data management” INSUB M19-M24 ---
 * • 7 Workshop on “Simulation and Modelling of OSN Infrastructures” UCY M24/(1 day) Nicosia
 * • 8 Online course on “Distributed Computing, Peer-to-Peer and GRIDS” KTH M25-M30 ---
 * • 9 Workshop on “Content Distribution for OSNs” FORTH M32/(1 day) Heraklion
 * • 10 Online course on “Complex Networks” UB M31-M36 ---
 * • 11 Summer School on “Security and Privacy in Social Networks” INSUB M36/(3 days) Como
 * • 12 Online course on “Advanced Topics in Distributed Systems” KTH M37-M42 ---
 * • 13 Conference on “iSocial: Decentralized Social Networks” FORTH M46/(2 days) Heraklion

#7 Oct
* Sublime at ubuntu fail!
  * ekana kai ayta alla prama : http://www.technoreply.com/how-to-install-sublime-text-2-on-ubuntu-12-04-unity/
  * http://www.technoreply.com/how-to-install-sublime-text-2-on-ubuntu-12-04-unity
  * Unity luncher:  
  * http://docs.sublimetext.info/en/latest/getting_started/install.html
* Google Safe API installed
 *  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python
  841  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python/README > README
  842  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/__init__.py __init__.py
  843  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/__init__.py > __init__.py
  844  ls
  845  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/safebrowsinglookup.py > safebrowsinglookup.py
  846  curl https://github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/setup.py > setup.py
  847  cat setup.py 
  848  curl https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/master/setup.py > setup.py
  849  curl https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/safebrowsinglookup.py > safebrowsinglookup.py
  850  curl https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/blob/master/__init__.py > __init__.py
  851  cat README 
  852  curl https://raw.github.com/juliensobrier/google-safe-browsing-lookup-python/README > README
  853  sudo     python setup.py install


#6 Oct 

Start point from here: 

* https://pypi.python.org/pypi/Google-Safe-Browsing-v2-Lookup
* You need to get an API key from Google at http://code.google.com/apis/safebrowsing/key_signup.html
 * Generate key: https://developers.google.com/safe-browsing/key_signup?hl=el&csw=1
 * http://sb.google.com/safebrowsing/api_signup?agreeTerms=1
 * Thank you for signing up for a Google Safe Browsing API key!
 * Your key is:
   ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw
    This is an example GET request for the lookup API:
     https://sb-ssl.google.com/safebrowsing/api/lookup?client=api&apikey=ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw&appver=1.0&pver=3.0&url=http%3A%2F%2Fianfette.org%2F
 * The v2 API uses a POST request instead of a GET. Here is an example POST body
  goog-malware-shavar;
  googpub-phish-shavar;
 * to be used with the following URL:
 *   http://safebrowsing.clients.google.com/safebrowsing/downloads?client=api&apikey=ABQIAAAATp6pdJwhucoxYxV9e8mlLBStkgmTDbcJ7HNYWRZyHJE5CHIpNw&appver=1.0&pver=2.2
* You can install the library from PyPI: http://pypi.python.org/pypi/
* 

#5 oct

#4 Οκτωβριου
* συναντηση polakis ¨προτασεις : χρησιμοποιησε σαν Blacklists kai thn http://www.surbl.org/Surbl http://www.surbl.org/ kathws kai uribl, joewein
 * gia python: https://github.com/infixfilip/surblclient:
  * cull a arxeia se upodirectory: ~/svn/twitter-spam/surblclient
  * python setup.py build
  * python setup.py install
  * test: python test_surblclient.py   :  Ran 2 tests in 0.015s - OK  
 * Online whitelists? 
 * Vasiko heuristics!: Poses  fores uparxei ena Username se Diaforetika trends ?
 * Afairesh keimenou twitter feature specfic opws rt @ wste na fanei xekathara to keimemo tou spam
* Apanthse o Boguna. Sunanthsh skype?
* career development plan scanned ston Saruna
* http://www.surbl.org/


Remote Desktop Connection 
Microsoft Document Connection 
Microsoft Messenger 
Microsoft Communicator
Microsoft Outlook

#3 Oct
* set skype with LAouratis for starting crawlingdata 
* paper about spam , see new file: IdentifySpam.md
* root@aneipero:~/DATA# gunzip -c tweets_28_July_2013.txt.gz  -d > /storage/data_tmp/tweets_28_July_2013.txt kana misawro /?
* as to kanoume import sthn vash: 28_July sto aneipero:  
* parsing to 28_July sthn vash 2_July_full!
* Parser.py: 
 * Peiraxame parametrous wste na mporei na trexei me:
  * python parser.py --file /storage/data_tmp/tweets_28_July_2013.txt --limit 10000 --query 
  * me auton ton tropo kanei query kateu8eian sto arxeio kai oxi sth bash.To do a query to a file NOT to a database
  * apla pairnei ta tweets me th seira pou ta diabazei apo to arxeio
  * Checks if url belongs to a white list ( polla opws:  +  white_list = ['youtube.com', 'twitpic.com', 'tumblr.com', 'facebook.com', 'twitter.com', 'twiurl.com'])
  * Check url in tweets in blacklisting sites
  * Gets a url shortened for example http://t.com/asdfasdfasdf
  * Return the real url
  * Check if tweets with common text but with different trends contains spam
  * 

 * Epomeno step:
  * Na ulopoihsoume tis me8odous pou kanei detect ta spams o tupos sto paper
  * me google safebrowsing


#2 October
* career devel plan ok . sent to vivi, sotiris
* aithsh phd einai etoimh, den thn exw steilei. perimenw ton va8mo apo thn stauroula
* mail shn kalia otan exw fwto. 
* Heuristics for identification of spam: 
 *  Take all trends of the tweets in tweets with_common_text. Take the set of this list. By doing this we have only different elements 
 *         #Heuristic #2: Remove characters
 *         #Heuristic #3 : Check text length
 *         #Heuristic #4: Check if it has a URL
* Triangular Pricing: 
  * Synanthsh gia na xekinhsoume siga siga me to triangular pricing. Me data apo crawling se proionta apo aeroporikes...
    * apo papers tou laoutari: 
    * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Crowd-assisted Search for Price Discrimination in E-Commerce: First results,”  arXiv:1307.4531
    * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Detecting price and search discrimination on the Internet,” in Proc. of ACM HotNets'12. [pdf]
    * gia sullogh data xrhsimopoioun to http://pdexperiment.cba.upc.edu/ na kanoume kat antistoixo, na xrhsimopoihsoume to idio tool, na ftiaxoume ena diko mas?
    * kai Using our distributed infrastructure, we collect data from multiple vantage points over a period of 20 days (early July 2012), on a set of 200 online vendors. 
  * DATA crawling: 
    * In "Crowd-assisted Search for Price Discrimination in E-Commerce: " they used $heriff http://pdexperiment.cba.upc.edu/.
    * Can we use some similar tool, should we build a new one?
    * we could use simple web crawlers as
    * http://scrapy.org/,
    * http://www.crummy.com/software/BeautifulSoup/ 

#1 Oct
git puhs parser
svn commit 


* Identification of spam:
 *  Find tweets with common text but different trending hashtags
Count #trends used for each account or found in message in different time periods
Which trending topics are more likely to be exploited? 
Structure of tweet (automated for spam)


* DONE : xanaantegraya OLA ta tweets apo SAPILA--> aneipero: 
  * antonakd@sapila:/storage/twitter-spam/DATA$ scp tweets_*  despoina@139.91.70.42://home/despoina/DATA
* arithmos trends ana idio xrhsth
* aithsh ok apo emena . ekremeh va8mos lukeiou . 
* mail ferrari draft se vivi  sotiri perimenw apanthsh 
* mail sthn Orfanou: https://mail.google.com/mail/u/0/?tab=8m#all/1416f2d505a31981?compose=1416f7c0238b9197
* tsech an ola ta data exoun antigrafei apo thn sapila 
* Efoson teleiwse epituxws 8eloume na tsekaroyme an ola ta tweets mphkan swsta. (python):
 * from pymongo import Connection
 * connection = Connection('localhost', 27017)
 * tweet_database = self.connection.tweet_database
 * tweet_database = connection.tweet_database
 * tweet_collection = tweet_database.tweet_collection
 * print tweet_collection.count()
  ** 27166717
 * 27100000 2013-10-01 10:24:32
 * sudo time python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_28_July_2013.txt
 * allaxa kai to onoma ths vashs se tweet_database_test. KAI eutuxws giati evale dedomena , 8a katesterefe thn allh!!
      * Total tweets stored: 27166717
      * 1911.69user 31.74system 36:23.88elapsed 88%CPU (0avgtext+0avgdata 106768maxresident)k
      * 191734800inputs+0outputs (15major+316264minor)pagefaults 0swaps
* xtes: despoina@aneipero:~$ sudo time python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_28_July_2013.txt 
* ..-rw-r--r-- 1 root root 92G Sep 27 19:21 /storage/data_tmp/tweets_28_July_2013.txt
 *  DONE Total tweets stored: 27166717 2734.57
 *  Done
 *  Flushing memory..
 *  Done
 *  Total tweets stored: 27166717
 *  2734.57user 80.21system 11:46:33elapsed 6%CPU (0avgtext+0avgdata 104576maxresident)k
 *  192001864inputs+176outputs (39major+210385minor)pagefaults 0swaps

#30
* To twitter spam den etrexe apo tote pou ekana zip to current tweet arxeio . Sugkekrimena etrexe alla den exw idea ti ekanse sta dat. Reposrt sto erro log den uphrxe 
 * ta ekana kill -9 kai ta evala na xanatrexoun . To current arxeio einai  tweets_09_30_2013.txt 
* career_development_plan_filled.doc https://docs.google.com/document/d/1QzFQsJBfSGB7DMHt5PXDunEsDiwYmnRPRLCye1su8no/edit
* xana ola ta parsing scripts sthn vash tweet_database. pi8anontha corruption apo delete databases: 
 * delete dbs : use tweets_28_July
 * db.dropDatabase()
 * vi parser:                 self.tweet_collection = self.tweet_database.tweet_collection
 * script /dev/null 
 * screen
 * sudo time python ~/svn/twitter-spam/parser.py --file /storage/data_tmp/tweets_28_July_2013.txt 
 * cntr a 
 * d

#28,29
* https://github.com/kantale/phd/blob/master/data_imported_to_Mongo

#27
##aneipero parsing tweetsL
* pip install pymongo
* install https://help.github.com/articles/generating-ssh-keys
* git clone git@github.com:kantale/phd.git
## mail
* apanthsh ston saruna gia secongmentshttps://mail.google.com/mail/u/0/?hl=el#all/1415eba3f6aa70f1?compose=1415ede837e45a87
* apanthsh zaharia gia paper boguna https://mail.google.com/mail/u/0/?hl=el#all/1415ef5ba2263c31?compose=1415ede837e45a87
* apanthsh se almira gia gossip algorithms https://mail.google.com/mail/u/0/?hl=el#all/1415031d0f4de7ea?compose=1415ede837e45a87
* egkatastash omngo db se aneipero
* mount ton disko se aneipero , + ~400 G
## compile th mongodb se 64bit susthmata.
 *  sudo apt-get install scons
 *  sudo apt-get install libc6-dev-amd64f
 *  sudo apt-get install python-software-properties
 *  sudo apt-get upgrade
 *  sudo add-apt-repository ppa:ubuntu-toolchain-r/test
 *  sudo apt-get install gcc-4.8
 *  sudo apt-get install g++-4.8
 *  sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 50
 *  sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 50
 *  sudo apt-get install lib64stdc++6
 *  sudo apt-get install g++-multilib
 *  sudo apt-get install g++-4.8-multilib

 *  cd /home/antonakd/tools
 *  wget https://github.com/mongodb/mongo/archive/master.zip

 *  wget https://github.com/mongodb/mongo/archive/v2.4.1.zip
 *  unzip v2.4.1.zip

 *  unzip master.zip


 *  cd mongo-master
Following instructions, how to build: https://github.com/mongodb/mongo/blob/master/docs/building.md

 *  scons --64
 *  scons --prefix=/home/antonakd/tools/mongo install --64
###xmm....Η ΣΑΠΙΛΑ ΕΙΝΑΙ 32-bit!!! 
Στη σαπίλα δεν μπορεί να τρέξει mongodb με πάνω από 2GB δεδομένα. Metafora sto aneipero !
* check if aneipero is 64bit
* http://downloads.mongodb.org/linux/mongodb-linux-x86_64-2.4.6.tgz
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_9_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_10_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_11_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_12_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_13_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_14_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_15_May_2013.zip ./
###scp -P6969  antonakd@139.91.70.64:/home/antonakd/DATA/tweets_16_May_2013.zip ./
tweets_11_May_2013.zip        tweets_22_April_2013.zip  tweets_4_May_2013.zip
nohup.out                 trends_20_April_2013.txt  trends_30_April_2013.txt  tweets_12_May_2013.zip        tweets_23_April_2013.zip  tweets_5_May_2013.zip
trends_10_May_2013.txt    trends_21_April_2013.txt  trends_3_May_2013.txt     tweets_13_May_2013.zip        tweets_24_April_2013.zip  tweets_6_May_2013.zip
trends_11_May_2013.txt    trends_22_April_2013.txt  trends_4_May_2013.txt     tweets_14_May_2013.zip        tweets_25_April_2013.zip  tweets_7_May_2013.zip
trends_12_May_2013.txt    trends_23_April_2013.txt  trends_5_May_2013.txt     tweets_15_May_2013.zip        tweets_27_April_2013.zip  tweets_8_May_2013.zip
trends_13_May_2013.txt    trends_24_April_2013.txt  trends_6_May_2013.txt     tweets_18_April_2013.zip      tweets_28_April_2013.zip  tweets_9_May_2013.zip
trends_14_May_2013.txt    trends_25_April_2013.txt  trends_7_May_2013.txt     tweets_19_April_2013.zip      tweets_29_April_2013.zip  UNZIPED
trends_15_May_2013.txt    trends_27_April_2013.txt  trends_8_May_2013.txt     tweets_1_May_2013.zip         tweets_2_May_2013.zip
trends_18_April_2013.txt  trends_28_April_2013.txt  trends_9_May_2013.txt     tweets_20_April_2013.txt.zip  tweets_30_April_2013.zip
trends_19_April_2013.txt  trends_29_April_2013.txt  tweets_10_May_2013.zip    tweets_21_April_2013.zip      tweets_3_May_2013.zip
antonakd@sapila:~/DATA$ cd DATA/Write failed: Broken pipe
##arxeia data apo sapila0--> aneipero.. Gia to /storage eixame problhma opote egkatastash ssh sto aneipero : sudo apt-get openssh-server
###Apo sapila sudo scp tweets_09_11_2013.txt.gz despoina@139.91.70.42:./


#26
##Memory problem insists: reinstall mongodb
* Directory: /home/antonakd/tools
wget http://fastdl.mongodb.org/linux/mongodb-linux-x86_64-2.4.6.tgz
tar zxvf mongodb-linux-x86_64-2.4.6.tgz 
Opote dokimase na trexis th mongod apo edw: 
* sudo mongod -dbpath storage/twitter-spam/mongodb
*   shutdown mongo
  * mongo: db.shutdownServer({timeoutSecs: 60});
* sudo time python /home/antonakd/twitter-spam/twitter-spam/parser.py --file tweets_2_Sept_2013.txt
/home/antonakd/tools/mongodb-linux-x86_64-2.4.6/bin/mongod 
##Memory problem with mongo : 
 * http://pranavl.wordpress.com/2012/09/12/mongodb-error-mmap-failed-with-out-of-memory-64-bit-build/
 * shutdown mongo
  * mongo: db.shutdownServer({timeoutSecs: 60});
 * sudo mongod -dbpath storage/twitter-spam/mongodb

##Change data dir in sapila : 
* change file sudo vi  /etc/mongodb.conf: 
 * dbpath=/storage/twitter-spam/mongodb
* use sudo
* data dir is in storage, we have enough space, use screen & run parser.
* empty the database ! mongo 
* use tweet_database
* db.dropDatabase()
* run both:  
 * script /dev/null
 * screen
 * PRWTA to mikritero: sudo time python /home/antonakd/twitter-spam/twitter-spam/parser.py --file tweets_2_Sept_2013.txt
 * detache: ctrl-a meta patas d
 * ...waiting
 * screen -r 28777.pts-2.planetlab2
 *  sudo time python /home/antonakd/twitter-spam/twitter-spam/parser.py --file tweets_28_July_2013.txt

#25
##problem when logging out of sapila

* We need a way to keep processes runnig : screen  :
* http://www.rackaid.com/resources/linux-screen-tutorial-and-how-to/
* Egkatastash 
* #> sudo yum install screen
* Gia na 3ekinhseis to screen:
* #> script /dev/null
* #> screen 
* 3ekinas na douleueis.
* Otan ena programma trexei gia polu wra h' otan apla 8eleis na fugeis. Patas:
* ctrl-a  d
* Dhladh ctrl-a meta patas d
* An to kaneis auto to session einai *detached* dld paramenei ekei GIA PANTA mexri kapoios na to kanei re-attach
* sth sunexeia mporeis na bgeis me logout (ctrl-d). 
* Prepei na kaneis ctrl-a duo fores. Mia gia na bgeis apo to "script" kai mia gia na bgeis teleios.
* Meta (p.x. thn epomenh mera) otan 3anakaneis login
* Patas:
*  #> script /dev/null
*  *  screen -ls
* Kai sou bgazei kati tetoio:

* There is a screen on:
 *  28777.pts-2.planetlab2  (Detached)
* 1 Socket in /var/run/screen/S-forthple_dcsITN.


* Dld uparxei ena session to opoio einai detach

* mporeis na kaneis re-attach me thn entolh:
*  screen -r 28777.pts-2.planetlab2 

* kai amesws epistrefeis sto session pou hsoun 2 meres prin!

* Gia na katastrepseis teleios to session patas ctrl-d
* Genikotera mporeis na exeis polla session ta opoia exoun thn idiothta oti an den pathseis ctrl-d DEN TERMATIZOUN POTE, apo pleuras susthmatos (nomizw mono me reboot). 


##Almira feedback:
Hi Disponia,

I'm fine and Sweden starts to be cold, but nice up till now.

During your presentation you mentioned that messages are stored in a centralized location and then the procedure starts to check them in parallel in order to identify the spam messages. While, in DOSN as you know there will be no centralized support, so the nodes will cooperate together in order to identify how to distinguish regular messages from the spam ones. And, this how we are going to develop our learning algorithm that will be gossip-based. Algorithm will start with some kind of general rules and then the nodes cooperate by exchanging their local information of how they identify spam messages, then, these information will be used to tune the existing rules to get more restricting ones that can identify more efficiently the spam messages. And , if you remember Fetemeh's idea, we can also stop spreading the spam messages in the social network.  

I hope that I could give you a brief idea of what we can do.

Regards,
Amira

##Twitter Spam Analysis/ parsing 

* Twitter Spam Analysis/ parsing : Pernoume ta arxeia twn tweets/trends kai ta vazoume sthn mongo db 

* Next steps script na trexei sta arxeia pou exoume katebasei
* an baleis "time" mprosta se mia entoly tou linux 8a sou dei3ei posh wra ekane (dokimase na trexeis: time ls)
* to script trexei pros to paron se unzip txt file me tweets, opote pame sto 
 
 * egkatastash mongo db se ena node 

 *  ssh -l forthple_dcsITN  planetlab2.cis.upenn.edu  kai egka8hstoume mongo db ws exhs (http://docs.mongodb.org/manual/tutorial/install-mongodb-on-linux/):
 * curl http://downloads.mongodb.org/linux/mongodb-linux-x86_64-2.4.6.tgz > mongodb.tgz
 * tar -zxvf mongodb.tgz
 * cp -R mongodb-linux-x86_64-2.4.6/ mongodb
 * sudo mkdir -p /data/db
 * FAIL! den uparxoun odhgies egkatastashs!
 * den einai ubintu opote to apt -get den uparxei 
 * pame sthn sapila!
 * already intsalled: 
 * xreiazomaste ena xeziparismeno arxeio : 
  * mkdir UNZIPED 
  * unzip tweets_9_May_2013.zip -d UNZIPED/ 
  * mongod : ERROR: dbpath (/data/db/) does not exist.
  *  sudo mkdir /data/db/
  * mongod:  Is a mongod instance already running?, terminating...an trexei hdh pasooo
  * show dbs
   * local 0.03125GB test  0.0625GB test-database 0.0625GB test_collection (empty)
  * sudo svn updateU    twitterMongo.p A    RunTwitterSpam.shA    checkANDRunTwitterSpam.shU    parser.pyA    crontab.txtUpdated to revision 33
  * time python parser.py --file <FILENAME>
  * sudo time python parser.py --file ../../DATA/UNZIPED/tweets_9_May_2013.txt OUTPUT: 
  * pame sthn sapila giati auto t o arxeio einai mallon polu palio kai sto structure twn tweets exei allaxei, to user den htan user...
  * sudo gzip  tweets_2_Sept_2013.txt.gz -d UNZIPED/
   * Database:
   * Collection(Database(Connection('localhost', 27017),
   * u'tweet_database'), u'tweet_collection')
   * Traceback (most recent call last):
   *   File "parser.py", line 122, in <module>
   *     tmdb.store_file(args.file)
   *   File "parser.py", line 29, in store_file
   *     self.tweet_collection.insert(generate_tweets(tweets_filename))
   *   File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py",
   * line 356, in insert
   *     docs = [self.__database._fix_incoming(doc, self) for doc in docs]
   *   File "parser.py", line 59, in generate_tweets
   *     'user' : tweet['user']['screen_name']
   * KeyError: 'user'
   * Command exited with non-zero status 1
   * 9.02user 0.28system 0:12.76elapsed 72%CPU (0avgtext+0avgdata 139040maxresident)k
   * 366928inputs+0outputs (30major+18137minor)pagefaults 0swaps
   * logs to mege8os tou arxeiou kai posh wra kanei gia na to swsei: 
    * 10.000 tweets --> 2 secs
    * 1.000.000 tweets --> 200 secs
    * 20.000 secs = 333 minutes = 5.30 wre Ara:
    * 100.000.000 tweets = 5.50 wres
   * <DBPATH> DB disk usage: 

##Laoutaris
*Sotiris proteinei na rixw mia matia se auta : 
 * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Crowd-assisted Search for Price Discrimination in E-Commerce: First results,”  arXiv:1307.4531
 * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Detecting price and search discrimination on the Internet,” in Proc. of ACM HotNets'12. [pdf]
* Xtes erixa mia matia se kapoia apo ta paper tou . Tha mpousame na kanoume?
 * data measurement of twitter/facebook. Pricing ? 
 * http://www.freshnetworks.com/blog/2011/08/a-guide-to-measuring-twitter-using-the-api/
* Find tweets with common text but different trending hashtags
* Count #trends used for each account or found in message in different time periods
* Which trending topics are more likely to be exploited? 
* Structure of tweet (automated for spam)
* Find tweets with common text but different trending hashtags
* Count #trends used for each account or found in message in different time periods
* Which trending topics are more likely to be exploited? 
* Structure of tweet (automated for spam)
* Metadata of users:
 * Investigate spam patterns for:
 * Language,
 * Geographic location,
 * Favorites
*Re-tweets, #URLs 


=======
##Twitter Spam Analysis/ parsing 

* Twitter Spam Analysis/ parsing : Pernoume ta arxeia twn tweets/trends kai ta vazoume sthn mongo db 


* Next steps script na trexei sta arxeia pou exoume katebasei
* an baleis "time" mprosta se mia entoly tou linux 8a sou dei3ei posh wra ekane (dokimase na trexeis: time ls)
* to script trexei pros to paron se unzip txt file me tweets, opote pame sto 
 
 * egkatastash mongo db se ena node 

 *  ssh -l forthple_dcsITN  planetlab2.cis.upenn.edu  kai egka8hstoume mongo db ws exhs (http://docs.mongodb.org/manual/tutorial/install-mongodb-on-linux/):
 * curl http://downloads.mongodb.org/linux/mongodb-linux-x86_64-2.4.6.tgz > mongodb.tgz
 * tar -zxvf mongodb.tgz
 * cp -R mongodb-linux-x86_64-2.4.6/ mongodb
 * sudo mkdir -p /data/db
 * FAIL! den uparxoun odhgies egkatastashs!
 * den einai ubintu opote to apt -get den uparxei 
 * pame sthn sapila!
 * already intsalled: 
 * xreiazomaste ena xeziparismeno arxeio : 
  * mkdir UNZIPED 
  * unzip tweets_9_May_2013.zip -d UNZIPED/ 
  * mongod : ERROR: dbpath (/data/db/) does not exist.
  *  sudo mkdir /data/db/
  * mongod:  Is a mongod instance already running?, terminating...an trexei hdh pasooo
  * show dbs
   * local 0.03125GB test  0.0625GB test-database 0.0625GB test_collection (empty)
  * sudo svn updateU    twitterMongo.p A    RunTwitterSpam.shA    checkANDRunTwitterSpam.shU    parser.pyA    crontab.txtUpdated to revision 33
  * time python parser.py --file <FILENAME>
  * sudo time python parser.py --file ../../DATA/UNZIPED/tweets_9_May_2013.txt OUTPUT: 
  * pame sthn sapila giati auto t o arxeio einai mallon polu palio kai sto structure twn tweets exei allaxei, to user den htan user...
  * sudo gzip  tweets_2_Sept_2013.txt.gz -d UNZIPED/
   * Database:
   * Collection(Database(Connection('localhost', 27017),
   * u'tweet_database'), u'tweet_collection')
   * Traceback (most recent call last):
   *   File "parser.py", line 122, in <module>
   *     tmdb.store_file(args.file)
   *   File "parser.py", line 29, in store_file
   *     self.tweet_collection.insert(generate_tweets(tweets_filename))
   *   File "/usr/local/lib/python2.7/site-packages/pymongo/collection.py",
   * line 356, in insert
   *     docs = [self.__database._fix_incoming(doc, self) for doc in docs]
   *   File "parser.py", line 59, in generate_tweets
   *     'user' : tweet['user']['screen_name']
   * KeyError: 'user'
   * Command exited with non-zero status 1
   * 9.02user 0.28system 0:12.76elapsed 72%CPU (0avgtext+0avgdata 139040maxresident)k
   * 366928inputs+0outputs (30major+18137minor)pagefaults 0swaps
   * logs to mege8os tou arxeiou kai posh wra kanei gia na to swsei: 
    * 10.000 tweets --> 2 secs
    * 1.000.000 tweets --> 200 secs
    * 20.000 secs = 333 minutes = 5.30 wre Ara:
    * 100.000.000 tweets = 5.50 wres
   * <DBPATH> DB disk usage: 

##Laoutaris
*Sotiris proteinei na rixw mia matia se auta : 
 * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Crowd-assisted Search for Price Discrimination in E-Commerce: First results,”  arXiv:1307.4531
 * J. Mikians, L. Gyarmati, V. Erramilli, N. Laoutaris, “Detecting price and search discrimination on the Internet,” in Proc. of ACM HotNets'12. [pdf]
* Xtes erixa mia matia se kapoia apo ta paper tou . Tha mpousame na kanoume?
 * data measurement of twitter/facebook. Pricing ? 
 * http://www.freshnetworks.com/blog/2011/08/a-guide-to-measuring-twitter-using-the-api/
* Find tweets with common text but different trending hashtags
* Count #trends used for each account or found in message in different time periods
* Which trending topics are more likely to be exploited? 
* Structure of tweet (automated for spam)
* Find tweets with common text but different trending hashtags
* Count #trends used for each account or found in message in different time periods
* Which trending topics are more likely to be exploited? 
* Structure of tweet (automated for spam)
* Metadata of users:
 * Investigate spam patterns for:
 * Language,
 * Geographic location,
 * Favorites
*Re-tweets, #URLs 
#24
*mongodb @ python ok !
* twitterMongo initial commit: @svn & git
* meta apo lampro fail tou git, edit mono localy kai commit ..: https://help.github.com/articles/generating-ssh-keys
* laoutaris : 
* crowd-sourcing, price discrimination, Measurement
* use of social networks, privacy, search, Economics, Privacy, Search, E-Commerce, Price Discrimination, Search Discrimination


 * Detecting price and search discrimination on the Internet: 

 * Empirically demonstrate the
 * existence of signs of both price and search discrimination on
 * the Internet, and to uncover the information vectors used to
 * facilitate them.

 * They outline the design of a large-scale, distributed watchdog system that allows users to detect discriminatory practices.
* what is a watchdog ? 
---------
 * Price discrimination: 
 * is deﬁned as the ability to price a product on a per customer basis, mostly using personal attributes of the customer. The collected information can
 * be used to estimate the price a customer is willing to pay.
* When David helps Goliath: The Case for 3G OnLoading: Narseo Vallina-Rodriguez†, Vijay Erramilli‡, Yan Grunenberger‡, Laszlo Gyarmati‡, Nikolaos Laoutaris‡, Rade Stanojevic‡, Konstantina Papagiannaki‡
 * ee einai gia Cellular, Wired, Networks, 4G, 3G, Onloading, DSL...ligo makria apo emas ...
* Privacy Risks in Named Data Networking: What is the Cost of Performance?  
 *  raise awareness of privacy attacks as an intrinsic and relevant issue in Named Data Networking architectures. 
 * Countermeasures against privacy attacks are subject to a trade-off between performance and privacy.


#23

* career development plan https://docs.google.com/document/d/1QzFQsJBfSGB7DMHt5PXDunEsDiwYmnRPRLCye1su8no/edit
* mail vivi+sotiru gia secondments: https://mail.google.com/mail/u/0/?hl=el#all/1414a36807cfc893
* ubuntu mongo db: 
 *  uname -a : 2.6.32-41-generic #89-Ubuntu
 *  http://docs.mongodb.org/manual/tutorial/install-mongodb-on-ubuntu/:
   *  sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 7F0CEB10
   *  echo 'deb http://downloads-distro.mongodb.org/repo/ubuntu-upstart dist 10gen' | sudo tee /etc/apt/sources.list.d/mongodb.list
   *  sudo apt-get update
   *  sudo apt-get install mongodb-10gen
   *  apt-get install mongodb-10gen=2.2.3
 * start by:  sudo service mongodb start
 * stop : sudo service mongodb stop
 * restart: sudo service mongodb restart
 * use : mongo, db.test.save( { a: 1 } ) , db.test.find()
 
  
 *  
* Ubuntu sto aneipero: 
 * ubuntu auth: auth is not defined
 * $ sudo apt-get install python-pip python-dev build-essential 
 * $ sudo pip install --upgrade pip 
 * $ sudo pip install --upgrade virtualen ubuntu auth: auth is not defined
 * lsb_release -a ubuntu 12.04.3
  * sudo apt-get install subversion libapache2-svn
  * svn checkout ok 
  * paper draft !


#18 september 2013

* Uparxei ena polu sovaro endexomeo gia summer school ta xristougenna sthn stokxolmh .
des to 316808 - iSocial Annex 1 Final_annotated.: selida 36
* mongodb testing :
 * how to print all data in a document: 
  * db.foo.find().toArray()
   db.foo.find().forEach(printjson)
 * How to save your functions in a file : > load('/opt/homebrew/Cellar/mongodb/2.4.6/.mongorc.js')
 * crud : create remove update delete : http://docs.mongodb.org/manual/crud/

* ECCS 13 day 1:
* 08:45-18:00 Complexity in Online Social Networks and Big Data
http://linc.ucy.ac.cy/isocial/index.php/events/72-workshopeccs13

=======================================================================================
Online & offline interaction networks   - ( sarunas  eisagwgh kai sthn sunexeia alain barrat)

=======================================================================================
outline:
case study: network analysis, measure homophily
selection & influence mechanism 
mine face to face interactions


issue of data mining mcpherson annu rev sociol2001 (longitudinal data, multiplexicity)

real world interactions
   MIT reality mining(
   sociopatterns.org

case study aNobii (sn for books!)

network properties (#tags, #books…properties)heterogeneity of users) 
correlations:
   between user's activities
   mixing patterns (between neighbour users,  the more I am active, the more my friends are active) 

homophily : 

geography 
topical alignment of users profile (tags, common books…) 
random pair of   users --> no global alignment 
average #of common books of two users  pretty large 
average normalised similarity measure between two users 

build model conserve the structure of social graph  but  remove assortativity related alignment /

result : real data vs null model  : homophily decreases in model 
stronger effect along communication network

homophily : selection or influence? 
measure the dynamics with snapshots of 15 days --> many new links between users more similar than random --> most new link between users that more similar --> compare new links between already preen users
….
 ==> there is a CLEAR selection mechanism !  (you van see this in the evolution graph of similarity before & after already present users) 
but also INFLUENCE 
opws oi perissoteres ereunes  apodiknioume to profanes !!

exw koitaxei ena paromoio paper panw se sdhmofilh sn me paromoia apotelesmata ..(?)

prediction of new links
not so much activity like big sns..

minig sns: 
bluetooth
mit reality monitoring mining project
mosar (hospitals) 

http://vimeo.com/6590604

online vs offline : between online linked attendes :  ..stronger behavioural & spatial trajectory similarity 


http://www.plosone.org/article/info:doi/10.1371/journal.pone.0011596
http://arxiv.org/abs/1003.2281
=======================================================================================
Maxi San Miguel

voter model, opinion diffusion, mobility network..
IFISC
* data : evolution of democrat share in US  presidential elections 1980-2012
* voter model: ann Prob 1975
* voter model as a diffusion model 


========================
Laoutaris

car pooling
amovens
in california there are already legal issues
use twitter api to retrieve location data 

h efarmogh pws sullegei mesw twitter ta dedomena/? einai ligo arbtrary ..to location katagrafete mono se kapoio tweet tu xrhsth ? density sta dedomena?

how about the sensitivity of data (google maps) 
 
standar heuristics to solve the distance optimisation problem (np compete) 
to overcome the "stranger danger" problem : analyse social relationships, use friends & fof


================the ecosystem of context -=================

 




* mongo db


#17 sept
* her-ath-barca: 
* mikrh suzhthsh me sotiri gia to paper : katagrafw background work, backgroundwork close to us ,poios einai o skopos mas,
ti kanoume gia na ton petuxoume, se ti diaferoume api tous allous, kai telows apotelesmata kai pws ta epituxame. 
Xekinhsa ena draft : documtns/isocial/paper_draft1/draft1
* eida ligo: THE RISKS of friendships in  social networks:  documtns/isocial/THE RISKS of friendships in  social networks 


#12 Sept

* Egkatastash brew sto air: 
 * sudo mkdir -p /opt/homebrew
 * sudo -s
 * cd /opt
 * curl -L http://github.com/mxcl/homebrew/tarball/master | tar xz --strip 1 -C homebrew
 * sudo -s
 * echo "/opt/homebrew/bin" > /etc/paths.d/homebrew
 * echo "/opt/homebrew/share/man" > /etc/manpaths.d/homebrew
 * brew install wget
 * brew update
 * brew install subversion - xreiazetai C++ prwta : 
checking how to run the C preprocessor... cpp
configure: error: in `/private/tmp/serf-Bm8g/serf-1.2.1':
configure: error: C preprocessor "cpp" fails sanity check OPOTE : 
 * brew install https://raw.github.com/Homebrew/homebrew-dupes/master/apple-gcc42.rb OK
 * brew install subversion -- pali fail sthn C++ 
 * xreazetai prwta C:  checking how to run the C preprocessor... cpp
 * brew tap homebrew/versions
 * dokimasa : apo edw http://stackoverflow.com/questions/15041937/configure-error-c-preprocessor-fails-sanity-check
 * export CPP=/opt/intel/composer_xe_2013.2.146/bin/intel64/icpc
 * export CXX=/opt/intel/composer_xe_2013.2.146/bin/intel64/icpc
 * Despoinas-MacBook-Air:twitter-spam antonakd$ 
 * Despoinas-MacBook-Air:twitter-spam antonakd$ ./configure CXX=/opt/intel/composer_xe_2013.2.146/bin/intel64/icpc
 * prama
 * https://github.com/mxcl/homebrew/issues/13586 :
 * Symlink : i ended up symlinking /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain to 
 /Applications/Xcode.app/Contents/Developer/Toolchains/OSX10.8.xctoolchain
 * Despoinas-MacBook-Air:twitter-spam antonakd$ sudo ln -s /Applications/Xcode.app/Contents/Developer/Toolchains/XcodeDefault.xctoolchain/ /Applications/Xcode.app/Contents/Developer/Toolchains/OSX10.8.xctoolchain
 * oute auto douleye ..egkatastash command line xcode: https://developer.apple.com/library/ios/documentation/DeveloperTools/Conceptual/WhatsNewXcode/Articles/xcode_4_3.html
 * brew install subversion OK 
Finally : /opt/homebrew/bin/svn checkout    https://dcs-svn.ics.forth.gr/svn/twitter-spam/ --username antonakd@gmail.com 
 * install mongo db : http://docs.mongodb.org/manual/tutorial/install-mongodb-on-os-x/
   *  brew install mongodb OK !
   *  mongod & 
   *  mongo 
   * > db.test.save( { a: 1 } )
   * > db.test.find()
   * http://docs.mongodb.org/manual/tutorial/getting-started/
   * http://docs.mongodb.org/manual/tutorial/generate-test-data/
  # tupwsame to poster
  

#10

#09 Sept
cron job . In order to be done we need bash scripts. All seem to be fine except that the script camnnot be started : 
Fixed checkANDRunTwitterSpam.sh & RunTwitterSpam.sh

Taxidia apo ite: 

metakinhseis & lunches plhrwnontai me thn hmerisia apozhmiwsh (70 euuw) an to sunedrio exei lunch tote aplws dinei 35 thn hmera

 
#6Sept
Parousiash apo Laerth : http://www.cs.vu.nl/~giuffrida/papers/usenixsec-2012.pdf
Allagh distasewn pster 
o alekos 8a upograyei to uhttp://www.uwv.nl/xv gramma  opou eleipe h hmerominhia gennhshs mikrhs


#5Σεπτ

* Ξενοδοχειο οκ κρατηση στο 
* https://secure.booking.com/confirmation.el.html?aid=357006;label=gog235jc-index-el-XX-XX-unspec-gr-com;sid=c281ee527bd5081b0c2431d4fc62a995;dcid=2;bn=188220614;hostname=www.booking.com;source=book;token=3d9d3e566757b6812b2e74ed60aedc6856a373e4ed803e189ac5ff898b4f5cf7
* Chic & Basic Ramblas 17῏21. Εβαλα στην σημειωση να εκδοθει 
 *  Hello, I have a special request about the receipt. I should be on the name: Despoina Antonakaki, with Address: Foundation for Research and Technology - Hellas (FORTH) Institute of Computer Science N. Plastira 100 Vassilika Vouton, GR-700 13 Heraklion, Crete, Greece EL 090101655
* Εισητηρια οκ απο κατρεα επικοινωνησα η ιδια . περιμενω επιβεβαιωση οτ ολα οκ epivevaiw8hke!
*   https://www.checkmytrip.com/cmt/apf/cmtng/pnr_retrieve?SITE=NCMTNCMT&LANGUAGE=US&R=595YKU&N=ANTONAKAKI
* declaration of conformity : 
   *  Declaration of Conformity (to be sent within 20 days from the signature of the agreement)
   *  Duly signed by researcher & host organisation
   *  Submitted via PP after the appointment of each researcher
   *  http://ec.europa.eu/research/participants/portal/page/home
   *  θα σταλέι απο την γραμματεία οχι απο εμενα.
   
* Να τσεκαρουμε τι αλλο εκκρεμέι γραφειοκρατικανα συμπληρ´ψσουμε οπως το career development plan
  *  https://mail.google.com/mail/u/0/?hl=el#search/career+development/140bf711fb0997cb?compose=140df13e4635df72
  *  Esteile o panagiwths thn forma . alla mexri pote rwtame thn vivi. einai so directory Documents/isocial/reports/
* Συνεχεια με την παρουσίαση
* Synexeia me to poster 
* ekana asfaleia sthn eenh ston foinika : 
*   dess sto Documnts/Asfaleia foinika..gia aithseis ktl
*   Gia apozimiwsh apo ton foinika
*   thn prwth fora poy 8a pas krata mazi thn selida poy sou edwse h stefania (h typwse thn FormaFoinika apo to dir ocumnts/Asfaleia foinika ) 
*   apo ton katalogo, opws kai mia fwtotupia ths prwths selida tuo biliariou trapezas gia na mpainoun 
*   oi apozhmiowseis hlektronika
*   Gia thn apozimiwsh 8a xreiazomai : 
*   1) gnwmateush
*   2) apodeixh apo giatro (paroxhs uphresiwn) 
*   3) Aithsh apozhmiwshs (ocumnts/Asfaleia foinika) 



#4Σεπτ

δουλεια απο το σπιτι λογω επιπλα σατο. Κυριως την παρουσιαση. Ξαναεβαλα την σαπιλα να τρεχει και εκανα καταμετρηση 

Twitter in numbers
antonakd@sapila:/storage/twitter-spam/DATA$ for i in *.txt.gz; do gunzip -c $i | grep -o '"in_reply_to_status_id"' | wc -l; done

1841713
1290092
4024880
6423915
2200265
1379648
1603280
1746089
1816545
2145386
2129782
37364884
2146038
2333166
19438621
988518
1923877
2344059
1873841
2444161
1611790
1548103
2251302
1870194
2371176
107111325

107111325

antonakd@sapila:/storage/twitter-spam/DATA_FROM_OTHER_NODES$ for i in *.txt.gz; do gunzip -c $i | grep -o '"in_reply_to_status_id"' | wc -l; done

372590
1457259
152764
1674912

[forthple_dcsITN@planetlab2 DATA]$ for i in *.txt.gz; do gunzip -c $i | grep -o '"in_reply_to_status_id"' | wc -l; done
1802153
1638362
594012


#3Sept

hp laserjet 4250 70.97
sunanthsh polakis sotoris despoina
TODO  : 
to scriptaki prepei na einia robust opote tha 8eloume ena cron job na tsekarei pote τρεχει και να ξεκιναει

καταμέτρηση των tweets εως τώρα 

Να δημιουργηθει ενα γραφημα που δειχνει τον αριθμό των trends ανα user , μεγαλο αριθμό trends…spammer?

επισημο logo isocial για παρουσίαση 

αλλαγές στα pies της παρουσίασης, οπου δεν υπαρχει πολύ πληροφορία

προσθήκη στην παρουσίαση των features του twitter που εκμεταλευονται οι spammers

εχει νοημά να στειθέι στο Pc μου το script , προς το παρον η σαπιλα τρεχει μια χαρά 

επίσης μιας και αναφέραμε για τα mac, θα μπορούσα να αν υπαρχει καποιο mac anti pc ?

Προσθηκη διαφάνειας με  next steps: 

Για  Identification : ας χρησιμοποιησουμε αρχικά απλές τεχνικές οπως καταμέτρηση των trends ana xrhsth
Ισως μια απλή παρατήρηση στα tweets μας δώσει heuristics για τους spammers 
Για verification : 
χρηση blacklists
availability accounts , flagged  accounts as spammers 
χρήση ετοιμών εργαλείων που εντοπιζουν features που χρησιμοποιούν spammers βλεπε Gianluca Stringhini
http://dl.acm.org/citation.cfm?id=1920263  

later use of semantics for verification of spammers 

http://www.slideshare.net/gianlucastringhini/detecting-spammers-on-social-networks

# 1Sept
* Meltini taxidi
* sumvash apo Giannh done 
* epihshs gia thn afsaleia egw eimai hdh asfalismenh sto ika + foinika. Gia to mikro prepei na kanw aithsh sthn stefania santse 
 (g292 2os orofos prwt porta dexia) 8a isxisei se ena mhna . mou esteile mail  me oles tis plhrofories + aithsh 
* suzhthsh me Vivi 
* Meltini: valame arxika to taxidi gia 17-21 kai to allazoume ama einia gia ligoteres meres. H aithsh prepei na ginei arxika 
kai allages mporoun na ginoun sthn sunexeia. 

# 8July  - 1 Sept 
* presentation for barca workshop 
* Literature review draft (not fininshed)

# 7July 
* Slides fopr presententaion barca workshop. Literature revoew: tsekare an to keimeno pou aexoume anaferestai sta 5 
* paper sta opoia katalhxame me thn Vivi. An oxi sumperilave kati gia ka8eana apo auta . 

#3 July 

* How to install twitter spam in a node 
 *  1. get svn latest version 
 * Create data, run directories
 *  Fix the sh file: dates ..carefull not to overight previous data files!!!
 *  Do you have twitter app ?? 
 *  If so create the .twitter file in home directory of  teh user that will be runnign the script ..and give PERMISSION only to that user
 *  If runnig with sudo : root !
 *  run for first time withou NOHUP to obtain the access token file 

#2July
* Bug fixed current time- previous time 
* git install in a node ...

#1July 
mail by vivi about conference in Barca: presentation: some slides about twotter spam + literature revirwq+ take a look at ASONAM papers
#15 June 
  * implement simple http server to serve trends
   * an http server give the trends so now we can use one node as server and each other can connect to that one to retrieve 
   * trends. 
   
# 14 June 2013 
  * Working on the litarature review:
    * Finished Ferrari's "user similarities on social network" (including a presetnation in google docs)
    * Added a summary (page) to the lierature review
  * Twitter's API changes v1.0 -> v.1.1 : 
    * Hello,
    * The script failed today because twitter discontinued the 1.0 version of its api.
    * The old version (1.0) allowed harvesting of daily and weekly trends without  aoauth2uthentication.
    * The new version (1.1) requires authentication even for getting the trends.
    * Moreover, the new version fetches 10 trends / 5 mins. It also has an extra parameter that allows you to retrieve geographically specific trends. This is the WOEID id: http://en.wikipedia.org/wiki/WOEID
    * So the technique to fetch trending tweets from now on will be the following:
    * 1. Fetch 10 trends.
    * 2. Mark the current timestamp (a)
    * 3. Fetch tweets for these 10 trends
    * 4. Count the current timestamp (b) 
    * 5. Estimate the time difference c = b - a 
    * 6. If c is less than 5 minutes wait: 5 mins - c
    * 7. Goto 1
   * script fixed and up and running again . 
   

#19May
* Keywords for search: 
 * data placement, replication 
 * distribution exploiting the trust relations of social networks
 * trust relations of social networks
* Sunergates: 
 * Elena Ferrari University of Insubria
 * Seif Haridi/KTH , Sarunas Girdzijauskas /KTH.
 * Marián Boguñá (UB)University of Barcelon
* conference names:
 * ASE IEEE social computing
 * IEEE Symposium on Security and Privacy
 * IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining ASONAM
 * USENIX Security Symposium
 * Network and Distributed System Security Symposium (NDSS)
 * Annual Computer Security Applications Conference ACSAC
 * RAID International Symposium on Research in Attacks, Intrusions and Defenses
 * Annual Computer Security Applications Conference (ACSAC)


#18May 

Literature review: 
Despoina vash toy programmatos sthn eishghsh ths symvashs soy anaferontai:

"Περιγραφή εργασίας: to perform data placement, replication and
distribution exploiting the trust relations of social networks. ESR5 will
use tools developed by the complex networks community to dynamically
reveal the communities of trust developed around individual peers along
with their temporal and behavioural patterns. An XML model with RDF
annotations will be investigated to efficiently store data. Finally, ESR5
will investigate efficient media streaming techniques to support social
services and applications, especially in collaboration with the industrial
partners."

Yparxei fysika megalh eleytheria sta ereynhtika projects se social networks
poy mporeis na epektatheis, alla tha hthela na diereynhseis ligo thn
perioxh toy community finding kai pws aytes oi texnikes mporoyn na
xrhsimopoihthoyn gia thn anaptyxh ergalivn se social networks, (opws
trust mechanisms, reputation management, recommendation systems). Fysika
kathemia apo aytes tis lexeis kleidia apotelei apo dikoy ths mia
perioxh. Tha hthela opws ean o xronos soy to epitrepei na kaneis ena
mikro literature review gia to pws oi texnikes toy community finding
mporoyn na xrhsimopoihthoyn sta social networks. Genika exv thn perithish
oti aytes oi texnikes mporoyn na apotelesoyn ena "powerful tool".
Epishs oi etairoi mas sto ergo energopoioyntai sthn perioxh ayth kai
kata synepeia tha mporoyse na apotelesei aparxh synergasias.

Xairetismoys
Vivi
#15May 2013
Ta exhs vhmata exoun dinei sta: 
* planetlab1.di.fct.unl.pt  PLE boot  
* planetlab2.cis.upenn.edu  PLC boot
  * gcc:  sudo yum install gcc
  * sudo yum install python
  * sudo yum groupinstall "Development tools"
  * sudo yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel
  * wget http://python.org/ftp/python/2.7.3/Python-2.7.3.tar.bz2
  * tar xvf Python-2.7.3.tar.bz2
  * tar jxf filename.tar.bz2
  * cd Python-2.7.3
  * ./configure --prefix=/usr/local
  * sudo make && sudo make altinstall
  * wget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea
  * *******************************************************************
  ***sudo ln -s /usr/local/bin/python2.7 /usr/bin/python2.7*******
  ******************************************************************
  * sudo sh setuptools-0.6c11-py2.7.egg --prefix=/usr/local/
  * sudo /usr/local/bin/python2.7/python get-pip.py
  * sudo pip install oauth2



#14 May 2013

* try to install gcc on  ssh -l forthple_dcsITN -i .ssh/id_rsa planet-plc-1.mpi-sws.org 
* according to http://www.rpm.org/max-rpm/ch-rpm-install.html 
* Use rpm -i (or --install) options file1.rpm … fileN.rpm so we need an rpm file: 
* Download from http://www.rpmfind.net/linux/rpm2html/search.php?query=gcc
* $ wget ftp://195.220.108.108/linux/fedora/linux/development/rawhide/x86_64/os/Packages/g/gcc-4.8.0-5.fc20.x86_64.rpm
* Tried rpm install the downloadded package --failed . too many dependecnies missing : 
*  error: Failed dependencies:
   binutils >= 2.20.51.0.2-12 is needed by gcc-4.8.0-5.fc20.x86_64
  cpp = 4.8.0-5.fc20 is needed by gcc-4.8.0-5.fc20.x86_64
  glibc-devel >= 2.2.90-12 is needed by gcc-4.8.0-5.fc20.x86_64
  ld-linux-x86-64.so.2()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  ld-linux-x86-64.so.2(GLIBC_2.3)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.11)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.14)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.2.5)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.3)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.3.2)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.3.4)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.4)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libc.so.6(GLIBC_2.7)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libdl.so.2()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libdl.so.2(GLIBC_2.2.5)(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libgcc >= 4.8.0-5.fc20 is needed by gcc-4.8.0-5.fc20.x86_64
  libgcc_s.so.1()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libgmp.so.10()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libgomp = 4.8.0-5.fc20 is needed by gcc-4.8.0-5.fc20.x86_64
  libgomp.so.1()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libm.so.6()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libmpc.so.3()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libmpfr.so.4()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  libz.so.1()(64bit) is needed by gcc-4.8.0-5.fc20.x86_64
  rpmlib(FileDigests) <= 4.6.0-1 is needed by gcc-4.8.0-5.fc20.x86_64
  rpmlib(PayloadIsXz) <= 5.2-1 is needed by gcc-4.8.0-5.fc20.x86_64
* According to this http://quaid.fedorapeople.org/TOS/Practical_Open_Source_Software_Exploration/html/sn-Building_the_Code-Installing_Prerequisites.html
* yum may help : 
* tried sudo yum install gcc
* seems ok ...Complete!
* now update python:
* sudo yum install python
Setting up Install Process
Parsing package install arguments
Package python-2.5.1-26.fc8.2.i386 already installed and latest version
Nothing to do
* Update yum? sudo yum update
Setting up Update Process
No Packages marked for Update
* udo yum install python27
Setting up Install Process
Parsing package install arguments
No package python27 available.
Nothing to do
* let's go from source!!
* cd Python-2.7.4
* http://toomuchdata.com/2012/06/25/how-to-install-python-2-7-3-on-centos-6-2/: 
* yum groupinstall "Development tools" sucess!
* # yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel
* DOWNLOAD AND INSTALL PYTHON 2.7.3:  
*  ./configure --prefix=/usr/local  sucess!
*  make && make altinstall
*  sudo -u root make && sudo  make altinstall
*  /usr/local/bin/python2.7/python OK !
*  Epishs sudo yum install subversion
Setting up Install Process
Parsing package install arguments
Package subversion-1.4.4-7.i386 already installed and latest version
Nothing to do
* sudo yum install svn1.7.9
Setting up Install Process
Parsing package install arguments
No package svn1.7.9 available.
Nothing to do
* svn --version
svn, version 1.4.4 (r25188)
   compiled Sep  2 2007, 14:30:15
* emeis 8eloume 1.7.9
* wget http://apache.mirror.1000mbps.com/subversion/subversion-1.7.9.tar.bz2
* bunzip2 subversion-1.7.9.tar.bz2 
* tar xvf subversion-1.7.9.tar
* sudo ./configure
* configure: error: no suitable apr found
* Install oath2: 
*   wget http://dl.fedoraproject.org/pub/epel/6/SRPMS/python-oauth2-1.5.170-1.el6.src.rpm






#13 May 2013
we have 5 nodes at : 
planetlab-01.naist.jp   PLC boot    n/a 
planetlab01.erin.utoronto.ca  PLC boot    n/a 
planetlab-1a.ics.uci.edu  PLC boot    n/a 
planetlab1.georgetown.edu PLC boot    n/a 
planet-plc-1.mpi-sws.org

Login @ ontws paizei to ssh -l forthple_dcsITN -i .ssh/id_rsa planet-plc-1.mpi-sws.org
intall python : 

ti Linux exoume ?
* http://www.computerhope.com/issues/ch001106.htm
* uname -arv 
* FEDORA : use rpm to install python, which need gcc
* how to install gcc?
* 

#20 April 2013

*  Also yesterday I made a change to the script to get only "today's tweets" so we don;t have redundant. (it just checks the date and if it's  older that one day it does not download ) I took a closer look at the twitter api and I am considering maybe it would be e nice idea to exclude re-tweets or replies?
   I took a look at these two papers: 

*  @spam: The Underground on 140 Characters or Less
*  CATS: Characterizing Automation of Twitter Spammers 
(on collecting dataset) and maybe it's also a nice idea to start collecting tweets that contain urls ? (although this can be done by filtering  the ones we are already downloading)\
...email thread...to be continued...

##19 Απριλιου 2013

 
Γεια σας, 

Το twitter-spam script τρεχει στον μηχάνημα(sapila) που μου έδωσε πρόσβαση ο Ιάσονας. 

Έκανα μια πρώτη απόπειρα να το ξεκινήσω χτες το πρωί αλλά είχα ένα failure λόγω της ώρας του μηχανληματος και oauth signature  (http://www.blainegarrett.com/2009/07/14/failed-to-validate-oauth-signature-and-token-on-twitter-oauth-check-your-cloc/) οπότε άλλαξα την ώρα στο μηχάνημα (εύχομαι να μην δημιουργεί προβλήματα!) 

Τελικά μετά από διάφορα error handling προσθήκες, έτρεχε από χτες το βραδύ 2013-04-18 20:55:51
 μέχρι και τις 09:47 σήμερα. Τα tweets συλλέγονται στο DATA/tweets_18_April_2013.txt και είναι 2.4G για μία μέρα.  (Θα κοιτάξω να αποθηκεύω σε zip για εξοικονόμηση χώρου. )


Επίσης έριξα μια πρώτη ματιά για δημοσιεύσεις γύρω απο twitter spam: 

* CATS: Characterizing automation of Twitter spammers  @ COMSNETS  7-10 Jan. 2013 το οποίο ασχολειται με features for distinguishing spam accounts κανωντας χρήση supervised learning. Αναφέρει καποιες τεχνικές για συλλογή των datasets αλλα δεν ειμαι σίγουρη αν εφαρμόζονται στην περίπτωσή μας. Μια πρώτη ιδέα ειναι η συλλογή διαφορετικών datasets σε διαφορετικές χρονικές περιόδους. Επίσης το πιο ενδιαφέρον σε αυτή την δουλέια ειναι τα features  που χρησιμοποιούνται για detection of spamming activity. 
* WarningBird: Detecting Suspicious URLs in Twitter Stream , Associated event: NDSS Symposium 2012, 
* Twitter Games: How Successful Spammers Pick Targets Annual Computer Security Applications Conference (ACSAC) 2012
* Searching for Spam: Detecting Fraudulent Accounts via Web Search @ Proceedings of the 14th International Conference on Passive and Active Measurement, Hong Kong, China, March 2013.
* Suspended Accounts in Retrospect: An Analysis of Twitter Spam @  Proceeding  IMC '11 Proceedings of the 2011 ACM SIGCOMM conference on Internet measurement conference
* DON’T FOLLOW ME Spam Detection in Twitter λιγο παλίο Security and Cryptography (SECRYPT), Proceedings of the 2010 International Conference on Date of Conference: 26-28 July 2010

* Όσον  αφορά τα θέματα που θίγει  ο Ηλίας παρακάτω: 
 * 1) Is it legal to capture *all* tweets/day?
 * 2) Has anyone done this? Record *all* tweets/day by using a set of distributed and co-operating clients?
ρώτησα ένα  colleague  που είχε αναφέρει ότι έκανε crawling το twitter οπότε μόλις μου απαντήσει θα ενημερώσω. 


 *  > Finally, for our project we don't need all tweets, but a carefully selected sample of them.
Όσον αφορά το selection των tweets θα μπορώ να προσθέσω περισσότερα αφού ρίξω μια ματιά σε σχετικές δημοσιεύσεις/ βιβλιογραφία  





##18 April
* telco : Vivi, Sotiris
* Hummingbird : https://docs.google.com/presentation/d/1QYz5ey4YPAbuxGRMa--ExUcK4a6tPUDwf_DlRh6_HVE/edit
* kaname skip to kommati tou matematical formalismou, kai zushthsame gia RSA ,deffie hellman . Diafores. 
* Kalo 8a einai na ta koitaxw ligo parapanw auta na ta xeka8arisw sto mualo mou . 
* Epishs gia thn epomenh for na rixw mia matia se dhmosieueis gurw apo twitter spam wste na lusoume to 8ema me to filtrarisma twn tweets gia to script 


* Sthn Sapila: 
  * antonakd@sapila:~/twitter-spam$ svn checkout  https://139.91.90.202/svn/twitter-spam/ --username antonakd@gmail.com
    * TTENTION!  Your password for authentication realm:

   <https://139.91.90.202:443> DCS Subversion Repository

  can only be stored to disk unencrypted!  You are advised to configure
 your system so that Subversion can store passwords encrypted, if 
possible.  See the documentation for details.
 * python twitter.py --get_daily_trends --output  trends_18_April_2013.txt 
 * python twitter.py --trend_filename trends_18_April_2013.txt --wait


Apopeira na trexei to scriptaki . Problhma me auth & wra tou mhxanhmatos : http://www.blainegarrett.com/2009/07/14/failed-to-validate-oauth-signature-and-token-on-twitter-oauth-check-your-cloc/

Έκανα μια πρώτη απόπειρα να το ξεκινήσω χτες το πρωί αλλά είχα ένα failure λόγω της ώρας του μηχανληματος και oauth signature  (http://www.blainegarrett.com/2009/07/14/failed-to-validate-oauth-signature-and-token-on-twitter-oauth-check-your-cloc/) οπότε άλλαξα την ώρα στο μηχάνημα (εύχομαι να μην δημιουργεί προβλήματα!) 

Τελικά μετά από διάφορα error handling προσθήκες, έτρεχε από χτες το βραδύ 2013-04-18 20:55:51
 μέχρι και τις 09:47 σήμερα. Τα tweets συλλέγονται στο DATA/tweets_18_April_2013.txt και είναι 2.4G για μία μέρα.  (Θα κοιτάξω να αποθηκεύω σε zip για εξοικονόμηση χώρου. )



### 17 April
* ssh sthn sapila monon apo to wifi tou gcc  : 
* ssh -p 6969 antonakd@139.91.70.64
* Egkatastash python : 
  * sudo apt-get install python    :sudo apt-get install python2.7
Reading package lists... Done
Building dependency tree       
Reading state information... Done
E: Couldn't find package python2.7
 opote to googlaroume kai http://eli.thegreenplace.net/2011/10/10/installing-python-2-7-on-ubuntu/
  *  sudo apt-get install libreadline-dev
  *  sudo apt-get install libsqlite3-dev
  *  sudo apt-get install libbz2-dev
  *  sudo apt-get install libssl-dev
* eprepe na exoume hdh kanei sudo apt-get upgrade : 1,411kB/s 4min 57s
* mkdir tools , antonakd@sapila:~$ cd tools
* PYTHON installation :
  * wget http://www.python.org/ftp/python/2.7.4/Python-2.7.4.tgz
  * tar zxvf Python-2.7.4.tgz 
  * cd python
  * ./configure 
  * make
  * sudo make install
  * python  me paei sthn palia ekdosh !!!
Python 2.6.5 (r265:79063, Apr 16 2010, 13:09:56) 
ls -l  /usr/local/bin/py*
ls -l  /usr/local/bin/py*
-rwxr-xr-x 1 root root      84 2013-04-17 23:08 /usr/local/bin/pydoc
lrwxrwxrwx 1 root root       7 2013-04-17 23:11 /usr/local/bin/python -> python2
lrwxrwxrwx 1 root root       9 2013-04-17 23:11 /usr/local/bin/python2 -> python2.7
-rwxr-xr-x 1 root root 4392477 2013-04-17 23:10 /usr/local/bin/python2.7
-rwxr-xr-x 1 root root    1674 2013-04-17 23:11 /usr/local/bin/python2.7-config
lrwxrwxrwx 1 root root      16 2013-04-17 23:11 /usr/local/bin/python2-config -> python2.7-config
lrwxrwxrwx 1 root root      14 2013-04-17 23:11 /usr/local/bin/python-config -> python2-config
  * python2
Python 2.7.4 (default, Apr 17 2013, 23:07:53) 
[GCC 4.4.3] on linux2
  * logout-login : 
  * python
Python 2.7.4 (default, Apr 17 2013, 23:07:53) 
[GCC 4.4.3] on linux2

  * theloume oath2 : 
pip
Usage: pip COMMAND [OPTIONS]

pip: error: You must give a command (use "pip help" see a list of commands)
antonakd@sapila:~$ 
  * sudo pip install oauth2
  *  enw fainetai na to kanei epituxhmena, otan kaneis import sthn python den paizei, opote : 
  *  cd ~/tools/
  *  wget https://pypi.python.org/packages/2.7/s/setuptools/setuptools-0.6c11-py2.7.egg#md5=fe1f997bc722265116870bc7919059ea
  *  sudo sh setuptools-0.6c11-py2.7.egg 
  *  sudo easy_install-2.7 pip
  *  sudo pip-2.7 install oauth2

  * Epishs ekana ta e3hs pou isws na mhn xreiazontan:
  * Ekana edit auto: /usr/share/python/debian_defaults
  * sudo rm /usr/bin/python ; sudo ln -s /usr/local/bin/python2.7 /usr/bin/python2.7; sudo ln -s /usr/bin/python2.7 /usr/bin/python
  * sudo mkdir /etc/python2.7; sudo cp /etc/python2.6/* /etc/python2.7



### 12 April 2013 

Skype teleconference: Vivi, Sotiris, Despoina: parousiash toy paper   Privacy-Preserving Enhanced Collaborative Tagging. 
https://docs.google.com/presentation/d/1Yupui8AA7bbYdBPTi3fziHhgTM0yXcDqcsAOqsb1YjQ/edit

epomenh evdomada 8a doume to HummingBird. 

Gia to twitter-spam : 

* Egkatesthsa to homebrew gia kalutero paketo svn ap;'to default tou mac (protash tou mstamat) : 
  *  Akolou8hsa odhgies http://ascarter.net/2010/02/22/homebrew-for-os-x.html 
  *   eutuxws kanenan conflict me mac ports
  *   ekgatastash paketwn se homebrew : 
     *   sudo brew  install subversion
     *   sudo brew  install python
     *   Egkatastash pip oauth2: sudo /opt/homebrew/bin/pip install oauth2 
* First commit sto svn : https://139.91.90.202/svn/twitter-spam/ : 
 * /opt/homebrew/bin/svn  co https://139.91.90.202/svn/twitter-spam/ --username antonakd@gmail.com
 * /opt/homebrew/bin/svn add twitter.py 
 * /opt/homebrew/bin/svn commit -m "Second version of twitter spam implementation in python" 
 


### 21 March 2013
* https://mail.google.com/mail/?ui=2&shva=1#inbox/13d6d9bca662fd69
* Epishs, an thymamai kala tha prepei na peraseis kapoia diasthmata (3 months) sto university of insubria, Italy, kai University of Barcelona.
Kalo einai na doyme ti kanoyn apo episthmonikhs pleyras oi ekei partners mas ekei kai na doyme pws mporoyme na synergastoyme. Opote isws stis epomenes
synanthseis na doyme prosfata papers tvn Elena Ferrari (Univ. Insubria) kai Marian Boguna (Univ. Barcelona). H prvth doyleyei se privacy models
kai o deyteros se complex systems.

### 21 Μαρτιου 2013
* paroysiash toy "Privacy-Preserving Social Plugins": Georgios Kontaxis, Michalis Polychronakis, and Angelos D. Keromytis, Columbia University; Evangelos P. Markatos, FORTH-ICS
  * giati to logarithmiko grafima twn data sto datastore sunarthsh toy plh8ous xrhstwn auxanetai ek8etika; 
* Tha arxisoume siga siga na koitazoume thn douleia pou kanoun sto ergasthrio, ua steilei sxetiko mail o polakis entos twn hmerwn 
* Gia ta epomena paper mporoume na doume kapoia twn sunergatwn mas apo Insubria univarsity (Elena Ferrari): 
  * J. Parra-Arnau, A. Perego, E. Ferrari, J. Fornè and D.

    Rebollo-Monedero. Privacy-Preserving Enhanced Collaborative Tagging.
    IEEE TKDE, to appear.:
    http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6399467
    
  * A Multi-layer Framework for Personalized Social Tag-based

    Applications. Data & Knowledge Engineering
    :http://www.sciencedirect.com/science/article/pii/S0169023X12000614September 2010,
    Volume 13, Issue 3, pp 215-249


  * A General Framework for Web Content Filtering http://link.springer.com/article/10.1007%2Fs11280-009-0073-5
* To workshop gia to Septembrio einai mia mera sthn barcelonh kai kalo tha htan na summetexw
* Gia ta grafeiotratika (eggrafa apo mail ths Vivis) den xreiazetai na ginei kati amesa, apla se genikes grammes na xerw tis upoxrewseis mou, 
me kurioteres ta minaiaia questionaires, reports. Tha prepei an ginei registration se kapoia site to isocial, apo Septembrio. Oi sunergasies
(triminiaies episkeyeis den einai akrivws ka8orismenes, alla einai eueliktes sthn hmeromhnia) .

###19 March 2013
* Μετα απο αναγνωση του  316808 - iSocial Annex 1 Final
εχω κανει highlight τα σημεία που μασ αφορουν . Στην σελίδα 36  αναφέρονται συγκεκριμένα πο μήνες που θα γίνει η επισκεψη σε αλλα ιδρύματα. 
Συγκεκριμένα: 22,23 24: Οκτωβριος, Νοεμβριος, Δεκέμβριος(2ου ετους), & Οκτωβριος, Νοεμβριος, Δεκέμβριος(3ου ετους)   

### 19 March 2013
* https://mail.google.com/mail/?ui=2&shva=1#inbox/13d6d9bca662fd69
* FORTH candidate 
* mail με όλες τις γραφειοκρατικές λεπτομέρειες και τη περιγραφή του projecy
* Vivi: Despoina, to parakatw email mas to esteile h project officer. Leei gia kapoia pragmata ta opoia prepei na eisai enhmerh, diavase to
prosektika (opws kai ta attachments) kai den ti rights and obligations exeis sto plaisio toy ergoy, kai to syzhtame thn erxomenh evdomada.
* Από το mail: formal requirements: submit an abstract and prepare a poster presentation by the end of his/her first year of study, to submit a paper to a high-quality peer-reviewed conference by the end of the second year, to present his/her early results in a workshop by the end of the second year, to give an open presentation of results at the iSocial conference and to submit a paper to a peer-reviewed journal by the end of the third year.
* " participants will be required to write a grant proposal and in the second a sales pitch for a venture capital firm...". The most promising ideas will be encouraged and supported to pursue commercialization through start-up establishment channels
* ...Data Placement, Replication, Distribution and Streaming Services (WP2). Project title Supervisor name: Evangelos Markatos/FORTH, co-supervisor: Seif Haridi/KTH. PhD enrolment: Yes (University of Crete) edw einai o markatos
* Objectives: ESR5 will develop a suite of data placement, replication and appropriate data distribution services for the DOSN infrastructure. Personal career development plan (M11) Outreach activities4 scientific publications in conferences and journals (M9-M43) / Phd thesis (M43) After-project career (M43)
* Tasks and methodology: 
    * To develop novel decentralized data placement, replication and distribution services. During this task, different methods will be examined, to perform data placement, replication and distribution exploiting the trust relations of social networks. ESR5 will use tools developed by the complex networks community (such as SNAP http://snap.stanford.edu/) to dynamically reveal the communities of trust developed around individual peers along with their temporal and behavioural patterns. An XML model with RDF annotations will be investigated to efficiently store data. Finally, ESR5 will investigate efficient media streaming techniques to support social services and applications, especially in collaboration with the industrial partners
    * To validate the developed methods and to integrate them in the iSocial network infrastruct
* Dissemination: Research activities plan: At least 4 scientific publications as well as submitting a thesis for a Ph.D. degree.
* xmm : "..The number of succeeding employment contracts for a fixed term is limited to three. " http://www.expatica.com/nl/employment/employment_information/Dutch-contracts-and-employment-law_13534.html

###14 Μαρτίου
Παρουσίαση του  http://www.internetsociety.org/towards-online-spam-filtering-social-networks
 δεν το καλύψαμε πλήρως σε ολοες τισ διαφάνειες αλλα επικεντρώσαμε στα κυριότερα σημεία . Καποιες ενδιαφερον ερωτήσεις:
 1. Για το parallelization η διαφάνεια δεν περιεγραφε με πολυ καλο τροπο το προβλημα . Καταλαβαν κατι λάθος αλλα ισως  να ενοουσαν 
 αυτο που  τελικά ελεγε και στο πειπερ το ποιο και εξήγησα. 
 2. Πιο ειναι το πιο σημαντικα απο τα evaluation metrics(?) απαντησα το accuracy  kai μαλλον επρεπε να πω το runtime performance ή εστω το 
 accuracy over time . 

Για το συμβόλαιο η Βιβί θα προσπαθήσει να κινήσει τις διαδικασίες απο τον επόμενο μήνα . 
Αναφερθήκαμε σε καποιες τριμηνιαιες αναφορές που θα πρέπει ν συμπληρώνουμε 

###7 Μαρτίου 2013
παρουσίαση του  blacr : http://www.internetsociety.org/blacr-ttp-free-blacklistable-anonymous-credentials-reputation. Δεν υπαρχαν πολλές απορίες ουτε αλλες εξελιξεις

##21 Feb 2013 
Ο χρόνος εφτασε μονο για την παρουσίαση του πρώτου  paper . 

1. Τι θα πρέπει να παραδοθεί στο τέλος. Αναφορά; Thesis? Manuscript? paper ? posa? se journal 
Αυτά καθορίζομνται απο το τμήμα οποτε μαλλον : 
* καταθεση  thesis 
* επικουρίες σε μαθήματα 
* quailifiers που θα πρέπει να περάσω το δευτερο έτος 
* παρακολούθηση μαθημάτων   
* Δεδομένης της ποιότητας της δουλεία ειναι σχεδόν βεβαιο οτι θα βγουν αρκετες δημοσιευσεις . Επιπλέον θα υπάρξει αρκετή κινητικότητα 
για την προωθηση συνεργασίεών / . Σαν  πρωτή  μετακίνησ ενδεχομενωσ τον  Σεπτέμβριο 16-20 satelite event στην  Βαρκελώνη κεώνη 
2. Ποιος είναι επίσημα ο supervisor? Ο ποιο  πιθανό υποψήφιος ειναι Β.Μαρκάτος 
3. Μπορέι να γίνει κποιου ειδουε επισημοποιησΗ  εισήγηση για το συμβόλαιο θα γίνει Ιουνιο . 
3. Μπορούν να καλυφθούν έξοδα μετακόμισης;
4. Για υλοποιηση καποιου συστηματος , υπαρχει ηδη κατι , θα υλοποιηθει κατι απο την αρχη ; python; 

## 18 Feb 2013
Γεια σου Γρηγόρη, για να σε συστήσει ο Κώστας περιμένω απλώς τον καλύτερο!  

Που λες,  
μόλις ξεκίνησα να ασχολούμε με κάποια θέματα κρυπτογραφίας και διαβάζω κάποια papers. Σύντομα κατάλαβα ότι πρέπει να αποκτήσω κάποιες βασικές μαθηματικές γνώσεις πριν προχωρήσω.  

Τα papers που διαβάζω θίγουν συχνά τα παρακάτω θέματα:

* Discrete logarithms http://en.wikipedia.org/wiki/Discrete_logarithm
* DDH: Decisional Diffie–Hellman assumption http://en.wikipedia.org/wiki/Decisional_Diffie%E2%80%93Hellman_assumption
* PBC : Pairing-based cryptography. http://en.wikipedia.org/wiki/Pairing-based_cryptography
* Pedersen commitment. http://en.wikipedia.org/wiki/Commitment_scheme
* Zero-knowledge proof. http://en.wikipedia.org/wiki/Zero-knowledge_proof
* Random oracle: http://en.wikipedia.org/wiki/Random_oracle

Το μοναδικό που ζητάω από εσένα είναι αν ξέρεις να μου συστήσεις κάποιες καλές πηγές (κυρίως βιβλία, αν υπάρχουν και online ακόμα καλύτερα) εισαγωγικές για τον über-άσχετο τα οποία να συζητούν (και) τα παραπάνω θέματα. Έχω καλό background από αλγόριθμους και προγραμματισμό.

Σε ευχαριστώ πολύ

## 12 Feb 2013
From Sotiris:
Despoina,

mporeis na jekinhseis apo ayta ta papers. Epeishs prepei na organvsoyme ebdomadiaia telcos gia na doyme poy badizoyme.

Xairetv,
&si

* NDSS 12:
    * https://www.internetsociety.org/you-are-what-you-information-leakage-through-users-interests
    * http://www.internetsociety.org/towards-online-spam-filtering-social-networks
    * http://www.internetsociety.org/blacr-ttp-free-blacklistable-anonymous-credentials-reputation

* Usenix security 12:
    * https://www.usenix.org/conference/usenixsecurity12/privacy-preserving-social-plugins

* Security and Privacy 12:
    * Hummingbird: Privacy at the time of Twitter - http://eprint.iacr.org/2011/640.pdf

* ACSAC 12:
    * All Your Face Are Belong to Us: Breaking Facebook's Social Authentication. - http://www.ics.forth.gr/~polakis/papers/polakis_acsac12.pdf

### From Polakis
Ta kuriotera sunedria tou xwrou einai ta ekshs:
* Security and Privacy, http://www.ieee-security.org/TC/SP-Index.html Follow @ciphernews
* Usenix Security, http://www.usenix.org Follow @usenix
* CCS, http://www.sigsac.org/ccs/CCS2013/
* NDSS, http://www.internetsociety.org Follow @internetsociety
* ACSAC, http://www.acsac.org/ @ACSAC_Conf
* RAID, http://www.raid-symposium.org/ 

Oson afora periodika, uparxoun ta
* Security 
* Privacy Magazine,  Follow @securityprivacy
* Usenix login https://www.usenix.org/publications/login

ktlp alla genika kalutera na diavazeis ta paper pou vgainoun se sunedria.
      

mpardounas%%1234*
